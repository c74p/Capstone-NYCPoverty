{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "As a refresher:\n",
    "* Data from https://data.cityofnewyork.us/browse?q=poverty\n",
    "* 12 annual data files, from 2005 to 2016 inclusive (e.g. NYCgov_Poverty_MeasureData__2016.csv)\n",
    "* CSV files with ~80 columns and ~60,000 rows each\n",
    "* Each file had essentially the same format and contained (mostly) the same information\n",
    "* Data types included:\n",
    "    * Classification types encoded as integers (e.g. 1 if in poverty, 2 if not in poverty)\n",
    "    * Floats for financial data (e.g. wages for the calendar year)\n",
    "\n",
    "I'll import a cleaned version of the files (see https://github.com/c74p/Springboard/blob/master/Capstone%20Project%201%20-%20Poverty/DataWranglingSummary.ipynb) for details.\n",
    "\n",
    "### Modeling approach\n",
    "\n",
    "The poverty rate overall in New York City is roughly 20%, and there are lots of imbalanced groups (education, income, \n",
    "disability status, etc.).  I'll use imbalanced test-train splits to improve my model.\n",
    "\n",
    "Overview of modeling approach:\n",
    "1. Use all years, households only, classify yes/no for poverty. Test and compare Logistic Regression, Support Vector \n",
    "Machines (SVM), and Random Forest algorithms.\n",
    "2. Run classifiers for individual years (the thresholds differ from year to year, so a predictor for a specific year would presumably be better for a specific year).\n",
    "3. Test running regressors on houshold income and poverty threshold, in order to predict poverty classification. Test and\n",
    "compare Linear Regression (Ordinary Least Squares), Stochastic Gradient Descent, and ElasticNet.\n",
    "    a. This is not likely to be useful, but I'm doing it as a learning exercise.\n",
    "4. Test steps 2 and 3 above at the person level, rather than at the household level.\n",
    "    a. This is not likely to be useful, but I'm doing it as a learning exercise.\n",
    "\n",
    "### Housekeeping part 1: imports and file prep\n",
    "\n",
    "After importing we'll make some quick modifications to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and setup\n",
    "# See below for model-specific imports\n",
    "from __future__ import print_function\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import seaborn as sns\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "# Model-specific imports\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, RUSBoostClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, \\\n",
    "    RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit, LogitResults\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Temporarily turn off warnings if they get to be too much\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_years.csv', index_col=0)\n",
    "\n",
    "# Group the columns into 1) raw input variables, 2) id variables of various things, 3) American Community Survey (census)\n",
    "# variables, 4) NYC government-calculated variables, and 5) output variables.\n",
    "#\n",
    "# The ACS and NYC variables are generally calculated from the raw input variables - my initial expectation is that\n",
    "# the raw input variables can be thought of as independent variables, and that the ACS and NYC variables are not\n",
    "# independent even though they are not output variables.\n",
    "\n",
    "raw_inp_vars = ['AGEP', 'Boro', 'CIT', 'DIS', 'ENG', 'ESR', 'Ethnicity', 'HHT', 'HIUnit_Head', 'HousingStatus', 'JWTR', 'LANX', 'MAR', 'MSP','NP', 'Off_Threshold', 'PreTaxIncome_PU', 'REL', 'SCH', 'SCHG', 'SCHL', 'SEX', 'TEN', 'WKHP', 'WKW', 'Year']\n",
    "id_vars = ['HIUnit_ID', 'Povunit_ID', 'PWGTP', 'SERIALNO', 'SNAPUnit_ID', 'SPORDER', 'TaxUnit_ID', 'WGTP']\n",
    "acs_vars = ['AgeCateg', 'INTP_adj', 'OI_adj', 'MRGP_adj', 'PA_adj', 'RETP_adj', 'RNTP_adj', 'SEMP_adj', 'SSIP_adj', 'SSP_adj',  'WAGP_adj']\n",
    "nyc_vars = ['CitizenStatus',  'EducAttain', 'FTPTWork', 'FamType_PU', 'NYCgov_Childcare', 'NYCgov_Commuting', 'NYCgov_EITC', 'NYCgov_FICAtax', 'NYCgov_HEAP', 'NYCgov_Housing', 'NYCgov_Income', 'NYCgov_IncomeTax', 'NYCgov_MOOP', 'NYCgov_MedPremiums', 'NYCgov_MedSpending', 'NYCgov_Nutrition', 'NYCgov_REL', 'NYCgov_SFN', 'NYCgov_SFR', 'NYCgov_SNAP', 'NYCgov_SchoolBreakfast', 'NYCgov_SchoolLunch', 'NYCgov_Threshold', 'NYCgov_WIC', 'Povunit_Rel', 'SNAPUnit_Rel',  'TaxUnit_FILER', 'TaxUnit_FILESTAT', 'TaxUnit_FILETYPE', 'TaxUnit_Rel', 'TotalWorkHrs_PU']\n",
    "output_vars = ['NYCgov_PovGap', 'NYCgov_Pov_Stat', 'NYCgov_PovGapIndex', 'Off_Pov_Stat']\n",
    "all_columns = raw_inp_vars + id_vars + acs_vars + nyc_vars + output_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create codes for the raw input variables that are number-coded, so we can create charts that make sense\n",
    "raw_codes = {'Boro': {1: 'Bronx', 2: 'Brooklyn', 3: 'Manhattan', 4: 'Queens', 5: 'Staten Island'},\n",
    "         'CIT': {1: 'Birth', 2: 'Territories', 3: 'US Parents', 4: 'Naturalized', 5: 'No'},\n",
    "         'DIS': {0: 'NA', 1: 'Yes', 2: 'No'},\n",
    "         'ENG': {0: '<5', 1: 'Very Well', 2: 'Well', 3: 'Not well', 4: 'Not at all', 5: 'Only Eng'},\n",
    "         'ESR': {0: '<16', 1: 'EMP', 2:'EMP/NAW', 3: 'UNEMP', 4: 'AF', 5: 'AF/NAW', 6:'NILF'},\n",
    "         'Ethnicity': {1: 'White', 2: 'Black', 3: 'Asian', 4: 'Hispanic', 5: 'Other'},\n",
    "         'HHT': {0: 'NA', 1: 'MAR', 2: 'MNW', 3: 'WNM', 4: 'Malone', 5: 'MNAlone', 6: 'Walone', 7: 'WNalone'},\n",
    "         'HIUnit_Head': {0: 'Not Head', 1: 'Head', 2: 'Not Head'},\n",
    "         'HousingStatus': {0: 'NA', 1: 'Public', 2: 'Mitchell', 3: 'Subsidy', 4: 'Regulated', 5: 'OtherReg', 6: 'MarketRate', 7: 'NoCash', 8: 'OwnF&C', 9: 'Own-Mortgage'},\n",
    "         'JWTR': {0: 'NA', 1: 'Car', 2: 'Bus', 3:'Streetcar', 4:'Subway', 5:'RR', 6:'Ferry', 7:'Taxi', 8:'Motorcycle', 9:'Bike', 10:'Walk', 11:'Home', 12: 'Other'},\n",
    "         'LANX': {0: 'NA', 1: 'Yes', 2: 'Only Eng'},\n",
    "         'MAR': {1: 'Married', 2:'Widowed', 3:'Divorced', 4:'Separated', 5:'Never Married'},\n",
    "         'MSP': {0: 'NA', 1: 'Yes', 2:'Spouse absent', 3:'Widowed', 4:'Divorced', 5:'Separated', 6:'Never Married'},\n",
    "         'REL': {0: 'Self', 1:'Spouse', 2:'Child', 3:'Adopted', 4:'Stepchild', 5:'Sibling', 6:'Parent', 7:'Grandchild', 8:'Parent-in-law', 9:'Child-in-law', 10:'Other', 11:'Boarder', 12:'Roommate', 13:'Partner', 14:'Foster', 15:'OtherNR', 16:'Inst', 17:'NonInst'},\n",
    "         'SCH': {0: 'NA', 1: 'NoPast3Mos', 2:'Public', 3:'Private/Home'},\n",
    "         'SCHG': {0: 'NA', 1:'Preschool', 2:'Kindergarten', 3:'1', 4:'2', 5:'3', 6:'4', 7:'5', 8:'6', 9:'7', 10:'8', 11:'9', 12:'10', 13:'11', 14:'12', 15:'College', 16:'Grad school'},\n",
    "         'SCHL': {0: 'NA', 1:'None', 2:'Preschool', 3:'Kindergarten', 4:'1', 5:'2', 6:'3', 7:'4', 8:'5', 9:'6', 10:'7', 11:'8', 12:'9', 13:'10', 14:'11', 15:'12-NoDip', 16:'Diploma', 17:'GED', 18:'<1yrCollege', 19:'CollNoDegree', 20:'Associates', 21:'Bachelors', 22:'Masters', 23:'Professional', 24:'Doctorate'},\n",
    "         'SEX': {1:'Male', 2:'Female'},\n",
    "         'TEN': {0: 'NA', 1:'Mortage', 2:'Free&Clear', 3:'Rent', 4:'OccButNoRent'},\n",
    "         'WKW': {0:'NA', 1:'50-52', 2:'48-49', 3:'40-47', 4:'27-39', 5:'14-26', 6:'<13'},\n",
    "        }\n",
    "\n",
    "# Create codes for the nyc variables that are number-coded, so we can create charts that make sense\n",
    "nyc_codes = {\n",
    "    'CitizenStatus': {1: 'Birth', 2: 'Naturalized', 3: 'No'},\n",
    "    'EducAttain': {0: 'NA', 1:'<HS', 2:'HS', 3:'SomeCollege', 4:'Bachelors+'},\n",
    "    'FTPTWork': {1:'FTYR', 2:'<FTYR', 3:'None'},\n",
    "    'FamType_PU': {1:'Family', 2:'Couple', 3:'M+kid', 4:'W+kid', 5:'Mnokid', 6:'Wnokid', 7:'Unrelated', 8:'UnrelAlone'},\n",
    "    'NYCgov_REL': {0:'Self', 1:'Spouse', 2:'Child', 3:'Sibling', 4:'Parent', 5:'Grandkid', 6:'Inlaw', 7:'OtherRel', 8:'Boarder', 9:'Roommate', 10:'Partner', 11:'FosterKid', 12:'OtherNonRel'},\n",
    "    'NYCgov_SFR': {0: 'NA', 1:'NoKids', 2:'Kids', 3:'OneParent', 4:'Kid', 5:'Kid-Monly', 6:'Kid-Wonly'},\n",
    "    'Povunit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other'},\n",
    "    'SNAPUnit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other'},\n",
    "    'TaxUnit_FILER': {1:'Filer', 0:'Non-Filer'},\n",
    "    'TaxUnit_FILESTAT': {0: 'NA', 1:'Joint', 2:'HH', 3:'MFS', 4:'Single'},\n",
    "    'TaxUnit_FILETYPE': {0: 'NA', 1: 'Normal', 2:'Dependent', 3:'BelowThresh'},\n",
    "    'TaxUnit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other', 5:'EIC', 6:'Relative'},\n",
    "    'TotalWorkHrs_PU': {1:'3500+', 2:'2340-3500', 3:'1750-2340', 4:'<1750', 5:'None'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key dataframes of interest\n",
    "# All 2016 data\n",
    "all_2016 = df[df.Year == 2016]\n",
    "\n",
    "# Our data set contains two sets of weights: household weights and person weights.  \n",
    "# We need to separate out each column by whether it should be weighted as a household variable or a person variable.\n",
    "# Lists to create weighted columns, separated based on whether they are personal or household statistics.\n",
    "personal_vars = ['AGEP', 'Boro', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'ENG', 'LANX', 'MSP', 'MAR', 'NYCgov_EITC', 'WKW', 'WKHP', 'DIS', 'JWTR', 'WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj', 'TaxUnit_Rel', 'NYCgov_REL', 'NYCgov_SFR', 'SNAPUnit_Rel', 'TaxUnit_FILER', 'TaxUnit_FILESTAT', 'TaxUnit_FILETYPE', 'Ethnicity', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork', 'PWGTP'] \n",
    "pu_vars = ['MRGP_adj', 'RNTP_adj', 'NP', 'TEN', 'HHT', 'FamType_PU', 'HousingStatus', 'TotalWorkHrs_PU', 'PreTaxIncome_PU', 'NYCgov_Income', 'NYCgov_Threshold', 'NYCgov_Pov_Stat',  'NYCgov_Housing', 'NYCgov_Childcare', 'NYCgov_Commuting', 'NYCgov_MOOP', 'NYCgov_MedSpending', 'NYCgov_MedPremiums', 'NYCgov_HEAP', 'NYCgov_WIC', 'NYCgov_SNAP', 'NYCgov_SchoolLunch', 'NYCgov_SchoolBreakfast', 'NYCgov_Nutrition', 'NYCgov_FICAtax', 'NYCgov_IncomeTax', 'Off_Threshold', 'Off_Pov_Stat', 'NYCgov_PovGap', 'NYCgov_PovGapIndex', 'WGTP']\n",
    "other_vars = ['HIUnit_Head', 'HIUnit_ID', 'NYCgov_SFN', 'Povunit_ID', 'Povunit_Rel', 'REL', 'SERIALNO', 'SNAPUnit_ID', 'SPORDER', 'TaxUnit_ID', 'Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Adding New Poverty-Unit Variables Based on Personal Variables\n",
    "Here's where we're actually adding new variables based on old variables.\n",
    "\n",
    "From the personal-level features, we'll create new household-level features (e.g. number of kids, mean salary among \n",
    "adults, count of people making more than $30k, count of adults working between 14-26 hours/week, minimum salary among\n",
    "adults working more than 26 hours/week, etc.)\n",
    "\n",
    "This is a wall of text, not much exciting narrative here.\n",
    "\n",
    "(Note on programming style/choices: the first function 'add_pu_columns' below is a real function, although it has a\n",
    "kludge in case one of the summary calculations fails. (That happens rarely, but it's still a code smell.)\n",
    "\n",
    "The second function, however, is not really a 'real' function; it's heavily hand-coded and relies on custom choices of\n",
    "various groupings.  It was put into a function solely to comply with the DRY principle - in particular, this function\n",
    "will typically be run twice (once for the whole grouping, and possibly once for a model run without the 'financial' \n",
    "features).  By putting it into a function for DRY purposes, we at least avoid accidentally running different code when we \n",
    "mean to run the same code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with CIT\n",
      "took 64.48582053184509 s so far\n",
      "done with SCHL\n",
      "took 134.63068413734436 s so far\n",
      "done with SEX\n",
      "took 178.26997876167297 s so far\n",
      "done with ENG\n",
      "took 270.48538613319397 s so far\n",
      "done with MSP\n",
      "took 351.7556619644165 s so far\n",
      "done with WKW\n",
      "took 527.8056879043579 s so far\n",
      "done with WKHP\n",
      "took 721.531191110611 s so far\n",
      "done with DIS\n",
      "took 781.8973388671875 s so far\n",
      "done with NP\n",
      "took 1017.774843454361 s so far\n",
      "done with JWTR\n",
      "took 1037.0357296466827 s so far\n",
      "done with WAGP\n",
      "took 1372.6890752315521 s so far\n",
      "done with INTP\n",
      "took 1524.2630858421326 s so far\n",
      "done with SEMP\n",
      "took 1681.711932182312 s so far\n",
      "done with SSP\n",
      "took 1845.299048423767 s so far\n",
      "done with SSIP\n",
      "took 1985.9200677871704 s so far\n",
      "done with PA\n",
      "took 2101.1818034648895 s so far\n",
      "done with RETP\n",
      "took 2227.952205657959 s so far\n",
      "done with OI\n",
      "took 2348.0948402881622 s so far\n",
      "done with Ethnicity\n",
      "took 2535.209809064865 s so far\n",
      "took 2999.9464485645294 s\n"
     ]
    }
   ],
   "source": [
    "def add_pu_columns(df, groups, group_names, categories, category_names, column):\n",
    "    \"\"\"\n",
    "    Adds columns to dataframe 'df' containing calculations by poverty-unit, restricted by categories, considering groups.\n",
    "    Calculations include any(), all(), min(), max(), count(), sum(), mean(), and % in given category.\n",
    "    Input: a dataframe with multi-index consisting of 'SERIALNO', 'Povunit_ID', and 'SPORDER'; a set of masks and list of\n",
    "    names for the groups; a set of masks and a list of names for the categories; and the column of interest.\n",
    "    Output: no return value.  Inserts a series of columns into the dataframe including min, max, count, sum, any, all,\n",
    "    % of total, and mean - within households, focusing on the groups and categories of interest. \n",
    "    \"\"\"\n",
    "    \n",
    "    for group, group_name in zip(groups, group_names):\n",
    "        for category, category_name in zip(categories, category_names):\n",
    "            stacked = df[column][group & category].stack().groupby(['SERIALNO', 'Povunit_ID'])\n",
    "            anys = stacked.any()\n",
    "            # would love to use .all() here, but it would always be True because we filtered out everyone else\n",
    "            mins = stacked.min()\n",
    "            maxes = stacked.max()\n",
    "            counts = stacked.count()\n",
    "            sums = stacked.sum()\n",
    "            means = sums/counts\n",
    "            # The divisor below only restricts by 'groups' - so the final calculation is within a household, within\n",
    "            # the group of interest (e.g. adults), what % is in the category of interest (e.g. works 40 hrs/week)\n",
    "            divisor_for_percents = df[column][group].stack().groupby(['SERIALNO', 'Povunit_ID']).count()\n",
    "            try:\n",
    "                percents = counts.div(divisor_for_percents, axis=0)\n",
    "                alls = percents == 1\n",
    "            except: # if the calculation failed, leave percents and alls as a column of zeros\n",
    "                df_len = len(df.groupby(['SERIALNO', 'Povunit_ID']).sum())\n",
    "                percents = np.zeros(df_len)\n",
    "                alls = np.zeros(df_len)\n",
    "            \n",
    "            # loop through, put in the dataframe, and fill in NAs of appropriate type\n",
    "            series_and_names = zip([anys, alls, mins, maxes, counts, sums, means, percents], \n",
    "                                  ['any', 'all', 'min', 'max', 'count', 'sum', 'mean', '%'])\n",
    "            for series, series_name in series_and_names:\n",
    "                column_title = series_name + '_' + group_name + '_' + category_name\n",
    "                df[column_title] = series\n",
    "                if series_name in ['any', 'all']:\n",
    "                    df[column_title] = df[column_title].fillna(False)\n",
    "                else:\n",
    "                    df[column_title] = df[column_title].fillna(0)\n",
    "                    \n",
    "def engineer_features(df, include_financials=True):\n",
    "    \"\"\"Create features for the dataframe. This function is heavily custom and was solely created for DRY-ness.\n",
    "    Input: a poverty dataframe and whether or not to include financial features.\n",
    "    Output: returns a copy of the dataframe summarized by poverty-unit, with *only* the new features included. \n",
    "    Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "\n",
    "    # Create dataframe to house new features \n",
    "    dfc = df.copy() # read as 'X new features'\n",
    "\n",
    "    # Count the original # of features - later we'll just slice out the new features\n",
    "    # Keep in mind that 'SERIALNO' and 'Povunit_ID' will go into the index, so we need to subtract 2 columns\n",
    "    features_to_mask = len(dfc.columns) - 2\n",
    "    \n",
    "    # This is the largest # of people in a household; when we group the columns below, for each existing feature we'll\n",
    "    # create one column for each person in a household - so we'll need to know this number at the end when we want to \n",
    "    # mask our existing features\n",
    "    max_ppl = dfc.SPORDER.max()\n",
    "\n",
    "    # First, some categoricals have odd ordering; remap them\n",
    "    fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "                  'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "    dfc['ENG'] = dfc['ENG'].map(fix_orders['ENG'])\n",
    "    dfc['WKW'] = dfc['WKW'].map(fix_orders['WKW'])\n",
    "    dfc['TotalWorkHrs_PU'] = dfc['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "    # Add column for total personal income\n",
    "    if include_financials:\n",
    "        dfc['TINP'] = dfc.WAGP_adj + dfc.INTP_adj + dfc.SEMP_adj + dfc.SSP_adj + dfc.SSIP_adj + \\\n",
    "                        dfc.PA_adj + dfc.RETP_adj + dfc.OI_adj\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    dfc = dfc.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Create masks for age groups to use in creating new features\n",
    "    mask_adult = (dfc.AgeCateg == 2) | (dfc.AgeCateg == 3)\n",
    "    mask_65_plus = dfc.AgeCateg == 3\n",
    "    mask_18_64 = dfc.AgeCateg == 2\n",
    "    mask_kid = dfc.AgeCateg == 1\n",
    "    mask_any_age = dfc.AgeCateg != 0\n",
    "    mask_any = mask_any_age\n",
    "\n",
    "    # add columns with age only, no categories\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "    add_pu_columns(dfc, groups, group_names, [mask_any_age], ['age'], 'AGEP')\n",
    "\n",
    "    # add columns for CIT\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_non_cit = dfc.CIT == 5\n",
    "    mask_cit = (dfc.CIT != 5) & (dfc.CIT != 0)\n",
    "    mask_naturalized = dfc.CIT == 4\n",
    "\n",
    "    categories = [mask_non_cit, mask_cit, mask_naturalized, mask_any]\n",
    "    category_names = ['non-cit', 'citizen', 'naturalized_cit', 'any_CIT']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'CIT')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with CIT')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for SCHL\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_college_degree = (dfc.SCHL >= 21)\n",
    "    mask_HS_diploma = (dfc.SCHL >= 17)\n",
    "    mask_no_diploma = (dfc.SCHL <= 16)\n",
    "\n",
    "    categories = [mask_college_degree, mask_HS_diploma, mask_no_diploma, mask_HS_diploma & ~mask_college_degree, mask_any]\n",
    "    category_names = ['college', 'HS', 'no_diploma', 'diploma_no_bachelors', 'any_SCHL']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'SCHL')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SCHL')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for SEX\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_male = dfc.SEX == 1\n",
    "    mask_female = dfc.SEX == 2\n",
    "\n",
    "    categories = [mask_male, mask_female, mask_any]\n",
    "    category_names = ['male', 'female', 'any_SEX']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'SEX')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SEX')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for English ability (ENG)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # Keep in mind we switched ENG above so that 0 is NA, 1 is not at all, 2 is not very well, ..., 5 is only English\n",
    "    mask_no_english = dfc.ENG == 1\n",
    "    mask_eng_nvw = dfc.ENG == 2\n",
    "    mask_sep_well = dfc.ENG == 3\n",
    "    mask_eng_vw = dfc.ENG == 4\n",
    "    mask_only_eng = dfc.ENG == 5\n",
    "\n",
    "    categories = [mask_no_english, mask_eng_nvw, mask_sep_well, mask_eng_vw, mask_only_eng, mask_any]\n",
    "    category_names = ['ENG_no', 'ENG_nvw', 'ENG_well', 'ENG_vw', 'ENG_only', 'ENG_any']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'ENG')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with ENG')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for marital status (MSP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_married = (dfc.MSP == 1) | (dfc.MSP == 2)\n",
    "    mask_widowed = dfc.MSP == 3\n",
    "    mask_sep_div = (dfc.MSP == 4) | (dfc.MSP == 5)\n",
    "    mask_not_married = dfc.MSP == 6\n",
    "\n",
    "    categories = [mask_married, mask_widowed, mask_sep_div, mask_not_married, mask_any]\n",
    "    category_names = ['married', 'widowed', 'sep/divorced', 'not_married', 'any_MSP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'MSP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with MSP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for weeks worked (WKW) -- this is *weeks* worked last year, not *hours per week* (that's WKHP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # Keep in mind we switched WKW above so that 0 is none, 1 is <14 weeks, 2 is 14-26 weeks, etc.\n",
    "    mask_0_WKW = dfc.WKW == 0\n",
    "    mask_u14_WKW = dfc.WKW == 1\n",
    "    mask_14_26_WKW = dfc.WKW == 2\n",
    "    mask_27_39_WKW = dfc.WKW == 3\n",
    "    mask_40_47_WKW = dfc.WKW == 4\n",
    "    mask_48_49_WKW = dfc.WKW == 5\n",
    "    mask_50_52_WKW = dfc.WKW == 6\n",
    "\n",
    "    categories = [mask_0_WKW, mask_u14_WKW, mask_14_26_WKW, mask_27_39_WKW, mask_40_47_WKW, mask_48_49_WKW, mask_50_52_WKW, \n",
    "                 (mask_40_47_WKW | mask_48_49_WKW | mask_50_52_WKW), ~mask_0_WKW, mask_any]\n",
    "    category_names = ['no_work', '<14WKW', '14-26WKW', '27-39WKW', '40-47WKW', '48-49WKW', '50-52WKW', '>40WKW', 'nonzero_WKW',\n",
    "                     'any_WKW']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'WKW')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WKW')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for usual hours worked per week last 12 months (WKHP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_0_WKHP = dfc.WKHP == 0\n",
    "    mask_u10_WKHP = dfc.WKHP < 10\n",
    "    mask_u15_WKHP = dfc.WKHP < 15\n",
    "    mask_u20_WKHP = dfc.WKHP < 20\n",
    "    mask_u30_WKHP = dfc.WKHP < 30\n",
    "    mask_u40_WKHP = dfc.WKHP < 40\n",
    "    mask_u50_WKHP = dfc.WKHP < 50\n",
    "    mask_50_plus_WKHP = dfc.WKHP >= 50\n",
    "    mask_40_plus_WKHP = dfc.WKHP >= 40\n",
    "\n",
    "    categories = [mask_0_WKHP, mask_u10_WKHP, mask_u15_WKHP, mask_u20_WKHP, mask_u30_WKHP, mask_u40_WKHP, \n",
    "                  mask_u50_WKHP, mask_50_plus_WKHP, mask_40_plus_WKHP, mask_any]\n",
    "    category_names = ['no_work_hrs', '<10_work_hrs', '<15_work_hrs', '<20_work_hrs', '<30_work_hrs', '<40_work_hrs', \n",
    "                      '<50_work_hrs', '50_plus_work_hrs', '40_plus_work_hrs', 'any_WKHP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'WKHP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WKHP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for disability status (DIS)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_DIS = dfc.DIS == 1\n",
    "    mask_not_DIS = dfc.DIS == 2\n",
    "\n",
    "    categories = [mask_DIS, mask_not_DIS, mask_any]\n",
    "    category_names = ['DIS', 'not_DIS', 'any_DIS']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'DIS')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with DIS')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for number of people (NP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_1_NP = dfc.NP == 1\n",
    "    mask_2_NP = dfc.NP == 2\n",
    "    mask_3_NP = dfc.NP == 3\n",
    "    mask_4_NP = dfc.NP == 4\n",
    "    mask_5_NP = dfc.NP == 5\n",
    "    mask_p5_NP = dfc.NP > 5\n",
    "    mask_p6_NP = dfc.NP > 6\n",
    "    mask_p8_NP = dfc.NP > 8\n",
    "    mask_p10_NP = dfc.NP > 10\n",
    "    mask_p12_NP = dfc.NP > 12\n",
    "\n",
    "    categories = [mask_1_NP, mask_2_NP, mask_3_NP, mask_4_NP, mask_5_NP, mask_p5_NP, mask_p6_NP, mask_p8_NP, mask_p10_NP, \n",
    "                  mask_p12_NP, mask_any]\n",
    "    category_names = ['NP1', 'NP2', 'NP3', 'NP4', 'NP5', 'NP>5', 'NP>6', 'NP>8', 'NP>10', 'NP>12', 'anyNP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'NP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with NP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for means of transportation to work (JWTR)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    categories = [mask_any]\n",
    "    category_names = ['work_trans']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'JWTR')\n",
    "    # Since only doing this to get means/avgs on JWTR, no need to add the 'AGEP' version here\n",
    "    #add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with JWTR')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for wages (WAGP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_0_WAG = dfc.WAGP_adj == 0\n",
    "    mask_u10_WAG = dfc.WAGP_adj < 10000\n",
    "    mask_u15_WAG = dfc.WAGP_adj < 15000\n",
    "    mask_u20_WAG = dfc.WAGP_adj < 20000\n",
    "    mask_u25_WAG = dfc.WAGP_adj < 25000\n",
    "    mask_u30_WAG = dfc.WAGP_adj < 30000\n",
    "    mask_u35_WAG = dfc.WAGP_adj < 35000\n",
    "    mask_u40_WAG = dfc.WAGP_adj < 40000\n",
    "    mask_u45_WAG = dfc.WAGP_adj < 45000\n",
    "    mask_u50_WAG = dfc.WAGP_adj < 50000\n",
    "    mask_u60_WAG = dfc.WAGP_adj < 60000\n",
    "    mask_u70_WAG = dfc.WAGP_adj < 70000\n",
    "    mask_u80_WAG = dfc.WAGP_adj < 80000\n",
    "\n",
    "    categories = [mask_0_WAG, mask_u10_WAG, mask_u15_WAG, mask_u20_WAG, mask_u25_WAG, mask_u30_WAG,  mask_u35_WAG, \n",
    "                  mask_u40_WAG, mask_u45_WAG, mask_u50_WAG, mask_u60_WAG, mask_u70_WAG, mask_u80_WAG, mask_any]\n",
    "    category_names = ['WAG0', 'WAG<10', 'WAG<15', 'WAG<20', 'WAG<25', 'WAG<30', 'WAG<35', \n",
    "                      'WAG<40', 'WAG<45', 'WAG<50', 'WAG<60', 'WAG<70', 'WAG<80', 'WAG_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'WAGP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WAGP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for interest income (INTP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_INT = dfc.INTP_adj <= 0\n",
    "    mask_INT_1q = (dfc.INTP_adj > 0) & (dfc.INTP_adj <= 400)\n",
    "    mask_INT_2q = (dfc.INTP_adj > 400) & (dfc.INTP_adj <= 4000)\n",
    "    mask_INT_3q = (dfc.INTP_adj > 4000) & (dfc.INTP_adj <= 15000)\n",
    "    mask_INT_4q = dfc.INTP_adj > 15000\n",
    "\n",
    "    categories = [mask_0_INT, mask_INT_1q, mask_INT_2q, mask_INT_3q, mask_INT_4q, mask_any]\n",
    "    category_names = ['INT0', 'INT1q', 'INT2q', 'INT3q', 'INT4q', 'INT_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'INTP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with INTP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for self-employment income (SEMP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_SEMP = dfc.SEMP_adj <= 0\n",
    "    mask_SEMP_1q = (dfc.SEMP_adj > 0) & (dfc.SEMP_adj <= 5000)\n",
    "    mask_SEMP_2q = (dfc.SEMP_adj > 5000) & (dfc.SEMP_adj <= 15000)\n",
    "    mask_SEMP_3q = (dfc.SEMP_adj > 15000) & (dfc.SEMP_adj <= 35000)\n",
    "    mask_SEMP_4q = dfc.SEMP_adj > 35000\n",
    "\n",
    "    categories = [mask_0_SEMP, mask_SEMP_1q, mask_SEMP_2q, mask_SEMP_3q, mask_SEMP_4q, mask_any]\n",
    "    category_names = ['SEMP0', 'SEMP1q', 'SEMP2q', 'SEMP3q', 'SEMP4q', 'SEMP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SEMP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SEMP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for social security income (SSP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    # min 10, 25% 8000, 50% 12,000, 75% 18,000, max 50,000\n",
    "    mask_0_SSP = dfc.SSP_adj <= 0\n",
    "    mask_SSP_1q = (dfc.SSP_adj > 0) & (dfc.SSP_adj <= 8000)\n",
    "    mask_SSP_2q = (dfc.SSP_adj > 8000) & (dfc.SSP_adj <= 12000)\n",
    "    mask_SSP_3q = (dfc.SSP_adj > 12000) & (dfc.SSP_adj <= 18000)\n",
    "    mask_SSP_4q = dfc.SSP_adj > 18000\n",
    "\n",
    "    categories = [mask_0_SSP, mask_SSP_1q, mask_SSP_2q, mask_SSP_3q, mask_SSP_4q, mask_any]\n",
    "    category_names = ['SSP0', 'SSP1q', 'SSP2q', 'SSP3q', 'SSP4q', 'SSP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SSP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SSP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for supplemental security income (SSIP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_SSIP = dfc.SSIP_adj <= 0 \n",
    "    mask_SSIP_1q = (dfc.SSIP_adj > 0) & (dfc.SSIP_adj <= 5500) \n",
    "    mask_SSIP_2q = (dfc.SSIP_adj > 5500) & (dfc.SSIP_adj <= 8000) \n",
    "    mask_SSIP_3q = (dfc.SSIP_adj > 8000)\n",
    "\n",
    "    categories = [mask_0_SSIP, mask_SSIP_1q, mask_SSIP_2q, mask_SSIP_3q, mask_any]\n",
    "    category_names = ['SSIP0', 'SSIP1q', 'SSIP2q', 'SSIP3q', 'SSIP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SSIP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SSIP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for public assistance income (PA_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_PA = dfc.PA_adj <= 0 \n",
    "    mask_PA_1q = (dfc.PA_adj > 0) & (dfc.PA_adj <= 900) \n",
    "    mask_PA_2q = (dfc.PA_adj > 900)\n",
    "\n",
    "    categories = [mask_0_PA, mask_PA_1q, mask_PA_2q, mask_any]\n",
    "    category_names = ['PA0', 'PA1q', 'PA2q', 'PA_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'PA_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with PA')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for retirement income (RETP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_RETP_1q = (dfc.RETP_adj > 0) & (dfc.RETP_adj <= 6000) \n",
    "    mask_RETP_2q = (dfc.RETP_adj > 6000) & (dfc.RETP_adj <= 13400) \n",
    "    mask_RETP_3q = (dfc.RETP_adj > 13400)\n",
    "\n",
    "    categories = [mask_RETP_1q, mask_RETP_2q, mask_RETP_3q, mask_any]\n",
    "    category_names = ['RETP1q', 'RETP2q', 'RETP3q', 'RETP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'RETP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with RETP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for other income (OI_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_OI_1q = (dfc.OI_adj > 0) & (dfc.OI_adj <= 2000) \n",
    "    mask_OI_2q = (dfc.OI_adj > 2000) & (dfc.OI_adj <= 6000) \n",
    "    mask_OI_3q = (dfc.OI_adj > 6000)\n",
    "\n",
    "    categories = [mask_OI_1q, mask_OI_2q, mask_OI_3q, mask_any]\n",
    "    category_names = ['OI1q', 'OI2q', 'OI3q', 'OI_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'OI_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with OI')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for ethnicity\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_white = dfc.Ethnicity == 1\n",
    "    mask_black = dfc.Ethnicity == 2\n",
    "    mask_asian = dfc.Ethnicity == 3\n",
    "    mask_hisp = dfc.Ethnicity == 4\n",
    "    mask_other = dfc.Ethnicity == 5\n",
    "\n",
    "    categories = [mask_white, mask_black, mask_asian, mask_hisp, mask_other, mask_any]\n",
    "    category_names = ['White', 'Black', 'Asian', 'Hisp', 'ETH_other', 'ETH_any']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'Ethnicity')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with Ethnicity')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    if include_financials:\n",
    "        # add columns for total personal income that we added above ('TINP')\n",
    "        groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "        group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "        mask_0_TINP = dfc.TINP == 0\n",
    "        mask_u10_TINP = dfc.TINP < 10000\n",
    "        mask_u15_TINP = dfc.TINP < 15000\n",
    "        mask_u20_TINP = dfc.TINP < 20000\n",
    "        mask_u25_TINP = dfc.TINP < 25000\n",
    "        mask_u30_TINP = dfc.TINP < 30000\n",
    "        mask_u35_TINP = dfc.TINP < 35000\n",
    "        mask_u40_TINP = dfc.TINP < 40000\n",
    "        mask_u45_TINP = dfc.TINP < 45000\n",
    "        mask_u50_TINP = dfc.TINP < 50000\n",
    "        mask_u60_TINP = dfc.TINP < 60000\n",
    "        mask_u70_TINP = dfc.TINP < 70000\n",
    "        mask_u80_TINP = dfc.TINP < 80000\n",
    "\n",
    "        categories = [mask_0_TINP, mask_u10_TINP, mask_u15_TINP, mask_u20_TINP, mask_u25_TINP, mask_u30_TINP,  mask_u35_TINP, \n",
    "                      mask_u40_TINP, mask_u45_TINP, mask_u50_TINP, mask_u60_TINP, mask_u70_TINP, mask_u80_TINP, mask_any]\n",
    "        category_names = ['TINP0', 'TINP<10', 'TINP<15', 'TINP<20', 'TINP<25', 'TINP<30', 'TINP<35', \n",
    "                          'TINP<40', 'TINP<45', 'TINP<50', 'TINP<60', 'TINP<70', 'TINP<80', 'TINP_any']\n",
    "\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'TINP')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s')\n",
    "\n",
    "    # Only return the new features that we engineered\n",
    "    # The variables features_to_mask and max_ppl were created at the beginning of this function\n",
    "    columns_to_mask = features_to_mask * max_ppl\n",
    "    dfc = dfc.iloc[:, columns_to_mask:].copy()\n",
    "\n",
    "    # We ended up with multi-level column headers - just keep the top level\n",
    "    dfc.columns = dfc.columns.get_level_values(0)\n",
    "    \n",
    "    return(dfc)\n",
    "\n",
    "#new_features = engineer_features(all_2016, include_financials=True)\n",
    "\n",
    "#new_features.to_csv('data/EngineeredFeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Putting Personal Features into Poverty Unit Rows\n",
    "Our dataset contains people in poverty units (a household may contain one or more poverty units). The entire \n",
    "poverty unit either is or is not in poverty, but the data set as constructed has people in different rows (the data is\n",
    "not tidy).\n",
    "\n",
    "To tidy up, we'll move information on all the people in the poverty unit, into the row for that poverty unit.\n",
    "Instead of having 3 people in a poverty unit represented by different rows, we'll put all three people in\n",
    "the same row but different columns. The columns will be named 'AGEP_1', 'AGEP_2', 'AGEP_3', etc, with zero values in all\n",
    "columns where person n does not exist.\n",
    "\n",
    "There are three main columns of interest for this:\n",
    "* SERIALNO is the serial number of each household.\n",
    "* PovUnit_ID is the serial number of the poverty unit within the household (1-18). Each household can have more than one poverty unit (although the vast majority of households have only one poverty unit).\n",
    "* SPORDER is the serial number of a person in the household (1-20). Note that the dataset only assigns serial numbers to\n",
    "the people in the *household*, not the *poverty unit*.  This means that if for example a household has two poverty units,\n",
    "the first with two people and the second with three people, the head of the second poverty unit will have SPORDER of 3,\n",
    "not 1.  (One-based counting scheme) This is not a problem, but a particularity to be aware of when looking at dataset\n",
    "rows for reference.\n",
    "\n",
    "Also, there are some poverty-unit-level columns (e.g. 'TotalWorkHrs_PU', the number of work hours in the poverty unit)\n",
    "that have the same value for each person in the poverty unit; we'll collect those separately.\n",
    "\n",
    "So the strategy in the next section is to create dataframes X_pers and X_pu, containing respectively the personal and\n",
    "poverty-unit features for each household.  We'll join those together, and then at the end add in all the new features we created in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pers_and_pu_features(df, include_financials=True, target_column='NYCgov_Pov_Stat'):\n",
    "    \"\"\"Create personal and poverty-unit features for the dataframe. No new features are created, just 'tidy'-ing the data.\n",
    "    Input: a poverty dataframe, whether or not to include financial features, and the target column.\n",
    "    Output: returns a copy of the dataframe, tidy-ed up, with poverty units in rows and only features of interest in \n",
    "    columns. Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # First, some categoricals have odd ordering; remap them\n",
    "    fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "                  'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "    dfc['ENG'] = dfc['ENG'].map(fix_orders['ENG'])\n",
    "    dfc['WKW'] = dfc['WKW'].map(fix_orders['WKW'])\n",
    "    dfc['TotalWorkHrs_PU'] = dfc['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "    # Add column for total personal income\n",
    "    if include_financials:\n",
    "        dfc['TINP'] = dfc.WAGP_adj + dfc.INTP_adj + dfc.SEMP_adj + dfc.SSP_adj + dfc.SSIP_adj + dfc.PA_adj + dfc.RETP_adj + dfc.OI_adj\n",
    "\n",
    "    categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', \n",
    "                    'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "    # We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "    personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    if include_financials:\n",
    "        personal_columns += ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', \n",
    "                             'OI_adj', 'TINP']\n",
    "    pu_columns = ['NP', 'TEN', 'HHT', 'MRGP_adj', 'RNTP_adj', 'HousingStatus', 'TotalWorkHrs_PU'] + [target_column]\n",
    "\n",
    "    # Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "    df_pers = dfc.copy()\n",
    "    df_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "    df_pers = df_pers[df_pers_columns]\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    df_pers = df_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "    df_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in df_pers.columns)]))\n",
    "    print('df_pers complete')\n",
    "\n",
    "    # Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "    df_pu = dfc.copy()\n",
    "    df_pu_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + pu_columns\n",
    "    df_pu = df_pu[df_pu_columns]\n",
    "\n",
    "    # Add column for total mortgage + rent\n",
    "    df_pu['MRNT'] = df_pu.MRGP_adj + df_pu.RNTP_adj\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    df_pu = df_pu.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "    df_pu = df_pu.stack().groupby(['SERIALNO', 'Povunit_ID']).max()\n",
    "    print('df_pu complete')\n",
    "\n",
    "    # Add the personal and poverty-unit dataframes\n",
    "    dfc = df_pers.join(df_pu)\n",
    "    return(dfc)\n",
    "\n",
    "\n",
    "# Get the personal and poverty-unit features\n",
    "#X = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_Pov_Stat')\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "# new_features = pd.read_csv('/data/EngineeredFeatures.csv', index_col=[0,1], header=0)\n",
    "#X = X.join(new_features)\n",
    "    \n",
    "#X.to_csv('/data/Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_y = pd.read_csv('data/Features.csv', index_col=[0,1], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "Most of our features are numerical or ordinal; but a few features are nominal, that is, categorical without any order,\n",
    "like disabled status (yes or no), for example.  We'll loop through and one-hot encode those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, old_df):\n",
    "    \"\"\"\n",
    "    Turn the categorical columns of df into one-hot encoded columns.\n",
    "    Input: the dataframe of interest (that has been tidy-ed up so that all people in the same poverty unit are in the\n",
    "    same row, and a reference dataframe (pre-tidy-ed version) so we have the correct number of loop iterations.\n",
    "    Output: returns the dataframe with columns transformed.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # Number of enumerated columns for each feature ('AGEP_1', 'AGEP_2', etc.)\n",
    "    # This is equal to the maximum number of people in any household, which is the max of SPORDER\n",
    "    n = old_df.SPORDER.max()\n",
    "\n",
    "    # Some categoricals have no ordering\n",
    "    nominal_pers = ['DIS', 'SEX', 'MSP', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    nominal_pu = ['TEN', 'HHT', 'HousingStatus']\n",
    "    \n",
    "    # Collect all the names that we need to change to str for get_dummies purposes\n",
    "    names = []\n",
    "    \n",
    "    # Loop through and collect the names of all the personal-variables columns\n",
    "    for feature in nominal_pers:\n",
    "        # Loop through and one-hot encode for each suffixed column '_1', '_2', etc.\n",
    "        for i in range(1,n+1):\n",
    "            suffixed_name = str(feature + '_' + str(i))\n",
    "            names.append(suffixed_name)\n",
    "\n",
    "    # Loop through and one-hot encode poverty-unit categoricals\n",
    "    for feature in nominal_pu:\n",
    "        names.append(feature)\n",
    "    \n",
    "    dfc[names] = dfc[names].astype(str)\n",
    "    # Assuming this doesn't work, just use dfc_names_only = dfc_names and dfc_non_names=dfc.drop(names, axis='columns') and go from there\n",
    "    dfc = pd.get_dummies(dfc, drop_first=True)\n",
    "    \n",
    "    return(dfc)\n",
    "\n",
    "X_and_y = one_hot_encode(X_and_y, all_2016)\n",
    "#X_and_y.to_csv('data/FeaturesCoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns with Low Standard Deviation\n",
    "The algorithm used above created thousands of features -- but not all of them will be useful.  Let's remove all of the \n",
    "features that have a Standard Deviation of less than 0.1, to reduce the noise and speed up our model runs (especially\n",
    "our run to remove co-linear features, which will take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5916\n",
      "4960\n"
     ]
    }
   ],
   "source": [
    "tester = X_and_y.copy()\n",
    "print('Number of columns before feature pruning: ' + str(len(tester.columns)))\n",
    "tester = tester.loc[:, tester.astype('float64').std() > .1] #4960 columns\n",
    "print('Number of columns after feature pruning: ' + str(len(tester.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Co-Linear Features\n",
    "We also introduced a lot of of features that are very highly correlated.  Out of the 4,960 columns, below we identify\n",
    "3,406 columns (nearly 70 percent!) to drop due to colinearity. This step took over 20 minutes on a fairly beefy AWS\n",
    "instance; don't run it unless you're ready to wait. If you don't want to run it, just un-comment the 'to_drop' line at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4960\n",
      "got correlations; took 1261.0507678985596s\n",
      "got uppers; took 1261.2725381851196s cumulative\n",
      "got to-drop, took 1262.4210934638977s cumulative\n",
      "['SCHL_19', 'WAGP_adj_15', 'SSP_adj_20', 'SSIP_adj_14', 'SSIP_adj_20', 'PA_adj_14', 'PA_adj_16', 'PA_adj_17', 'PA_adj_18', 'PA_adj_19', 'PA_adj_20', 'TINP_3', 'TINP_10', 'TINP_11', 'TINP_12', 'TINP_13', 'TINP_14', 'TINP_15', 'TINP_16', 'TINP_17', 'TINP_18', 'TINP_19', 'TINP_20', 'all_65+_age', 'min_65+_age', 'max_65+_age', 'sum_65+_age', 'mean_65+_age', '%_65+_age', 'all_18-64_age', 'mean_18-64_age', '%_18-64_age', 'all_kid_age', 'mean_kid_age', '%_kid_age', 'max_anyage_age', 'sum_anyage_age', 'max_adult_non-cit', 'sum_adult_non-cit', 'mean_adult_non-cit', 'any_adult_citizen', 'all_adult_citizen', 'mean_adult_citizen', '%_adult_citizen', 'max_adult_naturalized_cit', 'sum_adult_naturalized_cit', 'mean_adult_naturalized_cit', 'min_adult_any_CIT', 'max_adult_any_CIT', 'count_adult_any_CIT', 'sum_adult_any_CIT', 'mean_adult_any_CIT', 'min_65+_non-cit', 'max_65+_non-cit', 'count_65+_non-cit', 'sum_65+_non-cit', 'mean_65+_non-cit', '%_65+_non-cit', 'all_65+_citizen', 'min_65+_citizen', 'max_65+_citizen', 'sum_65+_citizen', 'mean_65+_citizen', '%_65+_citizen', 'min_65+_naturalized_cit', 'max_65+_naturalized_cit', 'sum_65+_naturalized_cit', 'mean_65+_naturalized_cit', '%_65+_naturalized_cit', 'any_65+_any_CIT', 'all_65+_any_CIT', 'min_65+_any_CIT', 'max_65+_any_CIT', 'count_65+_any_CIT', 'sum_65+_any_CIT', 'mean_65+_any_CIT', '%_65+_any_CIT', 'max_18-64_non-cit', 'count_18-64_non-cit', 'sum_18-64_non-cit', 'mean_18-64_non-cit', 'mean_18-64_citizen', '%_18-64_citizen', 'min_18-64_naturalized_cit', 'max_18-64_naturalized_cit', 'sum_18-64_naturalized_cit', 'mean_18-64_naturalized_cit', 'any_18-64_any_CIT', 'all_18-64_any_CIT', 'min_18-64_any_CIT', 'max_18-64_any_CIT', 'count_18-64_any_CIT', 'sum_18-64_any_CIT', 'mean_18-64_any_CIT', '%_18-64_any_CIT', 'max_kid_non-cit', 'mean_kid_non-cit', 'any_kid_citizen', 'all_kid_citizen', 'min_kid_citizen', 'max_kid_citizen', 'count_kid_citizen', 'sum_kid_citizen', 'mean_kid_citizen', '%_kid_citizen', 'max_kid_naturalized_cit', 'mean_kid_naturalized_cit', 'any_kid_any_CIT', 'all_kid_any_CIT', 'min_kid_any_CIT', 'max_kid_any_CIT', 'count_kid_any_CIT', 'sum_kid_any_CIT', 'mean_kid_any_CIT', '%_kid_any_CIT', 'any_anyage_non-cit', 'min_anyage_non-cit', 'max_anyage_non-cit', 'count_anyage_non-cit', 'sum_anyage_non-cit', 'mean_anyage_non-cit', '%_anyage_non-cit', 'any_anyage_citizen', 'all_anyage_citizen', 'max_anyage_citizen', 'sum_anyage_citizen', 'mean_anyage_citizen', '%_anyage_citizen', 'any_anyage_naturalized_cit', 'min_anyage_naturalized_cit', 'max_anyage_naturalized_cit', 'count_anyage_naturalized_cit', 'sum_anyage_naturalized_cit', 'mean_anyage_naturalized_cit', '%_anyage_naturalized_cit', 'min_anyage_any_CIT', 'max_anyage_any_CIT', 'count_anyage_any_CIT', 'sum_anyage_any_CIT', 'mean_anyage_any_CIT', 'max_adult_college', 'mean_adult_college', 'mean_adult_HS', 'any_adult_no_diploma', 'all_adult_no_diploma', 'max_adult_no_diploma', 'mean_adult_no_diploma', '%_adult_no_diploma', 'max_adult_diploma_no_bachelors', 'mean_adult_diploma_no_bachelors', 'min_adult_any_SCHL', 'max_adult_any_SCHL', 'count_adult_any_SCHL', 'sum_adult_any_SCHL', 'mean_adult_any_SCHL', 'min_65+_college', 'max_65+_college', 'sum_65+_college', 'mean_65+_college', '%_65+_college', 'min_65+_HS', 'max_65+_HS', 'sum_65+_HS', 'mean_65+_HS', '%_65+_HS', 'min_65+_no_diploma', 'max_65+_no_diploma', 'sum_65+_no_diploma', 'mean_65+_no_diploma', '%_65+_no_diploma', 'min_65+_diploma_no_bachelors', 'max_65+_diploma_no_bachelors', 'count_65+_diploma_no_bachelors', 'sum_65+_diploma_no_bachelors', 'mean_65+_diploma_no_bachelors', '%_65+_diploma_no_bachelors', 'any_65+_any_SCHL', 'all_65+_any_SCHL', 'min_65+_any_SCHL', 'max_65+_any_SCHL', 'count_65+_any_SCHL', 'sum_65+_any_SCHL', 'mean_65+_any_SCHL', '%_65+_any_SCHL', 'max_18-64_college', 'mean_18-64_college', 'mean_18-64_HS', 'max_18-64_no_diploma', 'sum_18-64_no_diploma', 'mean_18-64_no_diploma', 'max_18-64_diploma_no_bachelors', 'mean_18-64_diploma_no_bachelors', 'any_18-64_any_SCHL', 'all_18-64_any_SCHL', 'min_18-64_any_SCHL', 'max_18-64_any_SCHL', 'count_18-64_any_SCHL', 'sum_18-64_any_SCHL', 'mean_18-64_any_SCHL', '%_18-64_any_SCHL', 'max_kid_HS', 'sum_kid_HS', 'mean_kid_HS', 'any_kid_no_diploma', 'all_kid_no_diploma', 'min_kid_no_diploma', 'max_kid_no_diploma', 'count_kid_no_diploma', 'sum_kid_no_diploma', 'mean_kid_no_diploma', '%_kid_no_diploma', 'min_kid_diploma_no_bachelors', 'max_kid_diploma_no_bachelors', 'sum_kid_diploma_no_bachelors', 'mean_kid_diploma_no_bachelors', 'any_kid_any_SCHL', 'all_kid_any_SCHL', 'min_kid_any_SCHL', 'max_kid_any_SCHL', 'count_kid_any_SCHL', 'sum_kid_any_SCHL', 'mean_kid_any_SCHL', '%_kid_any_SCHL', 'any_anyage_college', 'min_anyage_college', 'max_anyage_college', 'count_anyage_college', 'sum_anyage_college', 'mean_anyage_college', '%_anyage_college', 'any_anyage_HS', 'min_anyage_HS', 'max_anyage_HS', 'count_anyage_HS', 'sum_anyage_HS', 'mean_anyage_HS', 'any_anyage_no_diploma', 'all_anyage_no_diploma', 'max_anyage_no_diploma', 'sum_anyage_no_diploma', 'mean_anyage_no_diploma', '%_anyage_no_diploma', 'any_anyage_diploma_no_bachelors', 'min_anyage_diploma_no_bachelors', 'max_anyage_diploma_no_bachelors', 'count_anyage_diploma_no_bachelors', 'sum_anyage_diploma_no_bachelors', 'mean_anyage_diploma_no_bachelors', '%_anyage_diploma_no_bachelors', 'min_anyage_any_SCHL', 'max_anyage_any_SCHL', 'count_anyage_any_SCHL', 'sum_anyage_any_SCHL', 'mean_anyage_any_SCHL', 'mean_adult_male', 'any_adult_female', 'all_adult_female', 'mean_adult_female', '%_adult_female', 'min_adult_any_SEX', 'max_adult_any_SEX', 'count_adult_any_SEX', 'sum_adult_any_SEX', 'mean_adult_any_SEX', 'min_65+_male', 'max_65+_male', 'count_65+_male', 'sum_65+_male', 'mean_65+_male', 'min_65+_female', 'max_65+_female', 'count_65+_female', 'sum_65+_female', 'mean_65+_female', '%_65+_female', 'any_65+_any_SEX', 'all_65+_any_SEX', 'min_65+_any_SEX', 'max_65+_any_SEX', 'count_65+_any_SEX', 'sum_65+_any_SEX', 'mean_65+_any_SEX', '%_65+_any_SEX', 'mean_18-64_male', 'mean_18-64_female', 'any_18-64_any_SEX', 'all_18-64_any_SEX', 'min_18-64_any_SEX', 'max_18-64_any_SEX', 'count_18-64_any_SEX', 'sum_18-64_any_SEX', 'mean_18-64_any_SEX', '%_18-64_any_SEX', 'mean_kid_male', 'mean_kid_female', 'any_kid_any_SEX', 'all_kid_any_SEX', 'min_kid_any_SEX', 'max_kid_any_SEX', 'count_kid_any_SEX', 'sum_kid_any_SEX', 'mean_kid_any_SEX', '%_kid_any_SEX', 'all_anyage_male', 'max_anyage_male', 'sum_anyage_male', 'mean_anyage_male', '%_anyage_male', 'any_anyage_female', 'all_anyage_female', 'max_anyage_female', 'sum_anyage_female', 'mean_anyage_female', '%_anyage_female', 'min_anyage_any_SEX', 'max_anyage_any_SEX', 'count_anyage_any_SEX', 'sum_anyage_any_SEX', 'mean_anyage_any_SEX', 'min_adult_ENG_no', 'max_adult_ENG_no', 'sum_adult_ENG_no', 'mean_adult_ENG_no', 'max_adult_ENG_nvw', 'sum_adult_ENG_nvw', 'mean_adult_ENG_nvw', 'max_adult_ENG_well', 'mean_adult_ENG_well', 'max_adult_ENG_vw', 'mean_adult_ENG_vw', 'mean_adult_ENG_only', '%_adult_ENG_only', 'min_adult_ENG_any', 'max_adult_ENG_any', 'count_adult_ENG_any', 'sum_adult_ENG_any', 'mean_adult_ENG_any', 'min_65+_ENG_no', 'max_65+_ENG_no', 'count_65+_ENG_no', 'sum_65+_ENG_no', 'mean_65+_ENG_no', '%_65+_ENG_no', 'min_65+_ENG_nvw', 'max_65+_ENG_nvw', 'count_65+_ENG_nvw', 'sum_65+_ENG_nvw', 'mean_65+_ENG_nvw', '%_65+_ENG_nvw', 'min_65+_ENG_well', 'max_65+_ENG_well', 'count_65+_ENG_well', 'sum_65+_ENG_well', 'mean_65+_ENG_well', '%_65+_ENG_well', 'min_65+_ENG_vw', 'max_65+_ENG_vw', 'sum_65+_ENG_vw', 'mean_65+_ENG_vw', '%_65+_ENG_vw', 'all_65+_ENG_only', 'min_65+_ENG_only', 'max_65+_ENG_only', 'sum_65+_ENG_only', 'mean_65+_ENG_only', '%_65+_ENG_only', 'any_65+_ENG_any', 'all_65+_ENG_any', 'min_65+_ENG_any', 'max_65+_ENG_any', 'count_65+_ENG_any', 'sum_65+_ENG_any', 'mean_65+_ENG_any', '%_65+_ENG_any', 'min_18-64_ENG_no', 'max_18-64_ENG_no', 'sum_18-64_ENG_no', 'mean_18-64_ENG_no', 'min_18-64_ENG_nvw', 'max_18-64_ENG_nvw', 'sum_18-64_ENG_nvw', 'mean_18-64_ENG_nvw', 'min_18-64_ENG_well', 'max_18-64_ENG_well', 'sum_18-64_ENG_well', 'mean_18-64_ENG_well', 'max_18-64_ENG_vw', 'sum_18-64_ENG_vw', 'mean_18-64_ENG_vw', 'sum_18-64_ENG_only', 'mean_18-64_ENG_only', '%_18-64_ENG_only', 'any_18-64_ENG_any', 'all_18-64_ENG_any', 'min_18-64_ENG_any', 'max_18-64_ENG_any', 'count_18-64_ENG_any', 'sum_18-64_ENG_any', 'mean_18-64_ENG_any', '%_18-64_ENG_any', 'max_kid_ENG_no', 'mean_kid_ENG_no', 'max_kid_ENG_nvw', 'mean_kid_ENG_nvw', 'max_kid_ENG_well', 'sum_kid_ENG_well', 'mean_kid_ENG_well', 'max_kid_ENG_vw', 'sum_kid_ENG_vw', 'mean_kid_ENG_vw', '%_kid_ENG_vw', 'max_kid_ENG_only', 'sum_kid_ENG_only', 'mean_kid_ENG_only', '%_kid_ENG_only', 'any_kid_ENG_any', 'all_kid_ENG_any', 'min_kid_ENG_any', 'max_kid_ENG_any', 'count_kid_ENG_any', 'sum_kid_ENG_any', 'mean_kid_ENG_any', '%_kid_ENG_any', 'any_anyage_ENG_no', 'all_anyage_ENG_no', 'min_anyage_ENG_no', 'max_anyage_ENG_no', 'count_anyage_ENG_no', 'sum_anyage_ENG_no', 'mean_anyage_ENG_no', '%_anyage_ENG_no', 'any_anyage_ENG_nvw', 'min_anyage_ENG_nvw', 'max_anyage_ENG_nvw', 'count_anyage_ENG_nvw', 'sum_anyage_ENG_nvw', 'mean_anyage_ENG_nvw', '%_anyage_ENG_nvw', 'any_anyage_ENG_well', 'min_anyage_ENG_well', 'max_anyage_ENG_well', 'sum_anyage_ENG_well', 'mean_anyage_ENG_well', '%_anyage_ENG_well', 'min_anyage_ENG_vw', 'max_anyage_ENG_vw', 'sum_anyage_ENG_vw', 'mean_anyage_ENG_vw', '%_anyage_ENG_vw', 'any_anyage_ENG_only', 'max_anyage_ENG_only', 'sum_anyage_ENG_only', 'mean_anyage_ENG_only', '%_anyage_ENG_only', 'min_anyage_ENG_any', 'max_anyage_ENG_any', 'count_anyage_ENG_any', 'sum_anyage_ENG_any', 'mean_anyage_ENG_any', 'max_adult_married', 'sum_adult_married', 'mean_adult_married', 'min_adult_widowed', 'max_adult_widowed', 'count_adult_widowed', 'sum_adult_widowed', 'mean_adult_widowed', 'min_adult_sep/divorced', 'max_adult_sep/divorced', 'count_adult_sep/divorced', 'sum_adult_sep/divorced', 'mean_adult_sep/divorced', 'max_adult_not_married', 'mean_adult_not_married', 'min_adult_any_MSP', 'max_adult_any_MSP', 'count_adult_any_MSP', 'sum_adult_any_MSP', 'mean_adult_any_MSP', 'all_65+_married', 'min_65+_married', 'max_65+_married', 'count_65+_married', 'sum_65+_married', 'mean_65+_married', '%_65+_married', 'all_65+_widowed', 'min_65+_widowed', 'max_65+_widowed', 'count_65+_widowed', 'sum_65+_widowed', 'mean_65+_widowed', '%_65+_widowed', 'all_65+_sep/divorced', 'min_65+_sep/divorced', 'max_65+_sep/divorced', 'count_65+_sep/divorced', 'sum_65+_sep/divorced', 'mean_65+_sep/divorced', '%_65+_sep/divorced', 'all_65+_not_married', 'min_65+_not_married', 'max_65+_not_married', 'count_65+_not_married', 'sum_65+_not_married', 'mean_65+_not_married', '%_65+_not_married', 'any_65+_any_MSP', 'all_65+_any_MSP', 'min_65+_any_MSP', 'max_65+_any_MSP', 'count_65+_any_MSP', 'sum_65+_any_MSP', 'mean_65+_any_MSP', '%_65+_any_MSP', 'min_18-64_married', 'max_18-64_married', 'sum_18-64_married', 'mean_18-64_married', '%_18-64_married', 'min_18-64_widowed', 'max_18-64_widowed', 'count_18-64_widowed', 'sum_18-64_widowed', 'mean_18-64_widowed', 'min_18-64_sep/divorced', 'max_18-64_sep/divorced', 'count_18-64_sep/divorced', 'sum_18-64_sep/divorced', 'mean_18-64_sep/divorced', 'max_18-64_not_married', 'count_18-64_not_married', 'mean_18-64_not_married', 'any_18-64_any_MSP', 'all_18-64_any_MSP', 'min_18-64_any_MSP', 'max_18-64_any_MSP', 'count_18-64_any_MSP', 'sum_18-64_any_MSP', 'mean_18-64_any_MSP', '%_18-64_any_MSP', 'max_kid_married', 'sum_kid_married', 'mean_kid_married', 'max_kid_sep/divorced', 'sum_kid_sep/divorced', 'mean_kid_sep/divorced', 'min_kid_not_married', 'max_kid_not_married', 'count_kid_not_married', 'sum_kid_not_married', 'mean_kid_not_married', 'any_kid_any_MSP', 'all_kid_any_MSP', 'min_kid_any_MSP', 'max_kid_any_MSP', 'count_kid_any_MSP', 'sum_kid_any_MSP', 'mean_kid_any_MSP', '%_kid_any_MSP', 'any_anyage_married', 'min_anyage_married', 'max_anyage_married', 'count_anyage_married', 'sum_anyage_married', 'mean_anyage_married', 'any_anyage_widowed', 'all_anyage_widowed', 'min_anyage_widowed', 'max_anyage_widowed', 'count_anyage_widowed', 'sum_anyage_widowed', 'mean_anyage_widowed', '%_anyage_widowed', 'any_anyage_sep/divorced', 'min_anyage_sep/divorced', 'max_anyage_sep/divorced', 'count_anyage_sep/divorced', 'sum_anyage_sep/divorced', 'mean_anyage_sep/divorced', '%_anyage_sep/divorced', 'min_anyage_not_married', 'max_anyage_not_married', 'sum_anyage_not_married', 'mean_anyage_not_married', '%_anyage_not_married', 'min_anyage_any_MSP', 'max_anyage_any_MSP', 'count_anyage_any_MSP', 'sum_anyage_any_MSP', 'mean_anyage_any_MSP', 'max_adult_no_work', 'mean_adult_no_work', 'max_adult_<14WKW', 'count_adult_<14WKW', 'sum_adult_<14WKW', 'mean_adult_<14WKW', 'max_adult_14-26WKW', 'count_adult_14-26WKW', 'sum_adult_14-26WKW', 'mean_adult_14-26WKW', 'max_adult_27-39WKW', 'count_adult_27-39WKW', 'sum_adult_27-39WKW', 'mean_adult_27-39WKW', 'max_adult_40-47WKW', 'count_adult_40-47WKW', 'sum_adult_40-47WKW', 'mean_adult_40-47WKW', 'max_adult_48-49WKW', 'count_adult_48-49WKW', 'sum_adult_48-49WKW', 'mean_adult_48-49WKW', 'mean_adult_50-52WKW', 'mean_adult_>40WKW', 'any_adult_nonzero_WKW', 'all_adult_nonzero_WKW', 'mean_adult_nonzero_WKW', '%_adult_nonzero_WKW', 'min_adult_any_WKW', 'max_adult_any_WKW', 'count_adult_any_WKW', 'sum_adult_any_WKW', 'mean_adult_any_WKW', 'min_65+_no_work', 'max_65+_no_work', 'sum_65+_no_work', 'mean_65+_no_work', '%_65+_no_work', 'max_65+_<14WKW', 'sum_65+_<14WKW', 'mean_65+_<14WKW', 'max_65+_14-26WKW', 'sum_65+_14-26WKW', 'mean_65+_14-26WKW', 'max_65+_27-39WKW', 'sum_65+_27-39WKW', 'mean_65+_27-39WKW', 'max_65+_40-47WKW', 'sum_65+_40-47WKW', 'mean_65+_40-47WKW', 'max_65+_48-49WKW', 'sum_65+_48-49WKW', 'mean_65+_48-49WKW', 'min_65+_50-52WKW', 'max_65+_50-52WKW', 'count_65+_50-52WKW', 'sum_65+_50-52WKW', 'mean_65+_50-52WKW', '%_65+_50-52WKW', 'min_65+_>40WKW', 'max_65+_>40WKW', 'count_65+_>40WKW', 'sum_65+_>40WKW', 'mean_65+_>40WKW', '%_65+_>40WKW', 'min_65+_nonzero_WKW', 'max_65+_nonzero_WKW', 'count_65+_nonzero_WKW', 'sum_65+_nonzero_WKW', 'mean_65+_nonzero_WKW', '%_65+_nonzero_WKW', 'any_65+_any_WKW', 'all_65+_any_WKW', 'min_65+_any_WKW', 'max_65+_any_WKW', 'count_65+_any_WKW', 'sum_65+_any_WKW', 'mean_65+_any_WKW', '%_65+_any_WKW', 'max_18-64_no_work', 'mean_18-64_no_work', 'max_18-64_<14WKW', 'count_18-64_<14WKW', 'sum_18-64_<14WKW', 'mean_18-64_<14WKW', 'any_18-64_14-26WKW', 'max_18-64_14-26WKW', 'count_18-64_14-26WKW', 'sum_18-64_14-26WKW', 'mean_18-64_14-26WKW', 'any_18-64_27-39WKW', 'max_18-64_27-39WKW', 'count_18-64_27-39WKW', 'sum_18-64_27-39WKW', 'mean_18-64_27-39WKW', 'any_18-64_40-47WKW', 'max_18-64_40-47WKW', 'count_18-64_40-47WKW', 'sum_18-64_40-47WKW', 'mean_18-64_40-47WKW', 'any_18-64_48-49WKW', 'min_18-64_48-49WKW', 'max_18-64_48-49WKW', 'count_18-64_48-49WKW', 'sum_18-64_48-49WKW', 'mean_18-64_48-49WKW', '%_18-64_48-49WKW', 'count_18-64_50-52WKW', 'mean_18-64_50-52WKW', 'count_18-64_>40WKW', 'mean_18-64_>40WKW', 'count_18-64_nonzero_WKW', 'mean_18-64_nonzero_WKW', 'any_18-64_any_WKW', 'all_18-64_any_WKW', 'min_18-64_any_WKW', 'max_18-64_any_WKW', 'count_18-64_any_WKW', 'sum_18-64_any_WKW', 'mean_18-64_any_WKW', '%_18-64_any_WKW', 'any_kid_no_work', 'all_kid_no_work', 'min_kid_no_work', 'max_kid_no_work', 'count_kid_no_work', 'sum_kid_no_work', 'mean_kid_no_work', '%_kid_no_work', 'max_kid_<14WKW', 'sum_kid_<14WKW', 'mean_kid_<14WKW', 'max_kid_14-26WKW', 'sum_kid_14-26WKW', 'mean_kid_14-26WKW', 'max_kid_27-39WKW', 'sum_kid_27-39WKW', 'mean_kid_27-39WKW', 'max_kid_40-47WKW', 'sum_kid_40-47WKW', 'mean_kid_40-47WKW', 'max_kid_50-52WKW', 'sum_kid_50-52WKW', 'mean_kid_50-52WKW', 'max_kid_>40WKW', 'sum_kid_>40WKW', 'mean_kid_>40WKW', 'max_kid_nonzero_WKW', 'sum_kid_nonzero_WKW', 'mean_kid_nonzero_WKW', 'any_kid_any_WKW', 'all_kid_any_WKW', 'min_kid_any_WKW', 'max_kid_any_WKW', 'count_kid_any_WKW', 'sum_kid_any_WKW', 'mean_kid_any_WKW', '%_kid_any_WKW', 'all_anyage_no_work', 'max_anyage_no_work', 'sum_anyage_no_work', 'mean_anyage_no_work', 'any_anyage_<14WKW', 'min_anyage_<14WKW', 'max_anyage_<14WKW', 'count_anyage_<14WKW', 'sum_anyage_<14WKW', 'mean_anyage_<14WKW', '%_anyage_<14WKW', 'any_anyage_14-26WKW', 'all_anyage_14-26WKW', 'min_anyage_14-26WKW', 'max_anyage_14-26WKW', 'count_anyage_14-26WKW', 'sum_anyage_14-26WKW', 'mean_anyage_14-26WKW', '%_anyage_14-26WKW', 'any_anyage_27-39WKW', 'min_anyage_27-39WKW', 'max_anyage_27-39WKW', 'count_anyage_27-39WKW', 'sum_anyage_27-39WKW', 'mean_anyage_27-39WKW', '%_anyage_27-39WKW', 'any_anyage_40-47WKW', 'min_anyage_40-47WKW', 'max_anyage_40-47WKW', 'count_anyage_40-47WKW', 'sum_anyage_40-47WKW', 'mean_anyage_40-47WKW', '%_anyage_40-47WKW', 'any_anyage_48-49WKW', 'min_anyage_48-49WKW', 'max_anyage_48-49WKW', 'count_anyage_48-49WKW', 'sum_anyage_48-49WKW', 'mean_anyage_48-49WKW', '%_anyage_48-49WKW', 'any_anyage_50-52WKW', 'min_anyage_50-52WKW', 'max_anyage_50-52WKW', 'count_anyage_50-52WKW', 'sum_anyage_50-52WKW', 'mean_anyage_50-52WKW', 'any_anyage_>40WKW', 'min_anyage_>40WKW', 'max_anyage_>40WKW', 'count_anyage_>40WKW', 'sum_anyage_>40WKW', 'mean_anyage_>40WKW', 'any_anyage_nonzero_WKW', 'all_anyage_nonzero_WKW', 'min_anyage_nonzero_WKW', 'max_anyage_nonzero_WKW', 'count_anyage_nonzero_WKW', 'sum_anyage_nonzero_WKW', 'mean_anyage_nonzero_WKW', '%_anyage_nonzero_WKW', 'min_anyage_any_WKW', 'max_anyage_any_WKW', 'count_anyage_any_WKW', 'sum_anyage_any_WKW', 'mean_anyage_any_WKW', 'any_adult_no_work_hrs', 'all_adult_no_work_hrs', 'min_adult_no_work_hrs', 'max_adult_no_work_hrs', 'count_adult_no_work_hrs', 'sum_adult_no_work_hrs', 'mean_adult_no_work_hrs', '%_adult_no_work_hrs', 'any_adult_<10_work_hrs', 'all_adult_<10_work_hrs', 'min_adult_<10_work_hrs', 'max_adult_<10_work_hrs', 'count_adult_<10_work_hrs', 'sum_adult_<10_work_hrs', 'mean_adult_<10_work_hrs', '%_adult_<10_work_hrs', 'any_adult_<15_work_hrs', 'all_adult_<15_work_hrs', 'min_adult_<15_work_hrs', 'max_adult_<15_work_hrs', 'count_adult_<15_work_hrs', 'sum_adult_<15_work_hrs', 'mean_adult_<15_work_hrs', '%_adult_<15_work_hrs', 'any_adult_<20_work_hrs', 'all_adult_<20_work_hrs', 'min_adult_<20_work_hrs', 'max_adult_<20_work_hrs', 'count_adult_<20_work_hrs', 'sum_adult_<20_work_hrs', 'mean_adult_<20_work_hrs', '%_adult_<20_work_hrs', 'sum_adult_<30_work_hrs', 'mean_adult_<30_work_hrs', 'mean_adult_<40_work_hrs', 'any_adult_50_plus_work_hrs', 'all_adult_50_plus_work_hrs', 'max_adult_50_plus_work_hrs', 'sum_adult_50_plus_work_hrs', 'mean_adult_50_plus_work_hrs', '%_adult_50_plus_work_hrs', 'any_adult_40_plus_work_hrs', 'all_adult_40_plus_work_hrs', 'max_adult_40_plus_work_hrs', 'mean_adult_40_plus_work_hrs', '%_adult_40_plus_work_hrs', 'min_adult_any_WKHP', 'max_adult_any_WKHP', 'count_adult_any_WKHP', 'sum_adult_any_WKHP', 'mean_adult_any_WKHP', 'any_65+_no_work_hrs', 'all_65+_no_work_hrs', 'min_65+_no_work_hrs', 'max_65+_no_work_hrs', 'count_65+_no_work_hrs', 'sum_65+_no_work_hrs', 'mean_65+_no_work_hrs', '%_65+_no_work_hrs', 'any_65+_<10_work_hrs', 'all_65+_<10_work_hrs', 'min_65+_<10_work_hrs', 'max_65+_<10_work_hrs', 'count_65+_<10_work_hrs', 'sum_65+_<10_work_hrs', 'mean_65+_<10_work_hrs', '%_65+_<10_work_hrs', 'any_65+_<15_work_hrs', 'all_65+_<15_work_hrs', 'min_65+_<15_work_hrs', 'max_65+_<15_work_hrs', 'count_65+_<15_work_hrs', 'sum_65+_<15_work_hrs', 'mean_65+_<15_work_hrs', '%_65+_<15_work_hrs', 'any_65+_<20_work_hrs', 'all_65+_<20_work_hrs', 'min_65+_<20_work_hrs', 'max_65+_<20_work_hrs', 'count_65+_<20_work_hrs', 'sum_65+_<20_work_hrs', 'mean_65+_<20_work_hrs', '%_65+_<20_work_hrs', 'any_65+_<30_work_hrs', 'all_65+_<30_work_hrs', 'min_65+_<30_work_hrs', 'max_65+_<30_work_hrs', 'count_65+_<30_work_hrs', 'sum_65+_<30_work_hrs', 'mean_65+_<30_work_hrs', '%_65+_<30_work_hrs', 'any_65+_<40_work_hrs', 'all_65+_<40_work_hrs', 'min_65+_<40_work_hrs', 'max_65+_<40_work_hrs', 'count_65+_<40_work_hrs', 'sum_65+_<40_work_hrs', 'mean_65+_<40_work_hrs', '%_65+_<40_work_hrs', 'any_65+_<50_work_hrs', 'all_65+_<50_work_hrs', 'min_65+_<50_work_hrs', 'max_65+_<50_work_hrs', 'count_65+_<50_work_hrs', 'sum_65+_<50_work_hrs', 'mean_65+_<50_work_hrs', '%_65+_<50_work_hrs', 'max_65+_50_plus_work_hrs', 'sum_65+_50_plus_work_hrs', 'mean_65+_50_plus_work_hrs', 'min_65+_40_plus_work_hrs', 'max_65+_40_plus_work_hrs', 'count_65+_40_plus_work_hrs', 'sum_65+_40_plus_work_hrs', 'mean_65+_40_plus_work_hrs', '%_65+_40_plus_work_hrs', 'any_65+_any_WKHP', 'all_65+_any_WKHP', 'min_65+_any_WKHP', 'max_65+_any_WKHP', 'count_65+_any_WKHP', 'sum_65+_any_WKHP', 'mean_65+_any_WKHP', '%_65+_any_WKHP', 'any_18-64_no_work_hrs', 'all_18-64_no_work_hrs', 'min_18-64_no_work_hrs', 'max_18-64_no_work_hrs', 'count_18-64_no_work_hrs', 'sum_18-64_no_work_hrs', 'mean_18-64_no_work_hrs', '%_18-64_no_work_hrs', 'any_18-64_<10_work_hrs', 'all_18-64_<10_work_hrs', 'min_18-64_<10_work_hrs', 'max_18-64_<10_work_hrs', 'count_18-64_<10_work_hrs', 'sum_18-64_<10_work_hrs', 'mean_18-64_<10_work_hrs', '%_18-64_<10_work_hrs', 'any_18-64_<15_work_hrs', 'all_18-64_<15_work_hrs', 'min_18-64_<15_work_hrs', 'max_18-64_<15_work_hrs', 'count_18-64_<15_work_hrs', 'sum_18-64_<15_work_hrs', 'mean_18-64_<15_work_hrs', '%_18-64_<15_work_hrs', 'any_18-64_<20_work_hrs', 'all_18-64_<20_work_hrs', 'min_18-64_<20_work_hrs', 'max_18-64_<20_work_hrs', 'count_18-64_<20_work_hrs', 'sum_18-64_<20_work_hrs', 'mean_18-64_<20_work_hrs', '%_18-64_<20_work_hrs', 'mean_18-64_<30_work_hrs', 'mean_18-64_<40_work_hrs', 'mean_18-64_<50_work_hrs', '%_18-64_<50_work_hrs', 'any_18-64_50_plus_work_hrs', 'all_18-64_50_plus_work_hrs', 'min_18-64_50_plus_work_hrs', 'max_18-64_50_plus_work_hrs', 'count_18-64_50_plus_work_hrs', 'sum_18-64_50_plus_work_hrs', 'mean_18-64_50_plus_work_hrs', '%_18-64_50_plus_work_hrs', 'max_18-64_40_plus_work_hrs', 'count_18-64_40_plus_work_hrs', 'mean_18-64_40_plus_work_hrs', 'any_18-64_any_WKHP', 'all_18-64_any_WKHP', 'min_18-64_any_WKHP', 'max_18-64_any_WKHP', 'count_18-64_any_WKHP', 'sum_18-64_any_WKHP', 'mean_18-64_any_WKHP', '%_18-64_any_WKHP', 'any_kid_no_work_hrs', 'all_kid_no_work_hrs', 'min_kid_no_work_hrs', 'max_kid_no_work_hrs', 'count_kid_no_work_hrs', 'sum_kid_no_work_hrs', 'mean_kid_no_work_hrs', '%_kid_no_work_hrs', 'any_kid_<10_work_hrs', 'all_kid_<10_work_hrs', 'min_kid_<10_work_hrs', 'max_kid_<10_work_hrs', 'count_kid_<10_work_hrs', 'sum_kid_<10_work_hrs', 'mean_kid_<10_work_hrs', '%_kid_<10_work_hrs', 'any_kid_<15_work_hrs', 'all_kid_<15_work_hrs', 'min_kid_<15_work_hrs', 'max_kid_<15_work_hrs', 'count_kid_<15_work_hrs', 'sum_kid_<15_work_hrs', 'mean_kid_<15_work_hrs', '%_kid_<15_work_hrs', 'any_kid_<20_work_hrs', 'all_kid_<20_work_hrs', 'min_kid_<20_work_hrs', 'max_kid_<20_work_hrs', 'count_kid_<20_work_hrs', 'sum_kid_<20_work_hrs', 'mean_kid_<20_work_hrs', '%_kid_<20_work_hrs', 'any_kid_<30_work_hrs', 'all_kid_<30_work_hrs', 'min_kid_<30_work_hrs', 'max_kid_<30_work_hrs', 'count_kid_<30_work_hrs', 'sum_kid_<30_work_hrs', 'mean_kid_<30_work_hrs', '%_kid_<30_work_hrs', 'any_kid_<40_work_hrs', 'all_kid_<40_work_hrs', 'min_kid_<40_work_hrs', 'max_kid_<40_work_hrs', 'count_kid_<40_work_hrs', 'sum_kid_<40_work_hrs', 'mean_kid_<40_work_hrs', '%_kid_<40_work_hrs', 'any_kid_<50_work_hrs', 'all_kid_<50_work_hrs', 'min_kid_<50_work_hrs', 'max_kid_<50_work_hrs', 'count_kid_<50_work_hrs', 'sum_kid_<50_work_hrs', 'mean_kid_<50_work_hrs', '%_kid_<50_work_hrs', 'max_kid_40_plus_work_hrs', 'sum_kid_40_plus_work_hrs', 'mean_kid_40_plus_work_hrs', 'any_kid_any_WKHP', 'all_kid_any_WKHP', 'min_kid_any_WKHP', 'max_kid_any_WKHP', 'count_kid_any_WKHP', 'sum_kid_any_WKHP', 'mean_kid_any_WKHP', '%_kid_any_WKHP', 'any_anyage_no_work_hrs', 'all_anyage_no_work_hrs', 'min_anyage_no_work_hrs', 'max_anyage_no_work_hrs', 'count_anyage_no_work_hrs', 'sum_anyage_no_work_hrs', 'mean_anyage_no_work_hrs', '%_anyage_no_work_hrs', 'any_anyage_<10_work_hrs', 'all_anyage_<10_work_hrs', 'min_anyage_<10_work_hrs', 'max_anyage_<10_work_hrs', 'count_anyage_<10_work_hrs', 'sum_anyage_<10_work_hrs', 'mean_anyage_<10_work_hrs', '%_anyage_<10_work_hrs', 'any_anyage_<15_work_hrs', 'all_anyage_<15_work_hrs', 'min_anyage_<15_work_hrs', 'max_anyage_<15_work_hrs', 'count_anyage_<15_work_hrs', 'sum_anyage_<15_work_hrs', 'mean_anyage_<15_work_hrs', '%_anyage_<15_work_hrs', 'any_anyage_<20_work_hrs', 'all_anyage_<20_work_hrs', 'min_anyage_<20_work_hrs', 'max_anyage_<20_work_hrs', 'count_anyage_<20_work_hrs', 'sum_anyage_<20_work_hrs', 'mean_anyage_<20_work_hrs', '%_anyage_<20_work_hrs', 'all_anyage_<30_work_hrs', 'min_anyage_<30_work_hrs', 'max_anyage_<30_work_hrs', 'count_anyage_<30_work_hrs', 'sum_anyage_<30_work_hrs', 'mean_anyage_<30_work_hrs', 'all_anyage_<40_work_hrs', 'max_anyage_<40_work_hrs', 'sum_anyage_<40_work_hrs', 'mean_anyage_<40_work_hrs', '%_anyage_<40_work_hrs', 'any_anyage_<50_work_hrs', 'all_anyage_<50_work_hrs', 'max_anyage_<50_work_hrs', 'count_anyage_<50_work_hrs', 'sum_anyage_<50_work_hrs', 'mean_anyage_<50_work_hrs', '%_anyage_<50_work_hrs', 'any_anyage_50_plus_work_hrs', 'all_anyage_50_plus_work_hrs', 'min_anyage_50_plus_work_hrs', 'max_anyage_50_plus_work_hrs', 'count_anyage_50_plus_work_hrs', 'sum_anyage_50_plus_work_hrs', 'mean_anyage_50_plus_work_hrs', '%_anyage_50_plus_work_hrs', 'any_anyage_40_plus_work_hrs', 'all_anyage_40_plus_work_hrs', 'min_anyage_40_plus_work_hrs', 'max_anyage_40_plus_work_hrs', 'count_anyage_40_plus_work_hrs', 'sum_anyage_40_plus_work_hrs', 'mean_anyage_40_plus_work_hrs', '%_anyage_40_plus_work_hrs', 'min_anyage_any_WKHP', 'max_anyage_any_WKHP', 'count_anyage_any_WKHP', 'sum_anyage_any_WKHP', 'mean_anyage_any_WKHP', 'max_adult_DIS', 'sum_adult_DIS', 'mean_adult_DIS', 'any_adult_not_DIS', 'all_adult_not_DIS', 'mean_adult_not_DIS', '%_adult_not_DIS', 'min_adult_any_DIS', 'max_adult_any_DIS', 'count_adult_any_DIS', 'sum_adult_any_DIS', 'mean_adult_any_DIS', 'min_65+_DIS', 'max_65+_DIS', 'count_65+_DIS', 'sum_65+_DIS', 'mean_65+_DIS', '%_65+_DIS', 'min_65+_not_DIS', 'max_65+_not_DIS', 'sum_65+_not_DIS', 'mean_65+_not_DIS', '%_65+_not_DIS', 'any_65+_any_DIS', 'all_65+_any_DIS', 'min_65+_any_DIS', 'max_65+_any_DIS', 'count_65+_any_DIS', 'sum_65+_any_DIS', 'mean_65+_any_DIS', '%_65+_any_DIS', 'min_18-64_DIS', 'max_18-64_DIS', 'sum_18-64_DIS', 'mean_18-64_DIS', 'mean_18-64_not_DIS', '%_18-64_not_DIS', 'any_18-64_any_DIS', 'all_18-64_any_DIS', 'min_18-64_any_DIS', 'max_18-64_any_DIS', 'count_18-64_any_DIS', 'sum_18-64_any_DIS', 'mean_18-64_any_DIS', '%_18-64_any_DIS', 'max_kid_DIS', 'mean_kid_DIS', 'any_kid_not_DIS', 'all_kid_not_DIS', 'min_kid_not_DIS', 'max_kid_not_DIS', 'count_kid_not_DIS', 'sum_kid_not_DIS', 'mean_kid_not_DIS', '%_kid_not_DIS', 'any_kid_any_DIS', 'all_kid_any_DIS', 'min_kid_any_DIS', 'max_kid_any_DIS', 'count_kid_any_DIS', 'sum_kid_any_DIS', 'mean_kid_any_DIS', '%_kid_any_DIS', 'any_anyage_DIS', 'all_anyage_DIS', 'min_anyage_DIS', 'max_anyage_DIS', 'count_anyage_DIS', 'sum_anyage_DIS', 'mean_anyage_DIS', '%_anyage_DIS', 'any_anyage_not_DIS', 'all_anyage_not_DIS', 'max_anyage_not_DIS', 'sum_anyage_not_DIS', '%_anyage_not_DIS', 'min_anyage_any_DIS', 'max_anyage_any_DIS', 'count_anyage_any_DIS', 'sum_anyage_any_DIS', 'mean_anyage_any_DIS', 'all_adult_NP1', 'max_adult_NP1', 'count_adult_NP1', 'sum_adult_NP1', 'mean_adult_NP1', '%_adult_NP1', 'all_adult_NP2', 'max_adult_NP2', 'count_adult_NP2', 'sum_adult_NP2', 'mean_adult_NP2', '%_adult_NP2', 'all_adult_NP3', 'count_adult_NP3', 'sum_adult_NP3', 'mean_adult_NP3', '%_adult_NP3', 'all_adult_NP4', 'max_adult_NP4', 'sum_adult_NP4', 'mean_adult_NP4', '%_adult_NP4', 'all_adult_NP5', 'max_adult_NP5', 'sum_adult_NP5', 'mean_adult_NP5', '%_adult_NP5', 'all_adult_NP>5', 'sum_adult_NP>5', 'mean_adult_NP>5', '%_adult_NP>5', 'all_adult_NP>6', 'max_adult_NP>6', 'sum_adult_NP>6', 'mean_adult_NP>6', '%_adult_NP>6', 'all_adult_NP>8', 'max_adult_NP>8', 'sum_adult_NP>8', 'mean_adult_NP>8', '%_adult_NP>8', 'sum_adult_NP>10', 'mean_adult_NP>10', 'sum_adult_NP>12', 'mean_adult_NP>12', 'min_adult_anyNP', 'max_adult_anyNP', 'count_adult_anyNP', 'sum_adult_anyNP', 'mean_adult_anyNP', 'all_65+_NP1', 'min_65+_NP1', 'max_65+_NP1', 'count_65+_NP1', 'sum_65+_NP1', 'mean_65+_NP1', '%_65+_NP1', 'all_65+_NP2', 'min_65+_NP2', 'max_65+_NP2', 'sum_65+_NP2', 'mean_65+_NP2', '%_65+_NP2', 'all_65+_NP3', 'min_65+_NP3', 'max_65+_NP3', 'sum_65+_NP3', 'mean_65+_NP3', '%_65+_NP3', 'all_65+_NP4', 'min_65+_NP4', 'max_65+_NP4', 'sum_65+_NP4', 'mean_65+_NP4', '%_65+_NP4', 'all_65+_NP5', 'min_65+_NP5', 'max_65+_NP5', 'sum_65+_NP5', 'mean_65+_NP5', '%_65+_NP5', 'all_65+_NP>5', 'min_65+_NP>5', 'max_65+_NP>5', 'sum_65+_NP>5', 'mean_65+_NP>5', '%_65+_NP>5', 'max_65+_NP>6', 'sum_65+_NP>6', 'mean_65+_NP>6', 'max_65+_NP>8', 'mean_65+_NP>8', 'max_65+_NP>10', 'mean_65+_NP>10', 'max_65+_NP>12', 'sum_65+_NP>12', 'mean_65+_NP>12', 'any_65+_anyNP', 'all_65+_anyNP', 'min_65+_anyNP', 'max_65+_anyNP', 'count_65+_anyNP', 'sum_65+_anyNP', 'mean_65+_anyNP', '%_65+_anyNP', 'all_18-64_NP1', 'min_18-64_NP1', 'max_18-64_NP1', 'count_18-64_NP1', 'sum_18-64_NP1', 'mean_18-64_NP1', '%_18-64_NP1', 'all_18-64_NP2', 'max_18-64_NP2', 'sum_18-64_NP2', 'mean_18-64_NP2', '%_18-64_NP2', 'any_18-64_NP3', 'all_18-64_NP3', 'min_18-64_NP3', 'max_18-64_NP3', 'sum_18-64_NP3', 'mean_18-64_NP3', '%_18-64_NP3', 'any_18-64_NP4', 'all_18-64_NP4', 'min_18-64_NP4', 'max_18-64_NP4', 'count_18-64_NP4', 'sum_18-64_NP4', 'mean_18-64_NP4', '%_18-64_NP4', 'any_18-64_NP5', 'all_18-64_NP5', 'min_18-64_NP5', 'max_18-64_NP5', 'count_18-64_NP5', 'sum_18-64_NP5', 'mean_18-64_NP5', '%_18-64_NP5', 'any_18-64_NP>5', 'all_18-64_NP>5', 'max_18-64_NP>5', 'count_18-64_NP>5', 'sum_18-64_NP>5', 'mean_18-64_NP>5', '%_18-64_NP>5', 'any_18-64_NP>6', 'all_18-64_NP>6', 'min_18-64_NP>6', 'max_18-64_NP>6', 'count_18-64_NP>6', 'sum_18-64_NP>6', 'mean_18-64_NP>6', '%_18-64_NP>6', 'max_18-64_NP>8', 'count_18-64_NP>8', 'sum_18-64_NP>8', 'mean_18-64_NP>8', 'min_18-64_NP>10', 'max_18-64_NP>10', 'count_18-64_NP>10', 'sum_18-64_NP>10', 'mean_18-64_NP>10', 'min_18-64_NP>12', 'max_18-64_NP>12', 'count_18-64_NP>12', 'sum_18-64_NP>12', 'mean_18-64_NP>12', 'any_18-64_anyNP', 'all_18-64_anyNP', 'min_18-64_anyNP', 'max_18-64_anyNP', 'count_18-64_anyNP', 'sum_18-64_anyNP', 'mean_18-64_anyNP', '%_18-64_anyNP', 'max_kid_NP1', 'sum_kid_NP1', 'mean_kid_NP1', 'all_kid_NP2', 'max_kid_NP2', 'count_kid_NP2', 'sum_kid_NP2', 'mean_kid_NP2', '%_kid_NP2', 'max_kid_NP3', 'count_kid_NP3', 'sum_kid_NP3', 'mean_kid_NP3', '%_kid_NP3', 'all_kid_NP4', 'count_kid_NP4', 'sum_kid_NP4', 'mean_kid_NP4', '%_kid_NP4', 'all_kid_NP5', 'mean_kid_NP5', '%_kid_NP5', 'all_kid_NP>5', 'mean_kid_NP>5', '%_kid_NP>5', 'all_kid_NP>6', 'mean_kid_NP>6', '%_kid_NP>6', 'sum_kid_NP>8', 'mean_kid_NP>8', 'mean_kid_NP>10', 'sum_kid_NP>12', 'mean_kid_NP>12', 'any_kid_anyNP', 'all_kid_anyNP', 'min_kid_anyNP', 'max_kid_anyNP', 'count_kid_anyNP', 'sum_kid_anyNP', 'mean_kid_anyNP', '%_kid_anyNP', 'any_anyage_NP1', 'all_anyage_NP1', 'min_anyage_NP1', 'max_anyage_NP1', 'count_anyage_NP1', 'sum_anyage_NP1', 'mean_anyage_NP1', '%_anyage_NP1', 'any_anyage_NP2', 'all_anyage_NP2', 'min_anyage_NP2', 'max_anyage_NP2', 'count_anyage_NP2', 'sum_anyage_NP2', 'mean_anyage_NP2', '%_anyage_NP2', 'any_anyage_NP3', 'all_anyage_NP3', 'max_anyage_NP3', 'count_anyage_NP3', 'sum_anyage_NP3', 'mean_anyage_NP3', '%_anyage_NP3', 'any_anyage_NP4', 'all_anyage_NP4', 'max_anyage_NP4', 'count_anyage_NP4', 'sum_anyage_NP4', 'mean_anyage_NP4', '%_anyage_NP4', 'any_anyage_NP5', 'all_anyage_NP5', 'max_anyage_NP5', 'sum_anyage_NP5', 'mean_anyage_NP5', '%_anyage_NP5', 'any_anyage_NP>5', 'all_anyage_NP>5', 'max_anyage_NP>5', 'sum_anyage_NP>5', 'mean_anyage_NP>5', '%_anyage_NP>5', 'any_anyage_NP>6', 'all_anyage_NP>6', 'max_anyage_NP>6', 'sum_anyage_NP>6', 'mean_anyage_NP>6', '%_anyage_NP>6', 'any_anyage_NP>8', 'all_anyage_NP>8', 'max_anyage_NP>8', 'sum_anyage_NP>8', 'mean_anyage_NP>8', '%_anyage_NP>8', 'max_anyage_NP>10', 'sum_anyage_NP>10', 'mean_anyage_NP>10', 'min_anyage_NP>12', 'max_anyage_NP>12', 'count_anyage_NP>12', 'sum_anyage_NP>12', 'mean_anyage_NP>12', 'min_anyage_anyNP', 'max_anyage_anyNP', 'count_anyage_anyNP', 'sum_anyage_anyNP', 'mean_anyage_anyNP', 'count_adult_work_trans', 'all_65+_work_trans', 'count_65+_work_trans', 'sum_65+_work_trans', 'mean_65+_work_trans', '%_65+_work_trans', 'all_18-64_work_trans', 'count_18-64_work_trans', 'sum_18-64_work_trans', '%_18-64_work_trans', 'all_kid_work_trans', 'count_kid_work_trans', 'sum_kid_work_trans', '%_kid_work_trans', 'any_anyage_work_trans', 'max_anyage_work_trans', 'count_anyage_work_trans', 'sum_anyage_work_trans', 'mean_anyage_work_trans', 'max_adult_WAG0', 'sum_adult_WAG0', 'mean_adult_WAG0', 'sum_adult_WAG<10', 'mean_adult_WAG<10', 'min_adult_WAG<15', 'max_adult_WAG<15', 'sum_adult_WAG<15', 'mean_adult_WAG<15', 'min_adult_WAG<20', 'max_adult_WAG<20', 'count_adult_WAG<20', 'sum_adult_WAG<20', 'mean_adult_WAG<20', 'min_adult_WAG<25', 'max_adult_WAG<25', 'count_adult_WAG<25', 'sum_adult_WAG<25', 'mean_adult_WAG<25', 'min_adult_WAG<30', 'max_adult_WAG<30', 'count_adult_WAG<30', 'sum_adult_WAG<30', 'mean_adult_WAG<30', 'min_adult_WAG<35', 'max_adult_WAG<35', 'count_adult_WAG<35', 'sum_adult_WAG<35', 'mean_adult_WAG<35', 'min_adult_WAG<40', 'max_adult_WAG<40', 'count_adult_WAG<40', 'sum_adult_WAG<40', 'mean_adult_WAG<40', 'min_adult_WAG<45', 'max_adult_WAG<45', 'count_adult_WAG<45', 'sum_adult_WAG<45', 'mean_adult_WAG<45', 'min_adult_WAG<50', 'max_adult_WAG<50', 'count_adult_WAG<50', 'sum_adult_WAG<50', 'mean_adult_WAG<50', 'max_adult_WAG<60', 'count_adult_WAG<60', 'sum_adult_WAG<60', 'mean_adult_WAG<60', 'max_adult_WAG<70', 'count_adult_WAG<70', 'sum_adult_WAG<70', 'mean_adult_WAG<70', 'min_adult_WAG<80', 'max_adult_WAG<80', 'count_adult_WAG<80', 'sum_adult_WAG<80', 'mean_adult_WAG<80', 'min_adult_WAG_any', 'max_adult_WAG_any', 'count_adult_WAG_any', 'sum_adult_WAG_any', 'mean_adult_WAG_any', 'any_65+_WAG0', 'all_65+_WAG0', 'min_65+_WAG0', 'max_65+_WAG0', 'count_65+_WAG0', 'sum_65+_WAG0', 'mean_65+_WAG0', '%_65+_WAG0', 'any_65+_WAG<10', 'all_65+_WAG<10', 'min_65+_WAG<10', 'max_65+_WAG<10', 'count_65+_WAG<10', 'sum_65+_WAG<10', 'mean_65+_WAG<10', '%_65+_WAG<10', 'any_65+_WAG<15', 'all_65+_WAG<15', 'min_65+_WAG<15', 'max_65+_WAG<15', 'count_65+_WAG<15', 'sum_65+_WAG<15', 'mean_65+_WAG<15', '%_65+_WAG<15', 'any_65+_WAG<20', 'all_65+_WAG<20', 'min_65+_WAG<20', 'max_65+_WAG<20', 'count_65+_WAG<20', 'sum_65+_WAG<20', 'mean_65+_WAG<20', '%_65+_WAG<20', 'any_65+_WAG<25', 'all_65+_WAG<25', 'min_65+_WAG<25', 'max_65+_WAG<25', 'count_65+_WAG<25', 'sum_65+_WAG<25', 'mean_65+_WAG<25', '%_65+_WAG<25', 'any_65+_WAG<30', 'all_65+_WAG<30', 'min_65+_WAG<30', 'max_65+_WAG<30', 'count_65+_WAG<30', 'sum_65+_WAG<30', 'mean_65+_WAG<30', '%_65+_WAG<30', 'any_65+_WAG<35', 'all_65+_WAG<35', 'min_65+_WAG<35', 'max_65+_WAG<35', 'count_65+_WAG<35', 'sum_65+_WAG<35', 'mean_65+_WAG<35', '%_65+_WAG<35', 'any_65+_WAG<40', 'all_65+_WAG<40', 'min_65+_WAG<40', 'max_65+_WAG<40', 'count_65+_WAG<40', 'sum_65+_WAG<40', 'mean_65+_WAG<40', '%_65+_WAG<40', 'any_65+_WAG<45', 'all_65+_WAG<45', 'min_65+_WAG<45', 'max_65+_WAG<45', 'count_65+_WAG<45', 'sum_65+_WAG<45', 'mean_65+_WAG<45', '%_65+_WAG<45', 'any_65+_WAG<50', 'all_65+_WAG<50', 'min_65+_WAG<50', 'max_65+_WAG<50', 'count_65+_WAG<50', 'sum_65+_WAG<50', 'mean_65+_WAG<50', '%_65+_WAG<50', 'any_65+_WAG<60', 'all_65+_WAG<60', 'min_65+_WAG<60', 'max_65+_WAG<60', 'count_65+_WAG<60', 'sum_65+_WAG<60', 'mean_65+_WAG<60', '%_65+_WAG<60', 'any_65+_WAG<70', 'all_65+_WAG<70', 'min_65+_WAG<70', 'max_65+_WAG<70', 'count_65+_WAG<70', 'sum_65+_WAG<70', 'mean_65+_WAG<70', '%_65+_WAG<70', 'any_65+_WAG<80', 'all_65+_WAG<80', 'min_65+_WAG<80', 'max_65+_WAG<80', 'count_65+_WAG<80', 'sum_65+_WAG<80', 'mean_65+_WAG<80', '%_65+_WAG<80', 'any_65+_WAG_any', 'all_65+_WAG_any', 'min_65+_WAG_any', 'max_65+_WAG_any', 'count_65+_WAG_any', 'sum_65+_WAG_any', 'mean_65+_WAG_any', '%_65+_WAG_any', 'max_18-64_WAG0', 'mean_18-64_WAG0', 'mean_18-64_WAG<10', 'mean_18-64_WAG<15', 'count_18-64_WAG<20', 'sum_18-64_WAG<20', 'mean_18-64_WAG<20', 'count_18-64_WAG<25', 'sum_18-64_WAG<25', 'mean_18-64_WAG<25', 'max_18-64_WAG<30', 'count_18-64_WAG<30', 'sum_18-64_WAG<30', 'mean_18-64_WAG<30', 'max_18-64_WAG<35', 'count_18-64_WAG<35', 'sum_18-64_WAG<35', 'mean_18-64_WAG<35', 'max_18-64_WAG<40', 'count_18-64_WAG<40', 'sum_18-64_WAG<40', 'mean_18-64_WAG<40', 'any_18-64_WAG<45', 'max_18-64_WAG<45', 'count_18-64_WAG<45', 'sum_18-64_WAG<45', 'mean_18-64_WAG<45', 'any_18-64_WAG<50', 'min_18-64_WAG<50', 'max_18-64_WAG<50', 'count_18-64_WAG<50', 'sum_18-64_WAG<50', 'mean_18-64_WAG<50', '%_18-64_WAG<50', 'count_18-64_WAG<60', 'sum_18-64_WAG<60', 'mean_18-64_WAG<60', 'count_18-64_WAG<70', 'sum_18-64_WAG<70', 'mean_18-64_WAG<70', 'max_18-64_WAG<80', 'count_18-64_WAG<80', 'sum_18-64_WAG<80', 'mean_18-64_WAG<80', 'any_18-64_WAG_any', 'all_18-64_WAG_any', 'min_18-64_WAG_any', 'max_18-64_WAG_any', 'count_18-64_WAG_any', 'sum_18-64_WAG_any', 'mean_18-64_WAG_any', '%_18-64_WAG_any', 'any_kid_WAG0', 'all_kid_WAG0', 'min_kid_WAG0', 'max_kid_WAG0', 'count_kid_WAG0', 'sum_kid_WAG0', 'mean_kid_WAG0', '%_kid_WAG0', 'any_kid_WAG<10', 'all_kid_WAG<10', 'min_kid_WAG<10', 'max_kid_WAG<10', 'count_kid_WAG<10', 'sum_kid_WAG<10', 'mean_kid_WAG<10', '%_kid_WAG<10', 'any_kid_WAG<15', 'all_kid_WAG<15', 'min_kid_WAG<15', 'max_kid_WAG<15', 'count_kid_WAG<15', 'sum_kid_WAG<15', 'mean_kid_WAG<15', '%_kid_WAG<15', 'any_kid_WAG<20', 'all_kid_WAG<20', 'min_kid_WAG<20', 'max_kid_WAG<20', 'count_kid_WAG<20', 'sum_kid_WAG<20', 'mean_kid_WAG<20', '%_kid_WAG<20', 'any_kid_WAG<25', 'all_kid_WAG<25', 'min_kid_WAG<25', 'max_kid_WAG<25', 'count_kid_WAG<25', 'sum_kid_WAG<25', 'mean_kid_WAG<25', '%_kid_WAG<25', 'any_kid_WAG<30', 'all_kid_WAG<30', 'min_kid_WAG<30', 'max_kid_WAG<30', 'count_kid_WAG<30', 'sum_kid_WAG<30', 'mean_kid_WAG<30', '%_kid_WAG<30', 'any_kid_WAG<35', 'all_kid_WAG<35', 'min_kid_WAG<35', 'max_kid_WAG<35', 'count_kid_WAG<35', 'sum_kid_WAG<35', 'mean_kid_WAG<35', '%_kid_WAG<35', 'any_kid_WAG<40', 'all_kid_WAG<40', 'min_kid_WAG<40', 'max_kid_WAG<40', 'count_kid_WAG<40', 'sum_kid_WAG<40', 'mean_kid_WAG<40', '%_kid_WAG<40', 'any_kid_WAG<45', 'all_kid_WAG<45', 'min_kid_WAG<45', 'max_kid_WAG<45', 'count_kid_WAG<45', 'sum_kid_WAG<45', 'mean_kid_WAG<45', '%_kid_WAG<45', 'any_kid_WAG<50', 'all_kid_WAG<50', 'min_kid_WAG<50', 'max_kid_WAG<50', 'count_kid_WAG<50', 'sum_kid_WAG<50', 'mean_kid_WAG<50', '%_kid_WAG<50', 'any_kid_WAG<60', 'all_kid_WAG<60', 'min_kid_WAG<60', 'max_kid_WAG<60', 'count_kid_WAG<60', 'sum_kid_WAG<60', 'mean_kid_WAG<60', '%_kid_WAG<60', 'any_kid_WAG<70', 'all_kid_WAG<70', 'min_kid_WAG<70', 'max_kid_WAG<70', 'count_kid_WAG<70', 'sum_kid_WAG<70', 'mean_kid_WAG<70', '%_kid_WAG<70', 'any_kid_WAG<80', 'all_kid_WAG<80', 'min_kid_WAG<80', 'max_kid_WAG<80', 'count_kid_WAG<80', 'sum_kid_WAG<80', 'mean_kid_WAG<80', '%_kid_WAG<80', 'any_kid_WAG_any', 'all_kid_WAG_any', 'min_kid_WAG_any', 'max_kid_WAG_any', 'count_kid_WAG_any', 'sum_kid_WAG_any', 'mean_kid_WAG_any', '%_kid_WAG_any', 'all_anyage_WAG0', 'min_anyage_WAG0', 'max_anyage_WAG0', 'count_anyage_WAG0', 'sum_anyage_WAG0', 'mean_anyage_WAG0', 'all_anyage_WAG<10', 'max_anyage_WAG<10', 'count_anyage_WAG<10', 'sum_anyage_WAG<10', 'mean_anyage_WAG<10', 'all_anyage_WAG<15', 'min_anyage_WAG<15', 'max_anyage_WAG<15', 'count_anyage_WAG<15', 'sum_anyage_WAG<15', 'mean_anyage_WAG<15', 'all_anyage_WAG<20', 'min_anyage_WAG<20', 'max_anyage_WAG<20', 'count_anyage_WAG<20', 'sum_anyage_WAG<20', 'mean_anyage_WAG<20', 'all_anyage_WAG<25', 'min_anyage_WAG<25', 'max_anyage_WAG<25', 'count_anyage_WAG<25', 'sum_anyage_WAG<25', 'mean_anyage_WAG<25', '%_anyage_WAG<25', 'all_anyage_WAG<30', 'min_anyage_WAG<30', 'max_anyage_WAG<30', 'count_anyage_WAG<30', 'sum_anyage_WAG<30', 'mean_anyage_WAG<30', '%_anyage_WAG<30', 'all_anyage_WAG<35', 'min_anyage_WAG<35', 'max_anyage_WAG<35', 'count_anyage_WAG<35', 'sum_anyage_WAG<35', 'mean_anyage_WAG<35', '%_anyage_WAG<35', 'all_anyage_WAG<40', 'min_anyage_WAG<40', 'max_anyage_WAG<40', 'count_anyage_WAG<40', 'sum_anyage_WAG<40', 'mean_anyage_WAG<40', '%_anyage_WAG<40', 'all_anyage_WAG<45', 'min_anyage_WAG<45', 'max_anyage_WAG<45', 'count_anyage_WAG<45', 'sum_anyage_WAG<45', 'mean_anyage_WAG<45', '%_anyage_WAG<45', 'all_anyage_WAG<50', 'min_anyage_WAG<50', 'max_anyage_WAG<50', 'count_anyage_WAG<50', 'sum_anyage_WAG<50', 'mean_anyage_WAG<50', '%_anyage_WAG<50', 'all_anyage_WAG<60', 'min_anyage_WAG<60', 'max_anyage_WAG<60', 'count_anyage_WAG<60', 'sum_anyage_WAG<60', 'mean_anyage_WAG<60', '%_anyage_WAG<60', 'all_anyage_WAG<70', 'min_anyage_WAG<70', 'max_anyage_WAG<70', 'count_anyage_WAG<70', 'sum_anyage_WAG<70', 'mean_anyage_WAG<70', '%_anyage_WAG<70', 'all_anyage_WAG<80', 'min_anyage_WAG<80', 'max_anyage_WAG<80', 'count_anyage_WAG<80', 'sum_anyage_WAG<80', 'mean_anyage_WAG<80', '%_anyage_WAG<80', 'min_anyage_WAG_any', 'max_anyage_WAG_any', 'count_anyage_WAG_any', 'sum_anyage_WAG_any', 'mean_anyage_WAG_any', 'max_adult_INT1q', 'sum_adult_INT1q', 'mean_adult_INT1q', 'max_adult_INT2q', 'count_adult_INT2q', 'sum_adult_INT2q', 'mean_adult_INT2q', 'min_adult_INT3q', 'max_adult_INT3q', 'count_adult_INT3q', 'sum_adult_INT3q', 'mean_adult_INT3q', 'min_adult_INT4q', 'max_adult_INT4q', 'count_adult_INT4q', 'sum_adult_INT4q', 'mean_adult_INT4q', 'min_adult_INT_any', 'max_adult_INT_any', 'count_adult_INT_any', 'sum_adult_INT_any', 'mean_adult_INT_any', 'all_65+_INT0', 'min_65+_INT0', 'max_65+_INT0', 'sum_65+_INT0', 'mean_65+_INT0', '%_65+_INT0', 'min_65+_INT1q', 'max_65+_INT1q', 'count_65+_INT1q', 'sum_65+_INT1q', 'mean_65+_INT1q', '%_65+_INT1q', 'min_65+_INT2q', 'max_65+_INT2q', 'count_65+_INT2q', 'sum_65+_INT2q', 'mean_65+_INT2q', '%_65+_INT2q', 'min_65+_INT3q', 'max_65+_INT3q', 'count_65+_INT3q', 'sum_65+_INT3q', 'mean_65+_INT3q', '%_65+_INT3q', 'min_65+_INT4q', 'max_65+_INT4q', 'count_65+_INT4q', 'sum_65+_INT4q', 'mean_65+_INT4q', '%_65+_INT4q', 'any_65+_INT_any', 'all_65+_INT_any', 'min_65+_INT_any', 'max_65+_INT_any', 'count_65+_INT_any', 'sum_65+_INT_any', 'mean_65+_INT_any', '%_65+_INT_any', 'mean_18-64_INT0', '%_18-64_INT0', 'min_18-64_INT1q', 'max_18-64_INT1q', 'sum_18-64_INT1q', 'mean_18-64_INT1q', 'min_18-64_INT2q', 'max_18-64_INT2q', 'count_18-64_INT2q', 'sum_18-64_INT2q', 'mean_18-64_INT2q', 'min_18-64_INT3q', 'max_18-64_INT3q', 'count_18-64_INT3q', 'sum_18-64_INT3q', 'mean_18-64_INT3q', 'min_18-64_INT4q', 'max_18-64_INT4q', 'count_18-64_INT4q', 'sum_18-64_INT4q', 'mean_18-64_INT4q', 'any_18-64_INT_any', 'all_18-64_INT_any', 'min_18-64_INT_any', 'max_18-64_INT_any', 'count_18-64_INT_any', 'sum_18-64_INT_any', 'mean_18-64_INT_any', '%_18-64_INT_any', 'any_kid_INT0', 'all_kid_INT0', 'min_kid_INT0', 'max_kid_INT0', 'count_kid_INT0', 'sum_kid_INT0', 'mean_kid_INT0', '%_kid_INT0', 'max_kid_INT1q', 'sum_kid_INT1q', 'mean_kid_INT1q', 'max_kid_INT2q', 'sum_kid_INT2q', 'mean_kid_INT2q', 'max_kid_INT3q', 'sum_kid_INT3q', 'mean_kid_INT3q', 'any_kid_INT_any', 'all_kid_INT_any', 'min_kid_INT_any', 'max_kid_INT_any', 'count_kid_INT_any', 'sum_kid_INT_any', 'mean_kid_INT_any', '%_kid_INT_any', 'all_anyage_INT0', 'max_anyage_INT0', 'count_anyage_INT0', 'sum_anyage_INT0', '%_anyage_INT0', 'any_anyage_INT1q', 'all_anyage_INT1q', 'min_anyage_INT1q', 'max_anyage_INT1q', 'count_anyage_INT1q', 'sum_anyage_INT1q', 'mean_anyage_INT1q', '%_anyage_INT1q', 'any_anyage_INT2q', 'all_anyage_INT2q', 'min_anyage_INT2q', 'max_anyage_INT2q', 'count_anyage_INT2q', 'sum_anyage_INT2q', 'mean_anyage_INT2q', '%_anyage_INT2q', 'any_anyage_INT3q', 'all_anyage_INT3q', 'min_anyage_INT3q', 'max_anyage_INT3q', 'count_anyage_INT3q', 'sum_anyage_INT3q', 'mean_anyage_INT3q', '%_anyage_INT3q', 'any_anyage_INT4q', 'all_anyage_INT4q', 'min_anyage_INT4q', 'max_anyage_INT4q', 'count_anyage_INT4q', 'sum_anyage_INT4q', 'mean_anyage_INT4q', '%_anyage_INT4q', 'min_anyage_INT_any', 'max_anyage_INT_any', 'count_anyage_INT_any', 'sum_anyage_INT_any', 'mean_anyage_INT_any', 'sum_adult_SEMP0', 'max_adult_SEMP1q', 'count_adult_SEMP1q', 'sum_adult_SEMP1q', 'mean_adult_SEMP1q', 'min_adult_SEMP2q', 'max_adult_SEMP2q', 'count_adult_SEMP2q', 'sum_adult_SEMP2q', 'mean_adult_SEMP2q', 'min_adult_SEMP3q', 'max_adult_SEMP3q', 'count_adult_SEMP3q', 'sum_adult_SEMP3q', 'mean_adult_SEMP3q', 'min_adult_SEMP4q', 'max_adult_SEMP4q', 'count_adult_SEMP4q', 'sum_adult_SEMP4q', 'mean_adult_SEMP4q', 'min_adult_SEMP_any', 'max_adult_SEMP_any', 'count_adult_SEMP_any', 'sum_adult_SEMP_any', 'mean_adult_SEMP_any', 'any_65+_SEMP0', 'all_65+_SEMP0', 'min_65+_SEMP0', 'max_65+_SEMP0', 'count_65+_SEMP0', 'sum_65+_SEMP0', 'mean_65+_SEMP0', '%_65+_SEMP0', 'max_65+_SEMP1q', 'sum_65+_SEMP1q', 'mean_65+_SEMP1q', 'max_65+_SEMP2q', 'sum_65+_SEMP2q', 'mean_65+_SEMP2q', 'max_65+_SEMP3q', 'sum_65+_SEMP3q', 'mean_65+_SEMP3q', 'max_65+_SEMP4q', 'sum_65+_SEMP4q', 'mean_65+_SEMP4q', 'any_65+_SEMP_any', 'all_65+_SEMP_any', 'min_65+_SEMP_any', 'max_65+_SEMP_any', 'count_65+_SEMP_any', 'sum_65+_SEMP_any', 'mean_65+_SEMP_any', '%_65+_SEMP_any', 'count_18-64_SEMP0', 'sum_18-64_SEMP0', 'mean_18-64_SEMP0', '%_18-64_SEMP0', 'min_18-64_SEMP1q', 'max_18-64_SEMP1q', 'count_18-64_SEMP1q', 'sum_18-64_SEMP1q', 'mean_18-64_SEMP1q', 'min_18-64_SEMP2q', 'max_18-64_SEMP2q', 'count_18-64_SEMP2q', 'sum_18-64_SEMP2q', 'mean_18-64_SEMP2q', 'any_18-64_SEMP3q', 'min_18-64_SEMP3q', 'max_18-64_SEMP3q', 'count_18-64_SEMP3q', 'sum_18-64_SEMP3q', 'mean_18-64_SEMP3q', 'min_18-64_SEMP4q', 'max_18-64_SEMP4q', 'count_18-64_SEMP4q', 'sum_18-64_SEMP4q', 'mean_18-64_SEMP4q', 'any_18-64_SEMP_any', 'all_18-64_SEMP_any', 'min_18-64_SEMP_any', 'max_18-64_SEMP_any', 'count_18-64_SEMP_any', 'sum_18-64_SEMP_any', 'mean_18-64_SEMP_any', '%_18-64_SEMP_any', 'any_kid_SEMP0', 'all_kid_SEMP0', 'min_kid_SEMP0', 'max_kid_SEMP0', 'count_kid_SEMP0', 'sum_kid_SEMP0', 'mean_kid_SEMP0', '%_kid_SEMP0', 'max_kid_SEMP1q', 'sum_kid_SEMP1q', 'mean_kid_SEMP1q', 'any_kid_SEMP_any', 'all_kid_SEMP_any', 'min_kid_SEMP_any', 'max_kid_SEMP_any', 'count_kid_SEMP_any', 'sum_kid_SEMP_any', 'mean_kid_SEMP_any', '%_kid_SEMP_any', 'all_anyage_SEMP0', 'max_anyage_SEMP0', 'count_anyage_SEMP0', 'sum_anyage_SEMP0', '%_anyage_SEMP0', 'any_anyage_SEMP1q', 'min_anyage_SEMP1q', 'max_anyage_SEMP1q', 'count_anyage_SEMP1q', 'sum_anyage_SEMP1q', 'mean_anyage_SEMP1q', 'any_anyage_SEMP2q', 'min_anyage_SEMP2q', 'max_anyage_SEMP2q', 'count_anyage_SEMP2q', 'sum_anyage_SEMP2q', 'mean_anyage_SEMP2q', '%_anyage_SEMP2q', 'any_anyage_SEMP3q', 'min_anyage_SEMP3q', 'max_anyage_SEMP3q', 'count_anyage_SEMP3q', 'sum_anyage_SEMP3q', 'mean_anyage_SEMP3q', 'any_anyage_SEMP4q', 'min_anyage_SEMP4q', 'max_anyage_SEMP4q', 'count_anyage_SEMP4q', 'sum_anyage_SEMP4q', 'mean_anyage_SEMP4q', '%_anyage_SEMP4q', 'min_anyage_SEMP_any', 'max_anyage_SEMP_any', 'count_anyage_SEMP_any', 'sum_anyage_SEMP_any', 'mean_anyage_SEMP_any', 'mean_adult_SSP0', 'min_adult_SSP1q', 'max_adult_SSP1q', 'count_adult_SSP1q', 'sum_adult_SSP1q', 'mean_adult_SSP1q', 'min_adult_SSP2q', 'max_adult_SSP2q', 'count_adult_SSP2q', 'sum_adult_SSP2q', 'mean_adult_SSP2q', 'min_adult_SSP3q', 'max_adult_SSP3q', 'count_adult_SSP3q', 'sum_adult_SSP3q', 'mean_adult_SSP3q', 'min_adult_SSP4q', 'max_adult_SSP4q', 'count_adult_SSP4q', 'sum_adult_SSP4q', 'mean_adult_SSP4q', 'min_adult_SSP_any', 'max_adult_SSP_any', 'count_adult_SSP_any', 'sum_adult_SSP_any', 'mean_adult_SSP_any', 'min_65+_SSP0', 'max_65+_SSP0', 'count_65+_SSP0', 'sum_65+_SSP0', 'mean_65+_SSP0', '%_65+_SSP0', 'min_65+_SSP1q', 'max_65+_SSP1q', 'count_65+_SSP1q', 'sum_65+_SSP1q', 'mean_65+_SSP1q', '%_65+_SSP1q', 'min_65+_SSP2q', 'max_65+_SSP2q', 'count_65+_SSP2q', 'sum_65+_SSP2q', 'mean_65+_SSP2q', '%_65+_SSP2q', 'any_65+_SSP3q', 'min_65+_SSP3q', 'max_65+_SSP3q', 'count_65+_SSP3q', 'sum_65+_SSP3q', 'mean_65+_SSP3q', '%_65+_SSP3q', 'any_65+_SSP4q', 'min_65+_SSP4q', 'max_65+_SSP4q', 'count_65+_SSP4q', 'sum_65+_SSP4q', 'mean_65+_SSP4q', '%_65+_SSP4q', 'any_65+_SSP_any', 'all_65+_SSP_any', 'min_65+_SSP_any', 'max_65+_SSP_any', 'count_65+_SSP_any', 'sum_65+_SSP_any', 'mean_65+_SSP_any', '%_65+_SSP_any', 'count_18-64_SSP0', 'sum_18-64_SSP0', 'mean_18-64_SSP0', '%_18-64_SSP0', 'min_18-64_SSP1q', 'max_18-64_SSP1q', 'count_18-64_SSP1q', 'sum_18-64_SSP1q', 'mean_18-64_SSP1q', 'min_18-64_SSP2q', 'max_18-64_SSP2q', 'count_18-64_SSP2q', 'sum_18-64_SSP2q', 'mean_18-64_SSP2q', 'min_18-64_SSP3q', 'max_18-64_SSP3q', 'count_18-64_SSP3q', 'sum_18-64_SSP3q', 'mean_18-64_SSP3q', 'min_18-64_SSP4q', 'max_18-64_SSP4q', 'count_18-64_SSP4q', 'sum_18-64_SSP4q', 'mean_18-64_SSP4q', 'any_18-64_SSP_any', 'all_18-64_SSP_any', 'min_18-64_SSP_any', 'max_18-64_SSP_any', 'count_18-64_SSP_any', 'sum_18-64_SSP_any', 'mean_18-64_SSP_any', '%_18-64_SSP_any', 'any_kid_SSP0', 'all_kid_SSP0', 'min_kid_SSP0', 'max_kid_SSP0', 'count_kid_SSP0', 'sum_kid_SSP0', 'mean_kid_SSP0', '%_kid_SSP0', 'max_kid_SSP1q', 'mean_kid_SSP1q', 'max_kid_SSP2q', 'sum_kid_SSP2q', 'mean_kid_SSP2q', 'max_kid_SSP3q', 'sum_kid_SSP3q', 'mean_kid_SSP3q', 'any_kid_SSP_any', 'all_kid_SSP_any', 'min_kid_SSP_any', 'max_kid_SSP_any', 'count_kid_SSP_any', 'sum_kid_SSP_any', 'mean_kid_SSP_any', '%_kid_SSP_any', 'any_anyage_SSP0', 'all_anyage_SSP0', 'max_anyage_SSP0', 'sum_anyage_SSP0', '%_anyage_SSP0', 'any_anyage_SSP1q', 'all_anyage_SSP1q', 'min_anyage_SSP1q', 'max_anyage_SSP1q', 'count_anyage_SSP1q', 'sum_anyage_SSP1q', 'mean_anyage_SSP1q', '%_anyage_SSP1q', 'any_anyage_SSP2q', 'all_anyage_SSP2q', 'min_anyage_SSP2q', 'max_anyage_SSP2q', 'count_anyage_SSP2q', 'sum_anyage_SSP2q', 'mean_anyage_SSP2q', '%_anyage_SSP2q', 'any_anyage_SSP3q', 'all_anyage_SSP3q', 'min_anyage_SSP3q', 'max_anyage_SSP3q', 'count_anyage_SSP3q', 'sum_anyage_SSP3q', 'mean_anyage_SSP3q', '%_anyage_SSP3q', 'any_anyage_SSP4q', 'all_anyage_SSP4q', 'min_anyage_SSP4q', 'max_anyage_SSP4q', 'count_anyage_SSP4q', 'sum_anyage_SSP4q', 'mean_anyage_SSP4q', '%_anyage_SSP4q', 'min_anyage_SSP_any', 'max_anyage_SSP_any', 'count_anyage_SSP_any', 'sum_anyage_SSP_any', 'mean_anyage_SSP_any', 'count_adult_SSIP0', 'min_adult_SSIP1q', 'max_adult_SSIP1q', 'count_adult_SSIP1q', 'sum_adult_SSIP1q', 'mean_adult_SSIP1q', 'max_adult_SSIP2q', 'count_adult_SSIP2q', 'sum_adult_SSIP2q', 'mean_adult_SSIP2q', 'min_adult_SSIP3q', 'max_adult_SSIP3q', 'count_adult_SSIP3q', 'sum_adult_SSIP3q', 'mean_adult_SSIP3q', 'min_adult_SSIP_any', 'max_adult_SSIP_any', 'count_adult_SSIP_any', 'sum_adult_SSIP_any', 'mean_adult_SSIP_any', 'all_65+_SSIP0', 'min_65+_SSIP0', 'max_65+_SSIP0', 'sum_65+_SSIP0', 'mean_65+_SSIP0', '%_65+_SSIP0', 'min_65+_SSIP1q', 'max_65+_SSIP1q', 'count_65+_SSIP1q', 'sum_65+_SSIP1q', 'mean_65+_SSIP1q', 'max_65+_SSIP2q', 'count_65+_SSIP2q', 'sum_65+_SSIP2q', 'mean_65+_SSIP2q', 'min_65+_SSIP3q', 'max_65+_SSIP3q', 'count_65+_SSIP3q', 'sum_65+_SSIP3q', 'mean_65+_SSIP3q', '%_65+_SSIP3q', 'any_65+_SSIP_any', 'all_65+_SSIP_any', 'min_65+_SSIP_any', 'max_65+_SSIP_any', 'count_65+_SSIP_any', 'sum_65+_SSIP_any', 'mean_65+_SSIP_any', '%_65+_SSIP_any', 'count_18-64_SSIP0', 'sum_18-64_SSIP0', 'mean_18-64_SSIP0', '%_18-64_SSIP0', 'max_18-64_SSIP1q', 'sum_18-64_SSIP1q', 'mean_18-64_SSIP1q', 'max_18-64_SSIP2q', 'sum_18-64_SSIP2q', 'mean_18-64_SSIP2q', 'min_18-64_SSIP3q', 'max_18-64_SSIP3q', 'count_18-64_SSIP3q', 'sum_18-64_SSIP3q', 'mean_18-64_SSIP3q', 'any_18-64_SSIP_any', 'all_18-64_SSIP_any', 'min_18-64_SSIP_any', 'max_18-64_SSIP_any', 'count_18-64_SSIP_any', 'sum_18-64_SSIP_any', 'mean_18-64_SSIP_any', '%_18-64_SSIP_any', 'any_kid_SSIP0', 'all_kid_SSIP0', 'min_kid_SSIP0', 'max_kid_SSIP0', 'count_kid_SSIP0', 'sum_kid_SSIP0', 'mean_kid_SSIP0', '%_kid_SSIP0', 'max_kid_SSIP1q', 'sum_kid_SSIP1q', 'mean_kid_SSIP1q', 'max_kid_SSIP2q', 'sum_kid_SSIP2q', 'mean_kid_SSIP2q', 'max_kid_SSIP3q', 'sum_kid_SSIP3q', 'mean_kid_SSIP3q', 'any_kid_SSIP_any', 'all_kid_SSIP_any', 'min_kid_SSIP_any', 'max_kid_SSIP_any', 'count_kid_SSIP_any', 'sum_kid_SSIP_any', 'mean_kid_SSIP_any', '%_kid_SSIP_any', 'any_anyage_SSIP0', 'all_anyage_SSIP0', 'max_anyage_SSIP0', 'count_anyage_SSIP0', 'sum_anyage_SSIP0', '%_anyage_SSIP0', 'any_anyage_SSIP1q', 'min_anyage_SSIP1q', 'max_anyage_SSIP1q', 'count_anyage_SSIP1q', 'sum_anyage_SSIP1q', 'mean_anyage_SSIP1q', 'any_anyage_SSIP2q', 'min_anyage_SSIP2q', 'max_anyage_SSIP2q', 'count_anyage_SSIP2q', 'sum_anyage_SSIP2q', 'mean_anyage_SSIP2q', 'any_anyage_SSIP3q', 'all_anyage_SSIP3q', 'min_anyage_SSIP3q', 'max_anyage_SSIP3q', 'count_anyage_SSIP3q', 'sum_anyage_SSIP3q', 'mean_anyage_SSIP3q', '%_anyage_SSIP3q', 'min_anyage_SSIP_any', 'max_anyage_SSIP_any', 'count_anyage_SSIP_any', 'sum_anyage_SSIP_any', 'mean_anyage_SSIP_any', 'count_adult_PA0', 'sum_adult_PA0', 'max_adult_PA1q', 'sum_adult_PA1q', 'mean_adult_PA1q', 'max_adult_PA2q', 'count_adult_PA2q', 'sum_adult_PA2q', 'mean_adult_PA2q', 'max_adult_PA3q', 'count_adult_PA3q', 'sum_adult_PA3q', 'mean_adult_PA3q', 'min_adult_PA_any', 'max_adult_PA_any', 'count_adult_PA_any', 'sum_adult_PA_any', 'mean_adult_PA_any', 'any_65+_PA0', 'all_65+_PA0', 'min_65+_PA0', 'max_65+_PA0', 'count_65+_PA0', 'sum_65+_PA0', 'mean_65+_PA0', '%_65+_PA0', 'max_65+_PA1q', 'sum_65+_PA1q', 'mean_65+_PA1q', 'max_65+_PA2q', 'sum_65+_PA2q', 'mean_65+_PA2q', 'max_65+_PA3q', 'sum_65+_PA3q', 'mean_65+_PA3q', 'any_65+_PA_any', 'all_65+_PA_any', 'min_65+_PA_any', 'max_65+_PA_any', 'count_65+_PA_any', 'sum_65+_PA_any', 'mean_65+_PA_any', '%_65+_PA_any', 'all_18-64_PA0', 'min_18-64_PA0', 'max_18-64_PA0', 'count_18-64_PA0', 'sum_18-64_PA0', 'mean_18-64_PA0', '%_18-64_PA0', 'max_18-64_PA1q', 'sum_18-64_PA1q', 'mean_18-64_PA1q', 'min_18-64_PA2q', 'max_18-64_PA2q', 'count_18-64_PA2q', 'sum_18-64_PA2q', 'mean_18-64_PA2q', 'min_18-64_PA3q', 'max_18-64_PA3q', 'count_18-64_PA3q', 'sum_18-64_PA3q', 'mean_18-64_PA3q', 'any_18-64_PA_any', 'all_18-64_PA_any', 'min_18-64_PA_any', 'max_18-64_PA_any', 'count_18-64_PA_any', 'sum_18-64_PA_any', 'mean_18-64_PA_any', '%_18-64_PA_any', 'any_kid_PA0', 'all_kid_PA0', 'min_kid_PA0', 'max_kid_PA0', 'count_kid_PA0', 'sum_kid_PA0', 'mean_kid_PA0', '%_kid_PA0', 'max_kid_PA1q', 'mean_kid_PA1q', 'max_kid_PA2q', 'sum_kid_PA2q', 'mean_kid_PA2q', 'max_kid_PA3q', 'sum_kid_PA3q', 'mean_kid_PA3q', 'any_kid_PA_any', 'all_kid_PA_any', 'min_kid_PA_any', 'max_kid_PA_any', 'count_kid_PA_any', 'sum_kid_PA_any', 'mean_kid_PA_any', '%_kid_PA_any', 'all_anyage_PA0', 'min_anyage_PA0', 'max_anyage_PA0', 'count_anyage_PA0', 'sum_anyage_PA0', 'min_anyage_PA1q', 'max_anyage_PA1q', 'count_anyage_PA1q', 'sum_anyage_PA1q', 'mean_anyage_PA1q', 'any_anyage_PA2q', 'min_anyage_PA2q', 'max_anyage_PA2q', 'count_anyage_PA2q', 'sum_anyage_PA2q', 'mean_anyage_PA2q', 'any_anyage_PA3q', 'min_anyage_PA3q', 'max_anyage_PA3q', 'count_anyage_PA3q', 'sum_anyage_PA3q', 'mean_anyage_PA3q', 'min_anyage_PA_any', 'max_anyage_PA_any', 'count_anyage_PA_any', 'sum_anyage_PA_any', 'mean_anyage_PA_any', 'min_adult_RETP1q', 'max_adult_RETP1q', 'count_adult_RETP1q', 'sum_adult_RETP1q', 'mean_adult_RETP1q', 'min_adult_RETP2q', 'max_adult_RETP2q', 'count_adult_RETP2q', 'sum_adult_RETP2q', 'mean_adult_RETP2q', 'min_adult_RETP3q', 'max_adult_RETP3q', 'count_adult_RETP3q', 'sum_adult_RETP3q', 'mean_adult_RETP3q', 'min_adult_RETP_any', 'max_adult_RETP_any', 'count_adult_RETP_any', 'sum_adult_RETP_any', 'mean_adult_RETP_any', '%_65+_RETP0', 'min_65+_RETP1q', 'max_65+_RETP1q', 'count_65+_RETP1q', 'sum_65+_RETP1q', 'mean_65+_RETP1q', '%_65+_RETP1q', 'min_65+_RETP2q', 'max_65+_RETP2q', 'count_65+_RETP2q', 'sum_65+_RETP2q', 'mean_65+_RETP2q', '%_65+_RETP2q', 'min_65+_RETP3q', 'max_65+_RETP3q', 'count_65+_RETP3q', 'sum_65+_RETP3q', 'mean_65+_RETP3q', '%_65+_RETP3q', 'any_65+_RETP_any', 'all_65+_RETP_any', 'min_65+_RETP_any', 'max_65+_RETP_any', 'count_65+_RETP_any', 'sum_65+_RETP_any', 'mean_65+_RETP_any', '%_65+_RETP_any', 'count_18-64_RETP0', '%_18-64_RETP0', 'max_18-64_RETP1q', 'count_18-64_RETP1q', 'sum_18-64_RETP1q', 'mean_18-64_RETP1q', 'max_18-64_RETP2q', 'sum_18-64_RETP2q', 'mean_18-64_RETP2q', 'min_18-64_RETP3q', 'max_18-64_RETP3q', 'count_18-64_RETP3q', 'sum_18-64_RETP3q', 'mean_18-64_RETP3q', 'any_18-64_RETP_any', 'all_18-64_RETP_any', 'min_18-64_RETP_any', 'max_18-64_RETP_any', 'count_18-64_RETP_any', 'sum_18-64_RETP_any', 'mean_18-64_RETP_any', '%_18-64_RETP_any', 'all_kid_RETP0', 'count_kid_RETP0', '%_kid_RETP0', 'max_kid_RETP1q', 'sum_kid_RETP1q', 'mean_kid_RETP1q', 'any_kid_RETP_any', 'all_kid_RETP_any', 'min_kid_RETP_any', 'max_kid_RETP_any', 'count_kid_RETP_any', 'sum_kid_RETP_any', 'mean_kid_RETP_any', '%_kid_RETP_any', 'any_anyage_RETP1q', 'all_anyage_RETP1q', 'min_anyage_RETP1q', 'max_anyage_RETP1q', 'count_anyage_RETP1q', 'sum_anyage_RETP1q', 'mean_anyage_RETP1q', '%_anyage_RETP1q', 'any_anyage_RETP2q', 'all_anyage_RETP2q', 'min_anyage_RETP2q', 'max_anyage_RETP2q', 'count_anyage_RETP2q', 'sum_anyage_RETP2q', 'mean_anyage_RETP2q', '%_anyage_RETP2q', 'any_anyage_RETP3q', 'all_anyage_RETP3q', 'min_anyage_RETP3q', 'max_anyage_RETP3q', 'count_anyage_RETP3q', 'sum_anyage_RETP3q', 'mean_anyage_RETP3q', '%_anyage_RETP3q', 'min_anyage_RETP_any', 'max_anyage_RETP_any', 'count_anyage_RETP_any', 'sum_anyage_RETP_any', 'mean_anyage_RETP_any', 'max_adult_OI1q', 'count_adult_OI1q', 'sum_adult_OI1q', 'mean_adult_OI1q', 'max_adult_OI2q', 'count_adult_OI2q', 'sum_adult_OI2q', 'mean_adult_OI2q', 'max_adult_OI3q', 'count_adult_OI3q', 'sum_adult_OI3q', 'mean_adult_OI3q', 'min_adult_OI_any', 'max_adult_OI_any', 'count_adult_OI_any', 'sum_adult_OI_any', 'mean_adult_OI_any', 'max_65+_OI1q', 'sum_65+_OI1q', 'mean_65+_OI1q', 'max_65+_OI2q', 'sum_65+_OI2q', 'mean_65+_OI2q', 'min_65+_OI3q', 'max_65+_OI3q', 'count_65+_OI3q', 'sum_65+_OI3q', 'mean_65+_OI3q', 'any_65+_OI_any', 'all_65+_OI_any', 'min_65+_OI_any', 'max_65+_OI_any', 'count_65+_OI_any', 'sum_65+_OI_any', 'mean_65+_OI_any', '%_65+_OI_any', 'max_18-64_OI1q', 'sum_18-64_OI1q', 'mean_18-64_OI1q', 'min_18-64_OI2q', 'max_18-64_OI2q', 'count_18-64_OI2q', 'sum_18-64_OI2q', 'mean_18-64_OI2q', 'min_18-64_OI3q', 'max_18-64_OI3q', 'count_18-64_OI3q', 'sum_18-64_OI3q', 'mean_18-64_OI3q', 'any_18-64_OI_any', 'all_18-64_OI_any', 'min_18-64_OI_any', 'max_18-64_OI_any', 'count_18-64_OI_any', 'sum_18-64_OI_any', 'mean_18-64_OI_any', '%_18-64_OI_any', 'max_kid_OI1q', 'sum_kid_OI1q', 'mean_kid_OI1q', 'max_kid_OI2q', 'sum_kid_OI2q', 'mean_kid_OI2q', 'max_kid_OI3q', 'sum_kid_OI3q', 'mean_kid_OI3q', 'any_kid_OI_any', 'all_kid_OI_any', 'min_kid_OI_any', 'max_kid_OI_any', 'count_kid_OI_any', 'sum_kid_OI_any', 'mean_kid_OI_any', '%_kid_OI_any', 'min_anyage_OI1q', 'max_anyage_OI1q', 'count_anyage_OI1q', 'sum_anyage_OI1q', 'mean_anyage_OI1q', 'any_anyage_OI2q', 'min_anyage_OI2q', 'max_anyage_OI2q', 'count_anyage_OI2q', 'sum_anyage_OI2q', 'mean_anyage_OI2q', 'any_anyage_OI3q', 'min_anyage_OI3q', 'max_anyage_OI3q', 'count_anyage_OI3q', 'sum_anyage_OI3q', 'mean_anyage_OI3q', '%_anyage_OI3q', 'min_anyage_OI_any', 'max_anyage_OI_any', 'count_anyage_OI_any', 'sum_anyage_OI_any', 'mean_anyage_OI_any', 'max_adult_White', 'mean_adult_White', '%_adult_White', 'all_adult_Black', 'sum_adult_Black', 'mean_adult_Black', '%_adult_Black', 'sum_adult_Asian', 'mean_adult_Asian', '%_adult_Asian', 'sum_adult_Hisp', 'mean_adult_Hisp', '%_adult_Hisp', 'max_adult_ETH_other', 'sum_adult_ETH_other', 'mean_adult_ETH_other', 'min_adult_ETH_any', 'max_adult_ETH_any', 'count_adult_ETH_any', 'sum_adult_ETH_any', 'mean_adult_ETH_any', 'all_65+_White', 'min_65+_White', 'max_65+_White', 'sum_65+_White', 'mean_65+_White', '%_65+_White', 'all_65+_Black', 'min_65+_Black', 'max_65+_Black', 'sum_65+_Black', 'mean_65+_Black', '%_65+_Black', 'all_65+_Asian', 'min_65+_Asian', 'max_65+_Asian', 'sum_65+_Asian', 'mean_65+_Asian', '%_65+_Asian', 'all_65+_Hisp', 'min_65+_Hisp', 'max_65+_Hisp', 'sum_65+_Hisp', 'mean_65+_Hisp', '%_65+_Hisp', 'max_65+_ETH_other', 'mean_65+_ETH_other', 'any_65+_ETH_any', 'all_65+_ETH_any', 'min_65+_ETH_any', 'max_65+_ETH_any', 'count_65+_ETH_any', 'sum_65+_ETH_any', 'mean_65+_ETH_any', '%_65+_ETH_any', 'max_18-64_White', 'sum_18-64_White', 'mean_18-64_White', '%_18-64_White', 'all_18-64_Black', 'max_18-64_Black', 'sum_18-64_Black', 'mean_18-64_Black', '%_18-64_Black', 'max_18-64_Asian', 'count_18-64_Asian', 'sum_18-64_Asian', 'mean_18-64_Asian', '%_18-64_Asian', 'max_18-64_Hisp', 'count_18-64_Hisp', 'sum_18-64_Hisp', 'mean_18-64_Hisp', '%_18-64_Hisp', 'any_18-64_ETH_other', 'max_18-64_ETH_other', 'count_18-64_ETH_other', 'sum_18-64_ETH_other', 'mean_18-64_ETH_other', '%_18-64_ETH_other', 'any_18-64_ETH_any', 'all_18-64_ETH_any', 'min_18-64_ETH_any', 'max_18-64_ETH_any', 'count_18-64_ETH_any', 'sum_18-64_ETH_any', 'mean_18-64_ETH_any', '%_18-64_ETH_any', 'all_kid_White', 'mean_kid_White', '%_kid_White', 'all_kid_Black', 'mean_kid_Black', '%_kid_Black', 'all_kid_Asian', 'mean_kid_Asian', '%_kid_Asian', 'all_kid_Hisp', 'mean_kid_Hisp', '%_kid_Hisp', 'mean_kid_ETH_other', '%_kid_ETH_other', 'any_kid_ETH_any', 'all_kid_ETH_any', 'min_kid_ETH_any', 'max_kid_ETH_any', 'count_kid_ETH_any', 'sum_kid_ETH_any', 'mean_kid_ETH_any', '%_kid_ETH_any', 'any_anyage_White', 'all_anyage_White', 'min_anyage_White', 'max_anyage_White', 'sum_anyage_White', 'mean_anyage_White', '%_anyage_White', 'any_anyage_Black', 'all_anyage_Black', 'max_anyage_Black', 'sum_anyage_Black', 'mean_anyage_Black', '%_anyage_Black', 'any_anyage_Asian', 'all_anyage_Asian', 'max_anyage_Asian', 'count_anyage_Asian', 'sum_anyage_Asian', 'mean_anyage_Asian', '%_anyage_Asian', 'any_anyage_Hisp', 'all_anyage_Hisp', 'max_anyage_Hisp', 'sum_anyage_Hisp', 'mean_anyage_Hisp', '%_anyage_Hisp', 'all_anyage_ETH_other', 'max_anyage_ETH_other', 'sum_anyage_ETH_other', 'mean_anyage_ETH_other', '%_anyage_ETH_other', 'min_anyage_ETH_any', 'max_anyage_ETH_any', 'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any', 'max_adult_TINP0', 'sum_adult_TINP0', 'mean_adult_TINP0', 'mean_adult_TINP<10', 'mean_adult_TINP<15', 'mean_adult_TINP<20', 'mean_adult_TINP<25', 'count_adult_TINP<30', 'sum_adult_TINP<30', 'mean_adult_TINP<30', 'count_adult_TINP<35', 'sum_adult_TINP<35', 'mean_adult_TINP<35', 'count_adult_TINP<40', 'sum_adult_TINP<40', 'mean_adult_TINP<40', 'max_adult_TINP<45', 'count_adult_TINP<45', 'sum_adult_TINP<45', 'mean_adult_TINP<45', 'min_adult_TINP<50', 'max_adult_TINP<50', 'count_adult_TINP<50', 'sum_adult_TINP<50', 'mean_adult_TINP<50', 'count_adult_TINP<60', 'sum_adult_TINP<60', 'mean_adult_TINP<60', 'count_adult_TINP<70', 'sum_adult_TINP<70', 'mean_adult_TINP<70', 'count_adult_TINP<80', 'sum_adult_TINP<80', 'mean_adult_TINP<80', 'min_adult_TINP_any', 'max_adult_TINP_any', 'count_adult_TINP_any', 'sum_adult_TINP_any', 'mean_adult_TINP_any', 'min_65+_TINP0', 'max_65+_TINP0', 'count_65+_TINP0', 'sum_65+_TINP0', 'mean_65+_TINP0', '%_65+_TINP0', 'min_65+_TINP<10', 'max_65+_TINP<10', 'count_65+_TINP<10', 'sum_65+_TINP<10', 'mean_65+_TINP<10', '%_65+_TINP<10', 'min_65+_TINP<15', 'max_65+_TINP<15', 'sum_65+_TINP<15', 'mean_65+_TINP<15', '%_65+_TINP<15', 'min_65+_TINP<20', 'max_65+_TINP<20', 'sum_65+_TINP<20', 'mean_65+_TINP<20', '%_65+_TINP<20', 'min_65+_TINP<25', 'max_65+_TINP<25', 'sum_65+_TINP<25', 'mean_65+_TINP<25', '%_65+_TINP<25', 'any_65+_TINP<30', 'min_65+_TINP<30', 'max_65+_TINP<30', 'count_65+_TINP<30', 'sum_65+_TINP<30', 'mean_65+_TINP<30', '%_65+_TINP<30', 'any_65+_TINP<35', 'all_65+_TINP<35', 'min_65+_TINP<35', 'max_65+_TINP<35', 'count_65+_TINP<35', 'sum_65+_TINP<35', 'mean_65+_TINP<35', '%_65+_TINP<35', 'any_65+_TINP<40', 'all_65+_TINP<40', 'min_65+_TINP<40', 'max_65+_TINP<40', 'count_65+_TINP<40', 'sum_65+_TINP<40', 'mean_65+_TINP<40', '%_65+_TINP<40', 'any_65+_TINP<45', 'all_65+_TINP<45', 'min_65+_TINP<45', 'max_65+_TINP<45', 'count_65+_TINP<45', 'sum_65+_TINP<45', 'mean_65+_TINP<45', '%_65+_TINP<45', 'any_65+_TINP<50', 'all_65+_TINP<50', 'min_65+_TINP<50', 'max_65+_TINP<50', 'count_65+_TINP<50', 'sum_65+_TINP<50', 'mean_65+_TINP<50', '%_65+_TINP<50', 'any_65+_TINP<60', 'all_65+_TINP<60', 'min_65+_TINP<60', 'max_65+_TINP<60', 'count_65+_TINP<60', 'sum_65+_TINP<60', 'mean_65+_TINP<60', '%_65+_TINP<60', 'any_65+_TINP<70', 'all_65+_TINP<70', 'min_65+_TINP<70', 'max_65+_TINP<70', 'count_65+_TINP<70', 'sum_65+_TINP<70', 'mean_65+_TINP<70', '%_65+_TINP<70', 'any_65+_TINP<80', 'all_65+_TINP<80', 'min_65+_TINP<80', 'max_65+_TINP<80', 'count_65+_TINP<80', 'sum_65+_TINP<80', 'mean_65+_TINP<80', '%_65+_TINP<80', 'any_65+_TINP_any', 'all_65+_TINP_any', 'min_65+_TINP_any', 'max_65+_TINP_any', 'count_65+_TINP_any', 'sum_65+_TINP_any', 'mean_65+_TINP_any', '%_65+_TINP_any', 'max_18-64_TINP0', 'count_18-64_TINP0', 'sum_18-64_TINP0', 'mean_18-64_TINP0', 'max_18-64_TINP<10', 'mean_18-64_TINP<10', 'mean_18-64_TINP<15', 'count_18-64_TINP<20', 'mean_18-64_TINP<20', 'count_18-64_TINP<25', 'mean_18-64_TINP<25', 'count_18-64_TINP<30', 'sum_18-64_TINP<30', 'mean_18-64_TINP<30', 'count_18-64_TINP<35', 'sum_18-64_TINP<35', 'mean_18-64_TINP<35', 'count_18-64_TINP<40', 'sum_18-64_TINP<40', 'mean_18-64_TINP<40', 'any_18-64_TINP<45', 'max_18-64_TINP<45', 'count_18-64_TINP<45', 'sum_18-64_TINP<45', 'mean_18-64_TINP<45', '%_18-64_TINP<45', 'any_18-64_TINP<50', 'min_18-64_TINP<50', 'max_18-64_TINP<50', 'count_18-64_TINP<50', 'sum_18-64_TINP<50', 'mean_18-64_TINP<50', '%_18-64_TINP<50', 'any_18-64_TINP<60', 'all_18-64_TINP<60', 'min_18-64_TINP<60', 'max_18-64_TINP<60', 'count_18-64_TINP<60', 'sum_18-64_TINP<60', 'mean_18-64_TINP<60', '%_18-64_TINP<60', 'any_18-64_TINP<70', 'all_18-64_TINP<70', 'min_18-64_TINP<70', 'max_18-64_TINP<70', 'count_18-64_TINP<70', 'sum_18-64_TINP<70', 'mean_18-64_TINP<70', '%_18-64_TINP<70', 'any_18-64_TINP<80', 'all_18-64_TINP<80', 'min_18-64_TINP<80', 'max_18-64_TINP<80', 'count_18-64_TINP<80', 'sum_18-64_TINP<80', 'mean_18-64_TINP<80', '%_18-64_TINP<80', 'any_18-64_TINP_any', 'all_18-64_TINP_any', 'min_18-64_TINP_any', 'max_18-64_TINP_any', 'count_18-64_TINP_any', 'sum_18-64_TINP_any', 'mean_18-64_TINP_any', '%_18-64_TINP_any', 'any_kid_TINP0', 'all_kid_TINP0', 'min_kid_TINP0', 'max_kid_TINP0', 'count_kid_TINP0', 'sum_kid_TINP0', 'mean_kid_TINP0', '%_kid_TINP0', 'any_kid_TINP<10', 'all_kid_TINP<10', 'min_kid_TINP<10', 'max_kid_TINP<10', 'count_kid_TINP<10', 'sum_kid_TINP<10', 'mean_kid_TINP<10', '%_kid_TINP<10', 'any_kid_TINP<15', 'all_kid_TINP<15', 'min_kid_TINP<15', 'max_kid_TINP<15', 'count_kid_TINP<15', 'sum_kid_TINP<15', 'mean_kid_TINP<15', '%_kid_TINP<15', 'any_kid_TINP<20', 'all_kid_TINP<20', 'min_kid_TINP<20', 'max_kid_TINP<20', 'count_kid_TINP<20', 'sum_kid_TINP<20', 'mean_kid_TINP<20', '%_kid_TINP<20', 'any_kid_TINP<25', 'all_kid_TINP<25', 'min_kid_TINP<25', 'max_kid_TINP<25', 'count_kid_TINP<25', 'sum_kid_TINP<25', 'mean_kid_TINP<25', '%_kid_TINP<25', 'any_kid_TINP<30', 'all_kid_TINP<30', 'min_kid_TINP<30', 'max_kid_TINP<30', 'count_kid_TINP<30', 'sum_kid_TINP<30', 'mean_kid_TINP<30', '%_kid_TINP<30', 'any_kid_TINP<35', 'all_kid_TINP<35', 'min_kid_TINP<35', 'max_kid_TINP<35', 'count_kid_TINP<35', 'sum_kid_TINP<35', 'mean_kid_TINP<35', '%_kid_TINP<35', 'any_kid_TINP<40', 'all_kid_TINP<40', 'min_kid_TINP<40', 'max_kid_TINP<40', 'count_kid_TINP<40', 'sum_kid_TINP<40', 'mean_kid_TINP<40', '%_kid_TINP<40', 'any_kid_TINP<45', 'all_kid_TINP<45', 'min_kid_TINP<45', 'max_kid_TINP<45', 'count_kid_TINP<45', 'sum_kid_TINP<45', 'mean_kid_TINP<45', '%_kid_TINP<45', 'any_kid_TINP<50', 'all_kid_TINP<50', 'min_kid_TINP<50', 'max_kid_TINP<50', 'count_kid_TINP<50', 'sum_kid_TINP<50', 'mean_kid_TINP<50', '%_kid_TINP<50', 'any_kid_TINP<60', 'all_kid_TINP<60', 'min_kid_TINP<60', 'max_kid_TINP<60', 'count_kid_TINP<60', 'sum_kid_TINP<60', 'mean_kid_TINP<60', '%_kid_TINP<60', 'any_kid_TINP<70', 'all_kid_TINP<70', 'min_kid_TINP<70', 'max_kid_TINP<70', 'count_kid_TINP<70', 'sum_kid_TINP<70', 'mean_kid_TINP<70', '%_kid_TINP<70', 'any_kid_TINP<80', 'all_kid_TINP<80', 'min_kid_TINP<80', 'max_kid_TINP<80', 'count_kid_TINP<80', 'sum_kid_TINP<80', 'mean_kid_TINP<80', '%_kid_TINP<80', 'any_kid_TINP_any', 'all_kid_TINP_any', 'min_kid_TINP_any', 'max_kid_TINP_any', 'count_kid_TINP_any', 'sum_kid_TINP_any', 'mean_kid_TINP_any', '%_kid_TINP_any', 'all_anyage_TINP0', 'max_anyage_TINP0', 'mean_anyage_TINP0', 'all_anyage_TINP<10', 'max_anyage_TINP<10', 'sum_anyage_TINP<10', 'mean_anyage_TINP<10', 'all_anyage_TINP<15', 'max_anyage_TINP<15', 'count_anyage_TINP<15', 'sum_anyage_TINP<15', 'mean_anyage_TINP<15', 'all_anyage_TINP<20', 'max_anyage_TINP<20', 'count_anyage_TINP<20', 'sum_anyage_TINP<20', 'mean_anyage_TINP<20', 'all_anyage_TINP<25', 'max_anyage_TINP<25', 'count_anyage_TINP<25', 'sum_anyage_TINP<25', 'mean_anyage_TINP<25', 'all_anyage_TINP<30', 'max_anyage_TINP<30', 'count_anyage_TINP<30', 'sum_anyage_TINP<30', 'mean_anyage_TINP<30', '%_anyage_TINP<30', 'all_anyage_TINP<35', 'max_anyage_TINP<35', 'count_anyage_TINP<35', 'sum_anyage_TINP<35', 'mean_anyage_TINP<35', '%_anyage_TINP<35', 'all_anyage_TINP<40', 'max_anyage_TINP<40', 'count_anyage_TINP<40', 'sum_anyage_TINP<40', 'mean_anyage_TINP<40', '%_anyage_TINP<40', 'all_anyage_TINP<45', 'min_anyage_TINP<45', 'max_anyage_TINP<45', 'count_anyage_TINP<45', 'sum_anyage_TINP<45', 'mean_anyage_TINP<45', '%_anyage_TINP<45', 'all_anyage_TINP<50', 'min_anyage_TINP<50', 'max_anyage_TINP<50', 'count_anyage_TINP<50', 'sum_anyage_TINP<50', 'mean_anyage_TINP<50', '%_anyage_TINP<50', 'all_anyage_TINP<60', 'max_anyage_TINP<60', 'count_anyage_TINP<60', 'sum_anyage_TINP<60', 'mean_anyage_TINP<60', '%_anyage_TINP<60', 'all_anyage_TINP<70', 'max_anyage_TINP<70', 'count_anyage_TINP<70', 'sum_anyage_TINP<70', 'mean_anyage_TINP<70', '%_anyage_TINP<70', 'all_anyage_TINP<80', 'min_anyage_TINP<80', 'max_anyage_TINP<80', 'count_anyage_TINP<80', 'sum_anyage_TINP<80', 'mean_anyage_TINP<80', '%_anyage_TINP<80', 'min_anyage_TINP_any', 'max_anyage_TINP_any', 'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any', 'MSP_2_1.0', 'HousingStatus_7.0', 'HousingStatus_8.0']\n"
     ]
    }
   ],
   "source": [
    "def id_cols_to_drop(df, threshold):\n",
    "    \"\"\"\n",
    "    Identifies columns to drop from a dataframe due to high correlation.\n",
    "    Input: the dataframe of interest and the correlation coefficient threshold.\n",
    "    Output: a list of the columns to drop.  Prints elapsed time to the screen because this takes a long time for a large\n",
    "    dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "        \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    tt = time.time() - time_0\n",
    "    print('Done. Took ' + str(tt) + 'seconds.')\n",
    "\n",
    "    return(to_drop)\n",
    "    \n",
    "#tester_copy = tester.copy()\n",
    "#print(len(tester_copy.columns))\n",
    "# to_drop = id_cols_to_drop(tester_copy, 0.95)\n",
    "to_drop = ['SCHL_19', 'WAGP_adj_15', 'SSP_adj_20', 'SSIP_adj_14', 'SSIP_adj_20', 'PA_adj_14', 'PA_adj_16', 'PA_adj_17', 'PA_adj_18', 'PA_adj_19', 'PA_adj_20', 'TINP_3', 'TINP_10', 'TINP_11', 'TINP_12', 'TINP_13', 'TINP_14', 'TINP_15', 'TINP_16', 'TINP_17', 'TINP_18', 'TINP_19', 'TINP_20', 'all_65+_age', 'min_65+_age', 'max_65+_age', 'sum_65+_age', 'mean_65+_age', '%_65+_age', 'all_18-64_age', 'mean_18-64_age', '%_18-64_age', 'all_kid_age', 'mean_kid_age', '%_kid_age', 'max_anyage_age', 'sum_anyage_age', 'max_adult_non-cit', 'sum_adult_non-cit', 'mean_adult_non-cit', 'any_adult_citizen', 'all_adult_citizen', 'mean_adult_citizen', '%_adult_citizen', 'max_adult_naturalized_cit', 'sum_adult_naturalized_cit', 'mean_adult_naturalized_cit', 'min_adult_any_CIT', 'max_adult_any_CIT', 'count_adult_any_CIT', 'sum_adult_any_CIT', 'mean_adult_any_CIT', 'min_65+_non-cit', 'max_65+_non-cit', 'count_65+_non-cit', 'sum_65+_non-cit', 'mean_65+_non-cit', '%_65+_non-cit', 'all_65+_citizen', 'min_65+_citizen', 'max_65+_citizen', 'sum_65+_citizen', 'mean_65+_citizen', '%_65+_citizen', 'min_65+_naturalized_cit', 'max_65+_naturalized_cit', 'sum_65+_naturalized_cit', 'mean_65+_naturalized_cit', '%_65+_naturalized_cit', 'any_65+_any_CIT', 'all_65+_any_CIT', 'min_65+_any_CIT', 'max_65+_any_CIT', 'count_65+_any_CIT', 'sum_65+_any_CIT', 'mean_65+_any_CIT', '%_65+_any_CIT', 'max_18-64_non-cit', 'count_18-64_non-cit', 'sum_18-64_non-cit', 'mean_18-64_non-cit', 'mean_18-64_citizen', '%_18-64_citizen', 'min_18-64_naturalized_cit', 'max_18-64_naturalized_cit', 'sum_18-64_naturalized_cit', 'mean_18-64_naturalized_cit', 'any_18-64_any_CIT', 'all_18-64_any_CIT', 'min_18-64_any_CIT', 'max_18-64_any_CIT', 'count_18-64_any_CIT', 'sum_18-64_any_CIT', 'mean_18-64_any_CIT', '%_18-64_any_CIT', 'max_kid_non-cit', 'mean_kid_non-cit', 'any_kid_citizen', 'all_kid_citizen', 'min_kid_citizen', 'max_kid_citizen', 'count_kid_citizen', 'sum_kid_citizen', 'mean_kid_citizen', '%_kid_citizen', 'max_kid_naturalized_cit', 'mean_kid_naturalized_cit', 'any_kid_any_CIT', 'all_kid_any_CIT', 'min_kid_any_CIT', 'max_kid_any_CIT', 'count_kid_any_CIT', 'sum_kid_any_CIT', 'mean_kid_any_CIT', '%_kid_any_CIT', 'any_anyage_non-cit', 'min_anyage_non-cit', 'max_anyage_non-cit', 'count_anyage_non-cit', 'sum_anyage_non-cit', 'mean_anyage_non-cit', '%_anyage_non-cit', 'any_anyage_citizen', 'all_anyage_citizen', 'max_anyage_citizen', 'sum_anyage_citizen', 'mean_anyage_citizen', '%_anyage_citizen', 'any_anyage_naturalized_cit', 'min_anyage_naturalized_cit', 'max_anyage_naturalized_cit', 'count_anyage_naturalized_cit', 'sum_anyage_naturalized_cit', 'mean_anyage_naturalized_cit', '%_anyage_naturalized_cit', 'min_anyage_any_CIT', 'max_anyage_any_CIT', 'count_anyage_any_CIT', 'sum_anyage_any_CIT', 'mean_anyage_any_CIT', 'max_adult_college', 'mean_adult_college', 'mean_adult_HS', 'any_adult_no_diploma', 'all_adult_no_diploma', 'max_adult_no_diploma', 'mean_adult_no_diploma', '%_adult_no_diploma', 'max_adult_diploma_no_bachelors', 'mean_adult_diploma_no_bachelors', 'min_adult_any_SCHL', 'max_adult_any_SCHL', 'count_adult_any_SCHL', 'sum_adult_any_SCHL', 'mean_adult_any_SCHL', 'min_65+_college', 'max_65+_college', 'sum_65+_college', 'mean_65+_college', '%_65+_college', 'min_65+_HS', 'max_65+_HS', 'sum_65+_HS', 'mean_65+_HS', '%_65+_HS', 'min_65+_no_diploma', 'max_65+_no_diploma', 'sum_65+_no_diploma', 'mean_65+_no_diploma', '%_65+_no_diploma', 'min_65+_diploma_no_bachelors', 'max_65+_diploma_no_bachelors', 'count_65+_diploma_no_bachelors', 'sum_65+_diploma_no_bachelors', 'mean_65+_diploma_no_bachelors', '%_65+_diploma_no_bachelors', 'any_65+_any_SCHL', 'all_65+_any_SCHL', 'min_65+_any_SCHL', 'max_65+_any_SCHL', 'count_65+_any_SCHL', 'sum_65+_any_SCHL', 'mean_65+_any_SCHL', '%_65+_any_SCHL', 'max_18-64_college', 'mean_18-64_college', 'mean_18-64_HS', 'max_18-64_no_diploma', 'sum_18-64_no_diploma', 'mean_18-64_no_diploma', 'max_18-64_diploma_no_bachelors', 'mean_18-64_diploma_no_bachelors', 'any_18-64_any_SCHL', 'all_18-64_any_SCHL', 'min_18-64_any_SCHL', 'max_18-64_any_SCHL', 'count_18-64_any_SCHL', 'sum_18-64_any_SCHL', 'mean_18-64_any_SCHL', '%_18-64_any_SCHL', 'max_kid_HS', 'sum_kid_HS', 'mean_kid_HS', 'any_kid_no_diploma', 'all_kid_no_diploma', 'min_kid_no_diploma', 'max_kid_no_diploma', 'count_kid_no_diploma', 'sum_kid_no_diploma', 'mean_kid_no_diploma', '%_kid_no_diploma', 'min_kid_diploma_no_bachelors', 'max_kid_diploma_no_bachelors', 'sum_kid_diploma_no_bachelors', 'mean_kid_diploma_no_bachelors', 'any_kid_any_SCHL', 'all_kid_any_SCHL', 'min_kid_any_SCHL', 'max_kid_any_SCHL', 'count_kid_any_SCHL', 'sum_kid_any_SCHL', 'mean_kid_any_SCHL', '%_kid_any_SCHL', 'any_anyage_college', 'min_anyage_college', 'max_anyage_college', 'count_anyage_college', 'sum_anyage_college', 'mean_anyage_college', '%_anyage_college', 'any_anyage_HS', 'min_anyage_HS', 'max_anyage_HS', 'count_anyage_HS', 'sum_anyage_HS', 'mean_anyage_HS', 'any_anyage_no_diploma', 'all_anyage_no_diploma', 'max_anyage_no_diploma', 'sum_anyage_no_diploma', 'mean_anyage_no_diploma', '%_anyage_no_diploma', 'any_anyage_diploma_no_bachelors', 'min_anyage_diploma_no_bachelors', 'max_anyage_diploma_no_bachelors', 'count_anyage_diploma_no_bachelors', 'sum_anyage_diploma_no_bachelors', 'mean_anyage_diploma_no_bachelors', '%_anyage_diploma_no_bachelors', 'min_anyage_any_SCHL', 'max_anyage_any_SCHL', 'count_anyage_any_SCHL', 'sum_anyage_any_SCHL', 'mean_anyage_any_SCHL', 'mean_adult_male', 'any_adult_female', 'all_adult_female', 'mean_adult_female', '%_adult_female', 'min_adult_any_SEX', 'max_adult_any_SEX', 'count_adult_any_SEX', 'sum_adult_any_SEX', 'mean_adult_any_SEX', 'min_65+_male', 'max_65+_male', 'count_65+_male', 'sum_65+_male', 'mean_65+_male', 'min_65+_female', 'max_65+_female', 'count_65+_female', 'sum_65+_female', 'mean_65+_female', '%_65+_female', 'any_65+_any_SEX', 'all_65+_any_SEX', 'min_65+_any_SEX', 'max_65+_any_SEX', 'count_65+_any_SEX', 'sum_65+_any_SEX', 'mean_65+_any_SEX', '%_65+_any_SEX', 'mean_18-64_male', 'mean_18-64_female', 'any_18-64_any_SEX', 'all_18-64_any_SEX', 'min_18-64_any_SEX', 'max_18-64_any_SEX', 'count_18-64_any_SEX', 'sum_18-64_any_SEX', 'mean_18-64_any_SEX', '%_18-64_any_SEX', 'mean_kid_male', 'mean_kid_female', 'any_kid_any_SEX', 'all_kid_any_SEX', 'min_kid_any_SEX', 'max_kid_any_SEX', 'count_kid_any_SEX', 'sum_kid_any_SEX', 'mean_kid_any_SEX', '%_kid_any_SEX', 'all_anyage_male', 'max_anyage_male', 'sum_anyage_male', 'mean_anyage_male', '%_anyage_male', 'any_anyage_female', 'all_anyage_female', 'max_anyage_female', 'sum_anyage_female', 'mean_anyage_female', '%_anyage_female', 'min_anyage_any_SEX', 'max_anyage_any_SEX', 'count_anyage_any_SEX', 'sum_anyage_any_SEX', 'mean_anyage_any_SEX', 'min_adult_ENG_no', 'max_adult_ENG_no', 'sum_adult_ENG_no', 'mean_adult_ENG_no', 'max_adult_ENG_nvw', 'sum_adult_ENG_nvw', 'mean_adult_ENG_nvw', 'max_adult_ENG_well', 'mean_adult_ENG_well', 'max_adult_ENG_vw', 'mean_adult_ENG_vw', 'mean_adult_ENG_only', '%_adult_ENG_only', 'min_adult_ENG_any', 'max_adult_ENG_any', 'count_adult_ENG_any', 'sum_adult_ENG_any', 'mean_adult_ENG_any', 'min_65+_ENG_no', 'max_65+_ENG_no', 'count_65+_ENG_no', 'sum_65+_ENG_no', 'mean_65+_ENG_no', '%_65+_ENG_no', 'min_65+_ENG_nvw', 'max_65+_ENG_nvw', 'count_65+_ENG_nvw', 'sum_65+_ENG_nvw', 'mean_65+_ENG_nvw', '%_65+_ENG_nvw', 'min_65+_ENG_well', 'max_65+_ENG_well', 'count_65+_ENG_well', 'sum_65+_ENG_well', 'mean_65+_ENG_well', '%_65+_ENG_well', 'min_65+_ENG_vw', 'max_65+_ENG_vw', 'sum_65+_ENG_vw', 'mean_65+_ENG_vw', '%_65+_ENG_vw', 'all_65+_ENG_only', 'min_65+_ENG_only', 'max_65+_ENG_only', 'sum_65+_ENG_only', 'mean_65+_ENG_only', '%_65+_ENG_only', 'any_65+_ENG_any', 'all_65+_ENG_any', 'min_65+_ENG_any', 'max_65+_ENG_any', 'count_65+_ENG_any', 'sum_65+_ENG_any', 'mean_65+_ENG_any', '%_65+_ENG_any', 'min_18-64_ENG_no', 'max_18-64_ENG_no', 'sum_18-64_ENG_no', 'mean_18-64_ENG_no', 'min_18-64_ENG_nvw', 'max_18-64_ENG_nvw', 'sum_18-64_ENG_nvw', 'mean_18-64_ENG_nvw', 'min_18-64_ENG_well', 'max_18-64_ENG_well', 'sum_18-64_ENG_well', 'mean_18-64_ENG_well', 'max_18-64_ENG_vw', 'sum_18-64_ENG_vw', 'mean_18-64_ENG_vw', 'sum_18-64_ENG_only', 'mean_18-64_ENG_only', '%_18-64_ENG_only', 'any_18-64_ENG_any', 'all_18-64_ENG_any', 'min_18-64_ENG_any', 'max_18-64_ENG_any', 'count_18-64_ENG_any', 'sum_18-64_ENG_any', 'mean_18-64_ENG_any', '%_18-64_ENG_any', 'max_kid_ENG_no', 'mean_kid_ENG_no', 'max_kid_ENG_nvw', 'mean_kid_ENG_nvw', 'max_kid_ENG_well', 'sum_kid_ENG_well', 'mean_kid_ENG_well', 'max_kid_ENG_vw', 'sum_kid_ENG_vw', 'mean_kid_ENG_vw', '%_kid_ENG_vw', 'max_kid_ENG_only', 'sum_kid_ENG_only', 'mean_kid_ENG_only', '%_kid_ENG_only', 'any_kid_ENG_any', 'all_kid_ENG_any', 'min_kid_ENG_any', 'max_kid_ENG_any', 'count_kid_ENG_any', 'sum_kid_ENG_any', 'mean_kid_ENG_any', '%_kid_ENG_any', 'any_anyage_ENG_no', 'all_anyage_ENG_no', 'min_anyage_ENG_no', 'max_anyage_ENG_no', 'count_anyage_ENG_no', 'sum_anyage_ENG_no', 'mean_anyage_ENG_no', '%_anyage_ENG_no', 'any_anyage_ENG_nvw', 'min_anyage_ENG_nvw', 'max_anyage_ENG_nvw', 'count_anyage_ENG_nvw', 'sum_anyage_ENG_nvw', 'mean_anyage_ENG_nvw', '%_anyage_ENG_nvw', 'any_anyage_ENG_well', 'min_anyage_ENG_well', 'max_anyage_ENG_well', 'sum_anyage_ENG_well', 'mean_anyage_ENG_well', '%_anyage_ENG_well', 'min_anyage_ENG_vw', 'max_anyage_ENG_vw', 'sum_anyage_ENG_vw', 'mean_anyage_ENG_vw', '%_anyage_ENG_vw', 'any_anyage_ENG_only', 'max_anyage_ENG_only', 'sum_anyage_ENG_only', 'mean_anyage_ENG_only', '%_anyage_ENG_only', 'min_anyage_ENG_any', 'max_anyage_ENG_any', 'count_anyage_ENG_any', 'sum_anyage_ENG_any', 'mean_anyage_ENG_any', 'max_adult_married', 'sum_adult_married', 'mean_adult_married', 'min_adult_widowed', 'max_adult_widowed', 'count_adult_widowed', 'sum_adult_widowed', 'mean_adult_widowed', 'min_adult_sep/divorced', 'max_adult_sep/divorced', 'count_adult_sep/divorced', 'sum_adult_sep/divorced', 'mean_adult_sep/divorced', 'max_adult_not_married', 'mean_adult_not_married', 'min_adult_any_MSP', 'max_adult_any_MSP', 'count_adult_any_MSP', 'sum_adult_any_MSP', 'mean_adult_any_MSP', 'all_65+_married', 'min_65+_married', 'max_65+_married', 'count_65+_married', 'sum_65+_married', 'mean_65+_married', '%_65+_married', 'all_65+_widowed', 'min_65+_widowed', 'max_65+_widowed', 'count_65+_widowed', 'sum_65+_widowed', 'mean_65+_widowed', '%_65+_widowed', 'all_65+_sep/divorced', 'min_65+_sep/divorced', 'max_65+_sep/divorced', 'count_65+_sep/divorced', 'sum_65+_sep/divorced', 'mean_65+_sep/divorced', '%_65+_sep/divorced', 'all_65+_not_married', 'min_65+_not_married', 'max_65+_not_married', 'count_65+_not_married', 'sum_65+_not_married', 'mean_65+_not_married', '%_65+_not_married', 'any_65+_any_MSP', 'all_65+_any_MSP', 'min_65+_any_MSP', 'max_65+_any_MSP', 'count_65+_any_MSP', 'sum_65+_any_MSP', 'mean_65+_any_MSP', '%_65+_any_MSP', 'min_18-64_married', 'max_18-64_married', 'sum_18-64_married', 'mean_18-64_married', '%_18-64_married', 'min_18-64_widowed', 'max_18-64_widowed', 'count_18-64_widowed', 'sum_18-64_widowed', 'mean_18-64_widowed', 'min_18-64_sep/divorced', 'max_18-64_sep/divorced', 'count_18-64_sep/divorced', 'sum_18-64_sep/divorced', 'mean_18-64_sep/divorced', 'max_18-64_not_married', 'count_18-64_not_married', 'mean_18-64_not_married', 'any_18-64_any_MSP', 'all_18-64_any_MSP', 'min_18-64_any_MSP', 'max_18-64_any_MSP', 'count_18-64_any_MSP', 'sum_18-64_any_MSP', 'mean_18-64_any_MSP', '%_18-64_any_MSP', 'max_kid_married', 'sum_kid_married', 'mean_kid_married', 'max_kid_sep/divorced', 'sum_kid_sep/divorced', 'mean_kid_sep/divorced', 'min_kid_not_married', 'max_kid_not_married', 'count_kid_not_married', 'sum_kid_not_married', 'mean_kid_not_married', 'any_kid_any_MSP', 'all_kid_any_MSP', 'min_kid_any_MSP', 'max_kid_any_MSP', 'count_kid_any_MSP', 'sum_kid_any_MSP', 'mean_kid_any_MSP', '%_kid_any_MSP', 'any_anyage_married', 'min_anyage_married', 'max_anyage_married', 'count_anyage_married', 'sum_anyage_married', 'mean_anyage_married', 'any_anyage_widowed', 'all_anyage_widowed', 'min_anyage_widowed', 'max_anyage_widowed', 'count_anyage_widowed', 'sum_anyage_widowed', 'mean_anyage_widowed', '%_anyage_widowed', 'any_anyage_sep/divorced', 'min_anyage_sep/divorced', 'max_anyage_sep/divorced', 'count_anyage_sep/divorced', 'sum_anyage_sep/divorced', 'mean_anyage_sep/divorced', '%_anyage_sep/divorced', 'min_anyage_not_married', 'max_anyage_not_married', 'sum_anyage_not_married', 'mean_anyage_not_married', '%_anyage_not_married', 'min_anyage_any_MSP', 'max_anyage_any_MSP', 'count_anyage_any_MSP', 'sum_anyage_any_MSP', 'mean_anyage_any_MSP', 'max_adult_no_work', 'mean_adult_no_work', 'max_adult_<14WKW', 'count_adult_<14WKW', 'sum_adult_<14WKW', 'mean_adult_<14WKW', 'max_adult_14-26WKW', 'count_adult_14-26WKW', 'sum_adult_14-26WKW', 'mean_adult_14-26WKW', 'max_adult_27-39WKW', 'count_adult_27-39WKW', 'sum_adult_27-39WKW', 'mean_adult_27-39WKW', 'max_adult_40-47WKW', 'count_adult_40-47WKW', 'sum_adult_40-47WKW', 'mean_adult_40-47WKW', 'max_adult_48-49WKW', 'count_adult_48-49WKW', 'sum_adult_48-49WKW', 'mean_adult_48-49WKW', 'mean_adult_50-52WKW', 'mean_adult_>40WKW', 'any_adult_nonzero_WKW', 'all_adult_nonzero_WKW', 'mean_adult_nonzero_WKW', '%_adult_nonzero_WKW', 'min_adult_any_WKW', 'max_adult_any_WKW', 'count_adult_any_WKW', 'sum_adult_any_WKW', 'mean_adult_any_WKW', 'min_65+_no_work', 'max_65+_no_work', 'sum_65+_no_work', 'mean_65+_no_work', '%_65+_no_work', 'max_65+_<14WKW', 'sum_65+_<14WKW', 'mean_65+_<14WKW', 'max_65+_14-26WKW', 'sum_65+_14-26WKW', 'mean_65+_14-26WKW', 'max_65+_27-39WKW', 'sum_65+_27-39WKW', 'mean_65+_27-39WKW', 'max_65+_40-47WKW', 'sum_65+_40-47WKW', 'mean_65+_40-47WKW', 'max_65+_48-49WKW', 'sum_65+_48-49WKW', 'mean_65+_48-49WKW', 'min_65+_50-52WKW', 'max_65+_50-52WKW', 'count_65+_50-52WKW', 'sum_65+_50-52WKW', 'mean_65+_50-52WKW', '%_65+_50-52WKW', 'min_65+_>40WKW', 'max_65+_>40WKW', 'count_65+_>40WKW', 'sum_65+_>40WKW', 'mean_65+_>40WKW', '%_65+_>40WKW', 'min_65+_nonzero_WKW', 'max_65+_nonzero_WKW', 'count_65+_nonzero_WKW', 'sum_65+_nonzero_WKW', 'mean_65+_nonzero_WKW', '%_65+_nonzero_WKW', 'any_65+_any_WKW', 'all_65+_any_WKW', 'min_65+_any_WKW', 'max_65+_any_WKW', 'count_65+_any_WKW', 'sum_65+_any_WKW', 'mean_65+_any_WKW', '%_65+_any_WKW', 'max_18-64_no_work', 'mean_18-64_no_work', 'max_18-64_<14WKW', 'count_18-64_<14WKW', 'sum_18-64_<14WKW', 'mean_18-64_<14WKW', 'any_18-64_14-26WKW', 'max_18-64_14-26WKW', 'count_18-64_14-26WKW', 'sum_18-64_14-26WKW', 'mean_18-64_14-26WKW', 'any_18-64_27-39WKW', 'max_18-64_27-39WKW', 'count_18-64_27-39WKW', 'sum_18-64_27-39WKW', 'mean_18-64_27-39WKW', 'any_18-64_40-47WKW', 'max_18-64_40-47WKW', 'count_18-64_40-47WKW', 'sum_18-64_40-47WKW', 'mean_18-64_40-47WKW', 'any_18-64_48-49WKW', 'min_18-64_48-49WKW', 'max_18-64_48-49WKW', 'count_18-64_48-49WKW', 'sum_18-64_48-49WKW', 'mean_18-64_48-49WKW', '%_18-64_48-49WKW', 'count_18-64_50-52WKW', 'mean_18-64_50-52WKW', 'count_18-64_>40WKW', 'mean_18-64_>40WKW', 'count_18-64_nonzero_WKW', 'mean_18-64_nonzero_WKW', 'any_18-64_any_WKW', 'all_18-64_any_WKW', 'min_18-64_any_WKW', 'max_18-64_any_WKW', 'count_18-64_any_WKW', 'sum_18-64_any_WKW', 'mean_18-64_any_WKW', '%_18-64_any_WKW', 'any_kid_no_work', 'all_kid_no_work', 'min_kid_no_work', 'max_kid_no_work', 'count_kid_no_work', 'sum_kid_no_work', 'mean_kid_no_work', '%_kid_no_work', 'max_kid_<14WKW', 'sum_kid_<14WKW', 'mean_kid_<14WKW', 'max_kid_14-26WKW', 'sum_kid_14-26WKW', 'mean_kid_14-26WKW', 'max_kid_27-39WKW', 'sum_kid_27-39WKW', 'mean_kid_27-39WKW', 'max_kid_40-47WKW', 'sum_kid_40-47WKW', 'mean_kid_40-47WKW', 'max_kid_50-52WKW', 'sum_kid_50-52WKW', 'mean_kid_50-52WKW', 'max_kid_>40WKW', 'sum_kid_>40WKW', 'mean_kid_>40WKW', 'max_kid_nonzero_WKW', 'sum_kid_nonzero_WKW', 'mean_kid_nonzero_WKW', 'any_kid_any_WKW', 'all_kid_any_WKW', 'min_kid_any_WKW', 'max_kid_any_WKW', 'count_kid_any_WKW', 'sum_kid_any_WKW', 'mean_kid_any_WKW', '%_kid_any_WKW', 'all_anyage_no_work', 'max_anyage_no_work', 'sum_anyage_no_work', 'mean_anyage_no_work', 'any_anyage_<14WKW', 'min_anyage_<14WKW', 'max_anyage_<14WKW', 'count_anyage_<14WKW', 'sum_anyage_<14WKW', 'mean_anyage_<14WKW', '%_anyage_<14WKW', 'any_anyage_14-26WKW', 'all_anyage_14-26WKW', 'min_anyage_14-26WKW', 'max_anyage_14-26WKW', 'count_anyage_14-26WKW', 'sum_anyage_14-26WKW', 'mean_anyage_14-26WKW', '%_anyage_14-26WKW', 'any_anyage_27-39WKW', 'min_anyage_27-39WKW', 'max_anyage_27-39WKW', 'count_anyage_27-39WKW', 'sum_anyage_27-39WKW', 'mean_anyage_27-39WKW', '%_anyage_27-39WKW', 'any_anyage_40-47WKW', 'min_anyage_40-47WKW', 'max_anyage_40-47WKW', 'count_anyage_40-47WKW', 'sum_anyage_40-47WKW', 'mean_anyage_40-47WKW', '%_anyage_40-47WKW', 'any_anyage_48-49WKW', 'min_anyage_48-49WKW', 'max_anyage_48-49WKW', 'count_anyage_48-49WKW', 'sum_anyage_48-49WKW', 'mean_anyage_48-49WKW', '%_anyage_48-49WKW', 'any_anyage_50-52WKW', 'min_anyage_50-52WKW', 'max_anyage_50-52WKW', 'count_anyage_50-52WKW', 'sum_anyage_50-52WKW', 'mean_anyage_50-52WKW', 'any_anyage_>40WKW', 'min_anyage_>40WKW', 'max_anyage_>40WKW', 'count_anyage_>40WKW', 'sum_anyage_>40WKW', 'mean_anyage_>40WKW', 'any_anyage_nonzero_WKW', 'all_anyage_nonzero_WKW', 'min_anyage_nonzero_WKW', 'max_anyage_nonzero_WKW', 'count_anyage_nonzero_WKW', 'sum_anyage_nonzero_WKW', 'mean_anyage_nonzero_WKW', '%_anyage_nonzero_WKW', 'min_anyage_any_WKW', 'max_anyage_any_WKW', 'count_anyage_any_WKW', 'sum_anyage_any_WKW', 'mean_anyage_any_WKW', 'any_adult_no_work_hrs', 'all_adult_no_work_hrs', 'min_adult_no_work_hrs', 'max_adult_no_work_hrs', 'count_adult_no_work_hrs', 'sum_adult_no_work_hrs', 'mean_adult_no_work_hrs', '%_adult_no_work_hrs', 'any_adult_<10_work_hrs', 'all_adult_<10_work_hrs', 'min_adult_<10_work_hrs', 'max_adult_<10_work_hrs', 'count_adult_<10_work_hrs', 'sum_adult_<10_work_hrs', 'mean_adult_<10_work_hrs', '%_adult_<10_work_hrs', 'any_adult_<15_work_hrs', 'all_adult_<15_work_hrs', 'min_adult_<15_work_hrs', 'max_adult_<15_work_hrs', 'count_adult_<15_work_hrs', 'sum_adult_<15_work_hrs', 'mean_adult_<15_work_hrs', '%_adult_<15_work_hrs', 'any_adult_<20_work_hrs', 'all_adult_<20_work_hrs', 'min_adult_<20_work_hrs', 'max_adult_<20_work_hrs', 'count_adult_<20_work_hrs', 'sum_adult_<20_work_hrs', 'mean_adult_<20_work_hrs', '%_adult_<20_work_hrs', 'sum_adult_<30_work_hrs', 'mean_adult_<30_work_hrs', 'mean_adult_<40_work_hrs', 'any_adult_50_plus_work_hrs', 'all_adult_50_plus_work_hrs', 'max_adult_50_plus_work_hrs', 'sum_adult_50_plus_work_hrs', 'mean_adult_50_plus_work_hrs', '%_adult_50_plus_work_hrs', 'any_adult_40_plus_work_hrs', 'all_adult_40_plus_work_hrs', 'max_adult_40_plus_work_hrs', 'mean_adult_40_plus_work_hrs', '%_adult_40_plus_work_hrs', 'min_adult_any_WKHP', 'max_adult_any_WKHP', 'count_adult_any_WKHP', 'sum_adult_any_WKHP', 'mean_adult_any_WKHP', 'any_65+_no_work_hrs', 'all_65+_no_work_hrs', 'min_65+_no_work_hrs', 'max_65+_no_work_hrs', 'count_65+_no_work_hrs', 'sum_65+_no_work_hrs', 'mean_65+_no_work_hrs', '%_65+_no_work_hrs', 'any_65+_<10_work_hrs', 'all_65+_<10_work_hrs', 'min_65+_<10_work_hrs', 'max_65+_<10_work_hrs', 'count_65+_<10_work_hrs', 'sum_65+_<10_work_hrs', 'mean_65+_<10_work_hrs', '%_65+_<10_work_hrs', 'any_65+_<15_work_hrs', 'all_65+_<15_work_hrs', 'min_65+_<15_work_hrs', 'max_65+_<15_work_hrs', 'count_65+_<15_work_hrs', 'sum_65+_<15_work_hrs', 'mean_65+_<15_work_hrs', '%_65+_<15_work_hrs', 'any_65+_<20_work_hrs', 'all_65+_<20_work_hrs', 'min_65+_<20_work_hrs', 'max_65+_<20_work_hrs', 'count_65+_<20_work_hrs', 'sum_65+_<20_work_hrs', 'mean_65+_<20_work_hrs', '%_65+_<20_work_hrs', 'any_65+_<30_work_hrs', 'all_65+_<30_work_hrs', 'min_65+_<30_work_hrs', 'max_65+_<30_work_hrs', 'count_65+_<30_work_hrs', 'sum_65+_<30_work_hrs', 'mean_65+_<30_work_hrs', '%_65+_<30_work_hrs', 'any_65+_<40_work_hrs', 'all_65+_<40_work_hrs', 'min_65+_<40_work_hrs', 'max_65+_<40_work_hrs', 'count_65+_<40_work_hrs', 'sum_65+_<40_work_hrs', 'mean_65+_<40_work_hrs', '%_65+_<40_work_hrs', 'any_65+_<50_work_hrs', 'all_65+_<50_work_hrs', 'min_65+_<50_work_hrs', 'max_65+_<50_work_hrs', 'count_65+_<50_work_hrs', 'sum_65+_<50_work_hrs', 'mean_65+_<50_work_hrs', '%_65+_<50_work_hrs', 'max_65+_50_plus_work_hrs', 'sum_65+_50_plus_work_hrs', 'mean_65+_50_plus_work_hrs', 'min_65+_40_plus_work_hrs', 'max_65+_40_plus_work_hrs', 'count_65+_40_plus_work_hrs', 'sum_65+_40_plus_work_hrs', 'mean_65+_40_plus_work_hrs', '%_65+_40_plus_work_hrs', 'any_65+_any_WKHP', 'all_65+_any_WKHP', 'min_65+_any_WKHP', 'max_65+_any_WKHP', 'count_65+_any_WKHP', 'sum_65+_any_WKHP', 'mean_65+_any_WKHP', '%_65+_any_WKHP', 'any_18-64_no_work_hrs', 'all_18-64_no_work_hrs', 'min_18-64_no_work_hrs', 'max_18-64_no_work_hrs', 'count_18-64_no_work_hrs', 'sum_18-64_no_work_hrs', 'mean_18-64_no_work_hrs', '%_18-64_no_work_hrs', 'any_18-64_<10_work_hrs', 'all_18-64_<10_work_hrs', 'min_18-64_<10_work_hrs', 'max_18-64_<10_work_hrs', 'count_18-64_<10_work_hrs', 'sum_18-64_<10_work_hrs', 'mean_18-64_<10_work_hrs', '%_18-64_<10_work_hrs', 'any_18-64_<15_work_hrs', 'all_18-64_<15_work_hrs', 'min_18-64_<15_work_hrs', 'max_18-64_<15_work_hrs', 'count_18-64_<15_work_hrs', 'sum_18-64_<15_work_hrs', 'mean_18-64_<15_work_hrs', '%_18-64_<15_work_hrs', 'any_18-64_<20_work_hrs', 'all_18-64_<20_work_hrs', 'min_18-64_<20_work_hrs', 'max_18-64_<20_work_hrs', 'count_18-64_<20_work_hrs', 'sum_18-64_<20_work_hrs', 'mean_18-64_<20_work_hrs', '%_18-64_<20_work_hrs', 'mean_18-64_<30_work_hrs', 'mean_18-64_<40_work_hrs', 'mean_18-64_<50_work_hrs', '%_18-64_<50_work_hrs', 'any_18-64_50_plus_work_hrs', 'all_18-64_50_plus_work_hrs', 'min_18-64_50_plus_work_hrs', 'max_18-64_50_plus_work_hrs', 'count_18-64_50_plus_work_hrs', 'sum_18-64_50_plus_work_hrs', 'mean_18-64_50_plus_work_hrs', '%_18-64_50_plus_work_hrs', 'max_18-64_40_plus_work_hrs', 'count_18-64_40_plus_work_hrs', 'mean_18-64_40_plus_work_hrs', 'any_18-64_any_WKHP', 'all_18-64_any_WKHP', 'min_18-64_any_WKHP', 'max_18-64_any_WKHP', 'count_18-64_any_WKHP', 'sum_18-64_any_WKHP', 'mean_18-64_any_WKHP', '%_18-64_any_WKHP', 'any_kid_no_work_hrs', 'all_kid_no_work_hrs', 'min_kid_no_work_hrs', 'max_kid_no_work_hrs', 'count_kid_no_work_hrs', 'sum_kid_no_work_hrs', 'mean_kid_no_work_hrs', '%_kid_no_work_hrs', 'any_kid_<10_work_hrs', 'all_kid_<10_work_hrs', 'min_kid_<10_work_hrs', 'max_kid_<10_work_hrs', 'count_kid_<10_work_hrs', 'sum_kid_<10_work_hrs', 'mean_kid_<10_work_hrs', '%_kid_<10_work_hrs', 'any_kid_<15_work_hrs', 'all_kid_<15_work_hrs', 'min_kid_<15_work_hrs', 'max_kid_<15_work_hrs', 'count_kid_<15_work_hrs', 'sum_kid_<15_work_hrs', 'mean_kid_<15_work_hrs', '%_kid_<15_work_hrs', 'any_kid_<20_work_hrs', 'all_kid_<20_work_hrs', 'min_kid_<20_work_hrs', 'max_kid_<20_work_hrs', 'count_kid_<20_work_hrs', 'sum_kid_<20_work_hrs', 'mean_kid_<20_work_hrs', '%_kid_<20_work_hrs', 'any_kid_<30_work_hrs', 'all_kid_<30_work_hrs', 'min_kid_<30_work_hrs', 'max_kid_<30_work_hrs', 'count_kid_<30_work_hrs', 'sum_kid_<30_work_hrs', 'mean_kid_<30_work_hrs', '%_kid_<30_work_hrs', 'any_kid_<40_work_hrs', 'all_kid_<40_work_hrs', 'min_kid_<40_work_hrs', 'max_kid_<40_work_hrs', 'count_kid_<40_work_hrs', 'sum_kid_<40_work_hrs', 'mean_kid_<40_work_hrs', '%_kid_<40_work_hrs', 'any_kid_<50_work_hrs', 'all_kid_<50_work_hrs', 'min_kid_<50_work_hrs', 'max_kid_<50_work_hrs', 'count_kid_<50_work_hrs', 'sum_kid_<50_work_hrs', 'mean_kid_<50_work_hrs', '%_kid_<50_work_hrs', 'max_kid_40_plus_work_hrs', 'sum_kid_40_plus_work_hrs', 'mean_kid_40_plus_work_hrs', 'any_kid_any_WKHP', 'all_kid_any_WKHP', 'min_kid_any_WKHP', 'max_kid_any_WKHP', 'count_kid_any_WKHP', 'sum_kid_any_WKHP', 'mean_kid_any_WKHP', '%_kid_any_WKHP', 'any_anyage_no_work_hrs', 'all_anyage_no_work_hrs', 'min_anyage_no_work_hrs', 'max_anyage_no_work_hrs', 'count_anyage_no_work_hrs', 'sum_anyage_no_work_hrs', 'mean_anyage_no_work_hrs', '%_anyage_no_work_hrs', 'any_anyage_<10_work_hrs', 'all_anyage_<10_work_hrs', 'min_anyage_<10_work_hrs', 'max_anyage_<10_work_hrs', 'count_anyage_<10_work_hrs', 'sum_anyage_<10_work_hrs', 'mean_anyage_<10_work_hrs', '%_anyage_<10_work_hrs', 'any_anyage_<15_work_hrs', 'all_anyage_<15_work_hrs', 'min_anyage_<15_work_hrs', 'max_anyage_<15_work_hrs', 'count_anyage_<15_work_hrs', 'sum_anyage_<15_work_hrs', 'mean_anyage_<15_work_hrs', '%_anyage_<15_work_hrs', 'any_anyage_<20_work_hrs', 'all_anyage_<20_work_hrs', 'min_anyage_<20_work_hrs', 'max_anyage_<20_work_hrs', 'count_anyage_<20_work_hrs', 'sum_anyage_<20_work_hrs', 'mean_anyage_<20_work_hrs', '%_anyage_<20_work_hrs', 'all_anyage_<30_work_hrs', 'min_anyage_<30_work_hrs', 'max_anyage_<30_work_hrs', 'count_anyage_<30_work_hrs', 'sum_anyage_<30_work_hrs', 'mean_anyage_<30_work_hrs', 'all_anyage_<40_work_hrs', 'max_anyage_<40_work_hrs', 'sum_anyage_<40_work_hrs', 'mean_anyage_<40_work_hrs', '%_anyage_<40_work_hrs', 'any_anyage_<50_work_hrs', 'all_anyage_<50_work_hrs', 'max_anyage_<50_work_hrs', 'count_anyage_<50_work_hrs', 'sum_anyage_<50_work_hrs', 'mean_anyage_<50_work_hrs', '%_anyage_<50_work_hrs', 'any_anyage_50_plus_work_hrs', 'all_anyage_50_plus_work_hrs', 'min_anyage_50_plus_work_hrs', 'max_anyage_50_plus_work_hrs', 'count_anyage_50_plus_work_hrs', 'sum_anyage_50_plus_work_hrs', 'mean_anyage_50_plus_work_hrs', '%_anyage_50_plus_work_hrs', 'any_anyage_40_plus_work_hrs', 'all_anyage_40_plus_work_hrs', 'min_anyage_40_plus_work_hrs', 'max_anyage_40_plus_work_hrs', 'count_anyage_40_plus_work_hrs', 'sum_anyage_40_plus_work_hrs', 'mean_anyage_40_plus_work_hrs', '%_anyage_40_plus_work_hrs', 'min_anyage_any_WKHP', 'max_anyage_any_WKHP', 'count_anyage_any_WKHP', 'sum_anyage_any_WKHP', 'mean_anyage_any_WKHP', 'max_adult_DIS', 'sum_adult_DIS', 'mean_adult_DIS', 'any_adult_not_DIS', 'all_adult_not_DIS', 'mean_adult_not_DIS', '%_adult_not_DIS', 'min_adult_any_DIS', 'max_adult_any_DIS', 'count_adult_any_DIS', 'sum_adult_any_DIS', 'mean_adult_any_DIS', 'min_65+_DIS', 'max_65+_DIS', 'count_65+_DIS', 'sum_65+_DIS', 'mean_65+_DIS', '%_65+_DIS', 'min_65+_not_DIS', 'max_65+_not_DIS', 'sum_65+_not_DIS', 'mean_65+_not_DIS', '%_65+_not_DIS', 'any_65+_any_DIS', 'all_65+_any_DIS', 'min_65+_any_DIS', 'max_65+_any_DIS', 'count_65+_any_DIS', 'sum_65+_any_DIS', 'mean_65+_any_DIS', '%_65+_any_DIS', 'min_18-64_DIS', 'max_18-64_DIS', 'sum_18-64_DIS', 'mean_18-64_DIS', 'mean_18-64_not_DIS', '%_18-64_not_DIS', 'any_18-64_any_DIS', 'all_18-64_any_DIS', 'min_18-64_any_DIS', 'max_18-64_any_DIS', 'count_18-64_any_DIS', 'sum_18-64_any_DIS', 'mean_18-64_any_DIS', '%_18-64_any_DIS', 'max_kid_DIS', 'mean_kid_DIS', 'any_kid_not_DIS', 'all_kid_not_DIS', 'min_kid_not_DIS', 'max_kid_not_DIS', 'count_kid_not_DIS', 'sum_kid_not_DIS', 'mean_kid_not_DIS', '%_kid_not_DIS', 'any_kid_any_DIS', 'all_kid_any_DIS', 'min_kid_any_DIS', 'max_kid_any_DIS', 'count_kid_any_DIS', 'sum_kid_any_DIS', 'mean_kid_any_DIS', '%_kid_any_DIS', 'any_anyage_DIS', 'all_anyage_DIS', 'min_anyage_DIS', 'max_anyage_DIS', 'count_anyage_DIS', 'sum_anyage_DIS', 'mean_anyage_DIS', '%_anyage_DIS', 'any_anyage_not_DIS', 'all_anyage_not_DIS', 'max_anyage_not_DIS', 'sum_anyage_not_DIS', '%_anyage_not_DIS', 'min_anyage_any_DIS', 'max_anyage_any_DIS', 'count_anyage_any_DIS', 'sum_anyage_any_DIS', 'mean_anyage_any_DIS', 'all_adult_NP1', 'max_adult_NP1', 'count_adult_NP1', 'sum_adult_NP1', 'mean_adult_NP1', '%_adult_NP1', 'all_adult_NP2', 'max_adult_NP2', 'count_adult_NP2', 'sum_adult_NP2', 'mean_adult_NP2', '%_adult_NP2', 'all_adult_NP3', 'count_adult_NP3', 'sum_adult_NP3', 'mean_adult_NP3', '%_adult_NP3', 'all_adult_NP4', 'max_adult_NP4', 'sum_adult_NP4', 'mean_adult_NP4', '%_adult_NP4', 'all_adult_NP5', 'max_adult_NP5', 'sum_adult_NP5', 'mean_adult_NP5', '%_adult_NP5', 'all_adult_NP>5', 'sum_adult_NP>5', 'mean_adult_NP>5', '%_adult_NP>5', 'all_adult_NP>6', 'max_adult_NP>6', 'sum_adult_NP>6', 'mean_adult_NP>6', '%_adult_NP>6', 'all_adult_NP>8', 'max_adult_NP>8', 'sum_adult_NP>8', 'mean_adult_NP>8', '%_adult_NP>8', 'sum_adult_NP>10', 'mean_adult_NP>10', 'sum_adult_NP>12', 'mean_adult_NP>12', 'min_adult_anyNP', 'max_adult_anyNP', 'count_adult_anyNP', 'sum_adult_anyNP', 'mean_adult_anyNP', 'all_65+_NP1', 'min_65+_NP1', 'max_65+_NP1', 'count_65+_NP1', 'sum_65+_NP1', 'mean_65+_NP1', '%_65+_NP1', 'all_65+_NP2', 'min_65+_NP2', 'max_65+_NP2', 'sum_65+_NP2', 'mean_65+_NP2', '%_65+_NP2', 'all_65+_NP3', 'min_65+_NP3', 'max_65+_NP3', 'sum_65+_NP3', 'mean_65+_NP3', '%_65+_NP3', 'all_65+_NP4', 'min_65+_NP4', 'max_65+_NP4', 'sum_65+_NP4', 'mean_65+_NP4', '%_65+_NP4', 'all_65+_NP5', 'min_65+_NP5', 'max_65+_NP5', 'sum_65+_NP5', 'mean_65+_NP5', '%_65+_NP5', 'all_65+_NP>5', 'min_65+_NP>5', 'max_65+_NP>5', 'sum_65+_NP>5', 'mean_65+_NP>5', '%_65+_NP>5', 'max_65+_NP>6', 'sum_65+_NP>6', 'mean_65+_NP>6', 'max_65+_NP>8', 'mean_65+_NP>8', 'max_65+_NP>10', 'mean_65+_NP>10', 'max_65+_NP>12', 'sum_65+_NP>12', 'mean_65+_NP>12', 'any_65+_anyNP', 'all_65+_anyNP', 'min_65+_anyNP', 'max_65+_anyNP', 'count_65+_anyNP', 'sum_65+_anyNP', 'mean_65+_anyNP', '%_65+_anyNP', 'all_18-64_NP1', 'min_18-64_NP1', 'max_18-64_NP1', 'count_18-64_NP1', 'sum_18-64_NP1', 'mean_18-64_NP1', '%_18-64_NP1', 'all_18-64_NP2', 'max_18-64_NP2', 'sum_18-64_NP2', 'mean_18-64_NP2', '%_18-64_NP2', 'any_18-64_NP3', 'all_18-64_NP3', 'min_18-64_NP3', 'max_18-64_NP3', 'sum_18-64_NP3', 'mean_18-64_NP3', '%_18-64_NP3', 'any_18-64_NP4', 'all_18-64_NP4', 'min_18-64_NP4', 'max_18-64_NP4', 'count_18-64_NP4', 'sum_18-64_NP4', 'mean_18-64_NP4', '%_18-64_NP4', 'any_18-64_NP5', 'all_18-64_NP5', 'min_18-64_NP5', 'max_18-64_NP5', 'count_18-64_NP5', 'sum_18-64_NP5', 'mean_18-64_NP5', '%_18-64_NP5', 'any_18-64_NP>5', 'all_18-64_NP>5', 'max_18-64_NP>5', 'count_18-64_NP>5', 'sum_18-64_NP>5', 'mean_18-64_NP>5', '%_18-64_NP>5', 'any_18-64_NP>6', 'all_18-64_NP>6', 'min_18-64_NP>6', 'max_18-64_NP>6', 'count_18-64_NP>6', 'sum_18-64_NP>6', 'mean_18-64_NP>6', '%_18-64_NP>6', 'max_18-64_NP>8', 'count_18-64_NP>8', 'sum_18-64_NP>8', 'mean_18-64_NP>8', 'min_18-64_NP>10', 'max_18-64_NP>10', 'count_18-64_NP>10', 'sum_18-64_NP>10', 'mean_18-64_NP>10', 'min_18-64_NP>12', 'max_18-64_NP>12', 'count_18-64_NP>12', 'sum_18-64_NP>12', 'mean_18-64_NP>12', 'any_18-64_anyNP', 'all_18-64_anyNP', 'min_18-64_anyNP', 'max_18-64_anyNP', 'count_18-64_anyNP', 'sum_18-64_anyNP', 'mean_18-64_anyNP', '%_18-64_anyNP', 'max_kid_NP1', 'sum_kid_NP1', 'mean_kid_NP1', 'all_kid_NP2', 'max_kid_NP2', 'count_kid_NP2', 'sum_kid_NP2', 'mean_kid_NP2', '%_kid_NP2', 'max_kid_NP3', 'count_kid_NP3', 'sum_kid_NP3', 'mean_kid_NP3', '%_kid_NP3', 'all_kid_NP4', 'count_kid_NP4', 'sum_kid_NP4', 'mean_kid_NP4', '%_kid_NP4', 'all_kid_NP5', 'mean_kid_NP5', '%_kid_NP5', 'all_kid_NP>5', 'mean_kid_NP>5', '%_kid_NP>5', 'all_kid_NP>6', 'mean_kid_NP>6', '%_kid_NP>6', 'sum_kid_NP>8', 'mean_kid_NP>8', 'mean_kid_NP>10', 'sum_kid_NP>12', 'mean_kid_NP>12', 'any_kid_anyNP', 'all_kid_anyNP', 'min_kid_anyNP', 'max_kid_anyNP', 'count_kid_anyNP', 'sum_kid_anyNP', 'mean_kid_anyNP', '%_kid_anyNP', 'any_anyage_NP1', 'all_anyage_NP1', 'min_anyage_NP1', 'max_anyage_NP1', 'count_anyage_NP1', 'sum_anyage_NP1', 'mean_anyage_NP1', '%_anyage_NP1', 'any_anyage_NP2', 'all_anyage_NP2', 'min_anyage_NP2', 'max_anyage_NP2', 'count_anyage_NP2', 'sum_anyage_NP2', 'mean_anyage_NP2', '%_anyage_NP2', 'any_anyage_NP3', 'all_anyage_NP3', 'max_anyage_NP3', 'count_anyage_NP3', 'sum_anyage_NP3', 'mean_anyage_NP3', '%_anyage_NP3', 'any_anyage_NP4', 'all_anyage_NP4', 'max_anyage_NP4', 'count_anyage_NP4', 'sum_anyage_NP4', 'mean_anyage_NP4', '%_anyage_NP4', 'any_anyage_NP5', 'all_anyage_NP5', 'max_anyage_NP5', 'sum_anyage_NP5', 'mean_anyage_NP5', '%_anyage_NP5', 'any_anyage_NP>5', 'all_anyage_NP>5', 'max_anyage_NP>5', 'sum_anyage_NP>5', 'mean_anyage_NP>5', '%_anyage_NP>5', 'any_anyage_NP>6', 'all_anyage_NP>6', 'max_anyage_NP>6', 'sum_anyage_NP>6', 'mean_anyage_NP>6', '%_anyage_NP>6', 'any_anyage_NP>8', 'all_anyage_NP>8', 'max_anyage_NP>8', 'sum_anyage_NP>8', 'mean_anyage_NP>8', '%_anyage_NP>8', 'max_anyage_NP>10', 'sum_anyage_NP>10', 'mean_anyage_NP>10', 'min_anyage_NP>12', 'max_anyage_NP>12', 'count_anyage_NP>12', 'sum_anyage_NP>12', 'mean_anyage_NP>12', 'min_anyage_anyNP', 'max_anyage_anyNP', 'count_anyage_anyNP', 'sum_anyage_anyNP', 'mean_anyage_anyNP', 'count_adult_work_trans', 'all_65+_work_trans', 'count_65+_work_trans', 'sum_65+_work_trans', 'mean_65+_work_trans', '%_65+_work_trans', 'all_18-64_work_trans', 'count_18-64_work_trans', 'sum_18-64_work_trans', '%_18-64_work_trans', 'all_kid_work_trans', 'count_kid_work_trans', 'sum_kid_work_trans', '%_kid_work_trans', 'any_anyage_work_trans', 'max_anyage_work_trans', 'count_anyage_work_trans', 'sum_anyage_work_trans', 'mean_anyage_work_trans', 'max_adult_WAG0', 'sum_adult_WAG0', 'mean_adult_WAG0', 'sum_adult_WAG<10', 'mean_adult_WAG<10', 'min_adult_WAG<15', 'max_adult_WAG<15', 'sum_adult_WAG<15', 'mean_adult_WAG<15', 'min_adult_WAG<20', 'max_adult_WAG<20', 'count_adult_WAG<20', 'sum_adult_WAG<20', 'mean_adult_WAG<20', 'min_adult_WAG<25', 'max_adult_WAG<25', 'count_adult_WAG<25', 'sum_adult_WAG<25', 'mean_adult_WAG<25', 'min_adult_WAG<30', 'max_adult_WAG<30', 'count_adult_WAG<30', 'sum_adult_WAG<30', 'mean_adult_WAG<30', 'min_adult_WAG<35', 'max_adult_WAG<35', 'count_adult_WAG<35', 'sum_adult_WAG<35', 'mean_adult_WAG<35', 'min_adult_WAG<40', 'max_adult_WAG<40', 'count_adult_WAG<40', 'sum_adult_WAG<40', 'mean_adult_WAG<40', 'min_adult_WAG<45', 'max_adult_WAG<45', 'count_adult_WAG<45', 'sum_adult_WAG<45', 'mean_adult_WAG<45', 'min_adult_WAG<50', 'max_adult_WAG<50', 'count_adult_WAG<50', 'sum_adult_WAG<50', 'mean_adult_WAG<50', 'max_adult_WAG<60', 'count_adult_WAG<60', 'sum_adult_WAG<60', 'mean_adult_WAG<60', 'max_adult_WAG<70', 'count_adult_WAG<70', 'sum_adult_WAG<70', 'mean_adult_WAG<70', 'min_adult_WAG<80', 'max_adult_WAG<80', 'count_adult_WAG<80', 'sum_adult_WAG<80', 'mean_adult_WAG<80', 'min_adult_WAG_any', 'max_adult_WAG_any', 'count_adult_WAG_any', 'sum_adult_WAG_any', 'mean_adult_WAG_any', 'any_65+_WAG0', 'all_65+_WAG0', 'min_65+_WAG0', 'max_65+_WAG0', 'count_65+_WAG0', 'sum_65+_WAG0', 'mean_65+_WAG0', '%_65+_WAG0', 'any_65+_WAG<10', 'all_65+_WAG<10', 'min_65+_WAG<10', 'max_65+_WAG<10', 'count_65+_WAG<10', 'sum_65+_WAG<10', 'mean_65+_WAG<10', '%_65+_WAG<10', 'any_65+_WAG<15', 'all_65+_WAG<15', 'min_65+_WAG<15', 'max_65+_WAG<15', 'count_65+_WAG<15', 'sum_65+_WAG<15', 'mean_65+_WAG<15', '%_65+_WAG<15', 'any_65+_WAG<20', 'all_65+_WAG<20', 'min_65+_WAG<20', 'max_65+_WAG<20', 'count_65+_WAG<20', 'sum_65+_WAG<20', 'mean_65+_WAG<20', '%_65+_WAG<20', 'any_65+_WAG<25', 'all_65+_WAG<25', 'min_65+_WAG<25', 'max_65+_WAG<25', 'count_65+_WAG<25', 'sum_65+_WAG<25', 'mean_65+_WAG<25', '%_65+_WAG<25', 'any_65+_WAG<30', 'all_65+_WAG<30', 'min_65+_WAG<30', 'max_65+_WAG<30', 'count_65+_WAG<30', 'sum_65+_WAG<30', 'mean_65+_WAG<30', '%_65+_WAG<30', 'any_65+_WAG<35', 'all_65+_WAG<35', 'min_65+_WAG<35', 'max_65+_WAG<35', 'count_65+_WAG<35', 'sum_65+_WAG<35', 'mean_65+_WAG<35', '%_65+_WAG<35', 'any_65+_WAG<40', 'all_65+_WAG<40', 'min_65+_WAG<40', 'max_65+_WAG<40', 'count_65+_WAG<40', 'sum_65+_WAG<40', 'mean_65+_WAG<40', '%_65+_WAG<40', 'any_65+_WAG<45', 'all_65+_WAG<45', 'min_65+_WAG<45', 'max_65+_WAG<45', 'count_65+_WAG<45', 'sum_65+_WAG<45', 'mean_65+_WAG<45', '%_65+_WAG<45', 'any_65+_WAG<50', 'all_65+_WAG<50', 'min_65+_WAG<50', 'max_65+_WAG<50', 'count_65+_WAG<50', 'sum_65+_WAG<50', 'mean_65+_WAG<50', '%_65+_WAG<50', 'any_65+_WAG<60', 'all_65+_WAG<60', 'min_65+_WAG<60', 'max_65+_WAG<60', 'count_65+_WAG<60', 'sum_65+_WAG<60', 'mean_65+_WAG<60', '%_65+_WAG<60', 'any_65+_WAG<70', 'all_65+_WAG<70', 'min_65+_WAG<70', 'max_65+_WAG<70', 'count_65+_WAG<70', 'sum_65+_WAG<70', 'mean_65+_WAG<70', '%_65+_WAG<70', 'any_65+_WAG<80', 'all_65+_WAG<80', 'min_65+_WAG<80', 'max_65+_WAG<80', 'count_65+_WAG<80', 'sum_65+_WAG<80', 'mean_65+_WAG<80', '%_65+_WAG<80', 'any_65+_WAG_any', 'all_65+_WAG_any', 'min_65+_WAG_any', 'max_65+_WAG_any', 'count_65+_WAG_any', 'sum_65+_WAG_any', 'mean_65+_WAG_any', '%_65+_WAG_any', 'max_18-64_WAG0', 'mean_18-64_WAG0', 'mean_18-64_WAG<10', 'mean_18-64_WAG<15', 'count_18-64_WAG<20', 'sum_18-64_WAG<20', 'mean_18-64_WAG<20', 'count_18-64_WAG<25', 'sum_18-64_WAG<25', 'mean_18-64_WAG<25', 'max_18-64_WAG<30', 'count_18-64_WAG<30', 'sum_18-64_WAG<30', 'mean_18-64_WAG<30', 'max_18-64_WAG<35', 'count_18-64_WAG<35', 'sum_18-64_WAG<35', 'mean_18-64_WAG<35', 'max_18-64_WAG<40', 'count_18-64_WAG<40', 'sum_18-64_WAG<40', 'mean_18-64_WAG<40', 'any_18-64_WAG<45', 'max_18-64_WAG<45', 'count_18-64_WAG<45', 'sum_18-64_WAG<45', 'mean_18-64_WAG<45', 'any_18-64_WAG<50', 'min_18-64_WAG<50', 'max_18-64_WAG<50', 'count_18-64_WAG<50', 'sum_18-64_WAG<50', 'mean_18-64_WAG<50', '%_18-64_WAG<50', 'count_18-64_WAG<60', 'sum_18-64_WAG<60', 'mean_18-64_WAG<60', 'count_18-64_WAG<70', 'sum_18-64_WAG<70', 'mean_18-64_WAG<70', 'max_18-64_WAG<80', 'count_18-64_WAG<80', 'sum_18-64_WAG<80', 'mean_18-64_WAG<80', 'any_18-64_WAG_any', 'all_18-64_WAG_any', 'min_18-64_WAG_any', 'max_18-64_WAG_any', 'count_18-64_WAG_any', 'sum_18-64_WAG_any', 'mean_18-64_WAG_any', '%_18-64_WAG_any', 'any_kid_WAG0', 'all_kid_WAG0', 'min_kid_WAG0', 'max_kid_WAG0', 'count_kid_WAG0', 'sum_kid_WAG0', 'mean_kid_WAG0', '%_kid_WAG0', 'any_kid_WAG<10', 'all_kid_WAG<10', 'min_kid_WAG<10', 'max_kid_WAG<10', 'count_kid_WAG<10', 'sum_kid_WAG<10', 'mean_kid_WAG<10', '%_kid_WAG<10', 'any_kid_WAG<15', 'all_kid_WAG<15', 'min_kid_WAG<15', 'max_kid_WAG<15', 'count_kid_WAG<15', 'sum_kid_WAG<15', 'mean_kid_WAG<15', '%_kid_WAG<15', 'any_kid_WAG<20', 'all_kid_WAG<20', 'min_kid_WAG<20', 'max_kid_WAG<20', 'count_kid_WAG<20', 'sum_kid_WAG<20', 'mean_kid_WAG<20', '%_kid_WAG<20', 'any_kid_WAG<25', 'all_kid_WAG<25', 'min_kid_WAG<25', 'max_kid_WAG<25', 'count_kid_WAG<25', 'sum_kid_WAG<25', 'mean_kid_WAG<25', '%_kid_WAG<25', 'any_kid_WAG<30', 'all_kid_WAG<30', 'min_kid_WAG<30', 'max_kid_WAG<30', 'count_kid_WAG<30', 'sum_kid_WAG<30', 'mean_kid_WAG<30', '%_kid_WAG<30', 'any_kid_WAG<35', 'all_kid_WAG<35', 'min_kid_WAG<35', 'max_kid_WAG<35', 'count_kid_WAG<35', 'sum_kid_WAG<35', 'mean_kid_WAG<35', '%_kid_WAG<35', 'any_kid_WAG<40', 'all_kid_WAG<40', 'min_kid_WAG<40', 'max_kid_WAG<40', 'count_kid_WAG<40', 'sum_kid_WAG<40', 'mean_kid_WAG<40', '%_kid_WAG<40', 'any_kid_WAG<45', 'all_kid_WAG<45', 'min_kid_WAG<45', 'max_kid_WAG<45', 'count_kid_WAG<45', 'sum_kid_WAG<45', 'mean_kid_WAG<45', '%_kid_WAG<45', 'any_kid_WAG<50', 'all_kid_WAG<50', 'min_kid_WAG<50', 'max_kid_WAG<50', 'count_kid_WAG<50', 'sum_kid_WAG<50', 'mean_kid_WAG<50', '%_kid_WAG<50', 'any_kid_WAG<60', 'all_kid_WAG<60', 'min_kid_WAG<60', 'max_kid_WAG<60', 'count_kid_WAG<60', 'sum_kid_WAG<60', 'mean_kid_WAG<60', '%_kid_WAG<60', 'any_kid_WAG<70', 'all_kid_WAG<70', 'min_kid_WAG<70', 'max_kid_WAG<70', 'count_kid_WAG<70', 'sum_kid_WAG<70', 'mean_kid_WAG<70', '%_kid_WAG<70', 'any_kid_WAG<80', 'all_kid_WAG<80', 'min_kid_WAG<80', 'max_kid_WAG<80', 'count_kid_WAG<80', 'sum_kid_WAG<80', 'mean_kid_WAG<80', '%_kid_WAG<80', 'any_kid_WAG_any', 'all_kid_WAG_any', 'min_kid_WAG_any', 'max_kid_WAG_any', 'count_kid_WAG_any', 'sum_kid_WAG_any', 'mean_kid_WAG_any', '%_kid_WAG_any', 'all_anyage_WAG0', 'min_anyage_WAG0', 'max_anyage_WAG0', 'count_anyage_WAG0', 'sum_anyage_WAG0', 'mean_anyage_WAG0', 'all_anyage_WAG<10', 'max_anyage_WAG<10', 'count_anyage_WAG<10', 'sum_anyage_WAG<10', 'mean_anyage_WAG<10', 'all_anyage_WAG<15', 'min_anyage_WAG<15', 'max_anyage_WAG<15', 'count_anyage_WAG<15', 'sum_anyage_WAG<15', 'mean_anyage_WAG<15', 'all_anyage_WAG<20', 'min_anyage_WAG<20', 'max_anyage_WAG<20', 'count_anyage_WAG<20', 'sum_anyage_WAG<20', 'mean_anyage_WAG<20', 'all_anyage_WAG<25', 'min_anyage_WAG<25', 'max_anyage_WAG<25', 'count_anyage_WAG<25', 'sum_anyage_WAG<25', 'mean_anyage_WAG<25', '%_anyage_WAG<25', 'all_anyage_WAG<30', 'min_anyage_WAG<30', 'max_anyage_WAG<30', 'count_anyage_WAG<30', 'sum_anyage_WAG<30', 'mean_anyage_WAG<30', '%_anyage_WAG<30', 'all_anyage_WAG<35', 'min_anyage_WAG<35', 'max_anyage_WAG<35', 'count_anyage_WAG<35', 'sum_anyage_WAG<35', 'mean_anyage_WAG<35', '%_anyage_WAG<35', 'all_anyage_WAG<40', 'min_anyage_WAG<40', 'max_anyage_WAG<40', 'count_anyage_WAG<40', 'sum_anyage_WAG<40', 'mean_anyage_WAG<40', '%_anyage_WAG<40', 'all_anyage_WAG<45', 'min_anyage_WAG<45', 'max_anyage_WAG<45', 'count_anyage_WAG<45', 'sum_anyage_WAG<45', 'mean_anyage_WAG<45', '%_anyage_WAG<45', 'all_anyage_WAG<50', 'min_anyage_WAG<50', 'max_anyage_WAG<50', 'count_anyage_WAG<50', 'sum_anyage_WAG<50', 'mean_anyage_WAG<50', '%_anyage_WAG<50', 'all_anyage_WAG<60', 'min_anyage_WAG<60', 'max_anyage_WAG<60', 'count_anyage_WAG<60', 'sum_anyage_WAG<60', 'mean_anyage_WAG<60', '%_anyage_WAG<60', 'all_anyage_WAG<70', 'min_anyage_WAG<70', 'max_anyage_WAG<70', 'count_anyage_WAG<70', 'sum_anyage_WAG<70', 'mean_anyage_WAG<70', '%_anyage_WAG<70', 'all_anyage_WAG<80', 'min_anyage_WAG<80', 'max_anyage_WAG<80', 'count_anyage_WAG<80', 'sum_anyage_WAG<80', 'mean_anyage_WAG<80', '%_anyage_WAG<80', 'min_anyage_WAG_any', 'max_anyage_WAG_any', 'count_anyage_WAG_any', 'sum_anyage_WAG_any', 'mean_anyage_WAG_any', 'max_adult_INT1q', 'sum_adult_INT1q', 'mean_adult_INT1q', 'max_adult_INT2q', 'count_adult_INT2q', 'sum_adult_INT2q', 'mean_adult_INT2q', 'min_adult_INT3q', 'max_adult_INT3q', 'count_adult_INT3q', 'sum_adult_INT3q', 'mean_adult_INT3q', 'min_adult_INT4q', 'max_adult_INT4q', 'count_adult_INT4q', 'sum_adult_INT4q', 'mean_adult_INT4q', 'min_adult_INT_any', 'max_adult_INT_any', 'count_adult_INT_any', 'sum_adult_INT_any', 'mean_adult_INT_any', 'all_65+_INT0', 'min_65+_INT0', 'max_65+_INT0', 'sum_65+_INT0', 'mean_65+_INT0', '%_65+_INT0', 'min_65+_INT1q', 'max_65+_INT1q', 'count_65+_INT1q', 'sum_65+_INT1q', 'mean_65+_INT1q', '%_65+_INT1q', 'min_65+_INT2q', 'max_65+_INT2q', 'count_65+_INT2q', 'sum_65+_INT2q', 'mean_65+_INT2q', '%_65+_INT2q', 'min_65+_INT3q', 'max_65+_INT3q', 'count_65+_INT3q', 'sum_65+_INT3q', 'mean_65+_INT3q', '%_65+_INT3q', 'min_65+_INT4q', 'max_65+_INT4q', 'count_65+_INT4q', 'sum_65+_INT4q', 'mean_65+_INT4q', '%_65+_INT4q', 'any_65+_INT_any', 'all_65+_INT_any', 'min_65+_INT_any', 'max_65+_INT_any', 'count_65+_INT_any', 'sum_65+_INT_any', 'mean_65+_INT_any', '%_65+_INT_any', 'mean_18-64_INT0', '%_18-64_INT0', 'min_18-64_INT1q', 'max_18-64_INT1q', 'sum_18-64_INT1q', 'mean_18-64_INT1q', 'min_18-64_INT2q', 'max_18-64_INT2q', 'count_18-64_INT2q', 'sum_18-64_INT2q', 'mean_18-64_INT2q', 'min_18-64_INT3q', 'max_18-64_INT3q', 'count_18-64_INT3q', 'sum_18-64_INT3q', 'mean_18-64_INT3q', 'min_18-64_INT4q', 'max_18-64_INT4q', 'count_18-64_INT4q', 'sum_18-64_INT4q', 'mean_18-64_INT4q', 'any_18-64_INT_any', 'all_18-64_INT_any', 'min_18-64_INT_any', 'max_18-64_INT_any', 'count_18-64_INT_any', 'sum_18-64_INT_any', 'mean_18-64_INT_any', '%_18-64_INT_any', 'any_kid_INT0', 'all_kid_INT0', 'min_kid_INT0', 'max_kid_INT0', 'count_kid_INT0', 'sum_kid_INT0', 'mean_kid_INT0', '%_kid_INT0', 'max_kid_INT1q', 'sum_kid_INT1q', 'mean_kid_INT1q', 'max_kid_INT2q', 'sum_kid_INT2q', 'mean_kid_INT2q', 'max_kid_INT3q', 'sum_kid_INT3q', 'mean_kid_INT3q', 'any_kid_INT_any', 'all_kid_INT_any', 'min_kid_INT_any', 'max_kid_INT_any', 'count_kid_INT_any', 'sum_kid_INT_any', 'mean_kid_INT_any', '%_kid_INT_any', 'all_anyage_INT0', 'max_anyage_INT0', 'count_anyage_INT0', 'sum_anyage_INT0', '%_anyage_INT0', 'any_anyage_INT1q', 'all_anyage_INT1q', 'min_anyage_INT1q', 'max_anyage_INT1q', 'count_anyage_INT1q', 'sum_anyage_INT1q', 'mean_anyage_INT1q', '%_anyage_INT1q', 'any_anyage_INT2q', 'all_anyage_INT2q', 'min_anyage_INT2q', 'max_anyage_INT2q', 'count_anyage_INT2q', 'sum_anyage_INT2q', 'mean_anyage_INT2q', '%_anyage_INT2q', 'any_anyage_INT3q', 'all_anyage_INT3q', 'min_anyage_INT3q', 'max_anyage_INT3q', 'count_anyage_INT3q', 'sum_anyage_INT3q', 'mean_anyage_INT3q', '%_anyage_INT3q', 'any_anyage_INT4q', 'all_anyage_INT4q', 'min_anyage_INT4q', 'max_anyage_INT4q', 'count_anyage_INT4q', 'sum_anyage_INT4q', 'mean_anyage_INT4q', '%_anyage_INT4q', 'min_anyage_INT_any', 'max_anyage_INT_any', 'count_anyage_INT_any', 'sum_anyage_INT_any', 'mean_anyage_INT_any', 'sum_adult_SEMP0', 'max_adult_SEMP1q', 'count_adult_SEMP1q', 'sum_adult_SEMP1q', 'mean_adult_SEMP1q', 'min_adult_SEMP2q', 'max_adult_SEMP2q', 'count_adult_SEMP2q', 'sum_adult_SEMP2q', 'mean_adult_SEMP2q', 'min_adult_SEMP3q', 'max_adult_SEMP3q', 'count_adult_SEMP3q', 'sum_adult_SEMP3q', 'mean_adult_SEMP3q', 'min_adult_SEMP4q', 'max_adult_SEMP4q', 'count_adult_SEMP4q', 'sum_adult_SEMP4q', 'mean_adult_SEMP4q', 'min_adult_SEMP_any', 'max_adult_SEMP_any', 'count_adult_SEMP_any', 'sum_adult_SEMP_any', 'mean_adult_SEMP_any', 'any_65+_SEMP0', 'all_65+_SEMP0', 'min_65+_SEMP0', 'max_65+_SEMP0', 'count_65+_SEMP0', 'sum_65+_SEMP0', 'mean_65+_SEMP0', '%_65+_SEMP0', 'max_65+_SEMP1q', 'sum_65+_SEMP1q', 'mean_65+_SEMP1q', 'max_65+_SEMP2q', 'sum_65+_SEMP2q', 'mean_65+_SEMP2q', 'max_65+_SEMP3q', 'sum_65+_SEMP3q', 'mean_65+_SEMP3q', 'max_65+_SEMP4q', 'sum_65+_SEMP4q', 'mean_65+_SEMP4q', 'any_65+_SEMP_any', 'all_65+_SEMP_any', 'min_65+_SEMP_any', 'max_65+_SEMP_any', 'count_65+_SEMP_any', 'sum_65+_SEMP_any', 'mean_65+_SEMP_any', '%_65+_SEMP_any', 'count_18-64_SEMP0', 'sum_18-64_SEMP0', 'mean_18-64_SEMP0', '%_18-64_SEMP0', 'min_18-64_SEMP1q', 'max_18-64_SEMP1q', 'count_18-64_SEMP1q', 'sum_18-64_SEMP1q', 'mean_18-64_SEMP1q', 'min_18-64_SEMP2q', 'max_18-64_SEMP2q', 'count_18-64_SEMP2q', 'sum_18-64_SEMP2q', 'mean_18-64_SEMP2q', 'any_18-64_SEMP3q', 'min_18-64_SEMP3q', 'max_18-64_SEMP3q', 'count_18-64_SEMP3q', 'sum_18-64_SEMP3q', 'mean_18-64_SEMP3q', 'min_18-64_SEMP4q', 'max_18-64_SEMP4q', 'count_18-64_SEMP4q', 'sum_18-64_SEMP4q', 'mean_18-64_SEMP4q', 'any_18-64_SEMP_any', 'all_18-64_SEMP_any', 'min_18-64_SEMP_any', 'max_18-64_SEMP_any', 'count_18-64_SEMP_any', 'sum_18-64_SEMP_any', 'mean_18-64_SEMP_any', '%_18-64_SEMP_any', 'any_kid_SEMP0', 'all_kid_SEMP0', 'min_kid_SEMP0', 'max_kid_SEMP0', 'count_kid_SEMP0', 'sum_kid_SEMP0', 'mean_kid_SEMP0', '%_kid_SEMP0', 'max_kid_SEMP1q', 'sum_kid_SEMP1q', 'mean_kid_SEMP1q', 'any_kid_SEMP_any', 'all_kid_SEMP_any', 'min_kid_SEMP_any', 'max_kid_SEMP_any', 'count_kid_SEMP_any', 'sum_kid_SEMP_any', 'mean_kid_SEMP_any', '%_kid_SEMP_any', 'all_anyage_SEMP0', 'max_anyage_SEMP0', 'count_anyage_SEMP0', 'sum_anyage_SEMP0', '%_anyage_SEMP0', 'any_anyage_SEMP1q', 'min_anyage_SEMP1q', 'max_anyage_SEMP1q', 'count_anyage_SEMP1q', 'sum_anyage_SEMP1q', 'mean_anyage_SEMP1q', 'any_anyage_SEMP2q', 'min_anyage_SEMP2q', 'max_anyage_SEMP2q', 'count_anyage_SEMP2q', 'sum_anyage_SEMP2q', 'mean_anyage_SEMP2q', '%_anyage_SEMP2q', 'any_anyage_SEMP3q', 'min_anyage_SEMP3q', 'max_anyage_SEMP3q', 'count_anyage_SEMP3q', 'sum_anyage_SEMP3q', 'mean_anyage_SEMP3q', 'any_anyage_SEMP4q', 'min_anyage_SEMP4q', 'max_anyage_SEMP4q', 'count_anyage_SEMP4q', 'sum_anyage_SEMP4q', 'mean_anyage_SEMP4q', '%_anyage_SEMP4q', 'min_anyage_SEMP_any', 'max_anyage_SEMP_any', 'count_anyage_SEMP_any', 'sum_anyage_SEMP_any', 'mean_anyage_SEMP_any', 'mean_adult_SSP0', 'min_adult_SSP1q', 'max_adult_SSP1q', 'count_adult_SSP1q', 'sum_adult_SSP1q', 'mean_adult_SSP1q', 'min_adult_SSP2q', 'max_adult_SSP2q', 'count_adult_SSP2q', 'sum_adult_SSP2q', 'mean_adult_SSP2q', 'min_adult_SSP3q', 'max_adult_SSP3q', 'count_adult_SSP3q', 'sum_adult_SSP3q', 'mean_adult_SSP3q', 'min_adult_SSP4q', 'max_adult_SSP4q', 'count_adult_SSP4q', 'sum_adult_SSP4q', 'mean_adult_SSP4q', 'min_adult_SSP_any', 'max_adult_SSP_any', 'count_adult_SSP_any', 'sum_adult_SSP_any', 'mean_adult_SSP_any', 'min_65+_SSP0', 'max_65+_SSP0', 'count_65+_SSP0', 'sum_65+_SSP0', 'mean_65+_SSP0', '%_65+_SSP0', 'min_65+_SSP1q', 'max_65+_SSP1q', 'count_65+_SSP1q', 'sum_65+_SSP1q', 'mean_65+_SSP1q', '%_65+_SSP1q', 'min_65+_SSP2q', 'max_65+_SSP2q', 'count_65+_SSP2q', 'sum_65+_SSP2q', 'mean_65+_SSP2q', '%_65+_SSP2q', 'any_65+_SSP3q', 'min_65+_SSP3q', 'max_65+_SSP3q', 'count_65+_SSP3q', 'sum_65+_SSP3q', 'mean_65+_SSP3q', '%_65+_SSP3q', 'any_65+_SSP4q', 'min_65+_SSP4q', 'max_65+_SSP4q', 'count_65+_SSP4q', 'sum_65+_SSP4q', 'mean_65+_SSP4q', '%_65+_SSP4q', 'any_65+_SSP_any', 'all_65+_SSP_any', 'min_65+_SSP_any', 'max_65+_SSP_any', 'count_65+_SSP_any', 'sum_65+_SSP_any', 'mean_65+_SSP_any', '%_65+_SSP_any', 'count_18-64_SSP0', 'sum_18-64_SSP0', 'mean_18-64_SSP0', '%_18-64_SSP0', 'min_18-64_SSP1q', 'max_18-64_SSP1q', 'count_18-64_SSP1q', 'sum_18-64_SSP1q', 'mean_18-64_SSP1q', 'min_18-64_SSP2q', 'max_18-64_SSP2q', 'count_18-64_SSP2q', 'sum_18-64_SSP2q', 'mean_18-64_SSP2q', 'min_18-64_SSP3q', 'max_18-64_SSP3q', 'count_18-64_SSP3q', 'sum_18-64_SSP3q', 'mean_18-64_SSP3q', 'min_18-64_SSP4q', 'max_18-64_SSP4q', 'count_18-64_SSP4q', 'sum_18-64_SSP4q', 'mean_18-64_SSP4q', 'any_18-64_SSP_any', 'all_18-64_SSP_any', 'min_18-64_SSP_any', 'max_18-64_SSP_any', 'count_18-64_SSP_any', 'sum_18-64_SSP_any', 'mean_18-64_SSP_any', '%_18-64_SSP_any', 'any_kid_SSP0', 'all_kid_SSP0', 'min_kid_SSP0', 'max_kid_SSP0', 'count_kid_SSP0', 'sum_kid_SSP0', 'mean_kid_SSP0', '%_kid_SSP0', 'max_kid_SSP1q', 'mean_kid_SSP1q', 'max_kid_SSP2q', 'sum_kid_SSP2q', 'mean_kid_SSP2q', 'max_kid_SSP3q', 'sum_kid_SSP3q', 'mean_kid_SSP3q', 'any_kid_SSP_any', 'all_kid_SSP_any', 'min_kid_SSP_any', 'max_kid_SSP_any', 'count_kid_SSP_any', 'sum_kid_SSP_any', 'mean_kid_SSP_any', '%_kid_SSP_any', 'any_anyage_SSP0', 'all_anyage_SSP0', 'max_anyage_SSP0', 'sum_anyage_SSP0', '%_anyage_SSP0', 'any_anyage_SSP1q', 'all_anyage_SSP1q', 'min_anyage_SSP1q', 'max_anyage_SSP1q', 'count_anyage_SSP1q', 'sum_anyage_SSP1q', 'mean_anyage_SSP1q', '%_anyage_SSP1q', 'any_anyage_SSP2q', 'all_anyage_SSP2q', 'min_anyage_SSP2q', 'max_anyage_SSP2q', 'count_anyage_SSP2q', 'sum_anyage_SSP2q', 'mean_anyage_SSP2q', '%_anyage_SSP2q', 'any_anyage_SSP3q', 'all_anyage_SSP3q', 'min_anyage_SSP3q', 'max_anyage_SSP3q', 'count_anyage_SSP3q', 'sum_anyage_SSP3q', 'mean_anyage_SSP3q', '%_anyage_SSP3q', 'any_anyage_SSP4q', 'all_anyage_SSP4q', 'min_anyage_SSP4q', 'max_anyage_SSP4q', 'count_anyage_SSP4q', 'sum_anyage_SSP4q', 'mean_anyage_SSP4q', '%_anyage_SSP4q', 'min_anyage_SSP_any', 'max_anyage_SSP_any', 'count_anyage_SSP_any', 'sum_anyage_SSP_any', 'mean_anyage_SSP_any', 'count_adult_SSIP0', 'min_adult_SSIP1q', 'max_adult_SSIP1q', 'count_adult_SSIP1q', 'sum_adult_SSIP1q', 'mean_adult_SSIP1q', 'max_adult_SSIP2q', 'count_adult_SSIP2q', 'sum_adult_SSIP2q', 'mean_adult_SSIP2q', 'min_adult_SSIP3q', 'max_adult_SSIP3q', 'count_adult_SSIP3q', 'sum_adult_SSIP3q', 'mean_adult_SSIP3q', 'min_adult_SSIP_any', 'max_adult_SSIP_any', 'count_adult_SSIP_any', 'sum_adult_SSIP_any', 'mean_adult_SSIP_any', 'all_65+_SSIP0', 'min_65+_SSIP0', 'max_65+_SSIP0', 'sum_65+_SSIP0', 'mean_65+_SSIP0', '%_65+_SSIP0', 'min_65+_SSIP1q', 'max_65+_SSIP1q', 'count_65+_SSIP1q', 'sum_65+_SSIP1q', 'mean_65+_SSIP1q', 'max_65+_SSIP2q', 'count_65+_SSIP2q', 'sum_65+_SSIP2q', 'mean_65+_SSIP2q', 'min_65+_SSIP3q', 'max_65+_SSIP3q', 'count_65+_SSIP3q', 'sum_65+_SSIP3q', 'mean_65+_SSIP3q', '%_65+_SSIP3q', 'any_65+_SSIP_any', 'all_65+_SSIP_any', 'min_65+_SSIP_any', 'max_65+_SSIP_any', 'count_65+_SSIP_any', 'sum_65+_SSIP_any', 'mean_65+_SSIP_any', '%_65+_SSIP_any', 'count_18-64_SSIP0', 'sum_18-64_SSIP0', 'mean_18-64_SSIP0', '%_18-64_SSIP0', 'max_18-64_SSIP1q', 'sum_18-64_SSIP1q', 'mean_18-64_SSIP1q', 'max_18-64_SSIP2q', 'sum_18-64_SSIP2q', 'mean_18-64_SSIP2q', 'min_18-64_SSIP3q', 'max_18-64_SSIP3q', 'count_18-64_SSIP3q', 'sum_18-64_SSIP3q', 'mean_18-64_SSIP3q', 'any_18-64_SSIP_any', 'all_18-64_SSIP_any', 'min_18-64_SSIP_any', 'max_18-64_SSIP_any', 'count_18-64_SSIP_any', 'sum_18-64_SSIP_any', 'mean_18-64_SSIP_any', '%_18-64_SSIP_any', 'any_kid_SSIP0', 'all_kid_SSIP0', 'min_kid_SSIP0', 'max_kid_SSIP0', 'count_kid_SSIP0', 'sum_kid_SSIP0', 'mean_kid_SSIP0', '%_kid_SSIP0', 'max_kid_SSIP1q', 'sum_kid_SSIP1q', 'mean_kid_SSIP1q', 'max_kid_SSIP2q', 'sum_kid_SSIP2q', 'mean_kid_SSIP2q', 'max_kid_SSIP3q', 'sum_kid_SSIP3q', 'mean_kid_SSIP3q', 'any_kid_SSIP_any', 'all_kid_SSIP_any', 'min_kid_SSIP_any', 'max_kid_SSIP_any', 'count_kid_SSIP_any', 'sum_kid_SSIP_any', 'mean_kid_SSIP_any', '%_kid_SSIP_any', 'any_anyage_SSIP0', 'all_anyage_SSIP0', 'max_anyage_SSIP0', 'count_anyage_SSIP0', 'sum_anyage_SSIP0', '%_anyage_SSIP0', 'any_anyage_SSIP1q', 'min_anyage_SSIP1q', 'max_anyage_SSIP1q', 'count_anyage_SSIP1q', 'sum_anyage_SSIP1q', 'mean_anyage_SSIP1q', 'any_anyage_SSIP2q', 'min_anyage_SSIP2q', 'max_anyage_SSIP2q', 'count_anyage_SSIP2q', 'sum_anyage_SSIP2q', 'mean_anyage_SSIP2q', 'any_anyage_SSIP3q', 'all_anyage_SSIP3q', 'min_anyage_SSIP3q', 'max_anyage_SSIP3q', 'count_anyage_SSIP3q', 'sum_anyage_SSIP3q', 'mean_anyage_SSIP3q', '%_anyage_SSIP3q', 'min_anyage_SSIP_any', 'max_anyage_SSIP_any', 'count_anyage_SSIP_any', 'sum_anyage_SSIP_any', 'mean_anyage_SSIP_any', 'count_adult_PA0', 'sum_adult_PA0', 'max_adult_PA1q', 'sum_adult_PA1q', 'mean_adult_PA1q', 'max_adult_PA2q', 'count_adult_PA2q', 'sum_adult_PA2q', 'mean_adult_PA2q', 'max_adult_PA3q', 'count_adult_PA3q', 'sum_adult_PA3q', 'mean_adult_PA3q', 'min_adult_PA_any', 'max_adult_PA_any', 'count_adult_PA_any', 'sum_adult_PA_any', 'mean_adult_PA_any', 'any_65+_PA0', 'all_65+_PA0', 'min_65+_PA0', 'max_65+_PA0', 'count_65+_PA0', 'sum_65+_PA0', 'mean_65+_PA0', '%_65+_PA0', 'max_65+_PA1q', 'sum_65+_PA1q', 'mean_65+_PA1q', 'max_65+_PA2q', 'sum_65+_PA2q', 'mean_65+_PA2q', 'max_65+_PA3q', 'sum_65+_PA3q', 'mean_65+_PA3q', 'any_65+_PA_any', 'all_65+_PA_any', 'min_65+_PA_any', 'max_65+_PA_any', 'count_65+_PA_any', 'sum_65+_PA_any', 'mean_65+_PA_any', '%_65+_PA_any', 'all_18-64_PA0', 'min_18-64_PA0', 'max_18-64_PA0', 'count_18-64_PA0', 'sum_18-64_PA0', 'mean_18-64_PA0', '%_18-64_PA0', 'max_18-64_PA1q', 'sum_18-64_PA1q', 'mean_18-64_PA1q', 'min_18-64_PA2q', 'max_18-64_PA2q', 'count_18-64_PA2q', 'sum_18-64_PA2q', 'mean_18-64_PA2q', 'min_18-64_PA3q', 'max_18-64_PA3q', 'count_18-64_PA3q', 'sum_18-64_PA3q', 'mean_18-64_PA3q', 'any_18-64_PA_any', 'all_18-64_PA_any', 'min_18-64_PA_any', 'max_18-64_PA_any', 'count_18-64_PA_any', 'sum_18-64_PA_any', 'mean_18-64_PA_any', '%_18-64_PA_any', 'any_kid_PA0', 'all_kid_PA0', 'min_kid_PA0', 'max_kid_PA0', 'count_kid_PA0', 'sum_kid_PA0', 'mean_kid_PA0', '%_kid_PA0', 'max_kid_PA1q', 'mean_kid_PA1q', 'max_kid_PA2q', 'sum_kid_PA2q', 'mean_kid_PA2q', 'max_kid_PA3q', 'sum_kid_PA3q', 'mean_kid_PA3q', 'any_kid_PA_any', 'all_kid_PA_any', 'min_kid_PA_any', 'max_kid_PA_any', 'count_kid_PA_any', 'sum_kid_PA_any', 'mean_kid_PA_any', '%_kid_PA_any', 'all_anyage_PA0', 'min_anyage_PA0', 'max_anyage_PA0', 'count_anyage_PA0', 'sum_anyage_PA0', 'min_anyage_PA1q', 'max_anyage_PA1q', 'count_anyage_PA1q', 'sum_anyage_PA1q', 'mean_anyage_PA1q', 'any_anyage_PA2q', 'min_anyage_PA2q', 'max_anyage_PA2q', 'count_anyage_PA2q', 'sum_anyage_PA2q', 'mean_anyage_PA2q', 'any_anyage_PA3q', 'min_anyage_PA3q', 'max_anyage_PA3q', 'count_anyage_PA3q', 'sum_anyage_PA3q', 'mean_anyage_PA3q', 'min_anyage_PA_any', 'max_anyage_PA_any', 'count_anyage_PA_any', 'sum_anyage_PA_any', 'mean_anyage_PA_any', 'min_adult_RETP1q', 'max_adult_RETP1q', 'count_adult_RETP1q', 'sum_adult_RETP1q', 'mean_adult_RETP1q', 'min_adult_RETP2q', 'max_adult_RETP2q', 'count_adult_RETP2q', 'sum_adult_RETP2q', 'mean_adult_RETP2q', 'min_adult_RETP3q', 'max_adult_RETP3q', 'count_adult_RETP3q', 'sum_adult_RETP3q', 'mean_adult_RETP3q', 'min_adult_RETP_any', 'max_adult_RETP_any', 'count_adult_RETP_any', 'sum_adult_RETP_any', 'mean_adult_RETP_any', '%_65+_RETP0', 'min_65+_RETP1q', 'max_65+_RETP1q', 'count_65+_RETP1q', 'sum_65+_RETP1q', 'mean_65+_RETP1q', '%_65+_RETP1q', 'min_65+_RETP2q', 'max_65+_RETP2q', 'count_65+_RETP2q', 'sum_65+_RETP2q', 'mean_65+_RETP2q', '%_65+_RETP2q', 'min_65+_RETP3q', 'max_65+_RETP3q', 'count_65+_RETP3q', 'sum_65+_RETP3q', 'mean_65+_RETP3q', '%_65+_RETP3q', 'any_65+_RETP_any', 'all_65+_RETP_any', 'min_65+_RETP_any', 'max_65+_RETP_any', 'count_65+_RETP_any', 'sum_65+_RETP_any', 'mean_65+_RETP_any', '%_65+_RETP_any', 'count_18-64_RETP0', '%_18-64_RETP0', 'max_18-64_RETP1q', 'count_18-64_RETP1q', 'sum_18-64_RETP1q', 'mean_18-64_RETP1q', 'max_18-64_RETP2q', 'sum_18-64_RETP2q', 'mean_18-64_RETP2q', 'min_18-64_RETP3q', 'max_18-64_RETP3q', 'count_18-64_RETP3q', 'sum_18-64_RETP3q', 'mean_18-64_RETP3q', 'any_18-64_RETP_any', 'all_18-64_RETP_any', 'min_18-64_RETP_any', 'max_18-64_RETP_any', 'count_18-64_RETP_any', 'sum_18-64_RETP_any', 'mean_18-64_RETP_any', '%_18-64_RETP_any', 'all_kid_RETP0', 'count_kid_RETP0', '%_kid_RETP0', 'max_kid_RETP1q', 'sum_kid_RETP1q', 'mean_kid_RETP1q', 'any_kid_RETP_any', 'all_kid_RETP_any', 'min_kid_RETP_any', 'max_kid_RETP_any', 'count_kid_RETP_any', 'sum_kid_RETP_any', 'mean_kid_RETP_any', '%_kid_RETP_any', 'any_anyage_RETP1q', 'all_anyage_RETP1q', 'min_anyage_RETP1q', 'max_anyage_RETP1q', 'count_anyage_RETP1q', 'sum_anyage_RETP1q', 'mean_anyage_RETP1q', '%_anyage_RETP1q', 'any_anyage_RETP2q', 'all_anyage_RETP2q', 'min_anyage_RETP2q', 'max_anyage_RETP2q', 'count_anyage_RETP2q', 'sum_anyage_RETP2q', 'mean_anyage_RETP2q', '%_anyage_RETP2q', 'any_anyage_RETP3q', 'all_anyage_RETP3q', 'min_anyage_RETP3q', 'max_anyage_RETP3q', 'count_anyage_RETP3q', 'sum_anyage_RETP3q', 'mean_anyage_RETP3q', '%_anyage_RETP3q', 'min_anyage_RETP_any', 'max_anyage_RETP_any', 'count_anyage_RETP_any', 'sum_anyage_RETP_any', 'mean_anyage_RETP_any', 'max_adult_OI1q', 'count_adult_OI1q', 'sum_adult_OI1q', 'mean_adult_OI1q', 'max_adult_OI2q', 'count_adult_OI2q', 'sum_adult_OI2q', 'mean_adult_OI2q', 'max_adult_OI3q', 'count_adult_OI3q', 'sum_adult_OI3q', 'mean_adult_OI3q', 'min_adult_OI_any', 'max_adult_OI_any', 'count_adult_OI_any', 'sum_adult_OI_any', 'mean_adult_OI_any', 'max_65+_OI1q', 'sum_65+_OI1q', 'mean_65+_OI1q', 'max_65+_OI2q', 'sum_65+_OI2q', 'mean_65+_OI2q', 'min_65+_OI3q', 'max_65+_OI3q', 'count_65+_OI3q', 'sum_65+_OI3q', 'mean_65+_OI3q', 'any_65+_OI_any', 'all_65+_OI_any', 'min_65+_OI_any', 'max_65+_OI_any', 'count_65+_OI_any', 'sum_65+_OI_any', 'mean_65+_OI_any', '%_65+_OI_any', 'max_18-64_OI1q', 'sum_18-64_OI1q', 'mean_18-64_OI1q', 'min_18-64_OI2q', 'max_18-64_OI2q', 'count_18-64_OI2q', 'sum_18-64_OI2q', 'mean_18-64_OI2q', 'min_18-64_OI3q', 'max_18-64_OI3q', 'count_18-64_OI3q', 'sum_18-64_OI3q', 'mean_18-64_OI3q', 'any_18-64_OI_any', 'all_18-64_OI_any', 'min_18-64_OI_any', 'max_18-64_OI_any', 'count_18-64_OI_any', 'sum_18-64_OI_any', 'mean_18-64_OI_any', '%_18-64_OI_any', 'max_kid_OI1q', 'sum_kid_OI1q', 'mean_kid_OI1q', 'max_kid_OI2q', 'sum_kid_OI2q', 'mean_kid_OI2q', 'max_kid_OI3q', 'sum_kid_OI3q', 'mean_kid_OI3q', 'any_kid_OI_any', 'all_kid_OI_any', 'min_kid_OI_any', 'max_kid_OI_any', 'count_kid_OI_any', 'sum_kid_OI_any', 'mean_kid_OI_any', '%_kid_OI_any', 'min_anyage_OI1q', 'max_anyage_OI1q', 'count_anyage_OI1q', 'sum_anyage_OI1q', 'mean_anyage_OI1q', 'any_anyage_OI2q', 'min_anyage_OI2q', 'max_anyage_OI2q', 'count_anyage_OI2q', 'sum_anyage_OI2q', 'mean_anyage_OI2q', 'any_anyage_OI3q', 'min_anyage_OI3q', 'max_anyage_OI3q', 'count_anyage_OI3q', 'sum_anyage_OI3q', 'mean_anyage_OI3q', '%_anyage_OI3q', 'min_anyage_OI_any', 'max_anyage_OI_any', 'count_anyage_OI_any', 'sum_anyage_OI_any', 'mean_anyage_OI_any', 'max_adult_White', 'mean_adult_White', '%_adult_White', 'all_adult_Black', 'sum_adult_Black', 'mean_adult_Black', '%_adult_Black', 'sum_adult_Asian', 'mean_adult_Asian', '%_adult_Asian', 'sum_adult_Hisp', 'mean_adult_Hisp', '%_adult_Hisp', 'max_adult_ETH_other', 'sum_adult_ETH_other', 'mean_adult_ETH_other', 'min_adult_ETH_any', 'max_adult_ETH_any', 'count_adult_ETH_any', 'sum_adult_ETH_any', 'mean_adult_ETH_any', 'all_65+_White', 'min_65+_White', 'max_65+_White', 'sum_65+_White', 'mean_65+_White', '%_65+_White', 'all_65+_Black', 'min_65+_Black', 'max_65+_Black', 'sum_65+_Black', 'mean_65+_Black', '%_65+_Black', 'all_65+_Asian', 'min_65+_Asian', 'max_65+_Asian', 'sum_65+_Asian', 'mean_65+_Asian', '%_65+_Asian', 'all_65+_Hisp', 'min_65+_Hisp', 'max_65+_Hisp', 'sum_65+_Hisp', 'mean_65+_Hisp', '%_65+_Hisp', 'max_65+_ETH_other', 'mean_65+_ETH_other', 'any_65+_ETH_any', 'all_65+_ETH_any', 'min_65+_ETH_any', 'max_65+_ETH_any', 'count_65+_ETH_any', 'sum_65+_ETH_any', 'mean_65+_ETH_any', '%_65+_ETH_any', 'max_18-64_White', 'sum_18-64_White', 'mean_18-64_White', '%_18-64_White', 'all_18-64_Black', 'max_18-64_Black', 'sum_18-64_Black', 'mean_18-64_Black', '%_18-64_Black', 'max_18-64_Asian', 'count_18-64_Asian', 'sum_18-64_Asian', 'mean_18-64_Asian', '%_18-64_Asian', 'max_18-64_Hisp', 'count_18-64_Hisp', 'sum_18-64_Hisp', 'mean_18-64_Hisp', '%_18-64_Hisp', 'any_18-64_ETH_other', 'max_18-64_ETH_other', 'count_18-64_ETH_other', 'sum_18-64_ETH_other', 'mean_18-64_ETH_other', '%_18-64_ETH_other', 'any_18-64_ETH_any', 'all_18-64_ETH_any', 'min_18-64_ETH_any', 'max_18-64_ETH_any', 'count_18-64_ETH_any', 'sum_18-64_ETH_any', 'mean_18-64_ETH_any', '%_18-64_ETH_any', 'all_kid_White', 'mean_kid_White', '%_kid_White', 'all_kid_Black', 'mean_kid_Black', '%_kid_Black', 'all_kid_Asian', 'mean_kid_Asian', '%_kid_Asian', 'all_kid_Hisp', 'mean_kid_Hisp', '%_kid_Hisp', 'mean_kid_ETH_other', '%_kid_ETH_other', 'any_kid_ETH_any', 'all_kid_ETH_any', 'min_kid_ETH_any', 'max_kid_ETH_any', 'count_kid_ETH_any', 'sum_kid_ETH_any', 'mean_kid_ETH_any', '%_kid_ETH_any', 'any_anyage_White', 'all_anyage_White', 'min_anyage_White', 'max_anyage_White', 'sum_anyage_White', 'mean_anyage_White', '%_anyage_White', 'any_anyage_Black', 'all_anyage_Black', 'max_anyage_Black', 'sum_anyage_Black', 'mean_anyage_Black', '%_anyage_Black', 'any_anyage_Asian', 'all_anyage_Asian', 'max_anyage_Asian', 'count_anyage_Asian', 'sum_anyage_Asian', 'mean_anyage_Asian', '%_anyage_Asian', 'any_anyage_Hisp', 'all_anyage_Hisp', 'max_anyage_Hisp', 'sum_anyage_Hisp', 'mean_anyage_Hisp', '%_anyage_Hisp', 'all_anyage_ETH_other', 'max_anyage_ETH_other', 'sum_anyage_ETH_other', 'mean_anyage_ETH_other', '%_anyage_ETH_other', 'min_anyage_ETH_any', 'max_anyage_ETH_any', 'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any', 'max_adult_TINP0', 'sum_adult_TINP0', 'mean_adult_TINP0', 'mean_adult_TINP<10', 'mean_adult_TINP<15', 'mean_adult_TINP<20', 'mean_adult_TINP<25', 'count_adult_TINP<30', 'sum_adult_TINP<30', 'mean_adult_TINP<30', 'count_adult_TINP<35', 'sum_adult_TINP<35', 'mean_adult_TINP<35', 'count_adult_TINP<40', 'sum_adult_TINP<40', 'mean_adult_TINP<40', 'max_adult_TINP<45', 'count_adult_TINP<45', 'sum_adult_TINP<45', 'mean_adult_TINP<45', 'min_adult_TINP<50', 'max_adult_TINP<50', 'count_adult_TINP<50', 'sum_adult_TINP<50', 'mean_adult_TINP<50', 'count_adult_TINP<60', 'sum_adult_TINP<60', 'mean_adult_TINP<60', 'count_adult_TINP<70', 'sum_adult_TINP<70', 'mean_adult_TINP<70', 'count_adult_TINP<80', 'sum_adult_TINP<80', 'mean_adult_TINP<80', 'min_adult_TINP_any', 'max_adult_TINP_any', 'count_adult_TINP_any', 'sum_adult_TINP_any', 'mean_adult_TINP_any', 'min_65+_TINP0', 'max_65+_TINP0', 'count_65+_TINP0', 'sum_65+_TINP0', 'mean_65+_TINP0', '%_65+_TINP0', 'min_65+_TINP<10', 'max_65+_TINP<10', 'count_65+_TINP<10', 'sum_65+_TINP<10', 'mean_65+_TINP<10', '%_65+_TINP<10', 'min_65+_TINP<15', 'max_65+_TINP<15', 'sum_65+_TINP<15', 'mean_65+_TINP<15', '%_65+_TINP<15', 'min_65+_TINP<20', 'max_65+_TINP<20', 'sum_65+_TINP<20', 'mean_65+_TINP<20', '%_65+_TINP<20', 'min_65+_TINP<25', 'max_65+_TINP<25', 'sum_65+_TINP<25', 'mean_65+_TINP<25', '%_65+_TINP<25', 'any_65+_TINP<30', 'min_65+_TINP<30', 'max_65+_TINP<30', 'count_65+_TINP<30', 'sum_65+_TINP<30', 'mean_65+_TINP<30', '%_65+_TINP<30', 'any_65+_TINP<35', 'all_65+_TINP<35', 'min_65+_TINP<35', 'max_65+_TINP<35', 'count_65+_TINP<35', 'sum_65+_TINP<35', 'mean_65+_TINP<35', '%_65+_TINP<35', 'any_65+_TINP<40', 'all_65+_TINP<40', 'min_65+_TINP<40', 'max_65+_TINP<40', 'count_65+_TINP<40', 'sum_65+_TINP<40', 'mean_65+_TINP<40', '%_65+_TINP<40', 'any_65+_TINP<45', 'all_65+_TINP<45', 'min_65+_TINP<45', 'max_65+_TINP<45', 'count_65+_TINP<45', 'sum_65+_TINP<45', 'mean_65+_TINP<45', '%_65+_TINP<45', 'any_65+_TINP<50', 'all_65+_TINP<50', 'min_65+_TINP<50', 'max_65+_TINP<50', 'count_65+_TINP<50', 'sum_65+_TINP<50', 'mean_65+_TINP<50', '%_65+_TINP<50', 'any_65+_TINP<60', 'all_65+_TINP<60', 'min_65+_TINP<60', 'max_65+_TINP<60', 'count_65+_TINP<60', 'sum_65+_TINP<60', 'mean_65+_TINP<60', '%_65+_TINP<60', 'any_65+_TINP<70', 'all_65+_TINP<70', 'min_65+_TINP<70', 'max_65+_TINP<70', 'count_65+_TINP<70', 'sum_65+_TINP<70', 'mean_65+_TINP<70', '%_65+_TINP<70', 'any_65+_TINP<80', 'all_65+_TINP<80', 'min_65+_TINP<80', 'max_65+_TINP<80', 'count_65+_TINP<80', 'sum_65+_TINP<80', 'mean_65+_TINP<80', '%_65+_TINP<80', 'any_65+_TINP_any', 'all_65+_TINP_any', 'min_65+_TINP_any', 'max_65+_TINP_any', 'count_65+_TINP_any', 'sum_65+_TINP_any', 'mean_65+_TINP_any', '%_65+_TINP_any', 'max_18-64_TINP0', 'count_18-64_TINP0', 'sum_18-64_TINP0', 'mean_18-64_TINP0', 'max_18-64_TINP<10', 'mean_18-64_TINP<10', 'mean_18-64_TINP<15', 'count_18-64_TINP<20', 'mean_18-64_TINP<20', 'count_18-64_TINP<25', 'mean_18-64_TINP<25', 'count_18-64_TINP<30', 'sum_18-64_TINP<30', 'mean_18-64_TINP<30', 'count_18-64_TINP<35', 'sum_18-64_TINP<35', 'mean_18-64_TINP<35', 'count_18-64_TINP<40', 'sum_18-64_TINP<40', 'mean_18-64_TINP<40', 'any_18-64_TINP<45', 'max_18-64_TINP<45', 'count_18-64_TINP<45', 'sum_18-64_TINP<45', 'mean_18-64_TINP<45', '%_18-64_TINP<45', 'any_18-64_TINP<50', 'min_18-64_TINP<50', 'max_18-64_TINP<50', 'count_18-64_TINP<50', 'sum_18-64_TINP<50', 'mean_18-64_TINP<50', '%_18-64_TINP<50', 'any_18-64_TINP<60', 'all_18-64_TINP<60', 'min_18-64_TINP<60', 'max_18-64_TINP<60', 'count_18-64_TINP<60', 'sum_18-64_TINP<60', 'mean_18-64_TINP<60', '%_18-64_TINP<60', 'any_18-64_TINP<70', 'all_18-64_TINP<70', 'min_18-64_TINP<70', 'max_18-64_TINP<70', 'count_18-64_TINP<70', 'sum_18-64_TINP<70', 'mean_18-64_TINP<70', '%_18-64_TINP<70', 'any_18-64_TINP<80', 'all_18-64_TINP<80', 'min_18-64_TINP<80', 'max_18-64_TINP<80', 'count_18-64_TINP<80', 'sum_18-64_TINP<80', 'mean_18-64_TINP<80', '%_18-64_TINP<80', 'any_18-64_TINP_any', 'all_18-64_TINP_any', 'min_18-64_TINP_any', 'max_18-64_TINP_any', 'count_18-64_TINP_any', 'sum_18-64_TINP_any', 'mean_18-64_TINP_any', '%_18-64_TINP_any', 'any_kid_TINP0', 'all_kid_TINP0', 'min_kid_TINP0', 'max_kid_TINP0', 'count_kid_TINP0', 'sum_kid_TINP0', 'mean_kid_TINP0', '%_kid_TINP0', 'any_kid_TINP<10', 'all_kid_TINP<10', 'min_kid_TINP<10', 'max_kid_TINP<10', 'count_kid_TINP<10', 'sum_kid_TINP<10', 'mean_kid_TINP<10', '%_kid_TINP<10', 'any_kid_TINP<15', 'all_kid_TINP<15', 'min_kid_TINP<15', 'max_kid_TINP<15', 'count_kid_TINP<15', 'sum_kid_TINP<15', 'mean_kid_TINP<15', '%_kid_TINP<15', 'any_kid_TINP<20', 'all_kid_TINP<20', 'min_kid_TINP<20', 'max_kid_TINP<20', 'count_kid_TINP<20', 'sum_kid_TINP<20', 'mean_kid_TINP<20', '%_kid_TINP<20', 'any_kid_TINP<25', 'all_kid_TINP<25', 'min_kid_TINP<25', 'max_kid_TINP<25', 'count_kid_TINP<25', 'sum_kid_TINP<25', 'mean_kid_TINP<25', '%_kid_TINP<25', 'any_kid_TINP<30', 'all_kid_TINP<30', 'min_kid_TINP<30', 'max_kid_TINP<30', 'count_kid_TINP<30', 'sum_kid_TINP<30', 'mean_kid_TINP<30', '%_kid_TINP<30', 'any_kid_TINP<35', 'all_kid_TINP<35', 'min_kid_TINP<35', 'max_kid_TINP<35', 'count_kid_TINP<35', 'sum_kid_TINP<35', 'mean_kid_TINP<35', '%_kid_TINP<35', 'any_kid_TINP<40', 'all_kid_TINP<40', 'min_kid_TINP<40', 'max_kid_TINP<40', 'count_kid_TINP<40', 'sum_kid_TINP<40', 'mean_kid_TINP<40', '%_kid_TINP<40', 'any_kid_TINP<45', 'all_kid_TINP<45', 'min_kid_TINP<45', 'max_kid_TINP<45', 'count_kid_TINP<45', 'sum_kid_TINP<45', 'mean_kid_TINP<45', '%_kid_TINP<45', 'any_kid_TINP<50', 'all_kid_TINP<50', 'min_kid_TINP<50', 'max_kid_TINP<50', 'count_kid_TINP<50', 'sum_kid_TINP<50', 'mean_kid_TINP<50', '%_kid_TINP<50', 'any_kid_TINP<60', 'all_kid_TINP<60', 'min_kid_TINP<60', 'max_kid_TINP<60', 'count_kid_TINP<60', 'sum_kid_TINP<60', 'mean_kid_TINP<60', '%_kid_TINP<60', 'any_kid_TINP<70', 'all_kid_TINP<70', 'min_kid_TINP<70', 'max_kid_TINP<70', 'count_kid_TINP<70', 'sum_kid_TINP<70', 'mean_kid_TINP<70', '%_kid_TINP<70', 'any_kid_TINP<80', 'all_kid_TINP<80', 'min_kid_TINP<80', 'max_kid_TINP<80', 'count_kid_TINP<80', 'sum_kid_TINP<80', 'mean_kid_TINP<80', '%_kid_TINP<80', 'any_kid_TINP_any', 'all_kid_TINP_any', 'min_kid_TINP_any', 'max_kid_TINP_any', 'count_kid_TINP_any', 'sum_kid_TINP_any', 'mean_kid_TINP_any', '%_kid_TINP_any', 'all_anyage_TINP0', 'max_anyage_TINP0', 'mean_anyage_TINP0', 'all_anyage_TINP<10', 'max_anyage_TINP<10', 'sum_anyage_TINP<10', 'mean_anyage_TINP<10', 'all_anyage_TINP<15', 'max_anyage_TINP<15', 'count_anyage_TINP<15', 'sum_anyage_TINP<15', 'mean_anyage_TINP<15', 'all_anyage_TINP<20', 'max_anyage_TINP<20', 'count_anyage_TINP<20', 'sum_anyage_TINP<20', 'mean_anyage_TINP<20', 'all_anyage_TINP<25', 'max_anyage_TINP<25', 'count_anyage_TINP<25', 'sum_anyage_TINP<25', 'mean_anyage_TINP<25', 'all_anyage_TINP<30', 'max_anyage_TINP<30', 'count_anyage_TINP<30', 'sum_anyage_TINP<30', 'mean_anyage_TINP<30', '%_anyage_TINP<30', 'all_anyage_TINP<35', 'max_anyage_TINP<35', 'count_anyage_TINP<35', 'sum_anyage_TINP<35', 'mean_anyage_TINP<35', '%_anyage_TINP<35', 'all_anyage_TINP<40', 'max_anyage_TINP<40', 'count_anyage_TINP<40', 'sum_anyage_TINP<40', 'mean_anyage_TINP<40', '%_anyage_TINP<40', 'all_anyage_TINP<45', 'min_anyage_TINP<45', 'max_anyage_TINP<45', 'count_anyage_TINP<45', 'sum_anyage_TINP<45', 'mean_anyage_TINP<45', '%_anyage_TINP<45', 'all_anyage_TINP<50', 'min_anyage_TINP<50', 'max_anyage_TINP<50', 'count_anyage_TINP<50', 'sum_anyage_TINP<50', 'mean_anyage_TINP<50', '%_anyage_TINP<50', 'all_anyage_TINP<60', 'max_anyage_TINP<60', 'count_anyage_TINP<60', 'sum_anyage_TINP<60', 'mean_anyage_TINP<60', '%_anyage_TINP<60', 'all_anyage_TINP<70', 'max_anyage_TINP<70', 'count_anyage_TINP<70', 'sum_anyage_TINP<70', 'mean_anyage_TINP<70', '%_anyage_TINP<70', 'all_anyage_TINP<80', 'min_anyage_TINP<80', 'max_anyage_TINP<80', 'count_anyage_TINP<80', 'sum_anyage_TINP<80', 'mean_anyage_TINP<80', '%_anyage_TINP<80', 'min_anyage_TINP_any', 'max_anyage_TINP_any', 'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any', 'MSP_2_1.0', 'HousingStatus_7.0', 'HousingStatus_8.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3406"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Random Forest Classifier\n",
    "In some initial modeling review (see appendix), the RandomForestClassifier was found to be a good choice of model, and\n",
    "it comes with the added advantage that we can review its feature_importances_ to see what's driving the model. \n",
    "Grid search for n_estimators and max_features (details in appendix) showed that n_estimators=1000 and \n",
    "max_features='auto' had good performance.\n",
    "\n",
    "Because our data is imbalanced (poverty is ~20% of the population), we'll consider the accuracy as well as the balanced\n",
    "accuracy and geometric mean, two metrics that give a better appreciation for classification on imbalanced data.\n",
    "\n",
    "Below the results show that we achieve nearly 93% overall accuracy (and 88% geometric mean) using the Random \n",
    "Forest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 103.06s to fit \n",
      "\n",
      "Accuracy: 0.9287041730021963\n",
      "Balanced accuracy: 0.8877352697992946\n",
      "Geometric mean: 0.8849946175662557\n",
      "Confusion matrix:\n",
      "[[4499  200]\n",
      " [ 222  998]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.95      0.96      0.82      0.96      0.88      0.79      4699\n",
      "        1.0       0.83      0.82      0.96      0.83      0.88      0.77      1220\n",
      "\n",
      "avg / total       0.93      0.93      0.85      0.93      0.88      0.79      5919\n",
      "\n",
      "n_estimators: 1000\n",
      "Training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "dropped = tester_copy.drop(to_drop, axis='columns') \n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = dropped['NYCgov_Pov_Stat']\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = dropped.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "rf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)], memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(rf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('n_estimators: ' + str(rf_pipeline.named_steps['clf'].n_estimators))\n",
    "print('Features: ' + str(len(dropped.columns)))\n",
    "\n",
    "# Save the model\n",
    "dump(rf_pipeline, 'data/rf_pipeline.joblib') \n",
    "# rf_pipeline = load('data/rf_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance with Random Forest Classifier\n",
    "What features are driving the model? Below we see the most important of the 1,554 features in the model, as a DataFrame and then in a chart. Remember that \n",
    "we're predicting the poverty of a household ('poverty unit'), rather than an individual.  'TINP' means total income for\n",
    "a single individual in the household, and 'WAG' means total wages for a person in the household.\n",
    "\n",
    "We see that the top 15 features are all related to total income and wages. While that's not shocking, let's dig deeper.\n",
    "1. The most-predictive levels of personal income or wages are \\\\$20,000, \\\\$25,000, and \\\\$15,000. At first glance this may seem\n",
    "odd since only 4 households with someone earning over \\\\$70,000 are in poverty.  But keep in mind that only 20% of the \n",
    "population is in poverty, so the most useful predictors are those that predict poverty, not the *absence* of poverty.\n",
    "2. Note that a wage of \\\\$70,000 is the fifteenth-most-important predictor; it is useful, just not as useful as those\n",
    "that help predict poverty.\n",
    "\n",
    "So the message here is clear, if not entirely surprising: the most effective way to get out of poverty is to make more money. Especially if you're not making that much money.\n",
    "\n",
    "A number of other points here:\n",
    "1. Total income obviously includes wages, but also includes items like investment income, self-employment income, and\n",
    "retirement income. In particular, those with low-wage jobs but other skills and interests can bolster their total \n",
    "income by taking a side job (if not already doing so).  \n",
    "2. Those in the workforce that have the means to do so can prevent being in poverty later by investing enough\n",
    "for retirement.\n",
    "3. The data available does not include hourly wage information - while hours worked per week and total annual wages \n",
    "are included, weeks worked per year are only presented in broad buckets. The impact of hourly wages only appears\n",
    "indirectly in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;20</th>\n",
       "      <td>0.017795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_adult_TINP&lt;20</th>\n",
       "      <td>0.016623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;20</th>\n",
       "      <td>0.015029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_TINP&lt;20</th>\n",
       "      <td>0.014029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;25</th>\n",
       "      <td>0.013671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_TINP&lt;25</th>\n",
       "      <td>0.013292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_TINP&lt;15</th>\n",
       "      <td>0.011896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_adult_WAG&lt;20</th>\n",
       "      <td>0.011588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;40</th>\n",
       "      <td>0.010976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_WAG&lt;20</th>\n",
       "      <td>0.010910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;15</th>\n",
       "      <td>0.010596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;35</th>\n",
       "      <td>0.010238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adult_TINP&lt;25</th>\n",
       "      <td>0.010182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adult_TINP&lt;20</th>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;70</th>\n",
       "      <td>0.009464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Importance\n",
       "any_anyage_TINP<20    0.017795\n",
       "any_adult_TINP<20     0.016623\n",
       "any_anyage_WAG<20     0.015029\n",
       "%_anyage_TINP<20      0.014029\n",
       "any_anyage_TINP<25    0.013671\n",
       "%_anyage_TINP<25      0.013292\n",
       "%_anyage_TINP<15      0.011896\n",
       "all_adult_WAG<20      0.011588\n",
       "any_anyage_WAG<40     0.010976\n",
       "%_anyage_WAG<20       0.010910\n",
       "any_anyage_TINP<15    0.010596\n",
       "any_anyage_TINP<35    0.010238\n",
       "%_adult_TINP<25       0.010182\n",
       "%_adult_TINP<20       0.010066\n",
       "any_anyage_WAG<70     0.009464"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances and sort\n",
    "rf_imps = list(zip(rf_pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "rf_imps = sorted(rf_imps, key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "# Put them into a DataFrame for easy manipulation\n",
    "data_rf = [tup[0] for tup in rf_imps]\n",
    "index_rf = [tup[1] for tup in rf_imps]\n",
    "test_imps = pd.DataFrame(data=data_rf, index=index_rf, columns=['Importance'])\n",
    "\n",
    "test_imps.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot importance of key features\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "test_imps.head(15).plot(kind='bar', ax=ax, legend=None)\n",
    "ax.set_title('Feature Importance for Key Features')\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Model Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about factors that are not strictly financial?  Specifically, things that people may have more control over, like \n",
    "education levels?\n",
    "\n",
    "Below are the DataFrame and a chart of the key non-financial factors. We see a couple of things:\n",
    "1. The relative importance to the model of these factors is much lower than the top-rated wage-related features. The\n",
    "top-rated overall feature is roughly 15x more important to the model than the top feature below.\n",
    "2. With that out of the way, the educational attainment of the head of the household ('SCHL_1') is the most important feature on \n",
    "this list. Focusing on improving educational opportunities, and tailoring them to communities of need, could improve\n",
    "poverty rates. For individual households with little opportunity to improve their wages in their current role, \n",
    "education would be the most powerful non-financial way to improve their poverty status.\n",
    "3. Disability status is important, with a variation on disability status of household members appearing in 8 of the 15 \n",
    "most-important features listed below (any feature with 'DIS' in the name). While there's little or nothing that a household can do about their disability \n",
    "status, this suggests an opportunity for local governments in focusing poverty efforts.\n",
    "4. Citizenship and English-speaking ability of the head of the household ('CIT_1' and 'ENG_1')rank highly on this list. While citizenship may be more difficult to change,\n",
    "English-speaking ability can be improved at little cost over time; and local governments can focus efforts and programs\n",
    "to communities with poor English skills and non-citizens.\n",
    "5. Total work hours for the poverty unit ('TotalWorkHrs_PU') is also an important factor, as we saw in EDA (the poverty rate \n",
    "among households with less than the equivalent of one 20 hours/week job is over 40%). Local governments can identify\n",
    "households under this threshold and target specific programs (e.g. childcare or older-adult care) to enable households\n",
    "to gain more work hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SCHL_1</th>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_18-64_not_DIS</th>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_anyage_not_DIS</th>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIT_1</th>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_adult_not_DIS</th>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENG_1</th>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_anyage_not_DIS</th>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalWorkHrs_PU</th>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_18-64_not_DIS</th>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_18-64_not_DIS</th>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_18-64_not_DIS</th>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGEP_1</th>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_adult_not_DIS</th>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boro_1_4.0</th>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_18-64_nonzero_WKW</th>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Importance\n",
       "SCHL_1                   0.001205\n",
       "max_18-64_not_DIS        0.001204\n",
       "count_anyage_not_DIS     0.000991\n",
       "CIT_1                    0.000942\n",
       "count_adult_not_DIS      0.000909\n",
       "ENG_1                    0.000908\n",
       "mean_anyage_not_DIS      0.000892\n",
       "TotalWorkHrs_PU          0.000865\n",
       "any_18-64_not_DIS        0.000859\n",
       "sum_18-64_not_DIS        0.000855\n",
       "count_18-64_not_DIS      0.000802\n",
       "AGEP_1                   0.000790\n",
       "sum_adult_not_DIS        0.000787\n",
       "Boro_1_4.0               0.000746\n",
       "max_18-64_nonzero_WKW    0.000733"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fin_vars = ['AGEP', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'LANX', 'ENG', 'MSP', 'MAR', 'WKW', 'WKHP', \n",
    "                    'DIS', 'TEN', 'HHT', 'JWTR', 'Povunit_Rel', 'FamType_PU', 'Ethnicity', \n",
    "                    'TotalWorkHrs_PU', 'Boro', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork']\n",
    "check_non_fin = lambda string: any (v in string for v in non_fin_vars)\n",
    "non_fins = test_imps.T[[x for x in test_imps.T.columns if check_non_fin(x)]].T.head(15)\n",
    "non_fins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot importance of key features\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "non_fins.plot(kind='bar', ax=ax, legend=None)\n",
    "ax.set_title('Feature Importance for Key \"Non-Financial\" Features')\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Model Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME with Random Forest Classifier\n",
    "Below we see a couple of examples of data points, and why they were classified as they were. For the first point, the\n",
    "household is not in poverty; looking at the chart below, we can see why.\n",
    "\n",
    "Our variables that end in _1, _2, _3, etc. indicate person 1 in the household, person 2 in the household, etc.\n",
    "\n",
    "Interestingly, this household has no wages for person 1, 2, or 3, which would suggest the household is in poverty (see \n",
    "the green bars to the right of the chart); but the first person is either self-employed or independently wealthy, as \n",
    "they have a total income of over \\\\$67,000 despite no wages (red bar).  Thus, they are correctly identified as not in\n",
    "poverty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test[7] # 0 means not in poverty\n",
    "predictions[7] # 0 means not in poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 72.62681746482849 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "\n",
    "# Specify the prediction function for use with LIME\n",
    "predict_fn = lambda x: rf_pipeline.predict_proba(x)\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns, \n",
    "                                                   class_names = ['Not Poverty', 'Poverty'])\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 7\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.as_pyplot_figure()\n",
    "\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a household in poverty.  As we can see below, there's no wages for person 1, 2, or 3; no income for\n",
    "person 2; and person 1 has less than \\\\$10,000 in total income.  This is a household in poverty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test[1657] # 1 means in poverty\n",
    "predictions[1657] # 1 means in poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.33846688270569 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "\n",
    "# Since predict_fn and explainer were calculated above, commenting them out here\n",
    "#predict_fn = lambda x: rf_pipeline.predict_proba(x)\n",
    "#explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns, class_names = ['Not Poverty', 'Poverty'])\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 1657\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.as_pyplot_figure()\n",
    "\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Balanced Random Forest Classifier\n",
    "Because our data is unbalanced (~20% of the sample is in poverty), our model will have a harder time identifying \n",
    "households that are in poverty. We can achieve better accuracy on households in poverty by using a Balanced Random \n",
    "Forest Classifier, at the expense of some overall accuracy.\n",
    "\n",
    "Below we see with a Balanced Random Forest Classifier, we get a total accuracy of about 90% (worse than the almost 93% \n",
    "with the Random Forest Classifier), but balanced accuracy and geometric mean of 91% (compared to about 88% above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 86.54s to fit \n",
      "\n",
      "Accuracy: 0.8986315255955398\n",
      "Balanced accuracy: 0.9124890541761589\n",
      "Geometric mean: 0.9121844230829197\n",
      "Confusion matrix:\n",
      "[[4177  522]\n",
      " [  78 1142]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.98      0.89      0.94      0.93      0.91      0.83      4699\n",
      "        1.0       0.69      0.94      0.89      0.79      0.91      0.84      1220\n",
      "\n",
      "avg / total       0.92      0.90      0.93      0.90      0.91      0.83      5919\n",
      "\n",
      "OOB score: 0.9254096975840513\n",
      "n_estimators: 1000\n",
      "Features: 1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/rf_pipeline.joblib']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = dropped['NYCgov_Pov_Stat']\n",
    "#y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = dropped.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', oob_score=True,\n",
    "                                            random_state=42)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_1000_estimators = {}\n",
    "\n",
    "brf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)],  memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "brf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = brf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(brf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('OOB score: ' + str(brf_pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(brf_pipeline.named_steps['clf'].n_estimators))\n",
    "print('Features: ' + str(len(dropped.columns)))\n",
    "\n",
    "# Save the model\n",
    "dump(brf_pipeline, 'data/brf_pipeline.joblib') \n",
    "# brf_pipeline = load('data/brf_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance with Balanced Random Forest Classifier\n",
    "Does this model show us any differences in the importance of features? On the whole, there's nothing earth-shattering.\n",
    "Instead of a wage of \\\\$70,000 being in the top-15 as above, it's a wage of \\\\$80,000, and it's actually the 11th most \n",
    "important in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;20</th>\n",
       "      <td>0.021380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adult_TINP&lt;20</th>\n",
       "      <td>0.019254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_adult_TINP&lt;20</th>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_TINP&lt;20</th>\n",
       "      <td>0.016419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;25</th>\n",
       "      <td>0.015935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_adult_TINP&lt;25</th>\n",
       "      <td>0.015337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;30</th>\n",
       "      <td>0.015120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_adult_TINP&lt;20</th>\n",
       "      <td>0.015058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;25</th>\n",
       "      <td>0.014472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%_anyage_TINP&lt;25</th>\n",
       "      <td>0.014061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;80</th>\n",
       "      <td>0.011892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_WAG&lt;45</th>\n",
       "      <td>0.011803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_adult_TINP&lt;25</th>\n",
       "      <td>0.011493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_anyage_TINP&lt;35</th>\n",
       "      <td>0.011421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_adult_TINP&lt;25</th>\n",
       "      <td>0.011246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Importance\n",
       "any_anyage_TINP<20     0.021380\n",
       "%_adult_TINP<20        0.019254\n",
       "count_adult_TINP<20    0.018400\n",
       "%_anyage_TINP<20       0.016419\n",
       "any_anyage_TINP<25     0.015935\n",
       "%_adult_TINP<25        0.015337\n",
       "any_anyage_TINP<30     0.015120\n",
       "any_adult_TINP<20      0.015058\n",
       "any_anyage_WAG<25      0.014472\n",
       "%_anyage_TINP<25       0.014061\n",
       "any_anyage_WAG<80      0.011892\n",
       "any_anyage_WAG<45      0.011803\n",
       "count_adult_TINP<25    0.011493\n",
       "any_anyage_TINP<35     0.011421\n",
       "any_adult_TINP<25      0.011246"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances and sort\n",
    "brf_imps = list(zip(brf_pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "brf_imps = sorted(brf_imps, key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "# Put them into a DataFrame for easy manipulation\n",
    "data_brf = [tup[0] for tup in brf_imps]\n",
    "index_brf = [tup[1] for tup in brf_imps]\n",
    "brf_imps = pd.DataFrame(data=data_brf, index=index_brf, columns=['Importance'])\n",
    "\n",
    "brf_imps.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot importance of key features\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "brf_imps.head(15).plot(kind='bar', ax=ax, legend=None)\n",
    "ax.set_title('Feature Importance for Key Features - Balanced Random Forest Classifier')\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Model Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about non-financial measures? Since this model is more sensitive to those in poverty, it's interesting to see how \n",
    "it differs there.\n",
    "\n",
    "First of all, the most important feature overall is about 20 times more important than the most important non-financial\n",
    "feature (it was a factor of 15x in our random forest).  As for the features themselves:\n",
    "1. Disability status is still a huge factor here, with the top and 5 of the top 15 features being disability-related.\n",
    "2. Educational attainment of the head of the household ('SCHL_1') is the second-most important on this list.\n",
    "3. Work hours is actually much more important in this model, with 7 of the top 15 non-financial features being related\n",
    "to work hours ('TotalWorkHrs_PU' and the various features with 'WKW' in their names).\n",
    "4. Again, English-speaking ability and citizenship status of the head of the household are among the most important non-\n",
    "financial factors in poverty status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_anyage_not_DIS</th>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHL_1</th>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalWorkHrs_PU</th>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_adult_&gt;40WKW</th>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_18-64_nonzero_WKW</th>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENG_1</th>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_adult_nonzero_WKW</th>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_adult_&gt;40WKW</th>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_18-64_not_DIS</th>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_adult_nonzero_WKW</th>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_18-64_not_DIS</th>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_anyage_not_DIS</th>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIT_1</th>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_adult_50-52WKW</th>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_18-64_not_DIS</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Importance\n",
       "count_anyage_not_DIS     0.001015\n",
       "SCHL_1                   0.000776\n",
       "TotalWorkHrs_PU          0.000735\n",
       "min_adult_>40WKW         0.000688\n",
       "min_18-64_nonzero_WKW    0.000611\n",
       "ENG_1                    0.000599\n",
       "min_adult_nonzero_WKW    0.000598\n",
       "max_adult_>40WKW         0.000596\n",
       "any_18-64_not_DIS        0.000594\n",
       "max_adult_nonzero_WKW    0.000592\n",
       "count_18-64_not_DIS      0.000583\n",
       "mean_anyage_not_DIS      0.000582\n",
       "CIT_1                    0.000578\n",
       "min_adult_50-52WKW       0.000567\n",
       "max_18-64_not_DIS        0.000562"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fins_brf = brf_imps.T[[x for x in brf_imps.T.columns if check_non_fin(x)]].T.head(15)\n",
    "non_fins_brf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot importance of key features\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "non_fins_brf.plot(kind='bar', ax=ax, legend=None)\n",
    "ax.set_title('Feature Importance for Key \"Non-Financial\" Features - Balanced Random Forest Classifier')\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Model Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME with Balanced Random Forest Classifier\n",
    "Below we see a couple of examples of data points, and why they were classified as they were. For the first point, the household is not in poverty; looking at the chart below, we can see why.\n",
    "\n",
    "Our variables that end in _1, _2, _3, etc. indicate person 1 in the household, person 2 in the household, etc.\n",
    "\n",
    "This household has no wages for person 2 or 3, and no total income for person 2.  Since person 1 has wages less than\n",
    "\\\\$14,000 and total income less than \\\\$10,000, the model correctly predicts poverty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test[4] # 1 means in poverty\n",
    "predictions[4] # 1 means in poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 72.93079781532288 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "\n",
    "# Specify the prediction function for use with LIME\n",
    "predict_fn = lambda x: brf_pipeline.predict_proba(x)\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns, \n",
    "                                                   class_names = ['Not Poverty', 'Poverty'])\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 4\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.as_pyplot_figure()\n",
    "\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For the point below, the total income and wages of person 1 and person 2 are so high, this household is pretty obviously\n",
    "not in poverty. The strongest piece of evidence that this household might be in poverty is that the head of the \n",
    "household has no interest/dividends/rental property income (INTP_adj_1 in green), which is clearly not sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test[4242] # 0 means not in poverty\n",
    "predictions[4242] # 0 means not in poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.33522152900696 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "\n",
    "# Since predict_fn and explainer were calculated above, commenting them out here\n",
    "#predict_fn = lambda x: brf_pipeline.predict_proba(x)\n",
    "#explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns,  class_names = ['Not Poverty', 'Poverty'])\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 4242\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.as_pyplot_figure()\n",
    "\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "To summarize:\n",
    "1. We can develop a model to predict NYC Poverty Status using only the ACS variables with 92.9% accuracy and 88.8% \n",
    "balanced accuracy, using a Random Forest Classifier with appropriate feature engineering.\n",
    "2. Since NYC poverty status is imbalanced (about 20% of households are in poverty), we can further improve our \n",
    "sensitivity to poverty households using a Balanced Random Forest Classifier, at the expense of some of our total \n",
    "accuracy. In this situation, we can achieve a 89.9% total accuracy and 91.2% balanced accuracy.\n",
    "3. The financial features (total personal income and personal wages) dominate the poverty prediction models. The top-15\n",
    "features of both models are personal income and wage-related. In particular, for predicting poverty, the features that\n",
    "focus on total income or wages in the \\\\$20,000, \\\\$25,000, \\\\$30,000 range are the most relevant.\n",
    "4. Among non-financial variables like education or English-speaking ability, the most important are the education level\n",
    "of the head of the household, the disability status of anyone in the household, the citizenship and English-speaking \n",
    "ability of the head of the household, and the number of total work hours available to the household."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "Old items that are mostly of historical interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing -- at a personal level -- total income versus non-financial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 335.54s to fit \n",
      "\n",
      "Test score: 0.35290137507414676\n",
      "Training score: 0.9194132193643912\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'clf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5f5aa6937271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTest score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OOB score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clf'"
     ]
    }
   ],
   "source": [
    "personal = all_2016[all_2016.AGEP >= 18].copy()\n",
    "\n",
    "# Add total personal income ('TINP') and total rent/mortgage ('MRNT')\n",
    "personal['TINP'] = personal.WAGP_adj + personal.INTP_adj + personal.SEMP_adj + personal.SSP_adj + personal.SSIP_adj + \\\n",
    "                    personal.PA_adj + personal.RETP_adj + personal.OI_adj\n",
    "personal['MRNT'] = personal.MRGP_adj + personal.RNTP_adj\n",
    "\n",
    "# Only keep the features that may be useful\n",
    "features_to_keep = ['AGEP', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'LANX', 'ENG', 'MSP', 'MAR', 'WKW', 'WKHP', \n",
    "                    'DIS', 'NP', 'TEN', 'HHT', 'JWTR', 'Povunit_Rel', 'FamType_PU', 'HousingStatus', 'Ethnicity', \n",
    "                    'TotalWorkHrs_PU', 'Boro', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork', 'MRNT', 'TINP']\n",
    "personal = personal[features_to_keep]\n",
    "\n",
    "# Track which columns we'll need to make dummies for\n",
    "dummy_these = ['AGEP', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'LANX', 'ENG', 'MSP', 'MAR', 'WKW', 'WKHP', \n",
    "                    'DIS', 'NP', 'TEN', 'HHT', 'JWTR', 'Povunit_Rel', 'FamType_PU', 'HousingStatus', 'Ethnicity', \n",
    "                    'TotalWorkHrs_PU', 'Boro', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork']\n",
    "\n",
    "# Pull off 'TINP' for our target variable\n",
    "y_pers = personal['TINP'].copy()\n",
    "X_pers = personal.copy().drop('TINP', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pers, y_pers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare our steps for the pipeline\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=1000, max_features='auto', oob_score=True, random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pers_inc_pipeline = imbPipeline(steps=[('cat', categorizer), \n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "# Fire away\n",
    "t0 = time.time()\n",
    "pers_inc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "print('\\nTest score: ' + str(pers_inc_pipeline.score(X_test, y_test)))\n",
    "print('Training score: ' + str(pers_inc_pipeline.score(X_train, y_train)))\n",
    "print('OOB score: ' + str(pers_inc_pipeline.named_steps['reg'].oob_score_))\n",
    "print('n_estimators: ' + str(pers_inc_pipeline.named_steps['reg'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_pers = pers_inc_pipeline.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(y_test, predictions_pers)#, marker='.', linestyle='none')\n",
    "lower = 0\n",
    "upper = max(y_test.max(), predictions_pers.max()) + 10000\n",
    "liner = np.arange(lower, upper)\n",
    "ax.plot(liner, liner, color='k')\n",
    "ax.set_xlim(lower, upper)\n",
    "ax.set_ylim(lower, upper)\n",
    "ax.set_title('Total Personal Income vs. Predicted')\n",
    "ax.set_xlabel('Actual Total Personal Income')\n",
    "ax.set_ylabel('Predicted Total Personal Income')\n",
    "plt.rcParams[\"figure.figsize\"] = [4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.015547567291145592, 'AGEP'),\n",
       " (0.006694876419869801, 'FamType_PU'),\n",
       " (0.006608194143419285, 'TotalWorkHrs_PU'),\n",
       " (0.004774831141534058, 'FTPTWork'),\n",
       " (0.00469248382048341, 'EducAttain'),\n",
       " (0.00436351341183179, 'MRNT'),\n",
       " (0.0037353994532746382, 'Boro'),\n",
       " (0.003696698220815743, 'JWTR'),\n",
       " (0.0036964648389549537, 'Ethnicity'),\n",
       " (0.0036936192163132564, 'TEN'),\n",
       " (0.0030972619116118702, 'WKHP'),\n",
       " (0.002844298571018428, 'Povunit_Rel'),\n",
       " (0.0027464484440693875, 'AgeCateg'),\n",
       " (0.002433785650907912, 'NP'),\n",
       " (0.0022940933411346323, 'HousingStatus')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imps_pers = list(zip(pers_inc_pipeline.named_steps['reg'].feature_importances_, \n",
    "                     X_train.columns))\n",
    "sorted(imps_pers, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "#scalers = [StandardScaler(), Normalizer(), PowerTransformer(), QuantileTransformer()]\n",
    "scalers = [Normalizer()]\n",
    "scaler = Normalizer()\n",
    "#classifiers = [LogisticRegression(), SGDClassifier(), AdaBoostClassifier(), BaggingClassifier(), GradientBoostingClassifier(), \n",
    "               #RandomForestClassifier(), BalancedBaggingClassifier(), BalancedRandomForestClassifier(), RUSBoostClassifier()]\n",
    "#classifiers = [BalancedBaggingClassifier(), BaggingClassifier(), RandomForestClassifier(), BalancedRandomForestClassifier(), \n",
    "               #AdaBoostClassifier(), GradientBoostingClassifier()]\n",
    "#classifiers = [RandomForestClassifier(), BalancedRandomForestClassifier()]\n",
    "classifiers = [BalancedRandomForestClassifier()]\n",
    "\n",
    "#sampler = TomekLinks(random_state=42)\n",
    "#scaler = QuantileTransformer()\n",
    "#clf = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = AdaBoostClassifier()\n",
    "#params={0: {'clf__C': [1, 1e-1, 1e-2, 1e-3], 'clf__max_iter': [1e2, 1e3, 1e4], # Logistic Regression\n",
    "                               #'clf__solver': ['lbfgs', 'liblinear', 'sag', 'saga']}, \n",
    "        #1: {'n_estimators': [1e1, 1e2, 1e3], 'max_features': [5, 10, 50, 100], # Random Forest Classifier\n",
    "                         #'criterion': ['gini', 'entropy']}\n",
    "       #}\n",
    "#params = {0: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy']},\n",
    "          #1: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy'], 'clf_sampling_strategy': [0.05, 0.25, 0.5, 0.75, 0.95]}\n",
    "         #}\n",
    "\n",
    "params = {0: {'clf__n_estimators': [1000], 'clf__max_features': [100],\n",
    "              'clf__sampling_strategy': ['not minority', 'not majority', 'all']}}\n",
    "          #1: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy']},\n",
    "         #}\n",
    "\n",
    "#parameters = {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100], 'clf__criterion': ['gini', 'entropy']}\n",
    "parameters = {'clf__n_estimators': [100], 'clf__max_features': ['auto'], 'clf__criterion': ['gini']}\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "#pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              #('dummies', dummy_encoder),\n",
    "                              #('sampler', sampler),\n",
    "                              #('scaler', scaler),\n",
    "                              #('clf', BalancedRandomForestClassifier())], \n",
    "                      #memory=cachedir)\n",
    "                    \n",
    "#grid = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, n_jobs=-1, pre_dispatch=2, verbose=9)#, scoring=balanced_accuracy_score())\n",
    "#grid = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, n_jobs=-1, verbose=9)\n",
    "\n",
    "#t0 = time.time()\n",
    "#grid.fit(X_train, y_train)\n",
    "#time_to_fit = time.time() - t0\n",
    "#print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "#print(grid.cv_results_)\n",
    "\n",
    "#for sampler, i in zip(samplers, range(len(samplers))):\n",
    "for i in range(1):\n",
    "    #for scaler, j in zip(scalers, range(len(scalers))):\n",
    "    for scaler in scalers:\n",
    "        for k in range(len(classifiers)):\n",
    "            #pipeline = Pipeline(steps=[#('cat', categorizer),\n",
    "            pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                                          ('dummies', dummy_encoder),\n",
    "                                          #('sampler', sampler),\n",
    "                                          ('scaler', scaler),\n",
    "                                          ('clf', classifiers[k])],\n",
    "                                  memory=cachedir)\n",
    "\n",
    "            #print(pipeline)\n",
    "            #print(params[i])\n",
    "            #pipeline.get_params().keys()\n",
    "            grid = GridSearchCV(estimator=pipeline, param_grid=params[k], cv=3, n_jobs=-1, verbose=9)#, scoring=balanced_accuracy_score())\n",
    "\n",
    "            t0 = time.time()\n",
    "            #pipeline.fit(X_train, y_train)\n",
    "            grid.fit(X_train, y_train)\n",
    "            time_to_fit = time.time() - t0\n",
    "            print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "            print(grid.cv_results_)\n",
    "            print('best estimator: ' + str(grid.best_estimator_))\n",
    "            print('best params: ' + str(grid.best_params_))\n",
    "            print('best index: ' + str(grid.best_index_))\n",
    "            \n",
    "            #print(str(sampler) + ',' + str(scaler) + ',' + str(classifiers[k]))\n",
    "            #print(str(scaler) + ',' + str(classifiers[k]))\n",
    "                  \n",
    "            #means = grid.cv_results_['mean_test_score']\n",
    "            #stds = grid.cv_results_['std_test_score']\n",
    "            #for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "                #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "            #predictions = pipeline.predict(X_test)\n",
    "\n",
    "#print('Predictions: ' + str(predictions))\n",
    "#print('Actual:\\n' + str(y_small))\n",
    "            #print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "            #print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "            #print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "            #print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975358685378098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_mean_score(grid.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.019535791275811728, 'WKW_2'),\n",
       " (0.020252231346152935, 'INTP_adj_1'),\n",
       " (0.020452137721584687, 'SCHL_2'),\n",
       " (0.020767468686063252, 'RNTP_adj'),\n",
       " (0.02515045254416771, 'WKHP_2'),\n",
       " (0.026205088630138082, 'AGEP_1'),\n",
       " (0.02817688155652038, 'SCHL_1'),\n",
       " (0.03238306328525264, 'WKW_1'),\n",
       " (0.03242418603775719, 'JWTR_1'),\n",
       " (0.03587014309356664, 'RETP_adj_1'),\n",
       " (0.041251391667779504, 'WKHP_1'),\n",
       " (0.05057339662820781, 'SSP_adj_1'),\n",
       " (0.052182437399624144, 'WAGP_adj_2'),\n",
       " (0.07156076688876317, 'TotalWorkHrs_PU'),\n",
       " (0.14873418922209963, 'WAGP_adj_1')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tester = BalancedRandomForestClassifier().fit(X=X_train, y=y_train)\n",
    "#len(tester.feature_importances_)\n",
    "#X_train.columns\n",
    "#geometric_mean_score(tester.predict(X_test), y_test)  #0.775727880752169\n",
    "imps = list(zip(tester.feature_importances_, X_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.356531</td>\n",
       "      <td>0.774929</td>\n",
       "      <td>7.338355</td>\n",
       "      <td>0.130668</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.912454</td>\n",
       "      <td>0.913203</td>\n",
       "      <td>0.911165</td>\n",
       "      <td>0.912274</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>22</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.269967</td>\n",
       "      <td>2.907710</td>\n",
       "      <td>8.925081</td>\n",
       "      <td>2.030989</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.918662</td>\n",
       "      <td>0.920046</td>\n",
       "      <td>0.921176</td>\n",
       "      <td>0.919961</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.631243</td>\n",
       "      <td>11.630676</td>\n",
       "      <td>24.091638</td>\n",
       "      <td>2.337423</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.919422</td>\n",
       "      <td>0.920426</td>\n",
       "      <td>0.919909</td>\n",
       "      <td>0.919919</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.915396</td>\n",
       "      <td>0.285015</td>\n",
       "      <td>8.093561</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.909033</td>\n",
       "      <td>0.911809</td>\n",
       "      <td>0.910404</td>\n",
       "      <td>0.910416</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>24</td>\n",
       "      <td>0.996515</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.996706</td>\n",
       "      <td>0.996621</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.711045</td>\n",
       "      <td>0.981712</td>\n",
       "      <td>7.328075</td>\n",
       "      <td>1.507757</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.920806</td>\n",
       "      <td>0.920289</td>\n",
       "      <td>0.919116</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151.528578</td>\n",
       "      <td>11.447976</td>\n",
       "      <td>19.518697</td>\n",
       "      <td>3.485998</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.919802</td>\n",
       "      <td>0.919792</td>\n",
       "      <td>0.921810</td>\n",
       "      <td>0.920468</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.778635</td>\n",
       "      <td>0.298928</td>\n",
       "      <td>7.595569</td>\n",
       "      <td>0.218479</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.916002</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.918388</td>\n",
       "      <td>0.917300</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>18</td>\n",
       "      <td>0.995248</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996326</td>\n",
       "      <td>0.995734</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.483098</td>\n",
       "      <td>3.360073</td>\n",
       "      <td>6.941224</td>\n",
       "      <td>1.106543</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.922463</td>\n",
       "      <td>0.924354</td>\n",
       "      <td>0.925231</td>\n",
       "      <td>0.924016</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>353.551459</td>\n",
       "      <td>24.645494</td>\n",
       "      <td>14.723334</td>\n",
       "      <td>2.187714</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.922970</td>\n",
       "      <td>0.925494</td>\n",
       "      <td>0.927005</td>\n",
       "      <td>0.925156</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.911089</td>\n",
       "      <td>0.593627</td>\n",
       "      <td>7.788339</td>\n",
       "      <td>0.047878</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.914608</td>\n",
       "      <td>0.914090</td>\n",
       "      <td>0.917754</td>\n",
       "      <td>0.915484</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>19</td>\n",
       "      <td>0.995818</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.996304</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.250116</td>\n",
       "      <td>6.208748</td>\n",
       "      <td>7.382807</td>\n",
       "      <td>1.209777</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.927024</td>\n",
       "      <td>0.929676</td>\n",
       "      <td>0.925992</td>\n",
       "      <td>0.927564</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>604.099197</td>\n",
       "      <td>40.388460</td>\n",
       "      <td>15.118818</td>\n",
       "      <td>2.104008</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.927277</td>\n",
       "      <td>0.927902</td>\n",
       "      <td>0.927893</td>\n",
       "      <td>0.927690</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.635937</td>\n",
       "      <td>0.202809</td>\n",
       "      <td>8.041993</td>\n",
       "      <td>0.094281</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.911187</td>\n",
       "      <td>0.911049</td>\n",
       "      <td>0.910784</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>23</td>\n",
       "      <td>0.995311</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.703423</td>\n",
       "      <td>0.274799</td>\n",
       "      <td>9.826621</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.920182</td>\n",
       "      <td>0.919539</td>\n",
       "      <td>0.921049</td>\n",
       "      <td>0.920257</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>125.815334</td>\n",
       "      <td>10.479840</td>\n",
       "      <td>25.741467</td>\n",
       "      <td>3.183750</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.919676</td>\n",
       "      <td>0.920426</td>\n",
       "      <td>0.920289</td>\n",
       "      <td>0.920130</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.241193</td>\n",
       "      <td>0.842785</td>\n",
       "      <td>6.291520</td>\n",
       "      <td>1.195959</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.913088</td>\n",
       "      <td>0.909275</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>21</td>\n",
       "      <td>0.996452</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.362928</td>\n",
       "      <td>1.091575</td>\n",
       "      <td>8.315560</td>\n",
       "      <td>0.948133</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.920182</td>\n",
       "      <td>0.921946</td>\n",
       "      <td>0.922443</td>\n",
       "      <td>0.921524</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>141.452599</td>\n",
       "      <td>12.096369</td>\n",
       "      <td>18.503021</td>\n",
       "      <td>1.951633</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.921820</td>\n",
       "      <td>0.920542</td>\n",
       "      <td>0.921186</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.892606</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>7.927964</td>\n",
       "      <td>0.195101</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.914354</td>\n",
       "      <td>0.915864</td>\n",
       "      <td>0.914713</td>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996262</td>\n",
       "      <td>0.995819</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.995924</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28.135110</td>\n",
       "      <td>1.850436</td>\n",
       "      <td>7.699444</td>\n",
       "      <td>1.007361</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.925250</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.924978</td>\n",
       "      <td>0.925621</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>273.912406</td>\n",
       "      <td>17.282531</td>\n",
       "      <td>13.551803</td>\n",
       "      <td>1.713333</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.927151</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.927386</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.285676</td>\n",
       "      <td>0.373293</td>\n",
       "      <td>7.967199</td>\n",
       "      <td>0.167094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.916002</td>\n",
       "      <td>0.920172</td>\n",
       "      <td>0.919402</td>\n",
       "      <td>0.918525</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>17</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.996009</td>\n",
       "      <td>0.995755</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44.109372</td>\n",
       "      <td>4.389925</td>\n",
       "      <td>7.425203</td>\n",
       "      <td>1.210115</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.926390</td>\n",
       "      <td>0.929042</td>\n",
       "      <td>0.926879</td>\n",
       "      <td>0.927437</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>356.878639</td>\n",
       "      <td>99.027548</td>\n",
       "      <td>11.762577</td>\n",
       "      <td>2.313773</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.928544</td>\n",
       "      <td>0.931323</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       29.356531      0.774929         7.338355        0.130668   \n",
       "1       21.269967      2.907710         8.925081        2.030989   \n",
       "2      133.631243     11.630676        24.091638        2.337423   \n",
       "3        6.915396      0.285015         8.093561        0.456263   \n",
       "4       17.711045      0.981712         7.328075        1.507757   \n",
       "5      151.528578     11.447976        19.518697        3.485998   \n",
       "6        8.778635      0.298928         7.595569        0.218479   \n",
       "7       36.483098      3.360073         6.941224        1.106543   \n",
       "8      353.551459     24.645494        14.723334        2.187714   \n",
       "9       10.911089      0.593627         7.788339        0.047878   \n",
       "10      62.250116      6.208748         7.382807        1.209777   \n",
       "11     604.099197     40.388460        15.118818        2.104008   \n",
       "12       6.635937      0.202809         8.041993        0.094281   \n",
       "13      18.703423      0.274799         9.826621        0.189647   \n",
       "14     125.815334     10.479840        25.741467        3.183750   \n",
       "15       5.241193      0.842785         6.291520        1.195959   \n",
       "16      16.362928      1.091575         8.315560        0.948133   \n",
       "17     141.452599     12.096369        18.503021        1.951633   \n",
       "18       7.892606      0.185923         7.927964        0.195101   \n",
       "19      28.135110      1.850436         7.699444        1.007361   \n",
       "20     273.912406     17.282531        13.551803        1.713333   \n",
       "21       9.285676      0.373293         7.967199        0.167094   \n",
       "22      44.109372      4.389925         7.425203        1.210115   \n",
       "23     356.878639     99.027548        11.762577        2.313773   \n",
       "\n",
       "   param_clf__criterion param_clf__max_features param_clf__n_estimators  \\\n",
       "0                  gini                       5                      10   \n",
       "1                  gini                       5                     100   \n",
       "2                  gini                       5                    1000   \n",
       "3                  gini                      10                      10   \n",
       "4                  gini                      10                     100   \n",
       "5                  gini                      10                    1000   \n",
       "6                  gini                      50                      10   \n",
       "7                  gini                      50                     100   \n",
       "8                  gini                      50                    1000   \n",
       "9                  gini                     100                      10   \n",
       "10                 gini                     100                     100   \n",
       "11                 gini                     100                    1000   \n",
       "12              entropy                       5                      10   \n",
       "13              entropy                       5                     100   \n",
       "14              entropy                       5                    1000   \n",
       "15              entropy                      10                      10   \n",
       "16              entropy                      10                     100   \n",
       "17              entropy                      10                    1000   \n",
       "18              entropy                      50                      10   \n",
       "19              entropy                      50                     100   \n",
       "20              entropy                      50                    1000   \n",
       "21              entropy                     100                      10   \n",
       "22              entropy                     100                     100   \n",
       "23              entropy                     100                    1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'clf__criterion': 'gini', 'clf__max_features'...           0.912454   \n",
       "1   {'clf__criterion': 'gini', 'clf__max_features'...           0.918662   \n",
       "2   {'clf__criterion': 'gini', 'clf__max_features'...           0.919422   \n",
       "3   {'clf__criterion': 'gini', 'clf__max_features'...           0.909033   \n",
       "4   {'clf__criterion': 'gini', 'clf__max_features'...           0.916255   \n",
       "5   {'clf__criterion': 'gini', 'clf__max_features'...           0.919802   \n",
       "6   {'clf__criterion': 'gini', 'clf__max_features'...           0.916002   \n",
       "7   {'clf__criterion': 'gini', 'clf__max_features'...           0.922463   \n",
       "8   {'clf__criterion': 'gini', 'clf__max_features'...           0.922970   \n",
       "9   {'clf__criterion': 'gini', 'clf__max_features'...           0.914608   \n",
       "10  {'clf__criterion': 'gini', 'clf__max_features'...           0.927024   \n",
       "11  {'clf__criterion': 'gini', 'clf__max_features'...           0.927277   \n",
       "12  {'clf__criterion': 'entropy', 'clf__max_featur...           0.911187   \n",
       "13  {'clf__criterion': 'entropy', 'clf__max_featur...           0.920182   \n",
       "14  {'clf__criterion': 'entropy', 'clf__max_featur...           0.919676   \n",
       "15  {'clf__criterion': 'entropy', 'clf__max_featur...           0.913088   \n",
       "16  {'clf__criterion': 'entropy', 'clf__max_featur...           0.920182   \n",
       "17  {'clf__criterion': 'entropy', 'clf__max_featur...           0.921196   \n",
       "18  {'clf__criterion': 'entropy', 'clf__max_featur...           0.914354   \n",
       "19  {'clf__criterion': 'entropy', 'clf__max_featur...           0.925250   \n",
       "20  {'clf__criterion': 'entropy', 'clf__max_featur...           0.927151   \n",
       "21  {'clf__criterion': 'entropy', 'clf__max_featur...           0.916002   \n",
       "22  {'clf__criterion': 'entropy', 'clf__max_featur...           0.926390   \n",
       "23  {'clf__criterion': 'entropy', 'clf__max_featur...           0.928544   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913203           0.911165         0.912274        0.000842   \n",
       "1            0.920046           0.921176         0.919961        0.001028   \n",
       "2            0.920426           0.919909         0.919919        0.000410   \n",
       "3            0.911809           0.910404         0.910416        0.001133   \n",
       "4            0.920806           0.920289         0.919116        0.002035   \n",
       "5            0.919792           0.921810         0.920468        0.000949   \n",
       "6            0.917511           0.918388         0.917300        0.000986   \n",
       "7            0.924354           0.925231         0.924016        0.001155   \n",
       "8            0.925494           0.927005         0.925156        0.001665   \n",
       "9            0.914090           0.917754         0.915484        0.001619   \n",
       "10           0.929676           0.925992         0.927564        0.001552   \n",
       "11           0.927902           0.927893         0.927690        0.000292   \n",
       "12           0.911049           0.910784         0.911007        0.000167   \n",
       "13           0.919539           0.921049         0.920257        0.000619   \n",
       "14           0.920426           0.920289         0.920130        0.000326   \n",
       "15           0.909275           0.915347         0.912570        0.002505   \n",
       "16           0.921946           0.922443         0.921524        0.000970   \n",
       "17           0.921820           0.920542         0.921186        0.000521   \n",
       "18           0.915864           0.914713         0.914977        0.000644   \n",
       "19           0.926635           0.924978         0.925621        0.000725   \n",
       "20           0.927015           0.927386         0.927184        0.000153   \n",
       "21           0.920172           0.919402         0.918525        0.001812   \n",
       "22           0.929042           0.926879         0.927437        0.001152   \n",
       "23           0.931323           0.927132         0.929000        0.001741   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                22            0.997085            0.995628   \n",
       "1                14            1.000000            1.000000   \n",
       "2                15            1.000000            1.000000   \n",
       "3                24            0.996515            0.996642   \n",
       "4                16            1.000000            1.000000   \n",
       "5                11            1.000000            1.000000   \n",
       "6                18            0.995248            0.995628   \n",
       "7                 8            1.000000            1.000000   \n",
       "8                 7            1.000000            1.000000   \n",
       "9                19            0.995818            0.996199   \n",
       "10                3            1.000000            1.000000   \n",
       "11                2            1.000000            1.000000   \n",
       "12               23            0.995311            0.995882   \n",
       "13               12            1.000000            1.000000   \n",
       "14               13            1.000000            1.000000   \n",
       "15               21            0.996452            0.996642   \n",
       "16                9            1.000000            1.000000   \n",
       "17               10            1.000000            1.000000   \n",
       "18               20            0.996262            0.995819   \n",
       "19                6            1.000000            1.000000   \n",
       "20                5            1.000000            1.000000   \n",
       "21               17            0.997466            0.996009   \n",
       "22                4            1.000000            1.000000   \n",
       "23                1            1.000000            1.000000   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.996769          0.996494         0.000626  \n",
       "1             1.000000          1.000000         0.000000  \n",
       "2             1.000000          1.000000         0.000000  \n",
       "3             0.996706          0.996621         0.000079  \n",
       "4             1.000000          1.000000         0.000000  \n",
       "5             1.000000          1.000000         0.000000  \n",
       "6             0.996326          0.995734         0.000446  \n",
       "7             1.000000          1.000000         0.000000  \n",
       "8             1.000000          1.000000         0.000000  \n",
       "9             0.996896          0.996304         0.000446  \n",
       "10            1.000000          1.000000         0.000000  \n",
       "11            1.000000          1.000000         0.000000  \n",
       "12            0.995882          0.995692         0.000269  \n",
       "13            1.000000          1.000000         0.000000  \n",
       "14            1.000000          1.000000         0.000000  \n",
       "15            0.996072          0.996389         0.000237  \n",
       "16            0.999937          0.999979         0.000030  \n",
       "17            1.000000          1.000000         0.000000  \n",
       "18            0.995692          0.995924         0.000244  \n",
       "19            1.000000          1.000000         0.000000  \n",
       "20            1.000000          1.000000         0.000000  \n",
       "21            0.995755          0.996410         0.000754  \n",
       "22            1.000000          1.000000         0.000000  \n",
       "23            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'mean_fit_time': np.array([ 29.3565313 ,  21.269967  , 133.63124331,   6.9153959 ,\n",
    "        17.71104503, 151.52857844,   8.77863534,  36.48309787,\n",
    "       353.55145939,  10.91108894,  62.25011571, 604.09919691,\n",
    "         6.63593658,  18.70342271, 125.81533424,   5.24119258,\n",
    "        16.36292839, 141.45259889,   7.89260626,  28.13510966,\n",
    "       273.91240621,   9.28567576,  44.10937214, 356.8786389 ]), 'std_fit_time': np.array([ 0.77492853,  2.90770999, 11.63067571,  0.2850153 ,  0.98171153,\n",
    "       11.44797585,  0.29892795,  3.36007335, 24.64549427,  0.59362711,\n",
    "        6.20874779, 40.38846034,  0.20280898,  0.27479866, 10.47984029,\n",
    "        0.84278515,  1.09157463, 12.09636917,  0.18592348,  1.8504363 ,\n",
    "       17.28253135,  0.37329269,  4.38992519, 99.02754836]), 'mean_score_time': np.array([ 7.33835514,  8.92508117, 24.09163777,  8.09356125,  7.32807509,\n",
    "       19.51869694,  7.59556937,  6.94122378, 14.72333399,  7.78833922,\n",
    "        7.38280678, 15.11881781,  8.04199298,  9.8266205 , 25.7414674 ,\n",
    "        6.29152044,  8.31556026, 18.50302108,  7.92796397,  7.69944366,\n",
    "       13.55180319,  7.96719853,  7.42520293, 11.7625773 ]), 'std_score_time': np.array([0.1306685 , 2.03098883, 2.33742256, 0.45626301, 1.50775737,\n",
    "       3.48599838, 0.21847926, 1.10654311, 2.18771397, 0.04787844,\n",
    "       1.2097773 , 2.10400838, 0.09428107, 0.18964651, 3.18375043,\n",
    "       1.19595878, 0.94813268, 1.95163257, 0.19510065, 1.0073612 ,\n",
    "       1.71333338, 0.16709411, 1.21011483, 2.31377346]), 'param_clf__criterion': np.ma.masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
    "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
    "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
    "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
    "                   'entropy'],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'param_clf__max_features': np.ma.masked_array(data=[5, 5, 5, 10, 10, 10, 50, 50, 50, 100, 100, 100, 5, 5,\n",
    "                   5, 10, 10, 10, 50, 50, 50, 100, 100, 100],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'param_clf__n_estimators': np.ma.masked_array(data=[10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
    "                   1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
    "                   100, 1000],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'params': [{'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 1000}], 'split0_test_score': np.array([0.91245407, 0.91866211, 0.91942227, 0.90903332, 0.91625491,\n",
    "       0.91980236, 0.91600152, 0.92246294, 0.92296972, 0.91460788,\n",
    "       0.92702395, 0.92727733, 0.91118713, 0.92018244, 0.91967566,\n",
    "       0.91308755, 0.92018244, 0.921196  , 0.91435449, 0.92525022,\n",
    "       0.92715064, 0.91600152, 0.92639047, 0.92854428]), 'split1_test_score': np.array([0.91320324, 0.92004562, 0.92042575, 0.91180943, 0.92080588,\n",
    "       0.91979219, 0.9175114 , 0.92435378, 0.92549417, 0.91409022,\n",
    "       0.92967562, 0.92790167, 0.91104916, 0.91953877, 0.92042575,\n",
    "       0.90927522, 0.92194627, 0.92181956, 0.91586417, 0.92663457,\n",
    "       0.9270147 , 0.92017233, 0.92904207, 0.93132286]), 'split2_test_score': np.array([0.91116462, 0.92117602, 0.91990876, 0.91040426, 0.92028894,\n",
    "       0.92180966, 0.91838804, 0.92523128, 0.92700545, 0.9177544 ,\n",
    "       0.92599164, 0.92789254, 0.91078444, 0.9210493 , 0.92028894,\n",
    "       0.9153466 , 0.92244329, 0.92054239, 0.91471296, 0.92497782,\n",
    "       0.92738563, 0.91940185, 0.92687872, 0.92713218]), 'mean_test_score': np.array([0.91227403, 0.91996114, 0.91991891, 0.91041561, 0.9191164 ,\n",
    "       0.92046798, 0.91730022, 0.92401588, 0.92515628, 0.91548403,\n",
    "       0.92756378, 0.92769049, 0.91100693, 0.9202568 , 0.92013009,\n",
    "       0.91256969, 0.92152391, 0.92118601, 0.91497719, 0.92562088,\n",
    "       0.92718365, 0.91852509, 0.92743707, 0.92899983]), 'std_test_score': np.array([0.00084192, 0.00102804, 0.00040974, 0.00113341, 0.00203455,\n",
    "       0.00094862, 0.00098567, 0.00115515, 0.00166481, 0.00161909,\n",
    "       0.00155163, 0.0002922 , 0.00016709, 0.00061889, 0.00032618,\n",
    "       0.00250546, 0.00097011, 0.00052144, 0.00064403, 0.00072536,\n",
    "       0.00015322, 0.00181211, 0.00115228, 0.00174085]), 'rank_test_score': np.array([22, 14, 15, 24, 16, 11, 18,  8,  7, 19,  3,  2, 23, 12, 13, 21,  9,\n",
    "       10, 20,  6,  5, 17,  4,  1], dtype=np.int32), 'split0_train_score': np.array([0.99708547, 1.        , 1.        , 0.99651524, 1.        ,\n",
    "       1.        , 0.99524805, 1.        , 1.        , 0.99581829,\n",
    "       1.        , 1.        , 0.99531141, 1.        , 1.        ,\n",
    "       0.99645188, 1.        , 1.        , 0.9962618 , 1.        ,\n",
    "       1.        , 0.99746563, 1.        , 1.        ]), 'split1_train_score': np.array([0.99562848, 1.        , 1.        , 0.99664217, 1.        ,\n",
    "       1.        , 0.99562848, 1.        , 1.        , 0.99619868,\n",
    "       1.        , 1.        , 0.99588191, 1.        , 1.        ,\n",
    "       0.99664217, 1.        , 1.        , 0.99581855, 1.        ,\n",
    "       1.        , 0.99600862, 1.        , 1.        ]), 'split2_train_score': np.array([0.99676908, 1.        , 1.        , 0.99670573, 1.        ,\n",
    "       1.        , 0.99632563, 1.        , 1.        , 0.99689579,\n",
    "       1.        , 1.        , 0.99588217, 1.        , 1.        ,\n",
    "       0.99607222, 0.99993665, 1.        , 0.99569211, 1.        ,\n",
    "       1.        , 0.99575546, 1.        , 1.        ]), 'mean_train_score': np.array([0.99649435, 1.        , 1.        , 0.99662105, 1.        ,\n",
    "       1.        , 0.99573405, 1.        , 1.        , 0.99630425,\n",
    "       1.        , 1.        , 0.99569183, 1.        , 1.        ,\n",
    "       0.99638876, 0.99997888, 1.        , 0.99592415, 1.        ,\n",
    "       1.        , 0.9964099 , 1.        , 1.        ]), 'std_train_score': np.array([6.25733424e-04, 0.00000000e+00, 0.00000000e+00, 7.91906591e-05,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.46206266e-04, 0.00000000e+00,\n",
    "       0.00000000e+00, 4.46177186e-04, 0.00000000e+00, 0.00000000e+00,\n",
    "       2.68995301e-04, 0.00000000e+00, 0.00000000e+00, 2.36922985e-04,\n",
    "       2.98640811e-05, 0.00000000e+00, 2.44267970e-04, 0.00000000e+00,\n",
    "       0.00000000e+00, 7.53630262e-04, 0.00000000e+00, 0.00000000e+00])})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.30s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1928.47s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, max_features=100, sampling_strategy='auto')\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0005020056104968013, 'JWTR_4'),\n",
       " (0.0006180397991121181, 'Boro_10'),\n",
       " (0.0006182323610456678, 'ENG_11'),\n",
       " (0.0006666647803905448, 'CIT_10'),\n",
       " (0.000845561954102215, 'Ethnicity_3'),\n",
       " (0.0010203369930211923, 'JWTR_3'),\n",
       " (0.0016273172555736843, 'INTP_adj_2'),\n",
       " (0.002282882484302701, 'Ethnicity_11'),\n",
       " (0.002428528916065317, 'AGEP_1'),\n",
       " (0.0039253585625141215, 'DIS_10'),\n",
       " (0.005603247830117554, 'JWTR_2'),\n",
       " (0.006984126312808381, 'INTP_adj_1'),\n",
       " (0.011814645668473192, 'Boro_1'),\n",
       " (0.016108428339244498, 'JWTR_1'),\n",
       " (0.05686880032439872, 'ENG_10')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline.named_steps['clf'].feature_importances_\n",
    "imps = list(zip(pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]\n",
    "#geometric_mean_score(y_test, pipeline.predict(X_test)) # 0.901335010891502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.12s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.78s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1172.32s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_features=100)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
       " <a list of 15 Text xticklabel objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imps = list(zip(X_train.columns, pipeline.named_steps['clf'].feature_importances_))\n",
    "imps=(sorted(imps, key=lambda tup: tup[1]))\n",
    "imps.reverse()\n",
    "#geometric_mean_score(y_test, pipeline.predict(X_test)) # 0.8741667300789631\n",
    "labels_i = [x[0] for x in imps][:15]\n",
    "ys_i = [x[1] for x in imps][:15]\n",
    "plt.plot(labels_i, ys_i)\n",
    "plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - No Financials\n",
    "This will be as above, but pulling out the financial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>AGEP_11</th>\n",
       "      <th>AGEP_12</th>\n",
       "      <th>AGEP_13</th>\n",
       "      <th>AGEP_14</th>\n",
       "      <th>AGEP_15</th>\n",
       "      <th>AGEP_16</th>\n",
       "      <th>AGEP_17</th>\n",
       "      <th>AGEP_18</th>\n",
       "      <th>...</th>\n",
       "      <th>WKW_19</th>\n",
       "      <th>WKW_2</th>\n",
       "      <th>WKW_20</th>\n",
       "      <th>WKW_3</th>\n",
       "      <th>WKW_4</th>\n",
       "      <th>WKW_5</th>\n",
       "      <th>WKW_6</th>\n",
       "      <th>WKW_7</th>\n",
       "      <th>WKW_8</th>\n",
       "      <th>WKW_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1521345</th>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521371</th>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521389</th>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521399</th>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521415</th>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_10  AGEP_11  AGEP_12  AGEP_13  AGEP_14  \\\n",
       "SERIALNO Povunit_ID                                                        \n",
       "1521345  1             32.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521371  1             32.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521389  1             57.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521399  1             39.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521415  1             36.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "                     AGEP_15  AGEP_16  AGEP_17  AGEP_18  ...    WKW_19  WKW_2  \\\n",
       "SERIALNO Povunit_ID                                      ...                    \n",
       "1521345  1               0.0      0.0      0.0      0.0  ...       0.0    0.0   \n",
       "1521371  1               0.0      0.0      0.0      0.0  ...       0.0    0.0   \n",
       "1521389  1               0.0      0.0      0.0      0.0  ...       0.0    1.0   \n",
       "1521399  1               0.0      0.0      0.0      0.0  ...       0.0    1.0   \n",
       "1521415  1               0.0      0.0      0.0      0.0  ...       0.0    3.0   \n",
       "\n",
       "                     WKW_20  WKW_3  WKW_4  WKW_5  WKW_6  WKW_7  WKW_8  WKW_9  \n",
       "SERIALNO Povunit_ID                                                           \n",
       "1521345  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521371  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521389  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521399  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521415  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = all_2016.copy()\n",
    "\n",
    "categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "# We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "pu_columns = ['NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU', 'NYCgov_Pov_Stat']\n",
    "\n",
    "# Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "X2_pers = X2.copy()\n",
    "X2_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "X2_pers = X2_pers[X2_pers_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X2_pers = X2_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "X2_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in X2_pers.columns)]))\n",
    "\n",
    "# Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "X2_pu = X2.copy()\n",
    "X2_pu_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + pu_columns\n",
    "X2_pu = X2_pu[X2_pu_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X2_pu = X2_pu.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "X2_pu = X2_pu.stack().groupby(['SERIALNO', 'Povunit_ID']).max()\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "X2 = X2_pers.add(X2_pu, fill_value=0)\n",
    "X2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.03s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 977.44s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y2 = X2['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X2 = X2.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_features=100)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X2_train, y2_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0019536750561223435, 'CIT_16'),\n",
       " (0.0019766238091623893, 'CIT_8'),\n",
       " (0.002074372847437007, 'CIT_19'),\n",
       " (0.002103638190090756, 'CIT_7'),\n",
       " (0.0021084495403344244, 'CIT_12'),\n",
       " (0.002192773240239379, 'CIT_20'),\n",
       " (0.0022114526799705417, 'CIT_5'),\n",
       " (0.0022167018769647475, 'CIT_15'),\n",
       " (0.0023101070754851017, 'CIT_18'),\n",
       " (0.0023378895980513356, 'DIS_7'),\n",
       " (0.0023659286886432707, 'CIT_6'),\n",
       " (0.0024051439784516827, 'CIT_3'),\n",
       " (0.0024677871327048293, 'CIT_17'),\n",
       " (0.002469216276971846, 'CIT_14'),\n",
       " (0.002591447212012863, 'CIT_4')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline.named_steps['clf'].feature_importances_\n",
    "imps = list(zip(pipeline.named_steps['clf'].feature_importances_, X2_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]\n",
    "#geometric_mean_score(y2_test, pipeline.predict(X2_test)) # 0.5891144868773415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'INTP_adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-1fcd7c603bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_2016\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTP_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#len(all_2016[all_2016.INTP_adj > 0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTP_adj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INTP_adj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'INTP_adj'"
     ]
    }
   ],
   "source": [
    "all_2016.INTP_adj.describe()\n",
    "#len(all_2016[all_2016.INTP_adj > 0])\n",
    "X.loc[X.INTP_adj > 0, 'INTP_adj'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    24259.000000\n",
       "mean      1623.764093\n",
       "std        994.621840\n",
       "min          4.030352\n",
       "25%        967.284480\n",
       "50%       1410.623200\n",
       "75%       2115.934800\n",
       "max       6448.563200\n",
       "Name: RNTP+MRGP, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = all_2016.copy()\n",
    "\n",
    "categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "# We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "#personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj', 'Ethnicity', 'Boro']\n",
    "personal_nums = ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj'] \n",
    "#pu_columns = ['NP', 'TEN', 'HHT', 'MRGP_adj', 'RNTP_adj', 'HousingStatus', 'TotalWorkHrs_PU', 'NYCgov_Pov_Stat']\n",
    "\n",
    "# Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "#X_pers = X.copy()\n",
    "#X_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "#X_pers = X_pers[X_pers_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "#X_pers = X_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "#X_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in X_pers.columns)]))\n",
    "\n",
    "# Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "X_trials = trials.copy()\n",
    "X_trials_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_nums\n",
    "X_trials = X_trials[X_trials_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X_trials = X_trials.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "X_trials = X_trials.stack().groupby(['SERIALNO', 'Povunit_ID']).sum()\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "#X = X_pers.add(X_pu, fill_value=0)\n",
    "#X.tail()\n",
    "#X_trials[X_trials.OI_adj > 0].OI_adj.describe()\n",
    "#X_trials.MRGP_adj.describe()\n",
    "#all_2016[all_2016.Povunit_Rel == 1].RNTP_adj.describe()\n",
    "#all_2016.loc[(all_2016.Povunit_Rel == 1) & (all_2016.RNTP_adj > 0)].RNTP_adj.describe()\n",
    "all_2016['RNTP+MRGP'] = all_2016.RNTP_adj + all_2016.MRGP_adj\n",
    "all_2016.loc[(all_2016.Povunit_Rel == 1) & (all_2016['RNTP+MRGP'] > 0)]['RNTP+MRGP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SERIALNO  SPORDER  Povunit_ID  ENG  WKW  TotalWorkHrs_PU\n",
      "710612        39        1           1  1.0  0.0                5\n",
      "710613        55        1           1  5.0  1.0                1\n",
      "710614        55        2           1  5.0  1.0                1\n",
      "710615        55        3           1  5.0  2.0                1\n",
      "710616        55        4           1  5.0  5.0                1\n",
      "710617        55        5           1  5.0  4.0                1\n",
      "710618        69        1           1  5.0  1.0                3\n",
      "710619       210        1           1  5.0  1.0                2\n",
      "710620       261        1           1  5.0  1.0                2\n",
      "710621       261        2           1  5.0  0.0                2\n",
      "        SERIALNO  SPORDER  Povunit_ID  ENG  WKW  TotalWorkHrs_PU\n",
      "710612        39        1           1    4    0                0\n",
      "710613        55        1           1    5    6                4\n",
      "710614        55        2           1    5    6                4\n",
      "710615        55        3           1    5    5                4\n",
      "710616        55        4           1    5    2                4\n",
      "710617        55        5           1    5    3                4\n",
      "710618        69        1           1    5    6                2\n",
      "710619       210        1           1    5    6                3\n",
      "710620       261        1           1    5    6                3\n",
      "710621       261        2           1    5    0                3\n"
     ]
    }
   ],
   "source": [
    "fX = all_2016.copy()\n",
    "print(fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].head(10))\n",
    "fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "              'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "#fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].map(fix_orders).head(10)\n",
    "fX['ENG'] = fX['ENG'].map(fix_orders['ENG'])\n",
    "fX['WKW'] = fX['WKW'].map(fix_orders['WKW'])\n",
    "fX['TotalWorkHrs_PU'] = fX['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "print(fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].head(10))\n",
    "\n",
    "#Number of adults, number of kids, number of retirement-age adults, number of working-age adults, any kids, \n",
    "#any retirement-age adults\n",
    "fX['n_adults'] = fX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SERIALNO  Povunit_ID  SPORDER  CIT  SCHL  SEX\n",
      "710612        39           1        1    1  18.0    1\n",
      "710613        55           1        1    1  20.0    1\n",
      "710614        55           1        2    1  16.0    2\n",
      "710615        55           1        3    1  21.0    1\n",
      "710616        55           1        4    1  16.0    1\n",
      "        SERIALNO  Povunit_ID  SPORDER  ENG  MSP  WKW\n",
      "710612        39           1        1  1.0  6.0  0.0\n",
      "710613        55           1        1  5.0  1.0  1.0\n",
      "710614        55           1        2  5.0  1.0  1.0\n",
      "710615        55           1        3  5.0  6.0  2.0\n",
      "710616        55           1        4  5.0  6.0  5.0\n",
      "        SERIALNO  Povunit_ID  SPORDER  WKHP  DIS  NP\n",
      "710612        39           1        1     0  1.0   1\n",
      "710613        55           1        1    32  2.0   5\n",
      "710614        55           1        2    40  2.0   5\n",
      "710615        55           1        3    10  2.0   5\n",
      "710616        55           1        4    40  2.0   5\n",
      "        SERIALNO  Povunit_ID  SPORDER  JWTR  Ethnicity\n",
      "710612        39           1        1   0.0          4\n",
      "710613        55           1        1   1.0          1\n",
      "710614        55           1        2   1.0          1\n",
      "710615        55           1        3   1.0          1\n",
      "710616        55           1        4   1.0          1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SERIALNO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 3078, in get_loc\n    return self._engine.get_loc(key)\n  File \"pandas/_libs/index.pyx\", line 140, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'SERIALNO'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-15-db1489088e2f>\", line 21, in add_columns_by_group\n    add_pu_columns(df1, groups, group_names, categories[column], category_names[column], column)\n  File \"<ipython-input-15-db1489088e2f>\", line 38, in add_pu_columns\n    df = df.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 3909, in set_index\n    level = frame[col]._values\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 2686, in __getitem__\n    return self._getitem_multilevel(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 2730, in _getitem_multilevel\n    loc = self.columns.get_loc(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/multi.py\", line 2237, in get_loc\n    loc = self._get_level_indexer(key, level=0)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/multi.py\", line 2496, in _get_level_indexer\n    loc = level_index.get_loc(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n    return self._engine.get_loc(self._maybe_cast_indexer(key))\n  File \"pandas/_libs/index.pyx\", line 140, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'SERIALNO'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-db1489088e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;31m#def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m \u001b[0mtest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengineer_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_fin_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAGEP_yes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0mtest_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/testnewfunctions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-db1489088e2f>\u001b[0m in \u001b[0;36mengineer_features\u001b[0;34m(df, columns_to_use, categories, category_names, num_processors, AGEP_yes)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# FIX THIS -- FOLLOW THE EXAMPLE BELOW TO SPLIT DFC INTO CHUNKS AND THEN MAP OVER THEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_columns_by_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Close the pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SERIALNO'"
     ]
    }
   ],
   "source": [
    "# DON'T USE THIS ONE FOR NOW - USE THE OTHER ONE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_columns_by_group(df):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Helper function \n",
    "    \"\"\"\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    #print('df1 columns: ' + str(df1.columns))\n",
    "    #columns = df1.columns[0]\n",
    "    columns = df1.columns\n",
    "    #print('columns: ' + str(columns))\n",
    "    for column in columns:\n",
    "        if not column in ['SERIALNO', 'Povunit_ID', 'SPORDER']:\n",
    "            #print('df1:' + str(df1.head()))\n",
    "            #print('groups:' + str(groups))\n",
    "            #print('group names:' + str(group_names))\n",
    "            #print('categories:' + str(categories[column]))\n",
    "            #print('category names:' + str(category_names[column]))\n",
    "            #print('column:' + str(column))\n",
    "            #print(columns)\n",
    "            print(df1.head())\n",
    "            add_pu_columns(df1, groups, group_names, categories[column], category_names[column], column)\n",
    "            add_pu_columns(df1, groups, group_names, categories[column], category_names[column], 'AGEP')\n",
    "            df1.drop(column, axis='columns')\n",
    "    return df1\n",
    "\n",
    "def add_pu_columns(df, groups, group_names, categories, category_names, column):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Adds columns to dataframe 'df' containing calculations by poverty-unit, restricted by categories, considering groups.\n",
    "    Calculations include any(), all(), min(), max(), count(), sum(), mean(), and % in given category.\n",
    "    Input: a dataframe with multi-index consisting of 'SERIALNO', 'Povunit_ID', and 'SPORDER'; a set of masks and list of\n",
    "    names for the groups; a set of masks and a list of names for the categories; and the column of interest.\n",
    "    Output: no return value.  Inserts a series of columns into the dataframe including min, max, count, sum, any, all,\n",
    "    % of total, and mean - within households, focusing on the groups and categories of interest. \n",
    "    \"\"\"\n",
    "    for group, group_name in zip(groups, group_names):\n",
    "        for category, category_name in zip(categories, category_names):\n",
    "            # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "            df = df.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "            stacked = df[group & category].stack().groupby(['SERIALNO', 'Povunit_ID'])[column]\n",
    "            #print('columns to be stacked ' + str(df[group & category].columns))\n",
    "            #print('length to be stacked ' + str(len(df[group & category])))\n",
    "            #print('cat:' + str(category_name) + ', group:' + str(group_name))\n",
    "            #print(df.loc[group & category].head())\n",
    "            anys = stacked.any()\n",
    "            # would love to use .all() here, but it would always be True because we filtered out everyone else\n",
    "            mins = stacked.min()\n",
    "            maxes = stacked.max()\n",
    "            counts = stacked.count()\n",
    "            sums = stacked.sum()\n",
    "            means = sums/counts\n",
    "            # The divisor below only restricts by 'groups' - so the final calculation is within a household, within\n",
    "            # the group of interest (e.g. adults), what % is in the category of interest (e.g. works 40 hrs/week)\n",
    "            divisor_for_percents = df[column][group].stack().groupby(['SERIALNO', 'Povunit_ID']).count()\n",
    "            try:\n",
    "                percents = counts.div(divisor_for_percents, axis=0)\n",
    "                alls = percents == 1\n",
    "            except: # if the calculation failed, leave percents and alls as a column of zeros\n",
    "                df_len = len(df.groupby(['SERIALNO', 'Povunit_ID']).sum())\n",
    "                percents = np.zeros(df_len)\n",
    "\n",
    "                alls = np.zeros(df_len)\n",
    "            \n",
    "            # loop through, put in the dataframe, and fill in NAs of appropriate type\n",
    "            series_and_names = zip([anys, alls, mins, maxes, counts, sums, means, percents], \n",
    "                                  ['any', 'all', 'min', 'max', 'count', 'sum', 'mean', '%'])\n",
    "            for series, series_name in series_and_names:\n",
    "                column_title = series_name + '_' + group_name + '_' + category_name\n",
    "                df[column_title] = series\n",
    "                if series_name in ['any', 'all']:\n",
    "                    df[column_title] = df[column_title].fillna(False)\n",
    "                else:\n",
    "                    df[column_title] = df[column_title].fillna(0)\n",
    "                    \n",
    "def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Create features for the dataframe. This function is heavily custom and was solely created for DRY-ness.\n",
    "    Input: a poverty dataframe and whether or not to include financial features.\n",
    "    Output: returns a copy of the dataframe summarized by poverty-unit, with *only* the new features included. \n",
    "    Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "\n",
    "    # Create dataframe to house new features \n",
    "    dfc = df.copy() \n",
    "    dfc = dfc[['SERIALNO', 'Povunit_ID', 'SPORDER'] + columns_to_use]\n",
    "\n",
    "    # Split columns_to_use into num_processors groups for use in parallel processing\n",
    "    n = len(columns_to_use)\n",
    "    s = num_processors\n",
    "    labels = [columns_to_use[i * (n//s + 1) : (i+1) * (n//s + 1)] for i in range(s)]\n",
    "    chunks = []\n",
    "    for i in range(s):\n",
    "        chunks.append(dfc[['SERIALNO', 'Povunit_ID', 'SPORDER'] + labels[i]])\n",
    "        #print(labels[i])\n",
    "\n",
    "    # engineer features in parallel\n",
    "    pool = Pool(num_processors)\n",
    "    \n",
    "    #curried = lambda x: partial(add_columns_by_group, dfc, groups, group_names, categories, category_names, x)\n",
    "    #def add_columns_by_group(df, groups, group_names, categories, category_names, columns):\n",
    "    #curried = partial(add_columns_by_group, dfc, groups, group_names, categories, category_names, chunks)\n",
    "    \n",
    "    \n",
    "    # FIX THIS -- FOLLOW THE EXAMPLE BELOW TO SPLIT DFC INTO CHUNKS AND THEN MAP OVER THEM\n",
    "    new_df = pd.concat(pool.map(add_columns_by_group, chunks))\n",
    "    \n",
    "    # Close the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "#def parallel_feature_calculation(df, partitions=10, processes=4):\n",
    "    # calculate features in parallel by splitting the dataframe into partitions and using parallel processes\n",
    "    #pool = Pool(processes)\n",
    "    #df_split = np.array_split(df, partitions, axis=1)  # split dataframe into partitions column wise\n",
    "    #df = pd.concat(pool.map(feature_calculation, df_split))\n",
    "    #pool.close()\n",
    "    #pool.join()\n",
    "    #return df\n",
    "\n",
    "    # add columns with age only, no categories\n",
    "    add_pu_columns(new_df, groups, group_names, [mask_any_age], ['age'], 'AGEP')\n",
    "\n",
    "    # We added a column 'TINP' - drop it if we're not doing financials\n",
    "    if not 'WAGP_adj' in columns_to_use:\n",
    "        new_df.drop('TINP', axis='columns')\n",
    "\n",
    "    # Only return the new features that we engineered\n",
    "    # The variables features_to_mask and max_ppl were created at the beginning of this function\n",
    "    #columns_to_mask = features_to_mask * max_ppl\n",
    "    #dfc = dfc.iloc[:, columns_to_mask:].copy()\n",
    "\n",
    "    # We ended up with multi-level column headers - just keep the top level\n",
    "    new_df.columns = new_df.columns.get_level_values(0)\n",
    "    \n",
    "    time_took = time.time() - time_0\n",
    "    print('Complete. Took ' + str(time_took) + 's')\n",
    "    return(new_df)\n",
    "\n",
    "dfa = all_2016.copy()\n",
    "\n",
    "# First, some categoricals have odd ordering; remap them\n",
    "fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "              'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "dfa['ENG'] = dfa['ENG'].map(fix_orders['ENG'])\n",
    "dfa['WKW'] = dfa['WKW'].map(fix_orders['WKW'])\n",
    "dfa['TotalWorkHrs_PU'] = dfa['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "# Add a column for total personal income - will be ignored if we don't need it\n",
    "dfa['TINP'] = dfa.WAGP_adj + dfa.INTP_adj + dfa.SEMP_adj + dfa.SSP_adj + dfa.SSIP_adj + \\\n",
    "                dfa.PA_adj + dfa.RETP_adj + dfa.OI_adj\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "dfa = dfa.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Create empty dicts for use in adding new columns\n",
    "categories = {}\n",
    "category_names = {}\n",
    "\n",
    "# Create masks for age groups to use in creating new features\n",
    "mask_adult = (dfa.AgeCateg == 2) | (dfa.AgeCateg == 3)\n",
    "mask_65_plus = dfa.AgeCateg == 3\n",
    "mask_18_64 = dfa.AgeCateg == 2\n",
    "mask_kid = dfa.AgeCateg == 1\n",
    "mask_any_age = dfa.AgeCateg != 0\n",
    "mask_any = mask_any_age\n",
    "\n",
    "groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "# add masks for CIT\n",
    "mask_non_cit = dfa.CIT == 5\n",
    "mask_cit = (dfa.CIT != 5) & (dfa.CIT != 0)\n",
    "mask_naturalized = dfa.CIT == 4\n",
    "\n",
    "categories['CIT'] = [mask_non_cit, mask_cit, mask_naturalized, mask_any]\n",
    "category_names['CIT'] = ['non-cit', 'citizen', 'naturalized_cit', 'any_CIT']\n",
    "\n",
    "# add masks for SCHL\n",
    "mask_college_degree = (dfa.SCHL >= 21)\n",
    "mask_HS_diploma = (dfa.SCHL >= 17)\n",
    "mask_no_diploma = (dfa.SCHL <= 16)\n",
    "\n",
    "categories['SCHL'] = [mask_college_degree, mask_HS_diploma, mask_no_diploma, mask_HS_diploma & ~mask_college_degree, mask_any]\n",
    "category_names['SCHL'] = ['college', 'HS', 'no_diploma', 'diploma_no_bachelors', 'any_SCHL']\n",
    "\n",
    "# add masks for SEX\n",
    "mask_male = dfa.SEX == 1\n",
    "mask_female = dfa.SEX == 2\n",
    "\n",
    "categories['SEX'] = [mask_male, mask_female, mask_any]\n",
    "category_names['SEX'] = ['male', 'female', 'any_SEX']\n",
    "\n",
    "# add masks for English ability (ENG)\n",
    "# Keep in mind we switched ENG above so that 0 is NA, 1 is not at all, 2 is not very well, ..., 5 is only English\n",
    "mask_no_english = dfa.ENG == 1\n",
    "mask_eng_nvw = dfa.ENG == 2\n",
    "mask_sep_well = dfa.ENG == 3\n",
    "mask_eng_vw = dfa.ENG == 4\n",
    "mask_only_eng = dfa.ENG == 5\n",
    "\n",
    "categories['ENG'] = [mask_no_english, mask_eng_nvw, mask_sep_well, mask_eng_vw, mask_only_eng, mask_any]\n",
    "category_names['ENG'] = ['ENG_no', 'ENG_nvw', 'ENG_well', 'ENG_vw', 'ENG_only', 'ENG_any']\n",
    "\n",
    "# add masks for marital status (MSP)\n",
    "mask_married = (dfa.MSP == 1) | (dfa.MSP == 2)\n",
    "mask_widowed = dfa.MSP == 3\n",
    "mask_sep_div = (dfa.MSP == 4) | (dfa.MSP == 5)\n",
    "mask_not_married = dfa.MSP == 6\n",
    "\n",
    "categories['MSP'] = [mask_married, mask_widowed, mask_sep_div, mask_not_married, mask_any]\n",
    "category_names['MSP'] = ['married', 'widowed', 'sep/divorced', 'not_married', 'any_MSP']\n",
    "\n",
    "# add masks for weeks worked (WKW) -- this is *weeks* worked last year, not *hours per week* (that's WKHP)\n",
    "# Keep in mind we switched WKW above so that 0 is none, 1 is <14 weeks, 2 is 14-26 weeks, etc.\n",
    "mask_0_WKW = dfa.WKW == 0\n",
    "mask_u14_WKW = dfa.WKW == 1\n",
    "mask_14_26_WKW = dfa.WKW == 2\n",
    "mask_27_39_WKW = dfa.WKW == 3\n",
    "mask_40_47_WKW = dfa.WKW == 4\n",
    "mask_48_49_WKW = dfa.WKW == 5\n",
    "mask_50_52_WKW = dfa.WKW == 6\n",
    "\n",
    "categories['WKW'] = [mask_0_WKW, mask_u14_WKW, mask_14_26_WKW, mask_27_39_WKW, mask_40_47_WKW, mask_48_49_WKW, mask_50_52_WKW, \n",
    "             (mask_40_47_WKW | mask_48_49_WKW | mask_50_52_WKW), ~mask_0_WKW, mask_any]\n",
    "category_names['WKW'] = ['no_work', '<14WKW', '14-26WKW', '27-39WKW', '40-47WKW', '48-49WKW', '50-52WKW', '>40WKW', 'nonzero_WKW',\n",
    "                 'any_WKW']\n",
    "\n",
    "# add masks for usual hours worked per week last 12 months (WKHP)\n",
    "mask_0_WKHP = dfa.WKHP == 0\n",
    "mask_u10_WKHP = dfa.WKHP < 10\n",
    "mask_u15_WKHP = dfa.WKHP < 15\n",
    "mask_u20_WKHP = dfa.WKHP < 20\n",
    "mask_u30_WKHP = dfa.WKHP < 30\n",
    "mask_u40_WKHP = dfa.WKHP < 40\n",
    "mask_u50_WKHP = dfa.WKHP < 50\n",
    "mask_50_plus_WKHP = dfa.WKHP >= 50\n",
    "mask_40_plus_WKHP = dfa.WKHP >= 40\n",
    "\n",
    "categories['WKHP'] = [mask_0_WKHP, mask_u10_WKHP, mask_u15_WKHP, mask_u20_WKHP, mask_u30_WKHP, mask_u40_WKHP, \n",
    "              mask_u50_WKHP, mask_50_plus_WKHP, mask_40_plus_WKHP, mask_any]\n",
    "category_names['WKHP'] = ['no_work_hrs', '<10_work_hrs', '<15_work_hrs', '<20_work_hrs', '<30_work_hrs', '<40_work_hrs', \n",
    "                  '<50_work_hrs', '50_plus_work_hrs', '40_plus_work_hrs', 'any_WKHP']\n",
    "\n",
    "# add masks for disability status (DIS)\n",
    "mask_DIS = dfa.DIS == 1\n",
    "mask_not_DIS = dfa.DIS == 2\n",
    "\n",
    "categories['DIS'] = [mask_DIS, mask_not_DIS, mask_any]\n",
    "category_names['DIS'] = ['DIS', 'not_DIS', 'any_DIS']\n",
    "\n",
    "# add masks for number of people (NP)\n",
    "mask_1_NP = dfa.NP == 1\n",
    "mask_2_NP = dfa.NP == 2\n",
    "mask_3_NP = dfa.NP == 3\n",
    "mask_4_NP = dfa.NP == 4\n",
    "mask_5_NP = dfa.NP == 5\n",
    "mask_p5_NP = dfa.NP > 5\n",
    "mask_p6_NP = dfa.NP > 6\n",
    "mask_p8_NP = dfa.NP > 8\n",
    "mask_p10_NP = dfa.NP > 10\n",
    "mask_p12_NP = dfa.NP > 12\n",
    "\n",
    "categories['NP'] = [mask_1_NP, mask_2_NP, mask_3_NP, mask_4_NP, mask_5_NP, mask_p5_NP, mask_p6_NP, mask_p8_NP, mask_p10_NP, \n",
    "              mask_p12_NP, mask_any]\n",
    "category_names['NP'] = ['NP1', 'NP2', 'NP3', 'NP4', 'NP5', 'NP>5', 'NP>6', 'NP>8', 'NP>10', 'NP>12', 'anyNP']\n",
    "\n",
    "# add masks for means of transportation to work (JWTR)\n",
    "categories['JWTR'] = [mask_any]\n",
    "category_names['JWTR'] = ['work_trans']\n",
    "\n",
    "# add masks for wages (WAGP_adj)\n",
    "mask_0_WAG = dfa.WAGP_adj == 0\n",
    "mask_u10_WAG = dfa.WAGP_adj < 10000\n",
    "mask_u15_WAG = dfa.WAGP_adj < 15000\n",
    "mask_u20_WAG = dfa.WAGP_adj < 20000\n",
    "mask_u25_WAG = dfa.WAGP_adj < 25000\n",
    "mask_u30_WAG = dfa.WAGP_adj < 30000\n",
    "mask_u35_WAG = dfa.WAGP_adj < 35000\n",
    "mask_u40_WAG = dfa.WAGP_adj < 40000\n",
    "mask_u45_WAG = dfa.WAGP_adj < 45000\n",
    "mask_u50_WAG = dfa.WAGP_adj < 50000\n",
    "mask_u60_WAG = dfa.WAGP_adj < 60000\n",
    "mask_u70_WAG = dfa.WAGP_adj < 70000\n",
    "mask_u80_WAG = dfa.WAGP_adj < 80000\n",
    "\n",
    "categories['WAGP_adj'] = [mask_0_WAG, mask_u10_WAG, mask_u15_WAG, mask_u20_WAG, mask_u25_WAG, mask_u30_WAG,  mask_u35_WAG, \n",
    "              mask_u40_WAG, mask_u45_WAG, mask_u50_WAG, mask_u60_WAG, mask_u70_WAG, mask_u80_WAG, mask_any]\n",
    "category_names['WAGP_adj'] = ['WAG0', 'WAG<10', 'WAG<15', 'WAG<20', 'WAG<25', 'WAG<30', 'WAG<35', \n",
    "                  'WAG<40', 'WAG<45', 'WAG<50', 'WAG<60', 'WAG<70', 'WAG<80', 'WAG_any']\n",
    "\n",
    "# add masks for interest income (INTP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_INT = dfa.INTP_adj <= 0\n",
    "mask_INT_1q = (dfa.INTP_adj > 0) & (dfa.INTP_adj <= 400)\n",
    "mask_INT_2q = (dfa.INTP_adj > 400) & (dfa.INTP_adj <= 4000)\n",
    "mask_INT_3q = (dfa.INTP_adj > 4000) & (dfa.INTP_adj <= 15000)\n",
    "mask_INT_4q = dfa.INTP_adj > 15000\n",
    "\n",
    "categories['INTP_adj'] = [mask_0_INT, mask_INT_1q, mask_INT_2q, mask_INT_3q, mask_INT_4q, mask_any]\n",
    "category_names['INTP_adj'] = ['INT0', 'INT1q', 'INT2q', 'INT3q', 'INT4q', 'INT_any']\n",
    "\n",
    "# add masks for self-employment income (SEMP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_SEMP = dfa.SEMP_adj <= 0\n",
    "mask_SEMP_1q = (dfa.SEMP_adj > 0) & (dfa.SEMP_adj <= 5000)\n",
    "mask_SEMP_2q = (dfa.SEMP_adj > 5000) & (dfa.SEMP_adj <= 15000)\n",
    "mask_SEMP_3q = (dfa.SEMP_adj > 15000) & (dfa.SEMP_adj <= 35000)\n",
    "mask_SEMP_4q = dfa.SEMP_adj > 35000\n",
    "\n",
    "categories['SEMP_adj'] = [mask_0_SEMP, mask_SEMP_1q, mask_SEMP_2q, mask_SEMP_3q, mask_SEMP_4q, mask_any]\n",
    "category_names['SEMP_adj'] = ['SEMP0', 'SEMP1q', 'SEMP2q', 'SEMP3q', 'SEMP4q', 'SEMP_any']\n",
    "\n",
    "# add masks for social security income (SSP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "# min 10, 25% 8000, 50% 12,000, 75% 18,000, max 50,000\n",
    "mask_0_SSP = dfa.SSP_adj <= 0\n",
    "mask_SSP_1q = (dfa.SSP_adj > 0) & (dfa.SSP_adj <= 8000)\n",
    "mask_SSP_2q = (dfa.SSP_adj > 8000) & (dfa.SSP_adj <= 12000)\n",
    "mask_SSP_3q = (dfa.SSP_adj > 12000) & (dfa.SSP_adj <= 18000)\n",
    "mask_SSP_4q = dfa.SSP_adj > 18000\n",
    "\n",
    "categories['SSP_adj'] = [mask_0_SSP, mask_SSP_1q, mask_SSP_2q, mask_SSP_3q, mask_SSP_4q, mask_any]\n",
    "category_names['SSP_adj'] = ['SSP0', 'SSP1q', 'SSP2q', 'SSP3q', 'SSP4q', 'SSP_any']\n",
    "\n",
    "# add masks for supplemental security income (SSIP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_SSIP = dfa.SSIP_adj <= 0 \n",
    "mask_SSIP_1q = (dfa.SSIP_adj > 0) & (dfa.SSIP_adj <= 5500) \n",
    "mask_SSIP_2q = (dfa.SSIP_adj > 5500) & (dfa.SSIP_adj <= 8000) \n",
    "mask_SSIP_3q = (dfa.SSIP_adj > 8000)\n",
    "\n",
    "categories['SSIP_adj'] = [mask_0_SSIP, mask_SSIP_1q, mask_SSIP_2q, mask_SSIP_3q, mask_any]\n",
    "category_names['SSIP_adj'] = ['SSIP0', 'SSIP1q', 'SSIP2q', 'SSIP3q', 'SSIP_any']\n",
    "\n",
    "# add masks for public assistance income (PA_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_PA = dfa.PA_adj <= 0 \n",
    "mask_PA_1q = (dfa.PA_adj > 0) & (dfa.PA_adj <= 900) \n",
    "mask_PA_2q = (dfa.PA_adj > 900)\n",
    "\n",
    "categories['PA_adj'] = [mask_0_PA, mask_PA_1q, mask_PA_2q, mask_any]\n",
    "category_names['PA_adj'] = ['PA0', 'PA1q', 'PA2q', 'PA_any']\n",
    "\n",
    "# add masks for retirement income (RETP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_RETP_1q = (dfa.RETP_adj > 0) & (dfa.RETP_adj <= 6000) \n",
    "mask_RETP_2q = (dfa.RETP_adj > 6000) & (dfa.RETP_adj <= 13400) \n",
    "mask_RETP_3q = (dfa.RETP_adj > 13400)\n",
    "\n",
    "categories['RETP_adj'] = [mask_RETP_1q, mask_RETP_2q, mask_RETP_3q, mask_any]\n",
    "category_names['RETP_adj'] = ['RETP1q', 'RETP2q', 'RETP3q', 'RETP_any']\n",
    "\n",
    "# add masks for other income (OI_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_OI_1q = (dfa.OI_adj > 0) & (dfa.OI_adj <= 2000) \n",
    "mask_OI_2q = (dfa.OI_adj > 2000) & (dfa.OI_adj <= 6000) \n",
    "mask_OI_3q = (dfa.OI_adj > 6000)\n",
    "\n",
    "categories['OI_adj'] = [mask_OI_1q, mask_OI_2q, mask_OI_3q, mask_any]\n",
    "category_names['OI_adj'] = ['OI1q', 'OI2q', 'OI3q', 'OI_any']\n",
    "\n",
    "# add masks for ethnicity\n",
    "mask_white = dfa.Ethnicity == 1\n",
    "mask_black = dfa.Ethnicity == 2\n",
    "mask_asian = dfa.Ethnicity == 3\n",
    "mask_hisp = dfa.Ethnicity == 4\n",
    "mask_other = dfa.Ethnicity == 5\n",
    "\n",
    "categories['Ethnicity'] = [mask_white, mask_black, mask_asian, mask_hisp, mask_other, mask_any]\n",
    "category_names['Ethnicity'] = ['White', 'Black', 'Asian', 'Hisp', 'ETH_other', 'ETH_any']\n",
    "\n",
    "# add masks for our constructed column 'TINP'\n",
    "mask_0_TINP = dfa.TINP == 0\n",
    "mask_u10_TINP = dfa.TINP < 10000\n",
    "mask_u15_TINP = dfa.TINP < 15000\n",
    "mask_u20_TINP = dfa.TINP < 20000\n",
    "mask_u25_TINP = dfa.TINP < 25000\n",
    "mask_u30_TINP = dfa.TINP < 30000\n",
    "mask_u35_TINP = dfa.TINP < 35000\n",
    "mask_u40_TINP = dfa.TINP < 40000\n",
    "mask_u45_TINP = dfa.TINP < 45000\n",
    "mask_u50_TINP = dfa.TINP < 50000\n",
    "mask_u60_TINP = dfa.TINP < 60000\n",
    "mask_u70_TINP = dfa.TINP < 70000\n",
    "mask_u80_TINP = dfa.TINP < 80000\n",
    "\n",
    "categories['TINP'] = [mask_0_TINP, mask_u10_TINP, mask_u15_TINP, mask_u20_TINP, mask_u25_TINP, mask_u30_TINP, \n",
    "                      mask_u35_TINP, mask_u40_TINP, mask_u45_TINP, mask_u50_TINP, mask_u60_TINP, mask_u70_TINP, \n",
    "                      mask_u80_TINP, mask_any]\n",
    "category_names['TINP'] = ['TINP0', 'TINP<10', 'TINP<15', 'TINP<20', 'TINP<25', 'TINP<30', 'TINP<35', \n",
    "              'TINP<40', 'TINP<45', 'TINP<50', 'TINP<60', 'TINP<70', 'TINP<80', 'TINP_any']\n",
    "\n",
    "financial_columns = ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj']\n",
    "non_fin_columns = ['CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'NP', 'JWTR', 'Ethnicity']\n",
    "\n",
    "#new_features = engineer_features(all_2016, include_financials=True)\n",
    "\n",
    "#new_features.to_csv('data/EngineeredFeatures.csv')\n",
    "\n",
    "#def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\n",
    "\n",
    "test_new = engineer_features(all_2016, non_fin_columns, categories, category_names, num_processors=4, AGEP_yes=True)\n",
    "\n",
    "test_new.to_csv('data/testnewfunctions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Coding Categorical Variables for One-Hot Encoding\n",
    "We need to do a little cleanup on the data before one-hot encoding. Some of our columns are categorical, and we need\n",
    "them to have type Categorical before one-hot encoding.  \n",
    "\n",
    "Normally we could just pass this to a pre-processor like \n",
    "dask-ml's 'Categorizer'; but remember that we split up each column like 'SCHL' into 20 columns 'SCHL_1', 'SCHL_2', etc. \n",
    "Moreover, some of these columns, like 'SCHL_20', will be pretty sparse since there are very few households with 20\n",
    "people. So we want to be sure that when we code each 'SCHL_n' column, we have ALL of the possible SCHL values encoded in\n",
    "the Categorical so that we don't get an error when we try to generalize to unseen data.\n",
    "\n",
    "Some categories are unordered (e.g. disability\n",
    "status), and we have to be aware of personal categories vs poverty-unit categories; the poverty-unit categories only show\n",
    "up in one column each, while the personal categories show up in many columns each (suffixed with '\\_1', '\\_2', etc.).\n",
    "\n",
    "Again this is one-off code poorly disguised as a function, solely for DRY purposes. 'Tighter' code would be to pull out\n",
    "the hard-coded lists and turn the loops into helper functions - falling back on YAGNI and 3-strikes rule for now (we're\n",
    "at 2 strikes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_categoricals(df, old_df):\n",
    "    \"\"\"Turn the categorical columns of df into true Categorical types in preparation for one-hot encoding, and return a \n",
    "    dictionary of columns to pass to the one-hot encoder.\n",
    "    Input: the dataframe of interest, and the 'old' dataframe with the original categories. (The dataframe at this\n",
    "    point will include columns like 'AGEP_1', 'AGEP_2', etc. which may not have all of the values, so we refer to old_df.)\n",
    "    Output: returns a 2-tuple of the dataframe with columns transformed, and a dictionary to pass to the one-hot encoder.)\n",
    "    \"\"\"\n",
    "    \n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # Number of enumerated columns for each feature ('AGEP_1', 'AGEP_2', etc.)\n",
    "    # This is equal to the maximum number of people in any household, which is the max of SPORDER\n",
    "    n = old_df.SPORDER.max()\n",
    "\n",
    "    # All the categoricals that we'll have to set up\n",
    "    categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "    personal_categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    pu_categoricals = ['NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "    categories = {} # Dict for each initial categorical\n",
    "\n",
    "    # Some categoricals have no ordering\n",
    "    unordered = ['DIS', 'SEX', 'MSP', 'JWTR', 'Ethnicity', 'Boro', 'TEN', 'HHT', 'HousingStatus']\n",
    "\n",
    "    # Loop through and assign appropriate category structure for personal categoricals\n",
    "    for feature in personal_categoricals:\n",
    "        cats = old_df[feature].unique() # Get all of the category values, to use in assigning the type of Categorical\n",
    "        if not 0 in cats:\n",
    "            # Even if 0 was not in the original categorization - here it means 'no person', so we need it\n",
    "            cats = np.append(cats, 0)\n",
    "        cats.sort()\n",
    "        # Loop through and assign for each suffixed column '_1', '_2', etc.\n",
    "        for i in range(1,n+1):\n",
    "            suffixed_name = feature + '_' + str(i)\n",
    "            # Assign Categorical type to columns\n",
    "            if feature in unordered:\n",
    "                categories[suffixed_name] = pd.Categorical(cats, ordered=False)\n",
    "                dfc[suffixed_name] = pd.Categorical(dfc[suffixed_name], ordered=False, categories=cats)\n",
    "            else: # Category is ordered\n",
    "                categories[suffixed_name] = pd.Categorical(cats, ordered=True, categories=cats)\n",
    "                dfc[suffixed_name] = pd.Categorical(dfc[suffixed_name], ordered=True, categories=cats)\n",
    "\n",
    "    # Loop through and assign appropriate category structure for poverty-unit categoricals\n",
    "    for feature in pu_categoricals:\n",
    "        cats = old_df[feature].unique() # Get all of the category values, to use in assigning the type of Categorical\n",
    "        if not 0 in cats:\n",
    "            # Even if 0 was not in the original categorization - here it means 'no person', so we need it\n",
    "            cats = np.append(cats, 0)\n",
    "        cats.sort()\n",
    "        # Assign Categorical type to columns\n",
    "        if feature in unordered:\n",
    "            categories[feature] = pd.Categorical(cats, ordered=False)\n",
    "            dfc[feature] = pd.Categorical(dfc[feature], ordered=False, categories=cats)\n",
    "        else: # Category is ordered\n",
    "            categories[feature] = pd.Categorical(cats, ordered=True, categories=cats)\n",
    "            dfc[feature] = pd.Categorical(dfc[feature], ordered=True, categories=cats)\n",
    "\n",
    "    # Create a dictionary 'dummy_these' that we'll pass to our dummy-maker later\n",
    "    # The poverty-unit categoricals can be passed as-is. For the personal categoricals, we'll have features \n",
    "    # like 'AGEP_1', 'AGEP_2', ..., 'AGEP_20' - so we have to loop through and assign categories.\n",
    "    dummy_these = {}\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        for feature in personal_categoricals:\n",
    "            name = feature + '_' + str(i)\n",
    "            dummy_these[name] = categories[name]\n",
    "\n",
    "    for feature in pu_categoricals:\n",
    "        dummy_these[feature] = categories[name]\n",
    "    \n",
    "    return(dfc, dummy_these)\n",
    "\n",
    "#X_and_y, dummy_these = code_categoricals(X_and_y, all_2016)\n",
    "#X_and_y.to_csv('data/FeaturesCoded.csv')\n",
    "\n",
    "\n",
    "    \n",
    "#for col in cols:\n",
    "#    if rama[col].dtype == 'bool':\n",
    "#        cats = rama[col].unique()\n",
    "#        cats.sort()\n",
    "#        rama[col] = pd.Categorical(rama[col], ordered=True, categories=cats)\n",
    "#    if rama[col].dtype == 'int64':\n",
    "#        cats = rama[col].unique()\n",
    "#        cats.sort()\n",
    "#        rama[col] = pd.Categorical(rama[col], ordered=True, categories=cats)\n",
    "\n",
    "#rama.info()\n",
    "\n",
    "#for col in cols:\n",
    "    #if rama[col].dtype == 'category':\n",
    "        # ind = cols.get_loc(col)\n",
    "        # categorical_features += ind\n",
    "        # categorical_names[ind] = cats # (cats from above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with grid search and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  3.6min remaining:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  5.3min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 11.8min finished\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.34s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1020.30s to fit \n",
      "Pipeline(memory='/mnt/ssd/tmp/tmp5ozdrgyr',\n",
      "     steps=[('dummies', DummyEncoder(columns=None, drop_first=True)), ('scaler', Normalizer(copy=True, norm='l2')), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0...mators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "0.9234668018246326\n",
      "{'clf__n_estimators': 1000}\n",
      "{'std_score_time': array([ 1.16240683,  3.84877212, 10.16093959]), 'mean_test_score': array([0.91518838, 0.92253759, 0.9234668 ]), 'split2_test_score': array([0.91572678, 0.91990876, 0.92206311]), 'std_train_score': array([7.87808717e-05, 0.00000000e+00, 0.00000000e+00]), 'params': [{'clf__n_estimators': 10}, {'clf__n_estimators': 100}, {'clf__n_estimators': 1000}], 'split0_train_score': array([0.99543813, 1.        , 1.        ]), 'std_test_score': array([0.00040945, 0.00190335, 0.0014685 ]), 'mean_fit_time': array([ 97.98711038,  94.02541296, 446.90180969]), 'mean_score_time': array([15.49286358, 16.71451068, 24.16282201]), 'split1_test_score': array([0.9151039 , 0.92435378, 0.92549417]), 'split0_test_score': array([0.91473457, 0.9233498 , 0.92284303]), 'mean_train_score': array([0.99535395, 1.        , 1.        ]), 'split2_train_score': array([0.99524865, 1.        , 1.        ]), 'split1_train_score': array([0.99537506, 1.        , 1.        ]), 'std_fit_time': array([ 8.68384898, 55.33325929,  9.10461366]), 'rank_test_score': array([3, 2, 1], dtype=int32), 'param_clf__n_estimators': masked_array(data=[10, 100, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  2.3min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  3.1min remaining:  1.5min\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1207838ff1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtime_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mretrieval_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain = {}\n",
    "results_balanced = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain, results_balanced]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "    \n",
    "    params = {'clf__n_estimators': [10, 100, 1000]}\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=9)\n",
    "\n",
    "    t0 = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    print(grid.best_estimator_)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.94s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.15s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 477.30s to fit \n",
      "\n",
      "Balanced accuracy: 0.8802950749897955\n",
      "Geometric mean: 0.8772013286319785\n",
      "Confusion matrix:\n",
      "[[4483  216]\n",
      " [ 236  984]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.95      0.95      0.81      0.95      0.88      0.78      4699\n",
      "        Pov       0.82      0.81      0.95      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.84      0.92      0.88      0.78      5919\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'named_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-af3514c8bac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix:\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nClassification report:\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nOOB score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nn_estimators: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'named_features'"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOB score: 0.9254096975840513\n",
      "\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.00670862784332334, 'any_adult_TINP<20'),\n",
       " (0.0066194372159959405, '%_adult_TINP<20'),\n",
       " (0.006479640639032289, '%_anyage_WAG<45'),\n",
       " (0.006334087270109876, '%_anyage_any_WKHP'),\n",
       " (0.0062931342915874214, '%_anyage_TINP<15'),\n",
       " (0.005944444651839958, 'all_anyage_WAG_any'),\n",
       " (0.005501383040418589, 'all_anyage_WAG<60'),\n",
       " (0.005464648575639451, '%_anyage_WAG<20'),\n",
       " (0.005377005353263044, 'any_anyage_WAG<50'),\n",
       " (0.005214485567674988, 'any_anyage_any_WKHP'),\n",
       " (0.0051429150100985345, 'all_anyage_TINP<20'),\n",
       " (0.00510779175422798, '%_anyage_WAG<70'),\n",
       " (0.005029627256854295, 'any_anyage_TINP<25'),\n",
       " (0.005021266220117347, 'all_anyage_age'),\n",
       " (0.004970895146790292, 'any_anyage_SSP_any')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(pipeline.named_steps['clf'].feature_importances_, pipeline.named_steps['dummies'].transformed_columns_))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini data set with n_estimators = 10 and RandomForestClassifier - prep for LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5618\n",
      "Took: 7.72s to fit \n",
      "\n",
      "Balanced accuracy: 1.0\n",
      "Geometric mean: 1.0\n",
      "Confusion matrix:\n",
      "[[7 0]\n",
      " [0 3]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00         7\n",
      "          1       1.00      1.00      1.00      1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00        10\n",
      "\n",
      "\n",
      "OOB score: 0.8\n",
      "n_estimators: 10\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y_small = X_and_y.iloc[:50,:].copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y_small['NYCgov_Pov_Stat']\n",
    "y.replace({'Not Pov': 0, 'Pov': 1}, inplace=True)\n",
    "X = X_and_y_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=10, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3eefa342b2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtime_took\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    272\u001b[0m         ).ravel()\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0myss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# for classification, the model needs to provide a list of tuples - classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-3eefa342b2db>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtime_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Specify the prediction function for use with LIME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/dask_ml/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mSame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \"\"\"\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             raise ValueError(\n\u001b[1;32m    623\u001b[0m                 \u001b[0;34m\"Columns of 'X' do not match the training \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "# Specify the prediction function for use with LIME\n",
    "predict_fn = lambda x: pipeline.named_steps['clf'].predict_proba(pipeline.predict(x))\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns)#,\n",
    "                                                   #class_names=['Pov', 'Not Pov']),\n",
    "                                                   #categorical_features=categorical_features, \n",
    "                                                   #categorical_names=categorical_names)\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 7\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 5000 and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1370.52s to fit \n",
      "\n",
      "Balanced accuracy: 0.8801138365679478\n",
      "Geometric mean: 0.8768956359864453\n",
      "Confusion matrix:\n",
      "[[4489  210]\n",
      " [ 238  982]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        Pov       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.84      0.92      0.88      0.78      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9264656191924312\n",
      "n_estimators: 5000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=5000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and RandomForestClassifier using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 242.49s to fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced accuracy: 0.8617460464207591\n",
      "Geometric mean: 0.8568130733410114\n",
      "Confusion matrix:\n",
      "[[4482  217]\n",
      " [ 281  939]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.94      0.95      0.77      0.95      0.86      0.75      4699\n",
      "        Pov       0.81      0.77      0.95      0.79      0.86      0.72      1220\n",
      "\n",
      "avg / total       0.91      0.92      0.81      0.92      0.86      0.74      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9227487751309342\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "X_and_y = pd.read_csv('data/FeaturesCoded.csv', index_col=[0,1], header=0)\n",
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with grid search and BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   9 | elapsed:  5.0min remaining:  2.5min\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed: 26.9min finished\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.35s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 2310.83s to fit \n",
      "Pipeline(memory='/mnt/ssd/tmp/tmpogjb52hr',\n",
      "     steps=[('dummies', DummyEncoder(columns=None, drop_first=True)), ('scaler', Normalizer(copy=True, norm='l2')), ('clf', BalancedRandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                criterion='gini', max_depth=None, max_features='auto',\n",
      "                max_leaf_nodes=None, min_imp...tate=42, replacement=False,\n",
      "                sampling_strategy='auto', verbose=0, warm_start=False))])\n",
      "0.8971109984794728\n",
      "{'clf__n_estimators': 1000}\n",
      "{'std_score_time': array([ 0.43724339,  6.47117318, 10.0884839 ]), 'mean_test_score': array([0.89453455, 0.89706876, 0.897111  ]), 'split2_test_score': array([0.89798505, 0.89925231, 0.89887213]), 'std_train_score': array([0.00174429, 0.00211428, 0.00166577]), 'params': [{'clf__n_estimators': 10}, {'clf__n_estimators': 100}, {'clf__n_estimators': 1000}], 'split0_train_score': array([0.92023063, 0.92130774, 0.92225813]), 'std_test_score': array([0.00300425, 0.00211323, 0.00223569]), 'mean_fit_time': array([  79.07977804,  111.69476787, 1272.5219895 ]), 'mean_score_time': array([15.21685592, 21.84757996, 24.02181101]), 'split1_test_score': array([0.89495692, 0.89774455, 0.89850482]), 'split0_test_score': array([0.89066261, 0.89421006, 0.89395667]), 'mean_train_score': array([0.9226431 , 0.92405801, 0.92382573]), 'split2_train_score': array([0.92429522, 0.92644916, 0.9261324 ]), 'split1_train_score': array([0.92340345, 0.92441713, 0.92308667]), 'std_fit_time': array([ 9.8503707 ,  5.03462801, 16.42877733]), 'rank_test_score': array([3, 2, 1], dtype=int32), 'param_clf__n_estimators': masked_array(data=[10, 100, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              #('sampler', sampler), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', balanced_clf)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "params = {'clf__n_estimators': [10, 100, 1000]}\n",
    "\n",
    "#grid = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=9)\n",
    "grid = GridSearchCV(pipeline, params, n_jobs=3, cv=3, verbose=9)\n",
    "\n",
    "t0 = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and BalancedRandomForestClassifier using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.13s to fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced accuracy: 0.9080515910256455\n",
      "Geometric mean: 0.9076684804536956\n",
      "Confusion matrix:\n",
      "[[4143  556]\n",
      " [  80 1140]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.98      0.88      0.93      0.93      0.91      0.82      4699\n",
      "        Pov       0.67      0.93      0.88      0.78      0.91      0.83      1220\n",
      "\n",
      "avg / total       0.92      0.89      0.92      0.90      0.91      0.82      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9238046967393141\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', oob_score=True,\n",
    "                                            random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and BalancedRandomForestClassifier with sampling_strategy changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.90s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.12s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.53s to fit \n",
      "\n",
      "Balanced accuracy: 0.9113460659575284\n",
      "Geometric mean: 0.9108903240199582\n",
      "Confusion matrix:\n",
      "[[4147  552]\n",
      " [  73 1147]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.98      0.88      0.94      0.93      0.91      0.82      4699\n",
      "        Pov       0.68      0.94      0.88      0.79      0.91      0.83      1220\n",
      "\n",
      "avg / total       0.92      0.89      0.93      0.90      0.91      0.83      5919\n",
      "\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, sampling_strategy=1.0, replacement=True, n_jobs=-1, \n",
    "                                            max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "#print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "SERIALNO  Povunit_ID\n",
      "1521345   1             2\n",
      "1521371   1             1\n",
      "1521389   1             2\n",
      "1521399   1             1\n",
      "1521415   1             2\n",
      "Name: NYCgov_Pov_Stat, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.84s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.08s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The {2} target class is/are not present in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ce3f4b637a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtime_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m                         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                         verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 437\u001b[0;31m                     for i, (s, t) in enumerate(zip(samplers, trees)))\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0msamplers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamplers_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_local_parallel_build_trees\u001b[0;34m(sampler, tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m     37\u001b[0m                                 class_weight=None):\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# resample before to fit the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_indices_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0;32m---> 83\u001b[0;31m             self.sampling_strategy, y, self._sampling_type)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         return OrderedDict(sorted(\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0m_sampling_strategy_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             .items()))\n\u001b[1;32m    447\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36m_sampling_strategy_dict\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_diff_sampling_strategy_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError(\"The {} target class is/are not present in the\"\n\u001b[0;32m--> 233\u001b[0;31m                          \" data.\".format(set_diff_sampling_strategy_target))\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;31m# check that there is no negative number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The {2} target class is/are not present in the data."
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "#X_and_y['NYCgov_Pov_Stat'] = X_and_y['NYCgov_Pov_Stat'].replace({'Pov': 1, 'Not Pov': 2})\n",
    "#X_and_y['NYCgov_Pov_Stat'] = X_and_y['NYCgov_Pov_Stat'].replace({1: 'Pov', 2:'Not Pov'})\n",
    "#X_and_y['NYCgov_Pov_Stat'] = pd.Categorical(X_and_y['NYCgov_Pov_Stat'], ordered=False, categories=['Pov', 'Not Pov'])\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "print(y.tail())\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "\n",
    "sampling_strat = {2: 5919, 1: 17757}\n",
    "\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, sampling_strategy=sampling_strat, replacement=True, \n",
    "                                            n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "#print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = list(zip(pipeline.named_steps['clf'].feature_importances_, pipeline.named_steps['dummies'].transformed_columns_))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set but no grid search, only 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.33s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 70.75s to fit \n",
      "{'confusion_matrix': array([[4503,  196],\n",
      "       [ 295,  925]]), 'geometric_mean_score': 0.8523916799769762, 'balanced_accuracy_score': 0.8582428594852759, 'feature_importances_': array([1.08379062e-04, 2.28520176e-04, 6.73097969e-05, ...,\n",
      "       0.00000000e+00, 1.17332300e-04, 0.00000000e+00]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.94      0.96      0.76      0.95      0.85      0.74      4699\\n        Pov       0.83      0.76      0.96      0.79      0.85      0.71      1220\\n\\navg / total       0.92      0.92      0.80      0.92      0.85      0.74      5919\\n', 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10477)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.33s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 54.02s to fit \n",
      "{'confusion_matrix': array([[4175,  524],\n",
      "       [  93, 1127]]), 'geometric_mean_score': 0.905956948071855, 'balanced_accuracy_score': 0.906128701956119, 'feature_importances_': array([0.00021626, 0.00045376, 0.        , ..., 0.        , 0.        ,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.98      0.89      0.92      0.93      0.91      0.82      4699\\n        Pov       0.68      0.92      0.89      0.79      0.91      0.82      1220\\n\\navg / total       0.92      0.90      0.92      0.90      0.91      0.82      5919\\n', 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10477)}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_small = X.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain = {}\n",
    "results_balanced = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain, results_balanced]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "    results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "    results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "    results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "    results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "    results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "    print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.053261627357831756, 'all_adult_any_WKHP'),\n",
       " (0.053249850993936886, 'any_anyage_TINP_any'),\n",
       " (0.052582859245591876, 'all_anyage_ETH_any'),\n",
       " (0.052276741730780694, 'all_anyage_SSP_any'),\n",
       " (0.05225465701237826, 'any_adult_WAG<50'),\n",
       " (0.05157735756906421, '%_anyage_TINP<25'),\n",
       " (0.05144051199957207, 'any_anyage_TINP<70'),\n",
       " (0.051439137088152176, 'all_anyage_any_WKW'),\n",
       " (0.05046858251637465, 'all_adult_TINP<80'),\n",
       " (0.03912715924380138, 'count_anyage_WAG<10'),\n",
       " (0.011321463620562803, 'all_adult_TINP<25'),\n",
       " (0.007184924649845273, 'MRNT'),\n",
       " (0.006452386132367269, '%_anyage_ETH_any'),\n",
       " (0.0050534530833320915, '%_anyage_ENG_any'),\n",
       " (0.004529686603494478, 'any_anyage_PA0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_plain['feature_importances_'], results_plain['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.06510250878867069, 'any_adult_TINP<20'),\n",
       " (0.06396830168664602, 'all_adult_SSIP_any'),\n",
       " (0.063710355411885, 'all_anyage_WAG<35'),\n",
       " (0.06274658841068068, 'all_anyage_WAG<60'),\n",
       " (0.06236858347937092, 'all_anyage_TINP_any'),\n",
       " (0.062242303320543556, 'any_adult_any_SEX'),\n",
       " (0.062148568051467415, 'all_anyage_WAG<30'),\n",
       " (0.06142120639451819, '%_anyage_ENG_any'),\n",
       " (0.06139662533699729, 'all_adult_TINP<80'),\n",
       " (0.060671661137871404, 'all_anyage_WAG<45'),\n",
       " (0.00716956500302484, 'any_anyage_TINP<15'),\n",
       " (0.006895951467055411, 'count_18-64_WAG<30'),\n",
       " (0.006417046063640315, '%_anyage_TINP<25'),\n",
       " (0.005957844465198908, 'count_anyage_WAG<60'),\n",
       " (0.0058310843547457, 'all_kid_TINP<40')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_balanced['feature_importances_'], results_balanced['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Pov_Gap instead of NYCGov_Pov_Stat\n",
    "We've been looking at poverty status as a classification problem (yes or no), but we can also view it as a regression \n",
    "problem.  Poverty status is essentially whether (Total Poverty-Unit Income) is less than (Poverty-Unit Threshold); but\n",
    "rather than viewing that as a yes-no, the data set has a feature 'NYCgov_Pov_Gap' which is, for households in poverty, \n",
    "the difference between the two.\n",
    "\n",
    "So, let's run the models against 'NYCgov_Pov_Gap' to see where that gets us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "X_pg_ef = pd.read_csv('data/EngineeredFeatures.csv', index_col=[0,1], header=0) # Reuse existing; no change here\n",
    "X_pg = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_PovGap')\n",
    "\n",
    "X_pg = X_pg.join(X_pg_ef)\n",
    "\n",
    "X_pg.to_csv('data/PGFeatures.csv')\n",
    "\n",
    "X_pg, dummy_these = code_categoricals(X_pg, all_2016)\n",
    "X_pg.to_csv('data/PGFeaturesCoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_2</th>\n",
       "      <th>AGEP_3</th>\n",
       "      <th>AGEP_4</th>\n",
       "      <th>AGEP_5</th>\n",
       "      <th>AGEP_6</th>\n",
       "      <th>AGEP_7</th>\n",
       "      <th>AGEP_8</th>\n",
       "      <th>AGEP_9</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_anyage_TINP&lt;80</th>\n",
       "      <th>%_anyage_TINP&lt;80</th>\n",
       "      <th>any_anyage_TINP_any</th>\n",
       "      <th>all_anyage_TINP_any</th>\n",
       "      <th>min_anyage_TINP_any</th>\n",
       "      <th>max_anyage_TINP_any</th>\n",
       "      <th>count_anyage_TINP_any</th>\n",
       "      <th>sum_anyage_TINP_any</th>\n",
       "      <th>mean_anyage_TINP_any</th>\n",
       "      <th>%_anyage_TINP_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  5549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_2  AGEP_3  AGEP_4  AGEP_5  AGEP_6  AGEP_7  \\\n",
       "SERIALNO Povunit_ID                                                           \n",
       "39       1               51       0       0       0       0       0       0   \n",
       "55       1               60      52      26      20      20       0       0   \n",
       "69       1               39       0       0       0       0       0       0   \n",
       "210      1               26       0       0       0       0       0       0   \n",
       "261      1               36      36       6       5       1       0       0   \n",
       "\n",
       "                     AGEP_8  AGEP_9  AGEP_10        ...          \\\n",
       "SERIALNO Povunit_ID                                 ...           \n",
       "39       1                0       0        0        ...           \n",
       "55       1                0       0        0        ...           \n",
       "69       1                0       0        0        ...           \n",
       "210      1                0       0        0        ...           \n",
       "261      1                0       0        0        ...           \n",
       "\n",
       "                     mean_anyage_TINP<80  %_anyage_TINP<80  \\\n",
       "SERIALNO Povunit_ID                                          \n",
       "39       1                          51.0               1.0   \n",
       "55       1                          29.5               0.8   \n",
       "69       1                           0.0               0.0   \n",
       "210      1                           0.0               0.0   \n",
       "261      1                          12.0               0.8   \n",
       "\n",
       "                     any_anyage_TINP_any  all_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          True                 True   \n",
       "55       1                          True                 True   \n",
       "69       1                          True                 True   \n",
       "210      1                          True                 True   \n",
       "261      1                          True                 True   \n",
       "\n",
       "                     min_anyage_TINP_any  max_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          51.0                 51.0   \n",
       "55       1                          20.0                 60.0   \n",
       "69       1                          39.0                 39.0   \n",
       "210      1                          26.0                 26.0   \n",
       "261      1                           1.0                 36.0   \n",
       "\n",
       "                     count_anyage_TINP_any  sum_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                               \n",
       "39       1                               1                 51.0   \n",
       "55       1                               5                178.0   \n",
       "69       1                               1                 39.0   \n",
       "210      1                               1                 26.0   \n",
       "261      1                               5                 84.0   \n",
       "\n",
       "                     mean_anyage_TINP_any  %_anyage_TINP_any  \n",
       "SERIALNO Povunit_ID                                           \n",
       "39       1                           51.0                1.0  \n",
       "55       1                           35.6                1.0  \n",
       "69       1                           39.0                1.0  \n",
       "210      1                           26.0                1.0  \n",
       "261      1                           16.8                1.0  \n",
       "\n",
       "[5 rows x 5549 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pg = pd.read_csv('data/PGFeaturesCoded.csv', index_col=[0,1], header=0) # Reuse existing; no change here\n",
    "X_pg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.04s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 435.60s to fit \n",
      "{'test score': 0.7637718358117817, 'feature_importances_': array([2.65924486e-04, 3.53370510e-04, 2.74746009e-04, ...,\n",
      "       3.13643695e-05, 2.95436761e-06, 1.88089018e-05]), 'transformed_columns_': Index(['AGEP_1', 'AGEP_2', 'AGEP_3', 'AGEP_4', 'AGEP_5', 'AGEP_6', 'AGEP_7',\n",
      "       'AGEP_8', 'AGEP_9', 'AGEP_10',\n",
      "       ...\n",
      "       'mean_anyage_TINP<80', '%_anyage_TINP<80', 'any_anyage_TINP_any',\n",
      "       'all_anyage_TINP_any', 'min_anyage_TINP_any', 'max_anyage_TINP_any',\n",
      "       'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any',\n",
      "       '%_anyage_TINP_any'],\n",
      "      dtype='object', length=5548), 'training score': 0.9532494932642507}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg.iloc[:50, :].copy()\n",
    "X_small = X_pg.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_PovGap']\n",
    "X = X_small.drop('NYCgov_PovGap', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5412542900219832, 'count_adult_SSIP0'),\n",
       " (0.044764803688412166, 'MRNT'),\n",
       " (0.03575995019220828, '%_anyage_TINP<15'),\n",
       " (0.026273516905920235, 'count_adult_PA0'),\n",
       " (0.024040902798597847, 'HousingStatus'),\n",
       " (0.022162946243779853, 'count_adult_TINP<15'),\n",
       " (0.011547900963612707, 'sum_anyage_TINP0'),\n",
       " (0.011313230636374887, 'any_anyage_TINP<15'),\n",
       " (0.004726736757495178, 'count_adult_TINP0'),\n",
       " (0.004470881799395084, 'count_anyage_SSIP0'),\n",
       " (0.003804604176778878, 'TEN'),\n",
       " (0.0036939593046493293, 'count_kid_not_DIS'),\n",
       " (0.003354132355255112, 'Boro_2'),\n",
       " (0.0029390726833299747, 'max_anyage_TINP0'),\n",
       " (0.002557372194562785, 'RNTP_adj')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_2</th>\n",
       "      <th>AGEP_3</th>\n",
       "      <th>AGEP_4</th>\n",
       "      <th>AGEP_5</th>\n",
       "      <th>AGEP_6</th>\n",
       "      <th>AGEP_7</th>\n",
       "      <th>AGEP_8</th>\n",
       "      <th>AGEP_9</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_anyage_TINP&lt;80</th>\n",
       "      <th>%_anyage_TINP&lt;80</th>\n",
       "      <th>any_anyage_TINP_any</th>\n",
       "      <th>all_anyage_TINP_any</th>\n",
       "      <th>min_anyage_TINP_any</th>\n",
       "      <th>max_anyage_TINP_any</th>\n",
       "      <th>count_anyage_TINP_any</th>\n",
       "      <th>sum_anyage_TINP_any</th>\n",
       "      <th>mean_anyage_TINP_any</th>\n",
       "      <th>%_anyage_TINP_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  5549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_2  AGEP_3  AGEP_4  AGEP_5  AGEP_6  AGEP_7  \\\n",
       "SERIALNO Povunit_ID                                                           \n",
       "39       1               51       0       0       0       0       0       0   \n",
       "55       1               60      52      26      20      20       0       0   \n",
       "69       1               39       0       0       0       0       0       0   \n",
       "210      1               26       0       0       0       0       0       0   \n",
       "261      1               36      36       6       5       1       0       0   \n",
       "\n",
       "                     AGEP_8  AGEP_9  AGEP_10        ...          \\\n",
       "SERIALNO Povunit_ID                                 ...           \n",
       "39       1                0       0        0        ...           \n",
       "55       1                0       0        0        ...           \n",
       "69       1                0       0        0        ...           \n",
       "210      1                0       0        0        ...           \n",
       "261      1                0       0        0        ...           \n",
       "\n",
       "                     mean_anyage_TINP<80  %_anyage_TINP<80  \\\n",
       "SERIALNO Povunit_ID                                          \n",
       "39       1                          51.0               1.0   \n",
       "55       1                          29.5               0.8   \n",
       "69       1                           0.0               0.0   \n",
       "210      1                           0.0               0.0   \n",
       "261      1                          12.0               0.8   \n",
       "\n",
       "                     any_anyage_TINP_any  all_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          True                 True   \n",
       "55       1                          True                 True   \n",
       "69       1                          True                 True   \n",
       "210      1                          True                 True   \n",
       "261      1                          True                 True   \n",
       "\n",
       "                     min_anyage_TINP_any  max_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          51.0                 51.0   \n",
       "55       1                          20.0                 60.0   \n",
       "69       1                          39.0                 39.0   \n",
       "210      1                          26.0                 26.0   \n",
       "261      1                           1.0                 36.0   \n",
       "\n",
       "                     count_anyage_TINP_any  sum_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                               \n",
       "39       1                               1                 51.0   \n",
       "55       1                               5                178.0   \n",
       "69       1                               1                 39.0   \n",
       "210      1                               1                 26.0   \n",
       "261      1                               5                 84.0   \n",
       "\n",
       "                     mean_anyage_TINP_any  %_anyage_TINP_any  \n",
       "SERIALNO Povunit_ID                                           \n",
       "39       1                           51.0                1.0  \n",
       "55       1                           35.6                1.0  \n",
       "69       1                           39.0                1.0  \n",
       "210      1                           26.0                1.0  \n",
       "261      1                           16.8                1.0  \n",
       "\n",
       "[5 rows x 5549 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Pov_Gap instead of NYCGov_Pov_Stat, with no Financials\n",
    "This is running the models against 'NYCgov_Pov_Gap', without financials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv with no financials\n",
    "X_pg_eng_no_fin = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_pg_no_fin = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_PovGap')\n",
    "\n",
    "X_pg_no_fin.join(X_pg_eng_no_fin)\n",
    "\n",
    "X_pg_no_fin.to_csv('data/PGFeaturesNoFin.csv')\n",
    "\n",
    "X_pg_no_fin, dummy_these = code_categoricals(X_pg_no_fin, all_2016)\n",
    "X_pg_no_fin.to_csv('data/PGFeaturesCodedNoFin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 2.55s to fit \n",
      "{'training score': 0.8864178444566567, 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5285), 'feature_importances_': array([0., 0., 0., ..., 0., 0., 0.]), 'test score': 0.20693738704979336}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "X_small = X_pg_no_fin.iloc[:50, :].copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_PovGap']\n",
    "X = X_small.drop('NYCgov_PovGap', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Income instead of NYCGov_Pov_Stat or NYCgov_Pov_Gap\n",
    "This is running the models against 'NYCgov_Income' - since the poverty calculation comes down to income vs threshold,\n",
    "and the initial poverty classifier shows the feature importance is primarily income-related, let's see what we can do to\n",
    "predict household income and find the relative importance of variables there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv \n",
    "X_pg_eng = pd.read_csv('data/EngineeredFeatures.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_pg_inc = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_Income')\n",
    "\n",
    "X_pg_inc = X_pg_inc.join(X_pg_eng)\n",
    "\n",
    "X_pg_inc.to_csv('data/PGFeaturesInc.csv')\n",
    "\n",
    "X_pg_inc, dummy_these = code_categoricals(X_pg_inc, all_2016)\n",
    "X_pg_inc.to_csv('data/PGFeaturesCodedInc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.18s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.35s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 296.30s to fit \n",
      "{'test score': 0.9729990614809677, 'feature_importances_': array([1.76265322e-02, 1.33508395e-03, 1.86835875e-04, ...,\n",
      "       7.67294103e-05, 9.75315989e-03, 0.00000000e+00]), 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10405), 'training score': 0.9904116648702307}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg_inc.iloc[:50, :].copy()\n",
    "X_small = X_pg_inc.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Income']\n",
    "X = X_small.drop('NYCgov_Income', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10587798972092581, 'any_anyage_SSP0'),\n",
       " (0.09244462976532644, 'min_adult_ETH_any'),\n",
       " (0.06807623458215825, 'all_adult_TINP<60'),\n",
       " (0.046101140457224174, 'mean_adult_SSIP_any'),\n",
       " (0.0459944407453176, 'min_adult_any_SEX'),\n",
       " (0.04577931790616139, 'min_adult_any_MSP'),\n",
       " (0.045658913558330134, 'mean_adult_INT_any'),\n",
       " (0.0455650902679534, 'mean_adult_any_MSP'),\n",
       " (0.04538766138869088, 'min_adult_SSP_any'),\n",
       " (0.04423539636490374, 'min_adult_PA_any'),\n",
       " (0.044052367770687724, 'min_adult_TINP_any'),\n",
       " (0.040786907341829416, 'all_anyage_TINP<50'),\n",
       " (0.029136605204614197, '%_adult_TINP<50'),\n",
       " (0.01762653216880664, 'WAGP_adj_1'),\n",
       " (0.016079479946236118, 'all_anyage_TINP<60')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Income instead of NYCGov_Pov_Stat or NYCgov_Pov_Gap - No Financials\n",
    "With the financials, we had everything we needed to actually calculate the NYCgov_Income.  So let's see how predictive\n",
    "we can get without the financials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv \n",
    "X_eng_inc_no_fin = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_inc_no_fin = pers_and_pu_features(all_2016, include_financials=False, target_column='NYCgov_Income')\n",
    "\n",
    "X_inc_no_fin = X_inc_no_fin.join(X_eng_inc_no_fin)\n",
    "\n",
    "#X_pg_inc.to_csv('data/PGFeaturesInc.csv')\n",
    "\n",
    "X_inc_no_fin, dummy_these = code_categoricals(X_inc_no_fin, all_2016)\n",
    "#X_pg_inc.to_csv('data/PGFeaturesCodedInc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 624.82s to fit \n",
      "{'training score': 0.9266131362072498, 'feature_importances_': array([0.00450581, 0.00378747, 0.00159843, ..., 0.00644462, 0.17289086,\n",
      "       0.        ]), 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'count_18-64_age', 'sum_18-64_age',\n",
      "       'mean_18-64_age', '%_18-64_age', 'any_kid_age', 'all_kid_age',\n",
      "       'min_kid_age',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=7685), 'test score': 0.5113921081129593}\n"
     ]
    }
   ],
   "source": [
    "print(len(X_inc_no_fin.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg_inc.iloc[:50, :].copy()\n",
    "X_small = X_inc_no_fin.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Income']\n",
    "X = X_small.drop('NYCgov_Income', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=100, max_features='auto', oob_score=True, random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.17647828610194521, 'TotalWorkHrs_PU_4'),\n",
       " (0.05120298914905345, 'TEN_3'),\n",
       " (0.03737420027016401, 'all_adult_college'),\n",
       " (0.02621767443123551, 'sum_adult_college'),\n",
       " (0.023151071578155193, 'MSP_2_1.0'),\n",
       " (0.018641885619837577, 'sum_anyage_college'),\n",
       " (0.018538562622136528, 'Boro_2_3'),\n",
       " (0.012198687139389928, 'Boro_1_3'),\n",
       " (0.010936901048609376, 'any_18-64_>40WKW'),\n",
       " (0.008332179551431998, 'sum_anyage_sep/divorced'),\n",
       " (0.007195776195791315, 'Boro_3_3'),\n",
       " (0.005849933739184079, 'JWTR_1_7.0'),\n",
       " (0.005405100453006394, 'SCHL_1_23.0'),\n",
       " (0.0053595862132493005, 'AGEP_11_6'),\n",
       " (0.0049020987620536785, 'any_adult_>40WKW')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - No Financials\n",
    "This will be as above, but pulling out the financial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "#X_no_fin_new_features = engineer_features(all_2016, include_financials=False)\n",
    "#X_no_fin_new_features.to_csv('data/EngineeredFeaturesNoFin.csv')\n",
    "#X_no_fin_new_features = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "#X_no_fin = pers_and_pu_features(all_2016, include_financials=False, target_column='NYCgov_Pov_Stat')\n",
    "\n",
    "#X_no_fin = X_no_fin.join(X_no_fin_new_features)\n",
    "\n",
    "#X_no_fin.to_csv('data/FeaturesNoFin.csv')\n",
    "#X_no_fin = pd.read_csv('data/FeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "#X_no_fin, dummy_these = code_categoricals(X_no_fin, all_2016)\n",
    "#X_no_fin.to_csv('data/FeaturesNoFinCoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_fin = pd.read_csv('data/FeaturesNoFinCoded.csv', index_col=[0,1], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 16.60s to fit \n",
      "{'balanced_accuracy_score': 0.6087474139946064, 'confusion_matrix': array([[4527,  172],\n",
      "       [ 910,  310]]), 'geometric_mean_score': 0.49477011127488796, 'feature_importances_': array([0.00374215, 0.01136674, 0.01506289, ..., 0.00948223, 0.00527128,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.83      0.96      0.25      0.89      0.49      0.26      4699\\n        Pov       0.64      0.25      0.96      0.36      0.49      0.23      1220\\n\\navg / total       0.79      0.82      0.40      0.78      0.49      0.26      5919\\n', 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'AGEP_1_1', 'AGEP_1_2', 'AGEP_1_3',\n",
      "       'AGEP_1_4', 'AGEP_1_5', 'AGEP_1_6', 'AGEP_1_7',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5105)}\n",
      "Took: 5.65s to fit \n",
      "{'balanced_accuracy_score': 0.7340716022592878, 'confusion_matrix': array([[3363, 1336],\n",
      "       [ 302,  918]]), 'geometric_mean_score': 0.7338412772834307, 'feature_importances_': array([0.00771805, 0.01047624, 0.0078005 , ..., 0.01705998, 0.03820723,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.92      0.72      0.75      0.80      0.73      0.54      4699\\n        Pov       0.41      0.75      0.72      0.53      0.73      0.54      1220\\n\\navg / total       0.81      0.72      0.74      0.75      0.73      0.54      5919\\n', 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'AGEP_1_1', 'AGEP_1_2', 'AGEP_1_3',\n",
      "       'AGEP_1_4', 'AGEP_1_5', 'AGEP_1_6', 'AGEP_1_7',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5105)}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_no_fin.iloc[:50, :].copy()\n",
    "X_small = X_no_fin.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain_no_fin = {}\n",
    "results_balanced_no_fin = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "    results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "    results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "    results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "    results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "    results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "    print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0333263835863417, 'WKW_1_6.0'),\n",
       " (0.019089687064374118, 'TEN_3'),\n",
       " (0.018658342125886018, 'TotalWorkHrs_PU_1'),\n",
       " (0.015062894956498082, 'MRNT'),\n",
       " (0.014952220424570705, 'TotalWorkHrs_PU_2'),\n",
       " (0.014058264808781803, 'DIS_1_2.0'),\n",
       " (0.011368339383472542, 'WKW_2_6.0'),\n",
       " (0.01136674338124465, 'RNTP_adj'),\n",
       " (0.01131130342588219, 'ENG_1_5.0'),\n",
       " (0.010803276411116742, 'CIT_1_1'),\n",
       " (0.01055147678313992, 'HousingStatus_6'),\n",
       " (0.010142020554241103, 'Ethnicity_1_1'),\n",
       " (0.009638502918302148, 'SEX_1_2'),\n",
       " (0.009620946071791698, 'JWTR_1_4.0'),\n",
       " (0.009482233140690393, 'TotalWorkHrs_PU_3')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_plain_no_fin['feature_importances_'], results_plain_no_fin['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03820723190748078, 'TotalWorkHrs_PU_4'),\n",
       " (0.030424103555162847, 'WKW_2_6.0'),\n",
       " (0.028615346415553754, 'WKHP_1_40'),\n",
       " (0.027021511173145822, 'WKW_1_6.0'),\n",
       " (0.022908203636657767, 'TotalWorkHrs_PU_2'),\n",
       " (0.021245426174740102, 'JWTR_1_4.0'),\n",
       " (0.018196157138579097, 'Ethnicity_2_1'),\n",
       " (0.017950247133279758, 'Ethnicity_1_1'),\n",
       " (0.01705998306092355, 'TotalWorkHrs_PU_3'),\n",
       " (0.016393462842024538, 'SCHL_1_22.0'),\n",
       " (0.015787585540996484, 'WKHP_2_40'),\n",
       " (0.014786053558510643, 'TEN_3'),\n",
       " (0.014167886506504471, 'SCHL_1_21.0'),\n",
       " (0.013906358546812292, 'ENG_1_5.0'),\n",
       " (0.01309187152147428, 'JWTR_2_4.0')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_balanced_no_fin['feature_importances_'], results_balanced_no_fin['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Financials, with SMOTEENN sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved it\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 29595 entries, (39, 1) to (1521415, 1)\n",
      "Columns: 5621 entries, AGEP_1 to %_anyage_TINP_any\n",
      "dtypes: bool(1297), float64(4178), int64(146)\n",
      "memory usage: 1013.2 MB\n"
     ]
    }
   ],
   "source": [
    "#tester_ef = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "#tester_ef.head()\n",
    "#len(tester.columns) #249\n",
    "#len(tester_ef.columns) #2580\n",
    "#tester_joined = tester.join(tester_ef)\n",
    "#tester_joined.head() #2829 columns\n",
    "tester = pd.read_csv('data/Features.csv', index_col=[0,1], header=0)\n",
    "tester, dummies = code_categoricals(tester, all_2016)\n",
    "tester.to_csv('data/TestingCoding.csv')\n",
    "print('saved it')\n",
    "tester = pd.read_csv('data/TestingCoding.csv', index_col=[0,1], header=0)\n",
    "tester.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:200: UserWarning: Persisting input arguments took 4.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  cloned_transformer, Xt, yt, **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 903.82s to fit \n",
      "{'balanced_accuracy_score': 0.7483153897411029, 'confusion_matrix': array([[3701,  998],\n",
      "       [ 355,  865]]), 'geometric_mean_score': 0.7472827519843549, 'feature_importances_': array([0.00101219, 0.001638  , 0.00023066, ..., 0.00143429, 0.00032838,\n",
      "       0.00031573]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.91      0.79      0.71      0.85      0.75      0.56      4699\\n        Pov       0.46      0.71      0.79      0.56      0.75      0.55      1220\\n\\navg / total       0.82      0.77      0.73      0.79      0.75      0.56      5919\\n', 'transformed_columns_': Index(['AGEP_1', 'AGEP_2', 'AGEP_3', 'AGEP_4', 'AGEP_5', 'AGEP_6', 'AGEP_7',\n",
      "       'AGEP_8', 'AGEP_9', 'AGEP_10',\n",
      "       ...\n",
      "       'mean_anyage_ETH_other', '%_anyage_ETH_other', 'any_anyage_ETH_any',\n",
      "       'all_anyage_ETH_any', 'min_anyage_ETH_any', 'max_anyage_ETH_any',\n",
      "       'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any',\n",
      "       '%_anyage_ETH_any'],\n",
      "      dtype='object', length=2828)}\n"
     ]
    }
   ],
   "source": [
    "X_and_y = pd.read_csv('data/FeaturesNoFinCoded.csv', index_col=[0,1], header=0)\n",
    "print(len(X_and_y.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "sampler = SMOTEENN(random_state=42)\n",
    "scaler = Normalizer()\n",
    "clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=1000, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('sampler', sampler), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05414204498575277, 'max_adult_40_plus_work_hrs'),\n",
       " (0.0299772802107448, '%_18-64_<30_work_hrs'),\n",
       " (0.029120004226272207, '%_anyage_40_plus_work_hrs'),\n",
       " (0.02813508930255575, 'max_anyage_40_plus_work_hrs'),\n",
       " (0.02807103273303036, 'any_anyage_>40WKW'),\n",
       " (0.027730196434804382, 'min_anyage_40_plus_work_hrs'),\n",
       " (0.026378429827302253, 'min_adult_>40WKW'),\n",
       " (0.022687981522365352, 'mean_18-64_50-52WKW'),\n",
       " (0.022232016123656696, 'all_18-64_<15_work_hrs'),\n",
       " (0.014389072985389828, 'any_adult_>40WKW'),\n",
       " (0.01381564852426873, 'count_adult_50-52WKW'),\n",
       " (0.01178808204087493, 'all_anyage_<40_work_hrs'),\n",
       " (0.011526602791514214, 'max_18-64_no_diploma'),\n",
       " (0.008817078681850138, 'sum_anyage_>40WKW'),\n",
       " (0.008134514402889726, 'sum_anyage_no_diploma')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_dict['feature_importances_'], results_dict['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 225.46s to fit \n",
      "\n",
      "Accuracy: 0.9241425916539956\n",
      "Balanced accuracy: 0.8790971396076599\n",
      "Geometric mean: 0.875750180666023\n",
      "Confusion matrix:\n",
      "[[4491  208]\n",
      " [ 241  979]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        1.0       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.83      0.92      0.88      0.77      5919\n",
      "\n",
      "OOB score: 0.9260010136847441\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "tester = X_and_y.copy()\n",
    "tester = tester.loc[:, tester.astype('float64').std() > .3] #4203 columns\n",
    "\n",
    "print(len(tester.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = tester['NYCgov_Pov_Stat']\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = tester.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "rf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)], memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(rf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('OOB score: ' + str(rf_pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(rf_pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.67s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 312.12s to fit \n",
      "\n",
      "Accuracy: 0.9241425916539956\n",
      "Balanced accuracy: 0.8794005700550169\n",
      "Geometric mean: 0.8760997784301491\n",
      "Confusion matrix:\n",
      "[[4490  209]\n",
      " [ 240  980]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        1.0       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.83      0.92      0.88      0.77      5919\n",
      "\n",
      "OOB score: 0.9281128569015036\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "rf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)], memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(rf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('OOB score: ' + str(rf_pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(rf_pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.008738746575772808, 'any_anyage_any_SEX'),\n",
       " (0.007793420790104585, 'all_anyage_TINP<20'),\n",
       " (0.007184138721496747, 'any_adult_TINP<20'),\n",
       " (0.006653662791125626, 'all_anyage_WAG<60'),\n",
       " (0.006535150897617367, 'any_anyage_ETH_any'),\n",
       " (0.006433470037326151, 'all_anyage_work_trans'),\n",
       " (0.006420108118935234, 'all_adult_TINP<20'),\n",
       " (0.00603712066356437, '%_anyage_SEMP_any'),\n",
       " (0.005989984744940004, 'any_anyage_TINP<70'),\n",
       " (0.0056792764598369684, '%_anyage_TINP<25'),\n",
       " (0.0054738810580131836, 'all_anyage_TINP<35'),\n",
       " (0.005471542245196101, '%_anyage_TINP<45'),\n",
       " (0.005455904001405748, 'any_anyage_TINP<40'),\n",
       " (0.0053834925472248125, '%_anyage_RETP_any'),\n",
       " (0.005367176152264387, 'any_anyage_any_DIS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_imps = list(zip(rf_pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "sorted(rf_imps, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
