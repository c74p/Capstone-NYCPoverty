{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "Old items that are mostly of historical interest. As with the main Models.ipynb, after importing we'll make some quick modifications to the data (so the items below still run if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and setup\n",
    "# See below for model-specific imports\n",
    "from __future__ import print_function\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import seaborn as sns\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "# Model-specific imports\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, RUSBoostClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, \\\n",
    "    RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit, LogitResults\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Temporarily turn off warnings if they get to be too much\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_years.csv', index_col=0)\n",
    "\n",
    "# Group the columns into 1) raw input variables, 2) id variables of various things, 3) American Community Survey (census)\n",
    "# variables, 4) NYC government-calculated variables, and 5) output variables.\n",
    "#\n",
    "# The ACS and NYC variables are generally calculated from the raw input variables - my initial expectation is that\n",
    "# the raw input variables can be thought of as independent variables, and that the ACS and NYC variables are not\n",
    "# independent even though they are not output variables.\n",
    "\n",
    "raw_inp_vars = ['AGEP', 'Boro', 'CIT', 'DIS', 'ENG', 'ESR', 'Ethnicity', 'HHT', 'HIUnit_Head', 'HousingStatus', 'JWTR', 'LANX', 'MAR', 'MSP','NP', 'Off_Threshold', 'PreTaxIncome_PU', 'REL', 'SCH', 'SCHG', 'SCHL', 'SEX', 'TEN', 'WKHP', 'WKW', 'Year']\n",
    "id_vars = ['HIUnit_ID', 'Povunit_ID', 'PWGTP', 'SERIALNO', 'SNAPUnit_ID', 'SPORDER', 'TaxUnit_ID', 'WGTP']\n",
    "acs_vars = ['AgeCateg', 'INTP_adj', 'OI_adj', 'MRGP_adj', 'PA_adj', 'RETP_adj', 'RNTP_adj', 'SEMP_adj', 'SSIP_adj', 'SSP_adj',  'WAGP_adj']\n",
    "nyc_vars = ['CitizenStatus',  'EducAttain', 'FTPTWork', 'FamType_PU', 'NYCgov_Childcare', 'NYCgov_Commuting', 'NYCgov_EITC', 'NYCgov_FICAtax', 'NYCgov_HEAP', 'NYCgov_Housing', 'NYCgov_Income', 'NYCgov_IncomeTax', 'NYCgov_MOOP', 'NYCgov_MedPremiums', 'NYCgov_MedSpending', 'NYCgov_Nutrition', 'NYCgov_REL', 'NYCgov_SFN', 'NYCgov_SFR', 'NYCgov_SNAP', 'NYCgov_SchoolBreakfast', 'NYCgov_SchoolLunch', 'NYCgov_Threshold', 'NYCgov_WIC', 'Povunit_Rel', 'SNAPUnit_Rel',  'TaxUnit_FILER', 'TaxUnit_FILESTAT', 'TaxUnit_FILETYPE', 'TaxUnit_Rel', 'TotalWorkHrs_PU']\n",
    "output_vars = ['NYCgov_PovGap', 'NYCgov_Pov_Stat', 'NYCgov_PovGapIndex', 'Off_Pov_Stat']\n",
    "all_columns = raw_inp_vars + id_vars + acs_vars + nyc_vars + output_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create codes for the raw input variables that are number-coded, so we can create charts that make sense\n",
    "raw_codes = {'Boro': {1: 'Bronx', 2: 'Brooklyn', 3: 'Manhattan', 4: 'Queens', 5: 'Staten Island'},\n",
    "         'CIT': {1: 'Birth', 2: 'Territories', 3: 'US Parents', 4: 'Naturalized', 5: 'No'},\n",
    "         'DIS': {0: 'NA', 1: 'Yes', 2: 'No'},\n",
    "         'ENG': {0: '<5', 1: 'Very Well', 2: 'Well', 3: 'Not well', 4: 'Not at all', 5: 'Only Eng'},\n",
    "         'ESR': {0: '<16', 1: 'EMP', 2:'EMP/NAW', 3: 'UNEMP', 4: 'AF', 5: 'AF/NAW', 6:'NILF'},\n",
    "         'Ethnicity': {1: 'White', 2: 'Black', 3: 'Asian', 4: 'Hispanic', 5: 'Other'},\n",
    "         'HHT': {0: 'NA', 1: 'MAR', 2: 'MNW', 3: 'WNM', 4: 'Malone', 5: 'MNAlone', 6: 'Walone', 7: 'WNalone'},\n",
    "         'HIUnit_Head': {0: 'Not Head', 1: 'Head', 2: 'Not Head'},\n",
    "         'HousingStatus': {0: 'NA', 1: 'Public', 2: 'Mitchell', 3: 'Subsidy', 4: 'Regulated', 5: 'OtherReg', 6: 'MarketRate', 7: 'NoCash', 8: 'OwnF&C', 9: 'Own-Mortgage'},\n",
    "         'JWTR': {0: 'NA', 1: 'Car', 2: 'Bus', 3:'Streetcar', 4:'Subway', 5:'RR', 6:'Ferry', 7:'Taxi', 8:'Motorcycle', 9:'Bike', 10:'Walk', 11:'Home', 12: 'Other'},\n",
    "         'LANX': {0: 'NA', 1: 'Yes', 2: 'Only Eng'},\n",
    "         'MAR': {1: 'Married', 2:'Widowed', 3:'Divorced', 4:'Separated', 5:'Never Married'},\n",
    "         'MSP': {0: 'NA', 1: 'Yes', 2:'Spouse absent', 3:'Widowed', 4:'Divorced', 5:'Separated', 6:'Never Married'},\n",
    "         'REL': {0: 'Self', 1:'Spouse', 2:'Child', 3:'Adopted', 4:'Stepchild', 5:'Sibling', 6:'Parent', 7:'Grandchild', 8:'Parent-in-law', 9:'Child-in-law', 10:'Other', 11:'Boarder', 12:'Roommate', 13:'Partner', 14:'Foster', 15:'OtherNR', 16:'Inst', 17:'NonInst'},\n",
    "         'SCH': {0: 'NA', 1: 'NoPast3Mos', 2:'Public', 3:'Private/Home'},\n",
    "         'SCHG': {0: 'NA', 1:'Preschool', 2:'Kindergarten', 3:'1', 4:'2', 5:'3', 6:'4', 7:'5', 8:'6', 9:'7', 10:'8', 11:'9', 12:'10', 13:'11', 14:'12', 15:'College', 16:'Grad school'},\n",
    "         'SCHL': {0: 'NA', 1:'None', 2:'Preschool', 3:'Kindergarten', 4:'1', 5:'2', 6:'3', 7:'4', 8:'5', 9:'6', 10:'7', 11:'8', 12:'9', 13:'10', 14:'11', 15:'12-NoDip', 16:'Diploma', 17:'GED', 18:'<1yrCollege', 19:'CollNoDegree', 20:'Associates', 21:'Bachelors', 22:'Masters', 23:'Professional', 24:'Doctorate'},\n",
    "         'SEX': {1:'Male', 2:'Female'},\n",
    "         'TEN': {0: 'NA', 1:'Mortage', 2:'Free&Clear', 3:'Rent', 4:'OccButNoRent'},\n",
    "         'WKW': {0:'NA', 1:'50-52', 2:'48-49', 3:'40-47', 4:'27-39', 5:'14-26', 6:'<13'},\n",
    "        }\n",
    "\n",
    "# Create codes for the nyc variables that are number-coded, so we can create charts that make sense\n",
    "nyc_codes = {\n",
    "    'CitizenStatus': {1: 'Birth', 2: 'Naturalized', 3: 'No'},\n",
    "    'EducAttain': {0: 'NA', 1:'<HS', 2:'HS', 3:'SomeCollege', 4:'Bachelors+'},\n",
    "    'FTPTWork': {1:'FTYR', 2:'<FTYR', 3:'None'},\n",
    "    'FamType_PU': {1:'Family', 2:'Couple', 3:'M+kid', 4:'W+kid', 5:'Mnokid', 6:'Wnokid', 7:'Unrelated', 8:'UnrelAlone'},\n",
    "    'NYCgov_REL': {0:'Self', 1:'Spouse', 2:'Child', 3:'Sibling', 4:'Parent', 5:'Grandkid', 6:'Inlaw', 7:'OtherRel', 8:'Boarder', 9:'Roommate', 10:'Partner', 11:'FosterKid', 12:'OtherNonRel'},\n",
    "    'NYCgov_SFR': {0: 'NA', 1:'NoKids', 2:'Kids', 3:'OneParent', 4:'Kid', 5:'Kid-Monly', 6:'Kid-Wonly'},\n",
    "    'Povunit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other'},\n",
    "    'SNAPUnit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other'},\n",
    "    'TaxUnit_FILER': {1:'Filer', 0:'Non-Filer'},\n",
    "    'TaxUnit_FILESTAT': {0: 'NA', 1:'Joint', 2:'HH', 3:'MFS', 4:'Single'},\n",
    "    'TaxUnit_FILETYPE': {0: 'NA', 1: 'Normal', 2:'Dependent', 3:'BelowThresh'},\n",
    "    'TaxUnit_Rel': {1:'Head', 2:'Spouse/Ptnr', 3:'Child', 4:'Other', 5:'EIC', 6:'Relative'},\n",
    "    'TotalWorkHrs_PU': {1:'3500+', 2:'2340-3500', 3:'1750-2340', 4:'<1750', 5:'None'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key dataframes of interest\n",
    "# All 2016 data\n",
    "all_2016 = df[df.Year == 2016]\n",
    "\n",
    "# Our data set contains two sets of weights: household weights and person weights.  \n",
    "# We need to separate out each column by whether it should be weighted as a household variable or a person variable.\n",
    "# Lists to create weighted columns, separated based on whether they are personal or household statistics.\n",
    "personal_vars = ['AGEP', 'Boro', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'ENG', 'LANX', 'MSP', 'MAR', 'NYCgov_EITC', 'WKW', 'WKHP', 'DIS', 'JWTR', 'WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj', 'TaxUnit_Rel', 'NYCgov_REL', 'NYCgov_SFR', 'SNAPUnit_Rel', 'TaxUnit_FILER', 'TaxUnit_FILESTAT', 'TaxUnit_FILETYPE', 'Ethnicity', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork', 'PWGTP'] \n",
    "pu_vars = ['MRGP_adj', 'RNTP_adj', 'NP', 'TEN', 'HHT', 'FamType_PU', 'HousingStatus', 'TotalWorkHrs_PU', 'PreTaxIncome_PU', 'NYCgov_Income', 'NYCgov_Threshold', 'NYCgov_Pov_Stat',  'NYCgov_Housing', 'NYCgov_Childcare', 'NYCgov_Commuting', 'NYCgov_MOOP', 'NYCgov_MedSpending', 'NYCgov_MedPremiums', 'NYCgov_HEAP', 'NYCgov_WIC', 'NYCgov_SNAP', 'NYCgov_SchoolLunch', 'NYCgov_SchoolBreakfast', 'NYCgov_Nutrition', 'NYCgov_FICAtax', 'NYCgov_IncomeTax', 'Off_Threshold', 'Off_Pov_Stat', 'NYCgov_PovGap', 'NYCgov_PovGapIndex', 'WGTP']\n",
    "other_vars = ['HIUnit_Head', 'HIUnit_ID', 'NYCgov_SFN', 'Povunit_ID', 'Povunit_Rel', 'REL', 'SERIALNO', 'SNAPUnit_ID', 'SPORDER', 'TaxUnit_ID', 'Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Adding New Poverty-Unit Variables Based on Personal Variables\n",
    "Here's where we're actually adding new variables based on old variables.\n",
    "\n",
    "From the personal-level features, we'll create new household-level features (e.g. number of kids, mean salary among \n",
    "adults, count of people making more than $30k, count of adults working between 14-26 hours/week, minimum salary among\n",
    "adults working more than 26 hours/week, etc.)\n",
    "\n",
    "This is a wall of text, not much exciting narrative here.\n",
    "\n",
    "(Note on programming style/choices: the first function 'add_pu_columns' below is a real function, although it has a\n",
    "kludge in case one of the summary calculations fails. (That happens rarely, but it's still a code smell.)\n",
    "\n",
    "The second function, however, is not really a 'real' function; it's heavily hand-coded and relies on custom choices of\n",
    "various groupings.  It was put into a function solely to comply with the DRY principle - in particular, this function\n",
    "will typically be run twice (once for the whole grouping, and possibly once for a model run without the 'financial' \n",
    "features).  By putting it into a function for DRY purposes, we at least avoid accidentally running different code when we \n",
    "mean to run the same code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with CIT\n",
      "took 64.48582053184509 s so far\n",
      "done with SCHL\n",
      "took 134.63068413734436 s so far\n",
      "done with SEX\n",
      "took 178.26997876167297 s so far\n",
      "done with ENG\n",
      "took 270.48538613319397 s so far\n",
      "done with MSP\n",
      "took 351.7556619644165 s so far\n",
      "done with WKW\n",
      "took 527.8056879043579 s so far\n",
      "done with WKHP\n",
      "took 721.531191110611 s so far\n",
      "done with DIS\n",
      "took 781.8973388671875 s so far\n",
      "done with NP\n",
      "took 1017.774843454361 s so far\n",
      "done with JWTR\n",
      "took 1037.0357296466827 s so far\n",
      "done with WAGP\n",
      "took 1372.6890752315521 s so far\n",
      "done with INTP\n",
      "took 1524.2630858421326 s so far\n",
      "done with SEMP\n",
      "took 1681.711932182312 s so far\n",
      "done with SSP\n",
      "took 1845.299048423767 s so far\n",
      "done with SSIP\n",
      "took 1985.9200677871704 s so far\n",
      "done with PA\n",
      "took 2101.1818034648895 s so far\n",
      "done with RETP\n",
      "took 2227.952205657959 s so far\n",
      "done with OI\n",
      "took 2348.0948402881622 s so far\n",
      "done with Ethnicity\n",
      "took 2535.209809064865 s so far\n",
      "took 2999.9464485645294 s\n"
     ]
    }
   ],
   "source": [
    "def add_pu_columns(df, groups, group_names, categories, category_names, column):\n",
    "    \"\"\"\n",
    "    Adds columns to dataframe 'df' containing calculations by poverty-unit, restricted by categories, considering groups.\n",
    "    Calculations include any(), all(), min(), max(), count(), sum(), mean(), and % in given category.\n",
    "    Input: a dataframe with multi-index consisting of 'SERIALNO', 'Povunit_ID', and 'SPORDER'; a set of masks and list of\n",
    "    names for the groups; a set of masks and a list of names for the categories; and the column of interest.\n",
    "    Output: no return value.  Inserts a series of columns into the dataframe including min, max, count, sum, any, all,\n",
    "    % of total, and mean - within households, focusing on the groups and categories of interest. \n",
    "    \"\"\"\n",
    "    \n",
    "    for group, group_name in zip(groups, group_names):\n",
    "        for category, category_name in zip(categories, category_names):\n",
    "            stacked = df[column][group & category].stack().groupby(['SERIALNO', 'Povunit_ID'])\n",
    "            anys = stacked.any()\n",
    "            # would love to use .all() here, but it would always be True because we filtered out everyone else\n",
    "            mins = stacked.min()\n",
    "            maxes = stacked.max()\n",
    "            counts = stacked.count()\n",
    "            sums = stacked.sum()\n",
    "            means = sums/counts\n",
    "            # The divisor below only restricts by 'groups' - so the final calculation is within a household, within\n",
    "            # the group of interest (e.g. adults), what % is in the category of interest (e.g. works 40 hrs/week)\n",
    "            divisor_for_percents = df[column][group].stack().groupby(['SERIALNO', 'Povunit_ID']).count()\n",
    "            try:\n",
    "                percents = counts.div(divisor_for_percents, axis=0)\n",
    "                alls = percents == 1\n",
    "            except: # if the calculation failed, leave percents and alls as a column of zeros\n",
    "                df_len = len(df.groupby(['SERIALNO', 'Povunit_ID']).sum())\n",
    "                percents = np.zeros(df_len)\n",
    "                alls = np.zeros(df_len)\n",
    "            \n",
    "            # loop through, put in the dataframe, and fill in NAs of appropriate type\n",
    "            series_and_names = zip([anys, alls, mins, maxes, counts, sums, means, percents], \n",
    "                                  ['any', 'all', 'min', 'max', 'count', 'sum', 'mean', '%'])\n",
    "            for series, series_name in series_and_names:\n",
    "                column_title = series_name + '_' + group_name + '_' + category_name\n",
    "                df[column_title] = series\n",
    "                if series_name in ['any', 'all']:\n",
    "                    df[column_title] = df[column_title].fillna(False)\n",
    "                else:\n",
    "                    df[column_title] = df[column_title].fillna(0)\n",
    "                    \n",
    "def engineer_features(df, include_financials=True):\n",
    "    \"\"\"Create features for the dataframe. This function is heavily custom and was solely created for DRY-ness.\n",
    "    Input: a poverty dataframe and whether or not to include financial features.\n",
    "    Output: returns a copy of the dataframe summarized by poverty-unit, with *only* the new features included. \n",
    "    Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "\n",
    "    # Create dataframe to house new features \n",
    "    dfc = df.copy() # read as 'X new features'\n",
    "\n",
    "    # Count the original # of features - later we'll just slice out the new features\n",
    "    # Keep in mind that 'SERIALNO' and 'Povunit_ID' will go into the index, so we need to subtract 2 columns\n",
    "    features_to_mask = len(dfc.columns) - 2\n",
    "    \n",
    "    # This is the largest # of people in a household; when we group the columns below, for each existing feature we'll\n",
    "    # create one column for each person in a household - so we'll need to know this number at the end when we want to \n",
    "    # mask our existing features\n",
    "    max_ppl = dfc.SPORDER.max()\n",
    "\n",
    "    # First, some categoricals have odd ordering; remap them\n",
    "    fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "                  'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "    dfc['ENG'] = dfc['ENG'].map(fix_orders['ENG'])\n",
    "    dfc['WKW'] = dfc['WKW'].map(fix_orders['WKW'])\n",
    "    dfc['TotalWorkHrs_PU'] = dfc['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "    # Add column for total personal income\n",
    "    if include_financials:\n",
    "        dfc['TINP'] = dfc.WAGP_adj + dfc.INTP_adj + dfc.SEMP_adj + dfc.SSP_adj + dfc.SSIP_adj + \\\n",
    "                        dfc.PA_adj + dfc.RETP_adj + dfc.OI_adj\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    dfc = dfc.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Create masks for age groups to use in creating new features\n",
    "    mask_adult = (dfc.AgeCateg == 2) | (dfc.AgeCateg == 3)\n",
    "    mask_65_plus = dfc.AgeCateg == 3\n",
    "    mask_18_64 = dfc.AgeCateg == 2\n",
    "    mask_kid = dfc.AgeCateg == 1\n",
    "    mask_any_age = dfc.AgeCateg != 0\n",
    "    mask_any = mask_any_age\n",
    "\n",
    "    # add columns with age only, no categories\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "    add_pu_columns(dfc, groups, group_names, [mask_any_age], ['age'], 'AGEP')\n",
    "\n",
    "    # add columns for CIT\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_non_cit = dfc.CIT == 5\n",
    "    mask_cit = (dfc.CIT != 5) & (dfc.CIT != 0)\n",
    "    mask_naturalized = dfc.CIT == 4\n",
    "\n",
    "    categories = [mask_non_cit, mask_cit, mask_naturalized, mask_any]\n",
    "    category_names = ['non-cit', 'citizen', 'naturalized_cit', 'any_CIT']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'CIT')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with CIT')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for SCHL\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_college_degree = (dfc.SCHL >= 21)\n",
    "    mask_HS_diploma = (dfc.SCHL >= 17)\n",
    "    mask_no_diploma = (dfc.SCHL <= 16)\n",
    "\n",
    "    categories = [mask_college_degree, mask_HS_diploma, mask_no_diploma, mask_HS_diploma & ~mask_college_degree, mask_any]\n",
    "    category_names = ['college', 'HS', 'no_diploma', 'diploma_no_bachelors', 'any_SCHL']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'SCHL')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SCHL')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for SEX\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_male = dfc.SEX == 1\n",
    "    mask_female = dfc.SEX == 2\n",
    "\n",
    "    categories = [mask_male, mask_female, mask_any]\n",
    "    category_names = ['male', 'female', 'any_SEX']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'SEX')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SEX')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for English ability (ENG)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # Keep in mind we switched ENG above so that 0 is NA, 1 is not at all, 2 is not very well, ..., 5 is only English\n",
    "    mask_no_english = dfc.ENG == 1\n",
    "    mask_eng_nvw = dfc.ENG == 2\n",
    "    mask_sep_well = dfc.ENG == 3\n",
    "    mask_eng_vw = dfc.ENG == 4\n",
    "    mask_only_eng = dfc.ENG == 5\n",
    "\n",
    "    categories = [mask_no_english, mask_eng_nvw, mask_sep_well, mask_eng_vw, mask_only_eng, mask_any]\n",
    "    category_names = ['ENG_no', 'ENG_nvw', 'ENG_well', 'ENG_vw', 'ENG_only', 'ENG_any']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'ENG')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with ENG')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for marital status (MSP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_married = (dfc.MSP == 1) | (dfc.MSP == 2)\n",
    "    mask_widowed = dfc.MSP == 3\n",
    "    mask_sep_div = (dfc.MSP == 4) | (dfc.MSP == 5)\n",
    "    mask_not_married = dfc.MSP == 6\n",
    "\n",
    "    categories = [mask_married, mask_widowed, mask_sep_div, mask_not_married, mask_any]\n",
    "    category_names = ['married', 'widowed', 'sep/divorced', 'not_married', 'any_MSP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'MSP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with MSP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for weeks worked (WKW) -- this is *weeks* worked last year, not *hours per week* (that's WKHP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # Keep in mind we switched WKW above so that 0 is none, 1 is <14 weeks, 2 is 14-26 weeks, etc.\n",
    "    mask_0_WKW = dfc.WKW == 0\n",
    "    mask_u14_WKW = dfc.WKW == 1\n",
    "    mask_14_26_WKW = dfc.WKW == 2\n",
    "    mask_27_39_WKW = dfc.WKW == 3\n",
    "    mask_40_47_WKW = dfc.WKW == 4\n",
    "    mask_48_49_WKW = dfc.WKW == 5\n",
    "    mask_50_52_WKW = dfc.WKW == 6\n",
    "\n",
    "    categories = [mask_0_WKW, mask_u14_WKW, mask_14_26_WKW, mask_27_39_WKW, mask_40_47_WKW, mask_48_49_WKW, mask_50_52_WKW, \n",
    "                 (mask_40_47_WKW | mask_48_49_WKW | mask_50_52_WKW), ~mask_0_WKW, mask_any]\n",
    "    category_names = ['no_work', '<14WKW', '14-26WKW', '27-39WKW', '40-47WKW', '48-49WKW', '50-52WKW', '>40WKW', 'nonzero_WKW',\n",
    "                     'any_WKW']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'WKW')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WKW')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for usual hours worked per week last 12 months (WKHP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_0_WKHP = dfc.WKHP == 0\n",
    "    mask_u10_WKHP = dfc.WKHP < 10\n",
    "    mask_u15_WKHP = dfc.WKHP < 15\n",
    "    mask_u20_WKHP = dfc.WKHP < 20\n",
    "    mask_u30_WKHP = dfc.WKHP < 30\n",
    "    mask_u40_WKHP = dfc.WKHP < 40\n",
    "    mask_u50_WKHP = dfc.WKHP < 50\n",
    "    mask_50_plus_WKHP = dfc.WKHP >= 50\n",
    "    mask_40_plus_WKHP = dfc.WKHP >= 40\n",
    "\n",
    "    categories = [mask_0_WKHP, mask_u10_WKHP, mask_u15_WKHP, mask_u20_WKHP, mask_u30_WKHP, mask_u40_WKHP, \n",
    "                  mask_u50_WKHP, mask_50_plus_WKHP, mask_40_plus_WKHP, mask_any]\n",
    "    category_names = ['no_work_hrs', '<10_work_hrs', '<15_work_hrs', '<20_work_hrs', '<30_work_hrs', '<40_work_hrs', \n",
    "                      '<50_work_hrs', '50_plus_work_hrs', '40_plus_work_hrs', 'any_WKHP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'WKHP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WKHP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for disability status (DIS)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_DIS = dfc.DIS == 1\n",
    "    mask_not_DIS = dfc.DIS == 2\n",
    "\n",
    "    categories = [mask_DIS, mask_not_DIS, mask_any]\n",
    "    category_names = ['DIS', 'not_DIS', 'any_DIS']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'DIS')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with DIS')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for number of people (NP)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_1_NP = dfc.NP == 1\n",
    "    mask_2_NP = dfc.NP == 2\n",
    "    mask_3_NP = dfc.NP == 3\n",
    "    mask_4_NP = dfc.NP == 4\n",
    "    mask_5_NP = dfc.NP == 5\n",
    "    mask_p5_NP = dfc.NP > 5\n",
    "    mask_p6_NP = dfc.NP > 6\n",
    "    mask_p8_NP = dfc.NP > 8\n",
    "    mask_p10_NP = dfc.NP > 10\n",
    "    mask_p12_NP = dfc.NP > 12\n",
    "\n",
    "    categories = [mask_1_NP, mask_2_NP, mask_3_NP, mask_4_NP, mask_5_NP, mask_p5_NP, mask_p6_NP, mask_p8_NP, mask_p10_NP, \n",
    "                  mask_p12_NP, mask_any]\n",
    "    category_names = ['NP1', 'NP2', 'NP3', 'NP4', 'NP5', 'NP>5', 'NP>6', 'NP>8', 'NP>10', 'NP>12', 'anyNP']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'NP')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with NP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for means of transportation to work (JWTR)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    categories = [mask_any]\n",
    "    category_names = ['work_trans']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'JWTR')\n",
    "    # Since only doing this to get means/avgs on JWTR, no need to add the 'AGEP' version here\n",
    "    #add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with JWTR')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for wages (WAGP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_0_WAG = dfc.WAGP_adj == 0\n",
    "    mask_u10_WAG = dfc.WAGP_adj < 10000\n",
    "    mask_u15_WAG = dfc.WAGP_adj < 15000\n",
    "    mask_u20_WAG = dfc.WAGP_adj < 20000\n",
    "    mask_u25_WAG = dfc.WAGP_adj < 25000\n",
    "    mask_u30_WAG = dfc.WAGP_adj < 30000\n",
    "    mask_u35_WAG = dfc.WAGP_adj < 35000\n",
    "    mask_u40_WAG = dfc.WAGP_adj < 40000\n",
    "    mask_u45_WAG = dfc.WAGP_adj < 45000\n",
    "    mask_u50_WAG = dfc.WAGP_adj < 50000\n",
    "    mask_u60_WAG = dfc.WAGP_adj < 60000\n",
    "    mask_u70_WAG = dfc.WAGP_adj < 70000\n",
    "    mask_u80_WAG = dfc.WAGP_adj < 80000\n",
    "\n",
    "    categories = [mask_0_WAG, mask_u10_WAG, mask_u15_WAG, mask_u20_WAG, mask_u25_WAG, mask_u30_WAG,  mask_u35_WAG, \n",
    "                  mask_u40_WAG, mask_u45_WAG, mask_u50_WAG, mask_u60_WAG, mask_u70_WAG, mask_u80_WAG, mask_any]\n",
    "    category_names = ['WAG0', 'WAG<10', 'WAG<15', 'WAG<20', 'WAG<25', 'WAG<30', 'WAG<35', \n",
    "                      'WAG<40', 'WAG<45', 'WAG<50', 'WAG<60', 'WAG<70', 'WAG<80', 'WAG_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'WAGP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with WAGP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for interest income (INTP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_INT = dfc.INTP_adj <= 0\n",
    "    mask_INT_1q = (dfc.INTP_adj > 0) & (dfc.INTP_adj <= 400)\n",
    "    mask_INT_2q = (dfc.INTP_adj > 400) & (dfc.INTP_adj <= 4000)\n",
    "    mask_INT_3q = (dfc.INTP_adj > 4000) & (dfc.INTP_adj <= 15000)\n",
    "    mask_INT_4q = dfc.INTP_adj > 15000\n",
    "\n",
    "    categories = [mask_0_INT, mask_INT_1q, mask_INT_2q, mask_INT_3q, mask_INT_4q, mask_any]\n",
    "    category_names = ['INT0', 'INT1q', 'INT2q', 'INT3q', 'INT4q', 'INT_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'INTP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with INTP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for self-employment income (SEMP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_SEMP = dfc.SEMP_adj <= 0\n",
    "    mask_SEMP_1q = (dfc.SEMP_adj > 0) & (dfc.SEMP_adj <= 5000)\n",
    "    mask_SEMP_2q = (dfc.SEMP_adj > 5000) & (dfc.SEMP_adj <= 15000)\n",
    "    mask_SEMP_3q = (dfc.SEMP_adj > 15000) & (dfc.SEMP_adj <= 35000)\n",
    "    mask_SEMP_4q = dfc.SEMP_adj > 35000\n",
    "\n",
    "    categories = [mask_0_SEMP, mask_SEMP_1q, mask_SEMP_2q, mask_SEMP_3q, mask_SEMP_4q, mask_any]\n",
    "    category_names = ['SEMP0', 'SEMP1q', 'SEMP2q', 'SEMP3q', 'SEMP4q', 'SEMP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SEMP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SEMP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for social security income (SSP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    # min 10, 25% 8000, 50% 12,000, 75% 18,000, max 50,000\n",
    "    mask_0_SSP = dfc.SSP_adj <= 0\n",
    "    mask_SSP_1q = (dfc.SSP_adj > 0) & (dfc.SSP_adj <= 8000)\n",
    "    mask_SSP_2q = (dfc.SSP_adj > 8000) & (dfc.SSP_adj <= 12000)\n",
    "    mask_SSP_3q = (dfc.SSP_adj > 12000) & (dfc.SSP_adj <= 18000)\n",
    "    mask_SSP_4q = dfc.SSP_adj > 18000\n",
    "\n",
    "    categories = [mask_0_SSP, mask_SSP_1q, mask_SSP_2q, mask_SSP_3q, mask_SSP_4q, mask_any]\n",
    "    category_names = ['SSP0', 'SSP1q', 'SSP2q', 'SSP3q', 'SSP4q', 'SSP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SSP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SSP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for supplemental security income (SSIP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_SSIP = dfc.SSIP_adj <= 0 \n",
    "    mask_SSIP_1q = (dfc.SSIP_adj > 0) & (dfc.SSIP_adj <= 5500) \n",
    "    mask_SSIP_2q = (dfc.SSIP_adj > 5500) & (dfc.SSIP_adj <= 8000) \n",
    "    mask_SSIP_3q = (dfc.SSIP_adj > 8000)\n",
    "\n",
    "    categories = [mask_0_SSIP, mask_SSIP_1q, mask_SSIP_2q, mask_SSIP_3q, mask_any]\n",
    "    category_names = ['SSIP0', 'SSIP1q', 'SSIP2q', 'SSIP3q', 'SSIP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'SSIP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with SSIP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for public assistance income (PA_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_0_PA = dfc.PA_adj <= 0 \n",
    "    mask_PA_1q = (dfc.PA_adj > 0) & (dfc.PA_adj <= 900) \n",
    "    mask_PA_2q = (dfc.PA_adj > 900)\n",
    "\n",
    "    categories = [mask_0_PA, mask_PA_1q, mask_PA_2q, mask_any]\n",
    "    category_names = ['PA0', 'PA1q', 'PA2q', 'PA_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'PA_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with PA')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for retirement income (RETP_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_RETP_1q = (dfc.RETP_adj > 0) & (dfc.RETP_adj <= 6000) \n",
    "    mask_RETP_2q = (dfc.RETP_adj > 6000) & (dfc.RETP_adj <= 13400) \n",
    "    mask_RETP_3q = (dfc.RETP_adj > 13400)\n",
    "\n",
    "    categories = [mask_RETP_1q, mask_RETP_2q, mask_RETP_3q, mask_any]\n",
    "    category_names = ['RETP1q', 'RETP2q', 'RETP3q', 'RETP_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'RETP_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with RETP')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for other income (OI_adj)\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    # cutoffs taken from quartiles of nonzero values\n",
    "    mask_OI_1q = (dfc.OI_adj > 0) & (dfc.OI_adj <= 2000) \n",
    "    mask_OI_2q = (dfc.OI_adj > 2000) & (dfc.OI_adj <= 6000) \n",
    "    mask_OI_3q = (dfc.OI_adj > 6000)\n",
    "\n",
    "    categories = [mask_OI_1q, mask_OI_2q, mask_OI_3q, mask_any]\n",
    "    category_names = ['OI1q', 'OI2q', 'OI3q', 'OI_any']\n",
    "\n",
    "    if include_financials:\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'OI_adj')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with OI')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    # add columns for ethnicity\n",
    "    groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "    group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "    mask_white = dfc.Ethnicity == 1\n",
    "    mask_black = dfc.Ethnicity == 2\n",
    "    mask_asian = dfc.Ethnicity == 3\n",
    "    mask_hisp = dfc.Ethnicity == 4\n",
    "    mask_other = dfc.Ethnicity == 5\n",
    "\n",
    "    categories = [mask_white, mask_black, mask_asian, mask_hisp, mask_other, mask_any]\n",
    "    category_names = ['White', 'Black', 'Asian', 'Hisp', 'ETH_other', 'ETH_any']\n",
    "\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'Ethnicity')\n",
    "    add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "    print('done with Ethnicity')\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s so far')\n",
    "\n",
    "    if include_financials:\n",
    "        # add columns for total personal income that we added above ('TINP')\n",
    "        groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "        group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "        mask_0_TINP = dfc.TINP == 0\n",
    "        mask_u10_TINP = dfc.TINP < 10000\n",
    "        mask_u15_TINP = dfc.TINP < 15000\n",
    "        mask_u20_TINP = dfc.TINP < 20000\n",
    "        mask_u25_TINP = dfc.TINP < 25000\n",
    "        mask_u30_TINP = dfc.TINP < 30000\n",
    "        mask_u35_TINP = dfc.TINP < 35000\n",
    "        mask_u40_TINP = dfc.TINP < 40000\n",
    "        mask_u45_TINP = dfc.TINP < 45000\n",
    "        mask_u50_TINP = dfc.TINP < 50000\n",
    "        mask_u60_TINP = dfc.TINP < 60000\n",
    "        mask_u70_TINP = dfc.TINP < 70000\n",
    "        mask_u80_TINP = dfc.TINP < 80000\n",
    "\n",
    "        categories = [mask_0_TINP, mask_u10_TINP, mask_u15_TINP, mask_u20_TINP, mask_u25_TINP, mask_u30_TINP,  mask_u35_TINP, \n",
    "                      mask_u40_TINP, mask_u45_TINP, mask_u50_TINP, mask_u60_TINP, mask_u70_TINP, mask_u80_TINP, mask_any]\n",
    "        category_names = ['TINP0', 'TINP<10', 'TINP<15', 'TINP<20', 'TINP<25', 'TINP<30', 'TINP<35', \n",
    "                          'TINP<40', 'TINP<45', 'TINP<50', 'TINP<60', 'TINP<70', 'TINP<80', 'TINP_any']\n",
    "\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'TINP')\n",
    "        add_pu_columns(dfc, groups, group_names, categories, category_names, 'AGEP')\n",
    "\n",
    "    time_took = time.time() - time_0\n",
    "    print('took ' + str(time_took) + ' s')\n",
    "\n",
    "    # Only return the new features that we engineered\n",
    "    # The variables features_to_mask and max_ppl were created at the beginning of this function\n",
    "    columns_to_mask = features_to_mask * max_ppl\n",
    "    dfc = dfc.iloc[:, columns_to_mask:].copy()\n",
    "\n",
    "    # We ended up with multi-level column headers - just keep the top level\n",
    "    dfc.columns = dfc.columns.get_level_values(0)\n",
    "    \n",
    "    return(dfc)\n",
    "\n",
    "#new_features = engineer_features(all_2016, include_financials=True)\n",
    "\n",
    "#new_features.to_csv('data/EngineeredFeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Putting Personal Features into Poverty Unit Rows\n",
    "Our dataset contains people in poverty units (a household may contain one or more poverty units). The entire \n",
    "poverty unit either is or is not in poverty, but the data set as constructed has people in different rows (the data is\n",
    "not tidy).\n",
    "\n",
    "To tidy up, we'll move information on all the people in the poverty unit, into the row for that poverty unit.\n",
    "Instead of having 3 people in a poverty unit represented by different rows, we'll put all three people in\n",
    "the same row but different columns. The columns will be named 'AGEP_1', 'AGEP_2', 'AGEP_3', etc, with zero values in all\n",
    "columns where person n does not exist.\n",
    "\n",
    "There are three main columns of interest for this:\n",
    "* SERIALNO is the serial number of each household.\n",
    "* PovUnit_ID is the serial number of the poverty unit within the household (1-18). Each household can have more than one poverty unit (although the vast majority of households have only one poverty unit).\n",
    "* SPORDER is the serial number of a person in the household (1-20). Note that the dataset only assigns serial numbers to\n",
    "the people in the *household*, not the *poverty unit*.  This means that if for example a household has two poverty units,\n",
    "the first with two people and the second with three people, the head of the second poverty unit will have SPORDER of 3,\n",
    "not 1.  (One-based counting scheme) This is not a problem, but a particularity to be aware of when looking at dataset\n",
    "rows for reference.\n",
    "\n",
    "Also, there are some poverty-unit-level columns (e.g. 'TotalWorkHrs_PU', the number of work hours in the poverty unit)\n",
    "that have the same value for each person in the poverty unit; we'll collect those separately.\n",
    "\n",
    "So the strategy in the next section is to create dataframes X_pers and X_pu, containing respectively the personal and\n",
    "poverty-unit features for each household.  We'll join those together, and then at the end add in all the new features we created in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pers_and_pu_features(df, include_financials=True, target_column='NYCgov_Pov_Stat'):\n",
    "    \"\"\"Create personal and poverty-unit features for the dataframe. No new features are created, just 'tidy'-ing the data.\n",
    "    Input: a poverty dataframe, whether or not to include financial features, and the target column.\n",
    "    Output: returns a copy of the dataframe, tidy-ed up, with poverty units in rows and only features of interest in \n",
    "    columns. Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # First, some categoricals have odd ordering; remap them\n",
    "    fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "                  'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "    dfc['ENG'] = dfc['ENG'].map(fix_orders['ENG'])\n",
    "    dfc['WKW'] = dfc['WKW'].map(fix_orders['WKW'])\n",
    "    dfc['TotalWorkHrs_PU'] = dfc['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "    # Add column for total personal income\n",
    "    if include_financials:\n",
    "        dfc['TINP'] = dfc.WAGP_adj + dfc.INTP_adj + dfc.SEMP_adj + dfc.SSP_adj + dfc.SSIP_adj + dfc.PA_adj + dfc.RETP_adj + dfc.OI_adj\n",
    "\n",
    "    categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', \n",
    "                    'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "    # We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "    personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    if include_financials:\n",
    "        personal_columns += ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', \n",
    "                             'OI_adj', 'TINP']\n",
    "    pu_columns = ['NP', 'TEN', 'HHT', 'MRGP_adj', 'RNTP_adj', 'HousingStatus', 'TotalWorkHrs_PU'] + [target_column]\n",
    "\n",
    "    # Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "    df_pers = dfc.copy()\n",
    "    df_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "    df_pers = df_pers[df_pers_columns]\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    df_pers = df_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "    df_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in df_pers.columns)]))\n",
    "    print('df_pers complete')\n",
    "\n",
    "    # Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "    df_pu = dfc.copy()\n",
    "    df_pu_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + pu_columns\n",
    "    df_pu = df_pu[df_pu_columns]\n",
    "\n",
    "    # Add column for total mortgage + rent\n",
    "    df_pu['MRNT'] = df_pu.MRGP_adj + df_pu.RNTP_adj\n",
    "\n",
    "    # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "    df_pu = df_pu.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "    # Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "    df_pu = df_pu.stack().groupby(['SERIALNO', 'Povunit_ID']).max()\n",
    "    print('df_pu complete')\n",
    "\n",
    "    # Add the personal and poverty-unit dataframes\n",
    "    dfc = df_pers.join(df_pu)\n",
    "    return(dfc)\n",
    "\n",
    "\n",
    "# Get the personal and poverty-unit features\n",
    "#X = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_Pov_Stat')\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "# new_features = pd.read_csv('/data/EngineeredFeatures.csv', index_col=[0,1], header=0)\n",
    "#X = X.join(new_features)\n",
    "    \n",
    "#X.to_csv('/data/Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_y = pd.read_csv('data/Features.csv', index_col=[0,1], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "Most of our features are numerical or ordinal; but a few features are nominal, that is, categorical without any order,\n",
    "like disabled status (yes or no), for example.  We'll loop through and one-hot encode those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, old_df):\n",
    "    \"\"\"\n",
    "    Turn the categorical columns of df into one-hot encoded columns.\n",
    "    Input: the dataframe of interest (that has been tidy-ed up so that all people in the same poverty unit are in the\n",
    "    same row, and a reference dataframe (pre-tidy-ed version) so we have the correct number of loop iterations.\n",
    "    Output: returns the dataframe with columns transformed.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # Number of enumerated columns for each feature ('AGEP_1', 'AGEP_2', etc.)\n",
    "    # This is equal to the maximum number of people in any household, which is the max of SPORDER\n",
    "    n = old_df.SPORDER.max()\n",
    "\n",
    "    # Some categoricals have no ordering\n",
    "    nominal_pers = ['DIS', 'SEX', 'MSP', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    nominal_pu = ['TEN', 'HHT', 'HousingStatus']\n",
    "    \n",
    "    # Collect all the names that we need to change to str for get_dummies purposes\n",
    "    names = []\n",
    "    \n",
    "    # Loop through and collect the names of all the personal-variables columns\n",
    "    for feature in nominal_pers:\n",
    "        # Loop through and one-hot encode for each suffixed column '_1', '_2', etc.\n",
    "        for i in range(1,n+1):\n",
    "            suffixed_name = str(feature + '_' + str(i))\n",
    "            names.append(suffixed_name)\n",
    "\n",
    "    # Loop through and one-hot encode poverty-unit categoricals\n",
    "    for feature in nominal_pu:\n",
    "        names.append(feature)\n",
    "    \n",
    "    dfc[names] = dfc[names].astype(str)\n",
    "    # Assuming this doesn't work, just use dfc_names_only = dfc_names and dfc_non_names=dfc.drop(names, axis='columns') and go from there\n",
    "    dfc = pd.get_dummies(dfc, drop_first=True)\n",
    "    \n",
    "    return(dfc)\n",
    "\n",
    "X_and_y = one_hot_encode(X_and_y, all_2016)\n",
    "#X_and_y.to_csv('data/FeaturesCoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns with Low Standard Deviation\n",
    "The algorithm used above created thousands of features -- but not all of them will be useful.  Let's remove all of the \n",
    "features that have a Standard Deviation of less than 0.1, to reduce the noise and speed up our model runs (especially\n",
    "our run to remove co-linear features, which will take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5916\n",
      "4960\n"
     ]
    }
   ],
   "source": [
    "tester = X_and_y.copy()\n",
    "print('Number of columns before feature pruning: ' + str(len(tester.columns)))\n",
    "tester = tester.loc[:, tester.astype('float64').std() > .1] #4960 columns\n",
    "print('Number of columns after feature pruning: ' + str(len(tester.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Co-Linear Features\n",
    "We also introduced a lot of of features that are very highly correlated.  Out of the 4,960 columns, below we identify\n",
    "3,406 columns (nearly 70 percent!) to drop due to colinearity. This step took over 20 minutes on a fairly beefy AWS\n",
    "instance; don't run it unless you're ready to wait. If you don't want to run it, just un-comment the 'to_drop' line at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4960\n",
      "got correlations; took 1261.0507678985596s\n",
      "got uppers; took 1261.2725381851196s cumulative\n",
      "got to-drop, took 1262.4210934638977s cumulative\n",
      "['SCHL_19', 'WAGP_adj_15', 'SSP_adj_20', 'SSIP_adj_14', 'SSIP_adj_20', 'PA_adj_14', 'PA_adj_16', 'PA_adj_17', 'PA_adj_18', 'PA_adj_19', 'PA_adj_20', 'TINP_3', 'TINP_10', 'TINP_11', 'TINP_12', 'TINP_13', 'TINP_14', 'TINP_15', 'TINP_16', 'TINP_17', 'TINP_18', 'TINP_19', 'TINP_20', 'all_65+_age', 'min_65+_age', 'max_65+_age', 'sum_65+_age', 'mean_65+_age', '%_65+_age', 'all_18-64_age', 'mean_18-64_age', '%_18-64_age', 'all_kid_age', 'mean_kid_age', '%_kid_age', 'max_anyage_age', 'sum_anyage_age', 'max_adult_non-cit', 'sum_adult_non-cit', 'mean_adult_non-cit', 'any_adult_citizen', 'all_adult_citizen', 'mean_adult_citizen', '%_adult_citizen', 'max_adult_naturalized_cit', 'sum_adult_naturalized_cit', 'mean_adult_naturalized_cit', 'min_adult_any_CIT', 'max_adult_any_CIT', 'count_adult_any_CIT', 'sum_adult_any_CIT', 'mean_adult_any_CIT', 'min_65+_non-cit', 'max_65+_non-cit', 'count_65+_non-cit', 'sum_65+_non-cit', 'mean_65+_non-cit', '%_65+_non-cit', 'all_65+_citizen', 'min_65+_citizen', 'max_65+_citizen', 'sum_65+_citizen', 'mean_65+_citizen', '%_65+_citizen', 'min_65+_naturalized_cit', 'max_65+_naturalized_cit', 'sum_65+_naturalized_cit', 'mean_65+_naturalized_cit', '%_65+_naturalized_cit', 'any_65+_any_CIT', 'all_65+_any_CIT', 'min_65+_any_CIT', 'max_65+_any_CIT', 'count_65+_any_CIT', 'sum_65+_any_CIT', 'mean_65+_any_CIT', '%_65+_any_CIT', 'max_18-64_non-cit', 'count_18-64_non-cit', 'sum_18-64_non-cit', 'mean_18-64_non-cit', 'mean_18-64_citizen', '%_18-64_citizen', 'min_18-64_naturalized_cit', 'max_18-64_naturalized_cit', 'sum_18-64_naturalized_cit', 'mean_18-64_naturalized_cit', 'any_18-64_any_CIT', 'all_18-64_any_CIT', 'min_18-64_any_CIT', 'max_18-64_any_CIT', 'count_18-64_any_CIT', 'sum_18-64_any_CIT', 'mean_18-64_any_CIT', '%_18-64_any_CIT', 'max_kid_non-cit', 'mean_kid_non-cit', 'any_kid_citizen', 'all_kid_citizen', 'min_kid_citizen', 'max_kid_citizen', 'count_kid_citizen', 'sum_kid_citizen', 'mean_kid_citizen', '%_kid_citizen', 'max_kid_naturalized_cit', 'mean_kid_naturalized_cit', 'any_kid_any_CIT', 'all_kid_any_CIT', 'min_kid_any_CIT', 'max_kid_any_CIT', 'count_kid_any_CIT', 'sum_kid_any_CIT', 'mean_kid_any_CIT', '%_kid_any_CIT', 'any_anyage_non-cit', 'min_anyage_non-cit', 'max_anyage_non-cit', 'count_anyage_non-cit', 'sum_anyage_non-cit', 'mean_anyage_non-cit', '%_anyage_non-cit', 'any_anyage_citizen', 'all_anyage_citizen', 'max_anyage_citizen', 'sum_anyage_citizen', 'mean_anyage_citizen', '%_anyage_citizen', 'any_anyage_naturalized_cit', 'min_anyage_naturalized_cit', 'max_anyage_naturalized_cit', 'count_anyage_naturalized_cit', 'sum_anyage_naturalized_cit', 'mean_anyage_naturalized_cit', '%_anyage_naturalized_cit', 'min_anyage_any_CIT', 'max_anyage_any_CIT', 'count_anyage_any_CIT', 'sum_anyage_any_CIT', 'mean_anyage_any_CIT', 'max_adult_college', 'mean_adult_college', 'mean_adult_HS', 'any_adult_no_diploma', 'all_adult_no_diploma', 'max_adult_no_diploma', 'mean_adult_no_diploma', '%_adult_no_diploma', 'max_adult_diploma_no_bachelors', 'mean_adult_diploma_no_bachelors', 'min_adult_any_SCHL', 'max_adult_any_SCHL', 'count_adult_any_SCHL', 'sum_adult_any_SCHL', 'mean_adult_any_SCHL', 'min_65+_college', 'max_65+_college', 'sum_65+_college', 'mean_65+_college', '%_65+_college', 'min_65+_HS', 'max_65+_HS', 'sum_65+_HS', 'mean_65+_HS', '%_65+_HS', 'min_65+_no_diploma', 'max_65+_no_diploma', 'sum_65+_no_diploma', 'mean_65+_no_diploma', '%_65+_no_diploma', 'min_65+_diploma_no_bachelors', 'max_65+_diploma_no_bachelors', 'count_65+_diploma_no_bachelors', 'sum_65+_diploma_no_bachelors', 'mean_65+_diploma_no_bachelors', '%_65+_diploma_no_bachelors', 'any_65+_any_SCHL', 'all_65+_any_SCHL', 'min_65+_any_SCHL', 'max_65+_any_SCHL', 'count_65+_any_SCHL', 'sum_65+_any_SCHL', 'mean_65+_any_SCHL', '%_65+_any_SCHL', 'max_18-64_college', 'mean_18-64_college', 'mean_18-64_HS', 'max_18-64_no_diploma', 'sum_18-64_no_diploma', 'mean_18-64_no_diploma', 'max_18-64_diploma_no_bachelors', 'mean_18-64_diploma_no_bachelors', 'any_18-64_any_SCHL', 'all_18-64_any_SCHL', 'min_18-64_any_SCHL', 'max_18-64_any_SCHL', 'count_18-64_any_SCHL', 'sum_18-64_any_SCHL', 'mean_18-64_any_SCHL', '%_18-64_any_SCHL', 'max_kid_HS', 'sum_kid_HS', 'mean_kid_HS', 'any_kid_no_diploma', 'all_kid_no_diploma', 'min_kid_no_diploma', 'max_kid_no_diploma', 'count_kid_no_diploma', 'sum_kid_no_diploma', 'mean_kid_no_diploma', '%_kid_no_diploma', 'min_kid_diploma_no_bachelors', 'max_kid_diploma_no_bachelors', 'sum_kid_diploma_no_bachelors', 'mean_kid_diploma_no_bachelors', 'any_kid_any_SCHL', 'all_kid_any_SCHL', 'min_kid_any_SCHL', 'max_kid_any_SCHL', 'count_kid_any_SCHL', 'sum_kid_any_SCHL', 'mean_kid_any_SCHL', '%_kid_any_SCHL', 'any_anyage_college', 'min_anyage_college', 'max_anyage_college', 'count_anyage_college', 'sum_anyage_college', 'mean_anyage_college', '%_anyage_college', 'any_anyage_HS', 'min_anyage_HS', 'max_anyage_HS', 'count_anyage_HS', 'sum_anyage_HS', 'mean_anyage_HS', 'any_anyage_no_diploma', 'all_anyage_no_diploma', 'max_anyage_no_diploma', 'sum_anyage_no_diploma', 'mean_anyage_no_diploma', '%_anyage_no_diploma', 'any_anyage_diploma_no_bachelors', 'min_anyage_diploma_no_bachelors', 'max_anyage_diploma_no_bachelors', 'count_anyage_diploma_no_bachelors', 'sum_anyage_diploma_no_bachelors', 'mean_anyage_diploma_no_bachelors', '%_anyage_diploma_no_bachelors', 'min_anyage_any_SCHL', 'max_anyage_any_SCHL', 'count_anyage_any_SCHL', 'sum_anyage_any_SCHL', 'mean_anyage_any_SCHL', 'mean_adult_male', 'any_adult_female', 'all_adult_female', 'mean_adult_female', '%_adult_female', 'min_adult_any_SEX', 'max_adult_any_SEX', 'count_adult_any_SEX', 'sum_adult_any_SEX', 'mean_adult_any_SEX', 'min_65+_male', 'max_65+_male', 'count_65+_male', 'sum_65+_male', 'mean_65+_male', 'min_65+_female', 'max_65+_female', 'count_65+_female', 'sum_65+_female', 'mean_65+_female', '%_65+_female', 'any_65+_any_SEX', 'all_65+_any_SEX', 'min_65+_any_SEX', 'max_65+_any_SEX', 'count_65+_any_SEX', 'sum_65+_any_SEX', 'mean_65+_any_SEX', '%_65+_any_SEX', 'mean_18-64_male', 'mean_18-64_female', 'any_18-64_any_SEX', 'all_18-64_any_SEX', 'min_18-64_any_SEX', 'max_18-64_any_SEX', 'count_18-64_any_SEX', 'sum_18-64_any_SEX', 'mean_18-64_any_SEX', '%_18-64_any_SEX', 'mean_kid_male', 'mean_kid_female', 'any_kid_any_SEX', 'all_kid_any_SEX', 'min_kid_any_SEX', 'max_kid_any_SEX', 'count_kid_any_SEX', 'sum_kid_any_SEX', 'mean_kid_any_SEX', '%_kid_any_SEX', 'all_anyage_male', 'max_anyage_male', 'sum_anyage_male', 'mean_anyage_male', '%_anyage_male', 'any_anyage_female', 'all_anyage_female', 'max_anyage_female', 'sum_anyage_female', 'mean_anyage_female', '%_anyage_female', 'min_anyage_any_SEX', 'max_anyage_any_SEX', 'count_anyage_any_SEX', 'sum_anyage_any_SEX', 'mean_anyage_any_SEX', 'min_adult_ENG_no', 'max_adult_ENG_no', 'sum_adult_ENG_no', 'mean_adult_ENG_no', 'max_adult_ENG_nvw', 'sum_adult_ENG_nvw', 'mean_adult_ENG_nvw', 'max_adult_ENG_well', 'mean_adult_ENG_well', 'max_adult_ENG_vw', 'mean_adult_ENG_vw', 'mean_adult_ENG_only', '%_adult_ENG_only', 'min_adult_ENG_any', 'max_adult_ENG_any', 'count_adult_ENG_any', 'sum_adult_ENG_any', 'mean_adult_ENG_any', 'min_65+_ENG_no', 'max_65+_ENG_no', 'count_65+_ENG_no', 'sum_65+_ENG_no', 'mean_65+_ENG_no', '%_65+_ENG_no', 'min_65+_ENG_nvw', 'max_65+_ENG_nvw', 'count_65+_ENG_nvw', 'sum_65+_ENG_nvw', 'mean_65+_ENG_nvw', '%_65+_ENG_nvw', 'min_65+_ENG_well', 'max_65+_ENG_well', 'count_65+_ENG_well', 'sum_65+_ENG_well', 'mean_65+_ENG_well', '%_65+_ENG_well', 'min_65+_ENG_vw', 'max_65+_ENG_vw', 'sum_65+_ENG_vw', 'mean_65+_ENG_vw', '%_65+_ENG_vw', 'all_65+_ENG_only', 'min_65+_ENG_only', 'max_65+_ENG_only', 'sum_65+_ENG_only', 'mean_65+_ENG_only', '%_65+_ENG_only', 'any_65+_ENG_any', 'all_65+_ENG_any', 'min_65+_ENG_any', 'max_65+_ENG_any', 'count_65+_ENG_any', 'sum_65+_ENG_any', 'mean_65+_ENG_any', '%_65+_ENG_any', 'min_18-64_ENG_no', 'max_18-64_ENG_no', 'sum_18-64_ENG_no', 'mean_18-64_ENG_no', 'min_18-64_ENG_nvw', 'max_18-64_ENG_nvw', 'sum_18-64_ENG_nvw', 'mean_18-64_ENG_nvw', 'min_18-64_ENG_well', 'max_18-64_ENG_well', 'sum_18-64_ENG_well', 'mean_18-64_ENG_well', 'max_18-64_ENG_vw', 'sum_18-64_ENG_vw', 'mean_18-64_ENG_vw', 'sum_18-64_ENG_only', 'mean_18-64_ENG_only', '%_18-64_ENG_only', 'any_18-64_ENG_any', 'all_18-64_ENG_any', 'min_18-64_ENG_any', 'max_18-64_ENG_any', 'count_18-64_ENG_any', 'sum_18-64_ENG_any', 'mean_18-64_ENG_any', '%_18-64_ENG_any', 'max_kid_ENG_no', 'mean_kid_ENG_no', 'max_kid_ENG_nvw', 'mean_kid_ENG_nvw', 'max_kid_ENG_well', 'sum_kid_ENG_well', 'mean_kid_ENG_well', 'max_kid_ENG_vw', 'sum_kid_ENG_vw', 'mean_kid_ENG_vw', '%_kid_ENG_vw', 'max_kid_ENG_only', 'sum_kid_ENG_only', 'mean_kid_ENG_only', '%_kid_ENG_only', 'any_kid_ENG_any', 'all_kid_ENG_any', 'min_kid_ENG_any', 'max_kid_ENG_any', 'count_kid_ENG_any', 'sum_kid_ENG_any', 'mean_kid_ENG_any', '%_kid_ENG_any', 'any_anyage_ENG_no', 'all_anyage_ENG_no', 'min_anyage_ENG_no', 'max_anyage_ENG_no', 'count_anyage_ENG_no', 'sum_anyage_ENG_no', 'mean_anyage_ENG_no', '%_anyage_ENG_no', 'any_anyage_ENG_nvw', 'min_anyage_ENG_nvw', 'max_anyage_ENG_nvw', 'count_anyage_ENG_nvw', 'sum_anyage_ENG_nvw', 'mean_anyage_ENG_nvw', '%_anyage_ENG_nvw', 'any_anyage_ENG_well', 'min_anyage_ENG_well', 'max_anyage_ENG_well', 'sum_anyage_ENG_well', 'mean_anyage_ENG_well', '%_anyage_ENG_well', 'min_anyage_ENG_vw', 'max_anyage_ENG_vw', 'sum_anyage_ENG_vw', 'mean_anyage_ENG_vw', '%_anyage_ENG_vw', 'any_anyage_ENG_only', 'max_anyage_ENG_only', 'sum_anyage_ENG_only', 'mean_anyage_ENG_only', '%_anyage_ENG_only', 'min_anyage_ENG_any', 'max_anyage_ENG_any', 'count_anyage_ENG_any', 'sum_anyage_ENG_any', 'mean_anyage_ENG_any', 'max_adult_married', 'sum_adult_married', 'mean_adult_married', 'min_adult_widowed', 'max_adult_widowed', 'count_adult_widowed', 'sum_adult_widowed', 'mean_adult_widowed', 'min_adult_sep/divorced', 'max_adult_sep/divorced', 'count_adult_sep/divorced', 'sum_adult_sep/divorced', 'mean_adult_sep/divorced', 'max_adult_not_married', 'mean_adult_not_married', 'min_adult_any_MSP', 'max_adult_any_MSP', 'count_adult_any_MSP', 'sum_adult_any_MSP', 'mean_adult_any_MSP', 'all_65+_married', 'min_65+_married', 'max_65+_married', 'count_65+_married', 'sum_65+_married', 'mean_65+_married', '%_65+_married', 'all_65+_widowed', 'min_65+_widowed', 'max_65+_widowed', 'count_65+_widowed', 'sum_65+_widowed', 'mean_65+_widowed', '%_65+_widowed', 'all_65+_sep/divorced', 'min_65+_sep/divorced', 'max_65+_sep/divorced', 'count_65+_sep/divorced', 'sum_65+_sep/divorced', 'mean_65+_sep/divorced', '%_65+_sep/divorced', 'all_65+_not_married', 'min_65+_not_married', 'max_65+_not_married', 'count_65+_not_married', 'sum_65+_not_married', 'mean_65+_not_married', '%_65+_not_married', 'any_65+_any_MSP', 'all_65+_any_MSP', 'min_65+_any_MSP', 'max_65+_any_MSP', 'count_65+_any_MSP', 'sum_65+_any_MSP', 'mean_65+_any_MSP', '%_65+_any_MSP', 'min_18-64_married', 'max_18-64_married', 'sum_18-64_married', 'mean_18-64_married', '%_18-64_married', 'min_18-64_widowed', 'max_18-64_widowed', 'count_18-64_widowed', 'sum_18-64_widowed', 'mean_18-64_widowed', 'min_18-64_sep/divorced', 'max_18-64_sep/divorced', 'count_18-64_sep/divorced', 'sum_18-64_sep/divorced', 'mean_18-64_sep/divorced', 'max_18-64_not_married', 'count_18-64_not_married', 'mean_18-64_not_married', 'any_18-64_any_MSP', 'all_18-64_any_MSP', 'min_18-64_any_MSP', 'max_18-64_any_MSP', 'count_18-64_any_MSP', 'sum_18-64_any_MSP', 'mean_18-64_any_MSP', '%_18-64_any_MSP', 'max_kid_married', 'sum_kid_married', 'mean_kid_married', 'max_kid_sep/divorced', 'sum_kid_sep/divorced', 'mean_kid_sep/divorced', 'min_kid_not_married', 'max_kid_not_married', 'count_kid_not_married', 'sum_kid_not_married', 'mean_kid_not_married', 'any_kid_any_MSP', 'all_kid_any_MSP', 'min_kid_any_MSP', 'max_kid_any_MSP', 'count_kid_any_MSP', 'sum_kid_any_MSP', 'mean_kid_any_MSP', '%_kid_any_MSP', 'any_anyage_married', 'min_anyage_married', 'max_anyage_married', 'count_anyage_married', 'sum_anyage_married', 'mean_anyage_married', 'any_anyage_widowed', 'all_anyage_widowed', 'min_anyage_widowed', 'max_anyage_widowed', 'count_anyage_widowed', 'sum_anyage_widowed', 'mean_anyage_widowed', '%_anyage_widowed', 'any_anyage_sep/divorced', 'min_anyage_sep/divorced', 'max_anyage_sep/divorced', 'count_anyage_sep/divorced', 'sum_anyage_sep/divorced', 'mean_anyage_sep/divorced', '%_anyage_sep/divorced', 'min_anyage_not_married', 'max_anyage_not_married', 'sum_anyage_not_married', 'mean_anyage_not_married', '%_anyage_not_married', 'min_anyage_any_MSP', 'max_anyage_any_MSP', 'count_anyage_any_MSP', 'sum_anyage_any_MSP', 'mean_anyage_any_MSP', 'max_adult_no_work', 'mean_adult_no_work', 'max_adult_<14WKW', 'count_adult_<14WKW', 'sum_adult_<14WKW', 'mean_adult_<14WKW', 'max_adult_14-26WKW', 'count_adult_14-26WKW', 'sum_adult_14-26WKW', 'mean_adult_14-26WKW', 'max_adult_27-39WKW', 'count_adult_27-39WKW', 'sum_adult_27-39WKW', 'mean_adult_27-39WKW', 'max_adult_40-47WKW', 'count_adult_40-47WKW', 'sum_adult_40-47WKW', 'mean_adult_40-47WKW', 'max_adult_48-49WKW', 'count_adult_48-49WKW', 'sum_adult_48-49WKW', 'mean_adult_48-49WKW', 'mean_adult_50-52WKW', 'mean_adult_>40WKW', 'any_adult_nonzero_WKW', 'all_adult_nonzero_WKW', 'mean_adult_nonzero_WKW', '%_adult_nonzero_WKW', 'min_adult_any_WKW', 'max_adult_any_WKW', 'count_adult_any_WKW', 'sum_adult_any_WKW', 'mean_adult_any_WKW', 'min_65+_no_work', 'max_65+_no_work', 'sum_65+_no_work', 'mean_65+_no_work', '%_65+_no_work', 'max_65+_<14WKW', 'sum_65+_<14WKW', 'mean_65+_<14WKW', 'max_65+_14-26WKW', 'sum_65+_14-26WKW', 'mean_65+_14-26WKW', 'max_65+_27-39WKW', 'sum_65+_27-39WKW', 'mean_65+_27-39WKW', 'max_65+_40-47WKW', 'sum_65+_40-47WKW', 'mean_65+_40-47WKW', 'max_65+_48-49WKW', 'sum_65+_48-49WKW', 'mean_65+_48-49WKW', 'min_65+_50-52WKW', 'max_65+_50-52WKW', 'count_65+_50-52WKW', 'sum_65+_50-52WKW', 'mean_65+_50-52WKW', '%_65+_50-52WKW', 'min_65+_>40WKW', 'max_65+_>40WKW', 'count_65+_>40WKW', 'sum_65+_>40WKW', 'mean_65+_>40WKW', '%_65+_>40WKW', 'min_65+_nonzero_WKW', 'max_65+_nonzero_WKW', 'count_65+_nonzero_WKW', 'sum_65+_nonzero_WKW', 'mean_65+_nonzero_WKW', '%_65+_nonzero_WKW', 'any_65+_any_WKW', 'all_65+_any_WKW', 'min_65+_any_WKW', 'max_65+_any_WKW', 'count_65+_any_WKW', 'sum_65+_any_WKW', 'mean_65+_any_WKW', '%_65+_any_WKW', 'max_18-64_no_work', 'mean_18-64_no_work', 'max_18-64_<14WKW', 'count_18-64_<14WKW', 'sum_18-64_<14WKW', 'mean_18-64_<14WKW', 'any_18-64_14-26WKW', 'max_18-64_14-26WKW', 'count_18-64_14-26WKW', 'sum_18-64_14-26WKW', 'mean_18-64_14-26WKW', 'any_18-64_27-39WKW', 'max_18-64_27-39WKW', 'count_18-64_27-39WKW', 'sum_18-64_27-39WKW', 'mean_18-64_27-39WKW', 'any_18-64_40-47WKW', 'max_18-64_40-47WKW', 'count_18-64_40-47WKW', 'sum_18-64_40-47WKW', 'mean_18-64_40-47WKW', 'any_18-64_48-49WKW', 'min_18-64_48-49WKW', 'max_18-64_48-49WKW', 'count_18-64_48-49WKW', 'sum_18-64_48-49WKW', 'mean_18-64_48-49WKW', '%_18-64_48-49WKW', 'count_18-64_50-52WKW', 'mean_18-64_50-52WKW', 'count_18-64_>40WKW', 'mean_18-64_>40WKW', 'count_18-64_nonzero_WKW', 'mean_18-64_nonzero_WKW', 'any_18-64_any_WKW', 'all_18-64_any_WKW', 'min_18-64_any_WKW', 'max_18-64_any_WKW', 'count_18-64_any_WKW', 'sum_18-64_any_WKW', 'mean_18-64_any_WKW', '%_18-64_any_WKW', 'any_kid_no_work', 'all_kid_no_work', 'min_kid_no_work', 'max_kid_no_work', 'count_kid_no_work', 'sum_kid_no_work', 'mean_kid_no_work', '%_kid_no_work', 'max_kid_<14WKW', 'sum_kid_<14WKW', 'mean_kid_<14WKW', 'max_kid_14-26WKW', 'sum_kid_14-26WKW', 'mean_kid_14-26WKW', 'max_kid_27-39WKW', 'sum_kid_27-39WKW', 'mean_kid_27-39WKW', 'max_kid_40-47WKW', 'sum_kid_40-47WKW', 'mean_kid_40-47WKW', 'max_kid_50-52WKW', 'sum_kid_50-52WKW', 'mean_kid_50-52WKW', 'max_kid_>40WKW', 'sum_kid_>40WKW', 'mean_kid_>40WKW', 'max_kid_nonzero_WKW', 'sum_kid_nonzero_WKW', 'mean_kid_nonzero_WKW', 'any_kid_any_WKW', 'all_kid_any_WKW', 'min_kid_any_WKW', 'max_kid_any_WKW', 'count_kid_any_WKW', 'sum_kid_any_WKW', 'mean_kid_any_WKW', '%_kid_any_WKW', 'all_anyage_no_work', 'max_anyage_no_work', 'sum_anyage_no_work', 'mean_anyage_no_work', 'any_anyage_<14WKW', 'min_anyage_<14WKW', 'max_anyage_<14WKW', 'count_anyage_<14WKW', 'sum_anyage_<14WKW', 'mean_anyage_<14WKW', '%_anyage_<14WKW', 'any_anyage_14-26WKW', 'all_anyage_14-26WKW', 'min_anyage_14-26WKW', 'max_anyage_14-26WKW', 'count_anyage_14-26WKW', 'sum_anyage_14-26WKW', 'mean_anyage_14-26WKW', '%_anyage_14-26WKW', 'any_anyage_27-39WKW', 'min_anyage_27-39WKW', 'max_anyage_27-39WKW', 'count_anyage_27-39WKW', 'sum_anyage_27-39WKW', 'mean_anyage_27-39WKW', '%_anyage_27-39WKW', 'any_anyage_40-47WKW', 'min_anyage_40-47WKW', 'max_anyage_40-47WKW', 'count_anyage_40-47WKW', 'sum_anyage_40-47WKW', 'mean_anyage_40-47WKW', '%_anyage_40-47WKW', 'any_anyage_48-49WKW', 'min_anyage_48-49WKW', 'max_anyage_48-49WKW', 'count_anyage_48-49WKW', 'sum_anyage_48-49WKW', 'mean_anyage_48-49WKW', '%_anyage_48-49WKW', 'any_anyage_50-52WKW', 'min_anyage_50-52WKW', 'max_anyage_50-52WKW', 'count_anyage_50-52WKW', 'sum_anyage_50-52WKW', 'mean_anyage_50-52WKW', 'any_anyage_>40WKW', 'min_anyage_>40WKW', 'max_anyage_>40WKW', 'count_anyage_>40WKW', 'sum_anyage_>40WKW', 'mean_anyage_>40WKW', 'any_anyage_nonzero_WKW', 'all_anyage_nonzero_WKW', 'min_anyage_nonzero_WKW', 'max_anyage_nonzero_WKW', 'count_anyage_nonzero_WKW', 'sum_anyage_nonzero_WKW', 'mean_anyage_nonzero_WKW', '%_anyage_nonzero_WKW', 'min_anyage_any_WKW', 'max_anyage_any_WKW', 'count_anyage_any_WKW', 'sum_anyage_any_WKW', 'mean_anyage_any_WKW', 'any_adult_no_work_hrs', 'all_adult_no_work_hrs', 'min_adult_no_work_hrs', 'max_adult_no_work_hrs', 'count_adult_no_work_hrs', 'sum_adult_no_work_hrs', 'mean_adult_no_work_hrs', '%_adult_no_work_hrs', 'any_adult_<10_work_hrs', 'all_adult_<10_work_hrs', 'min_adult_<10_work_hrs', 'max_adult_<10_work_hrs', 'count_adult_<10_work_hrs', 'sum_adult_<10_work_hrs', 'mean_adult_<10_work_hrs', '%_adult_<10_work_hrs', 'any_adult_<15_work_hrs', 'all_adult_<15_work_hrs', 'min_adult_<15_work_hrs', 'max_adult_<15_work_hrs', 'count_adult_<15_work_hrs', 'sum_adult_<15_work_hrs', 'mean_adult_<15_work_hrs', '%_adult_<15_work_hrs', 'any_adult_<20_work_hrs', 'all_adult_<20_work_hrs', 'min_adult_<20_work_hrs', 'max_adult_<20_work_hrs', 'count_adult_<20_work_hrs', 'sum_adult_<20_work_hrs', 'mean_adult_<20_work_hrs', '%_adult_<20_work_hrs', 'sum_adult_<30_work_hrs', 'mean_adult_<30_work_hrs', 'mean_adult_<40_work_hrs', 'any_adult_50_plus_work_hrs', 'all_adult_50_plus_work_hrs', 'max_adult_50_plus_work_hrs', 'sum_adult_50_plus_work_hrs', 'mean_adult_50_plus_work_hrs', '%_adult_50_plus_work_hrs', 'any_adult_40_plus_work_hrs', 'all_adult_40_plus_work_hrs', 'max_adult_40_plus_work_hrs', 'mean_adult_40_plus_work_hrs', '%_adult_40_plus_work_hrs', 'min_adult_any_WKHP', 'max_adult_any_WKHP', 'count_adult_any_WKHP', 'sum_adult_any_WKHP', 'mean_adult_any_WKHP', 'any_65+_no_work_hrs', 'all_65+_no_work_hrs', 'min_65+_no_work_hrs', 'max_65+_no_work_hrs', 'count_65+_no_work_hrs', 'sum_65+_no_work_hrs', 'mean_65+_no_work_hrs', '%_65+_no_work_hrs', 'any_65+_<10_work_hrs', 'all_65+_<10_work_hrs', 'min_65+_<10_work_hrs', 'max_65+_<10_work_hrs', 'count_65+_<10_work_hrs', 'sum_65+_<10_work_hrs', 'mean_65+_<10_work_hrs', '%_65+_<10_work_hrs', 'any_65+_<15_work_hrs', 'all_65+_<15_work_hrs', 'min_65+_<15_work_hrs', 'max_65+_<15_work_hrs', 'count_65+_<15_work_hrs', 'sum_65+_<15_work_hrs', 'mean_65+_<15_work_hrs', '%_65+_<15_work_hrs', 'any_65+_<20_work_hrs', 'all_65+_<20_work_hrs', 'min_65+_<20_work_hrs', 'max_65+_<20_work_hrs', 'count_65+_<20_work_hrs', 'sum_65+_<20_work_hrs', 'mean_65+_<20_work_hrs', '%_65+_<20_work_hrs', 'any_65+_<30_work_hrs', 'all_65+_<30_work_hrs', 'min_65+_<30_work_hrs', 'max_65+_<30_work_hrs', 'count_65+_<30_work_hrs', 'sum_65+_<30_work_hrs', 'mean_65+_<30_work_hrs', '%_65+_<30_work_hrs', 'any_65+_<40_work_hrs', 'all_65+_<40_work_hrs', 'min_65+_<40_work_hrs', 'max_65+_<40_work_hrs', 'count_65+_<40_work_hrs', 'sum_65+_<40_work_hrs', 'mean_65+_<40_work_hrs', '%_65+_<40_work_hrs', 'any_65+_<50_work_hrs', 'all_65+_<50_work_hrs', 'min_65+_<50_work_hrs', 'max_65+_<50_work_hrs', 'count_65+_<50_work_hrs', 'sum_65+_<50_work_hrs', 'mean_65+_<50_work_hrs', '%_65+_<50_work_hrs', 'max_65+_50_plus_work_hrs', 'sum_65+_50_plus_work_hrs', 'mean_65+_50_plus_work_hrs', 'min_65+_40_plus_work_hrs', 'max_65+_40_plus_work_hrs', 'count_65+_40_plus_work_hrs', 'sum_65+_40_plus_work_hrs', 'mean_65+_40_plus_work_hrs', '%_65+_40_plus_work_hrs', 'any_65+_any_WKHP', 'all_65+_any_WKHP', 'min_65+_any_WKHP', 'max_65+_any_WKHP', 'count_65+_any_WKHP', 'sum_65+_any_WKHP', 'mean_65+_any_WKHP', '%_65+_any_WKHP', 'any_18-64_no_work_hrs', 'all_18-64_no_work_hrs', 'min_18-64_no_work_hrs', 'max_18-64_no_work_hrs', 'count_18-64_no_work_hrs', 'sum_18-64_no_work_hrs', 'mean_18-64_no_work_hrs', '%_18-64_no_work_hrs', 'any_18-64_<10_work_hrs', 'all_18-64_<10_work_hrs', 'min_18-64_<10_work_hrs', 'max_18-64_<10_work_hrs', 'count_18-64_<10_work_hrs', 'sum_18-64_<10_work_hrs', 'mean_18-64_<10_work_hrs', '%_18-64_<10_work_hrs', 'any_18-64_<15_work_hrs', 'all_18-64_<15_work_hrs', 'min_18-64_<15_work_hrs', 'max_18-64_<15_work_hrs', 'count_18-64_<15_work_hrs', 'sum_18-64_<15_work_hrs', 'mean_18-64_<15_work_hrs', '%_18-64_<15_work_hrs', 'any_18-64_<20_work_hrs', 'all_18-64_<20_work_hrs', 'min_18-64_<20_work_hrs', 'max_18-64_<20_work_hrs', 'count_18-64_<20_work_hrs', 'sum_18-64_<20_work_hrs', 'mean_18-64_<20_work_hrs', '%_18-64_<20_work_hrs', 'mean_18-64_<30_work_hrs', 'mean_18-64_<40_work_hrs', 'mean_18-64_<50_work_hrs', '%_18-64_<50_work_hrs', 'any_18-64_50_plus_work_hrs', 'all_18-64_50_plus_work_hrs', 'min_18-64_50_plus_work_hrs', 'max_18-64_50_plus_work_hrs', 'count_18-64_50_plus_work_hrs', 'sum_18-64_50_plus_work_hrs', 'mean_18-64_50_plus_work_hrs', '%_18-64_50_plus_work_hrs', 'max_18-64_40_plus_work_hrs', 'count_18-64_40_plus_work_hrs', 'mean_18-64_40_plus_work_hrs', 'any_18-64_any_WKHP', 'all_18-64_any_WKHP', 'min_18-64_any_WKHP', 'max_18-64_any_WKHP', 'count_18-64_any_WKHP', 'sum_18-64_any_WKHP', 'mean_18-64_any_WKHP', '%_18-64_any_WKHP', 'any_kid_no_work_hrs', 'all_kid_no_work_hrs', 'min_kid_no_work_hrs', 'max_kid_no_work_hrs', 'count_kid_no_work_hrs', 'sum_kid_no_work_hrs', 'mean_kid_no_work_hrs', '%_kid_no_work_hrs', 'any_kid_<10_work_hrs', 'all_kid_<10_work_hrs', 'min_kid_<10_work_hrs', 'max_kid_<10_work_hrs', 'count_kid_<10_work_hrs', 'sum_kid_<10_work_hrs', 'mean_kid_<10_work_hrs', '%_kid_<10_work_hrs', 'any_kid_<15_work_hrs', 'all_kid_<15_work_hrs', 'min_kid_<15_work_hrs', 'max_kid_<15_work_hrs', 'count_kid_<15_work_hrs', 'sum_kid_<15_work_hrs', 'mean_kid_<15_work_hrs', '%_kid_<15_work_hrs', 'any_kid_<20_work_hrs', 'all_kid_<20_work_hrs', 'min_kid_<20_work_hrs', 'max_kid_<20_work_hrs', 'count_kid_<20_work_hrs', 'sum_kid_<20_work_hrs', 'mean_kid_<20_work_hrs', '%_kid_<20_work_hrs', 'any_kid_<30_work_hrs', 'all_kid_<30_work_hrs', 'min_kid_<30_work_hrs', 'max_kid_<30_work_hrs', 'count_kid_<30_work_hrs', 'sum_kid_<30_work_hrs', 'mean_kid_<30_work_hrs', '%_kid_<30_work_hrs', 'any_kid_<40_work_hrs', 'all_kid_<40_work_hrs', 'min_kid_<40_work_hrs', 'max_kid_<40_work_hrs', 'count_kid_<40_work_hrs', 'sum_kid_<40_work_hrs', 'mean_kid_<40_work_hrs', '%_kid_<40_work_hrs', 'any_kid_<50_work_hrs', 'all_kid_<50_work_hrs', 'min_kid_<50_work_hrs', 'max_kid_<50_work_hrs', 'count_kid_<50_work_hrs', 'sum_kid_<50_work_hrs', 'mean_kid_<50_work_hrs', '%_kid_<50_work_hrs', 'max_kid_40_plus_work_hrs', 'sum_kid_40_plus_work_hrs', 'mean_kid_40_plus_work_hrs', 'any_kid_any_WKHP', 'all_kid_any_WKHP', 'min_kid_any_WKHP', 'max_kid_any_WKHP', 'count_kid_any_WKHP', 'sum_kid_any_WKHP', 'mean_kid_any_WKHP', '%_kid_any_WKHP', 'any_anyage_no_work_hrs', 'all_anyage_no_work_hrs', 'min_anyage_no_work_hrs', 'max_anyage_no_work_hrs', 'count_anyage_no_work_hrs', 'sum_anyage_no_work_hrs', 'mean_anyage_no_work_hrs', '%_anyage_no_work_hrs', 'any_anyage_<10_work_hrs', 'all_anyage_<10_work_hrs', 'min_anyage_<10_work_hrs', 'max_anyage_<10_work_hrs', 'count_anyage_<10_work_hrs', 'sum_anyage_<10_work_hrs', 'mean_anyage_<10_work_hrs', '%_anyage_<10_work_hrs', 'any_anyage_<15_work_hrs', 'all_anyage_<15_work_hrs', 'min_anyage_<15_work_hrs', 'max_anyage_<15_work_hrs', 'count_anyage_<15_work_hrs', 'sum_anyage_<15_work_hrs', 'mean_anyage_<15_work_hrs', '%_anyage_<15_work_hrs', 'any_anyage_<20_work_hrs', 'all_anyage_<20_work_hrs', 'min_anyage_<20_work_hrs', 'max_anyage_<20_work_hrs', 'count_anyage_<20_work_hrs', 'sum_anyage_<20_work_hrs', 'mean_anyage_<20_work_hrs', '%_anyage_<20_work_hrs', 'all_anyage_<30_work_hrs', 'min_anyage_<30_work_hrs', 'max_anyage_<30_work_hrs', 'count_anyage_<30_work_hrs', 'sum_anyage_<30_work_hrs', 'mean_anyage_<30_work_hrs', 'all_anyage_<40_work_hrs', 'max_anyage_<40_work_hrs', 'sum_anyage_<40_work_hrs', 'mean_anyage_<40_work_hrs', '%_anyage_<40_work_hrs', 'any_anyage_<50_work_hrs', 'all_anyage_<50_work_hrs', 'max_anyage_<50_work_hrs', 'count_anyage_<50_work_hrs', 'sum_anyage_<50_work_hrs', 'mean_anyage_<50_work_hrs', '%_anyage_<50_work_hrs', 'any_anyage_50_plus_work_hrs', 'all_anyage_50_plus_work_hrs', 'min_anyage_50_plus_work_hrs', 'max_anyage_50_plus_work_hrs', 'count_anyage_50_plus_work_hrs', 'sum_anyage_50_plus_work_hrs', 'mean_anyage_50_plus_work_hrs', '%_anyage_50_plus_work_hrs', 'any_anyage_40_plus_work_hrs', 'all_anyage_40_plus_work_hrs', 'min_anyage_40_plus_work_hrs', 'max_anyage_40_plus_work_hrs', 'count_anyage_40_plus_work_hrs', 'sum_anyage_40_plus_work_hrs', 'mean_anyage_40_plus_work_hrs', '%_anyage_40_plus_work_hrs', 'min_anyage_any_WKHP', 'max_anyage_any_WKHP', 'count_anyage_any_WKHP', 'sum_anyage_any_WKHP', 'mean_anyage_any_WKHP', 'max_adult_DIS', 'sum_adult_DIS', 'mean_adult_DIS', 'any_adult_not_DIS', 'all_adult_not_DIS', 'mean_adult_not_DIS', '%_adult_not_DIS', 'min_adult_any_DIS', 'max_adult_any_DIS', 'count_adult_any_DIS', 'sum_adult_any_DIS', 'mean_adult_any_DIS', 'min_65+_DIS', 'max_65+_DIS', 'count_65+_DIS', 'sum_65+_DIS', 'mean_65+_DIS', '%_65+_DIS', 'min_65+_not_DIS', 'max_65+_not_DIS', 'sum_65+_not_DIS', 'mean_65+_not_DIS', '%_65+_not_DIS', 'any_65+_any_DIS', 'all_65+_any_DIS', 'min_65+_any_DIS', 'max_65+_any_DIS', 'count_65+_any_DIS', 'sum_65+_any_DIS', 'mean_65+_any_DIS', '%_65+_any_DIS', 'min_18-64_DIS', 'max_18-64_DIS', 'sum_18-64_DIS', 'mean_18-64_DIS', 'mean_18-64_not_DIS', '%_18-64_not_DIS', 'any_18-64_any_DIS', 'all_18-64_any_DIS', 'min_18-64_any_DIS', 'max_18-64_any_DIS', 'count_18-64_any_DIS', 'sum_18-64_any_DIS', 'mean_18-64_any_DIS', '%_18-64_any_DIS', 'max_kid_DIS', 'mean_kid_DIS', 'any_kid_not_DIS', 'all_kid_not_DIS', 'min_kid_not_DIS', 'max_kid_not_DIS', 'count_kid_not_DIS', 'sum_kid_not_DIS', 'mean_kid_not_DIS', '%_kid_not_DIS', 'any_kid_any_DIS', 'all_kid_any_DIS', 'min_kid_any_DIS', 'max_kid_any_DIS', 'count_kid_any_DIS', 'sum_kid_any_DIS', 'mean_kid_any_DIS', '%_kid_any_DIS', 'any_anyage_DIS', 'all_anyage_DIS', 'min_anyage_DIS', 'max_anyage_DIS', 'count_anyage_DIS', 'sum_anyage_DIS', 'mean_anyage_DIS', '%_anyage_DIS', 'any_anyage_not_DIS', 'all_anyage_not_DIS', 'max_anyage_not_DIS', 'sum_anyage_not_DIS', '%_anyage_not_DIS', 'min_anyage_any_DIS', 'max_anyage_any_DIS', 'count_anyage_any_DIS', 'sum_anyage_any_DIS', 'mean_anyage_any_DIS', 'all_adult_NP1', 'max_adult_NP1', 'count_adult_NP1', 'sum_adult_NP1', 'mean_adult_NP1', '%_adult_NP1', 'all_adult_NP2', 'max_adult_NP2', 'count_adult_NP2', 'sum_adult_NP2', 'mean_adult_NP2', '%_adult_NP2', 'all_adult_NP3', 'count_adult_NP3', 'sum_adult_NP3', 'mean_adult_NP3', '%_adult_NP3', 'all_adult_NP4', 'max_adult_NP4', 'sum_adult_NP4', 'mean_adult_NP4', '%_adult_NP4', 'all_adult_NP5', 'max_adult_NP5', 'sum_adult_NP5', 'mean_adult_NP5', '%_adult_NP5', 'all_adult_NP>5', 'sum_adult_NP>5', 'mean_adult_NP>5', '%_adult_NP>5', 'all_adult_NP>6', 'max_adult_NP>6', 'sum_adult_NP>6', 'mean_adult_NP>6', '%_adult_NP>6', 'all_adult_NP>8', 'max_adult_NP>8', 'sum_adult_NP>8', 'mean_adult_NP>8', '%_adult_NP>8', 'sum_adult_NP>10', 'mean_adult_NP>10', 'sum_adult_NP>12', 'mean_adult_NP>12', 'min_adult_anyNP', 'max_adult_anyNP', 'count_adult_anyNP', 'sum_adult_anyNP', 'mean_adult_anyNP', 'all_65+_NP1', 'min_65+_NP1', 'max_65+_NP1', 'count_65+_NP1', 'sum_65+_NP1', 'mean_65+_NP1', '%_65+_NP1', 'all_65+_NP2', 'min_65+_NP2', 'max_65+_NP2', 'sum_65+_NP2', 'mean_65+_NP2', '%_65+_NP2', 'all_65+_NP3', 'min_65+_NP3', 'max_65+_NP3', 'sum_65+_NP3', 'mean_65+_NP3', '%_65+_NP3', 'all_65+_NP4', 'min_65+_NP4', 'max_65+_NP4', 'sum_65+_NP4', 'mean_65+_NP4', '%_65+_NP4', 'all_65+_NP5', 'min_65+_NP5', 'max_65+_NP5', 'sum_65+_NP5', 'mean_65+_NP5', '%_65+_NP5', 'all_65+_NP>5', 'min_65+_NP>5', 'max_65+_NP>5', 'sum_65+_NP>5', 'mean_65+_NP>5', '%_65+_NP>5', 'max_65+_NP>6', 'sum_65+_NP>6', 'mean_65+_NP>6', 'max_65+_NP>8', 'mean_65+_NP>8', 'max_65+_NP>10', 'mean_65+_NP>10', 'max_65+_NP>12', 'sum_65+_NP>12', 'mean_65+_NP>12', 'any_65+_anyNP', 'all_65+_anyNP', 'min_65+_anyNP', 'max_65+_anyNP', 'count_65+_anyNP', 'sum_65+_anyNP', 'mean_65+_anyNP', '%_65+_anyNP', 'all_18-64_NP1', 'min_18-64_NP1', 'max_18-64_NP1', 'count_18-64_NP1', 'sum_18-64_NP1', 'mean_18-64_NP1', '%_18-64_NP1', 'all_18-64_NP2', 'max_18-64_NP2', 'sum_18-64_NP2', 'mean_18-64_NP2', '%_18-64_NP2', 'any_18-64_NP3', 'all_18-64_NP3', 'min_18-64_NP3', 'max_18-64_NP3', 'sum_18-64_NP3', 'mean_18-64_NP3', '%_18-64_NP3', 'any_18-64_NP4', 'all_18-64_NP4', 'min_18-64_NP4', 'max_18-64_NP4', 'count_18-64_NP4', 'sum_18-64_NP4', 'mean_18-64_NP4', '%_18-64_NP4', 'any_18-64_NP5', 'all_18-64_NP5', 'min_18-64_NP5', 'max_18-64_NP5', 'count_18-64_NP5', 'sum_18-64_NP5', 'mean_18-64_NP5', '%_18-64_NP5', 'any_18-64_NP>5', 'all_18-64_NP>5', 'max_18-64_NP>5', 'count_18-64_NP>5', 'sum_18-64_NP>5', 'mean_18-64_NP>5', '%_18-64_NP>5', 'any_18-64_NP>6', 'all_18-64_NP>6', 'min_18-64_NP>6', 'max_18-64_NP>6', 'count_18-64_NP>6', 'sum_18-64_NP>6', 'mean_18-64_NP>6', '%_18-64_NP>6', 'max_18-64_NP>8', 'count_18-64_NP>8', 'sum_18-64_NP>8', 'mean_18-64_NP>8', 'min_18-64_NP>10', 'max_18-64_NP>10', 'count_18-64_NP>10', 'sum_18-64_NP>10', 'mean_18-64_NP>10', 'min_18-64_NP>12', 'max_18-64_NP>12', 'count_18-64_NP>12', 'sum_18-64_NP>12', 'mean_18-64_NP>12', 'any_18-64_anyNP', 'all_18-64_anyNP', 'min_18-64_anyNP', 'max_18-64_anyNP', 'count_18-64_anyNP', 'sum_18-64_anyNP', 'mean_18-64_anyNP', '%_18-64_anyNP', 'max_kid_NP1', 'sum_kid_NP1', 'mean_kid_NP1', 'all_kid_NP2', 'max_kid_NP2', 'count_kid_NP2', 'sum_kid_NP2', 'mean_kid_NP2', '%_kid_NP2', 'max_kid_NP3', 'count_kid_NP3', 'sum_kid_NP3', 'mean_kid_NP3', '%_kid_NP3', 'all_kid_NP4', 'count_kid_NP4', 'sum_kid_NP4', 'mean_kid_NP4', '%_kid_NP4', 'all_kid_NP5', 'mean_kid_NP5', '%_kid_NP5', 'all_kid_NP>5', 'mean_kid_NP>5', '%_kid_NP>5', 'all_kid_NP>6', 'mean_kid_NP>6', '%_kid_NP>6', 'sum_kid_NP>8', 'mean_kid_NP>8', 'mean_kid_NP>10', 'sum_kid_NP>12', 'mean_kid_NP>12', 'any_kid_anyNP', 'all_kid_anyNP', 'min_kid_anyNP', 'max_kid_anyNP', 'count_kid_anyNP', 'sum_kid_anyNP', 'mean_kid_anyNP', '%_kid_anyNP', 'any_anyage_NP1', 'all_anyage_NP1', 'min_anyage_NP1', 'max_anyage_NP1', 'count_anyage_NP1', 'sum_anyage_NP1', 'mean_anyage_NP1', '%_anyage_NP1', 'any_anyage_NP2', 'all_anyage_NP2', 'min_anyage_NP2', 'max_anyage_NP2', 'count_anyage_NP2', 'sum_anyage_NP2', 'mean_anyage_NP2', '%_anyage_NP2', 'any_anyage_NP3', 'all_anyage_NP3', 'max_anyage_NP3', 'count_anyage_NP3', 'sum_anyage_NP3', 'mean_anyage_NP3', '%_anyage_NP3', 'any_anyage_NP4', 'all_anyage_NP4', 'max_anyage_NP4', 'count_anyage_NP4', 'sum_anyage_NP4', 'mean_anyage_NP4', '%_anyage_NP4', 'any_anyage_NP5', 'all_anyage_NP5', 'max_anyage_NP5', 'sum_anyage_NP5', 'mean_anyage_NP5', '%_anyage_NP5', 'any_anyage_NP>5', 'all_anyage_NP>5', 'max_anyage_NP>5', 'sum_anyage_NP>5', 'mean_anyage_NP>5', '%_anyage_NP>5', 'any_anyage_NP>6', 'all_anyage_NP>6', 'max_anyage_NP>6', 'sum_anyage_NP>6', 'mean_anyage_NP>6', '%_anyage_NP>6', 'any_anyage_NP>8', 'all_anyage_NP>8', 'max_anyage_NP>8', 'sum_anyage_NP>8', 'mean_anyage_NP>8', '%_anyage_NP>8', 'max_anyage_NP>10', 'sum_anyage_NP>10', 'mean_anyage_NP>10', 'min_anyage_NP>12', 'max_anyage_NP>12', 'count_anyage_NP>12', 'sum_anyage_NP>12', 'mean_anyage_NP>12', 'min_anyage_anyNP', 'max_anyage_anyNP', 'count_anyage_anyNP', 'sum_anyage_anyNP', 'mean_anyage_anyNP', 'count_adult_work_trans', 'all_65+_work_trans', 'count_65+_work_trans', 'sum_65+_work_trans', 'mean_65+_work_trans', '%_65+_work_trans', 'all_18-64_work_trans', 'count_18-64_work_trans', 'sum_18-64_work_trans', '%_18-64_work_trans', 'all_kid_work_trans', 'count_kid_work_trans', 'sum_kid_work_trans', '%_kid_work_trans', 'any_anyage_work_trans', 'max_anyage_work_trans', 'count_anyage_work_trans', 'sum_anyage_work_trans', 'mean_anyage_work_trans', 'max_adult_WAG0', 'sum_adult_WAG0', 'mean_adult_WAG0', 'sum_adult_WAG<10', 'mean_adult_WAG<10', 'min_adult_WAG<15', 'max_adult_WAG<15', 'sum_adult_WAG<15', 'mean_adult_WAG<15', 'min_adult_WAG<20', 'max_adult_WAG<20', 'count_adult_WAG<20', 'sum_adult_WAG<20', 'mean_adult_WAG<20', 'min_adult_WAG<25', 'max_adult_WAG<25', 'count_adult_WAG<25', 'sum_adult_WAG<25', 'mean_adult_WAG<25', 'min_adult_WAG<30', 'max_adult_WAG<30', 'count_adult_WAG<30', 'sum_adult_WAG<30', 'mean_adult_WAG<30', 'min_adult_WAG<35', 'max_adult_WAG<35', 'count_adult_WAG<35', 'sum_adult_WAG<35', 'mean_adult_WAG<35', 'min_adult_WAG<40', 'max_adult_WAG<40', 'count_adult_WAG<40', 'sum_adult_WAG<40', 'mean_adult_WAG<40', 'min_adult_WAG<45', 'max_adult_WAG<45', 'count_adult_WAG<45', 'sum_adult_WAG<45', 'mean_adult_WAG<45', 'min_adult_WAG<50', 'max_adult_WAG<50', 'count_adult_WAG<50', 'sum_adult_WAG<50', 'mean_adult_WAG<50', 'max_adult_WAG<60', 'count_adult_WAG<60', 'sum_adult_WAG<60', 'mean_adult_WAG<60', 'max_adult_WAG<70', 'count_adult_WAG<70', 'sum_adult_WAG<70', 'mean_adult_WAG<70', 'min_adult_WAG<80', 'max_adult_WAG<80', 'count_adult_WAG<80', 'sum_adult_WAG<80', 'mean_adult_WAG<80', 'min_adult_WAG_any', 'max_adult_WAG_any', 'count_adult_WAG_any', 'sum_adult_WAG_any', 'mean_adult_WAG_any', 'any_65+_WAG0', 'all_65+_WAG0', 'min_65+_WAG0', 'max_65+_WAG0', 'count_65+_WAG0', 'sum_65+_WAG0', 'mean_65+_WAG0', '%_65+_WAG0', 'any_65+_WAG<10', 'all_65+_WAG<10', 'min_65+_WAG<10', 'max_65+_WAG<10', 'count_65+_WAG<10', 'sum_65+_WAG<10', 'mean_65+_WAG<10', '%_65+_WAG<10', 'any_65+_WAG<15', 'all_65+_WAG<15', 'min_65+_WAG<15', 'max_65+_WAG<15', 'count_65+_WAG<15', 'sum_65+_WAG<15', 'mean_65+_WAG<15', '%_65+_WAG<15', 'any_65+_WAG<20', 'all_65+_WAG<20', 'min_65+_WAG<20', 'max_65+_WAG<20', 'count_65+_WAG<20', 'sum_65+_WAG<20', 'mean_65+_WAG<20', '%_65+_WAG<20', 'any_65+_WAG<25', 'all_65+_WAG<25', 'min_65+_WAG<25', 'max_65+_WAG<25', 'count_65+_WAG<25', 'sum_65+_WAG<25', 'mean_65+_WAG<25', '%_65+_WAG<25', 'any_65+_WAG<30', 'all_65+_WAG<30', 'min_65+_WAG<30', 'max_65+_WAG<30', 'count_65+_WAG<30', 'sum_65+_WAG<30', 'mean_65+_WAG<30', '%_65+_WAG<30', 'any_65+_WAG<35', 'all_65+_WAG<35', 'min_65+_WAG<35', 'max_65+_WAG<35', 'count_65+_WAG<35', 'sum_65+_WAG<35', 'mean_65+_WAG<35', '%_65+_WAG<35', 'any_65+_WAG<40', 'all_65+_WAG<40', 'min_65+_WAG<40', 'max_65+_WAG<40', 'count_65+_WAG<40', 'sum_65+_WAG<40', 'mean_65+_WAG<40', '%_65+_WAG<40', 'any_65+_WAG<45', 'all_65+_WAG<45', 'min_65+_WAG<45', 'max_65+_WAG<45', 'count_65+_WAG<45', 'sum_65+_WAG<45', 'mean_65+_WAG<45', '%_65+_WAG<45', 'any_65+_WAG<50', 'all_65+_WAG<50', 'min_65+_WAG<50', 'max_65+_WAG<50', 'count_65+_WAG<50', 'sum_65+_WAG<50', 'mean_65+_WAG<50', '%_65+_WAG<50', 'any_65+_WAG<60', 'all_65+_WAG<60', 'min_65+_WAG<60', 'max_65+_WAG<60', 'count_65+_WAG<60', 'sum_65+_WAG<60', 'mean_65+_WAG<60', '%_65+_WAG<60', 'any_65+_WAG<70', 'all_65+_WAG<70', 'min_65+_WAG<70', 'max_65+_WAG<70', 'count_65+_WAG<70', 'sum_65+_WAG<70', 'mean_65+_WAG<70', '%_65+_WAG<70', 'any_65+_WAG<80', 'all_65+_WAG<80', 'min_65+_WAG<80', 'max_65+_WAG<80', 'count_65+_WAG<80', 'sum_65+_WAG<80', 'mean_65+_WAG<80', '%_65+_WAG<80', 'any_65+_WAG_any', 'all_65+_WAG_any', 'min_65+_WAG_any', 'max_65+_WAG_any', 'count_65+_WAG_any', 'sum_65+_WAG_any', 'mean_65+_WAG_any', '%_65+_WAG_any', 'max_18-64_WAG0', 'mean_18-64_WAG0', 'mean_18-64_WAG<10', 'mean_18-64_WAG<15', 'count_18-64_WAG<20', 'sum_18-64_WAG<20', 'mean_18-64_WAG<20', 'count_18-64_WAG<25', 'sum_18-64_WAG<25', 'mean_18-64_WAG<25', 'max_18-64_WAG<30', 'count_18-64_WAG<30', 'sum_18-64_WAG<30', 'mean_18-64_WAG<30', 'max_18-64_WAG<35', 'count_18-64_WAG<35', 'sum_18-64_WAG<35', 'mean_18-64_WAG<35', 'max_18-64_WAG<40', 'count_18-64_WAG<40', 'sum_18-64_WAG<40', 'mean_18-64_WAG<40', 'any_18-64_WAG<45', 'max_18-64_WAG<45', 'count_18-64_WAG<45', 'sum_18-64_WAG<45', 'mean_18-64_WAG<45', 'any_18-64_WAG<50', 'min_18-64_WAG<50', 'max_18-64_WAG<50', 'count_18-64_WAG<50', 'sum_18-64_WAG<50', 'mean_18-64_WAG<50', '%_18-64_WAG<50', 'count_18-64_WAG<60', 'sum_18-64_WAG<60', 'mean_18-64_WAG<60', 'count_18-64_WAG<70', 'sum_18-64_WAG<70', 'mean_18-64_WAG<70', 'max_18-64_WAG<80', 'count_18-64_WAG<80', 'sum_18-64_WAG<80', 'mean_18-64_WAG<80', 'any_18-64_WAG_any', 'all_18-64_WAG_any', 'min_18-64_WAG_any', 'max_18-64_WAG_any', 'count_18-64_WAG_any', 'sum_18-64_WAG_any', 'mean_18-64_WAG_any', '%_18-64_WAG_any', 'any_kid_WAG0', 'all_kid_WAG0', 'min_kid_WAG0', 'max_kid_WAG0', 'count_kid_WAG0', 'sum_kid_WAG0', 'mean_kid_WAG0', '%_kid_WAG0', 'any_kid_WAG<10', 'all_kid_WAG<10', 'min_kid_WAG<10', 'max_kid_WAG<10', 'count_kid_WAG<10', 'sum_kid_WAG<10', 'mean_kid_WAG<10', '%_kid_WAG<10', 'any_kid_WAG<15', 'all_kid_WAG<15', 'min_kid_WAG<15', 'max_kid_WAG<15', 'count_kid_WAG<15', 'sum_kid_WAG<15', 'mean_kid_WAG<15', '%_kid_WAG<15', 'any_kid_WAG<20', 'all_kid_WAG<20', 'min_kid_WAG<20', 'max_kid_WAG<20', 'count_kid_WAG<20', 'sum_kid_WAG<20', 'mean_kid_WAG<20', '%_kid_WAG<20', 'any_kid_WAG<25', 'all_kid_WAG<25', 'min_kid_WAG<25', 'max_kid_WAG<25', 'count_kid_WAG<25', 'sum_kid_WAG<25', 'mean_kid_WAG<25', '%_kid_WAG<25', 'any_kid_WAG<30', 'all_kid_WAG<30', 'min_kid_WAG<30', 'max_kid_WAG<30', 'count_kid_WAG<30', 'sum_kid_WAG<30', 'mean_kid_WAG<30', '%_kid_WAG<30', 'any_kid_WAG<35', 'all_kid_WAG<35', 'min_kid_WAG<35', 'max_kid_WAG<35', 'count_kid_WAG<35', 'sum_kid_WAG<35', 'mean_kid_WAG<35', '%_kid_WAG<35', 'any_kid_WAG<40', 'all_kid_WAG<40', 'min_kid_WAG<40', 'max_kid_WAG<40', 'count_kid_WAG<40', 'sum_kid_WAG<40', 'mean_kid_WAG<40', '%_kid_WAG<40', 'any_kid_WAG<45', 'all_kid_WAG<45', 'min_kid_WAG<45', 'max_kid_WAG<45', 'count_kid_WAG<45', 'sum_kid_WAG<45', 'mean_kid_WAG<45', '%_kid_WAG<45', 'any_kid_WAG<50', 'all_kid_WAG<50', 'min_kid_WAG<50', 'max_kid_WAG<50', 'count_kid_WAG<50', 'sum_kid_WAG<50', 'mean_kid_WAG<50', '%_kid_WAG<50', 'any_kid_WAG<60', 'all_kid_WAG<60', 'min_kid_WAG<60', 'max_kid_WAG<60', 'count_kid_WAG<60', 'sum_kid_WAG<60', 'mean_kid_WAG<60', '%_kid_WAG<60', 'any_kid_WAG<70', 'all_kid_WAG<70', 'min_kid_WAG<70', 'max_kid_WAG<70', 'count_kid_WAG<70', 'sum_kid_WAG<70', 'mean_kid_WAG<70', '%_kid_WAG<70', 'any_kid_WAG<80', 'all_kid_WAG<80', 'min_kid_WAG<80', 'max_kid_WAG<80', 'count_kid_WAG<80', 'sum_kid_WAG<80', 'mean_kid_WAG<80', '%_kid_WAG<80', 'any_kid_WAG_any', 'all_kid_WAG_any', 'min_kid_WAG_any', 'max_kid_WAG_any', 'count_kid_WAG_any', 'sum_kid_WAG_any', 'mean_kid_WAG_any', '%_kid_WAG_any', 'all_anyage_WAG0', 'min_anyage_WAG0', 'max_anyage_WAG0', 'count_anyage_WAG0', 'sum_anyage_WAG0', 'mean_anyage_WAG0', 'all_anyage_WAG<10', 'max_anyage_WAG<10', 'count_anyage_WAG<10', 'sum_anyage_WAG<10', 'mean_anyage_WAG<10', 'all_anyage_WAG<15', 'min_anyage_WAG<15', 'max_anyage_WAG<15', 'count_anyage_WAG<15', 'sum_anyage_WAG<15', 'mean_anyage_WAG<15', 'all_anyage_WAG<20', 'min_anyage_WAG<20', 'max_anyage_WAG<20', 'count_anyage_WAG<20', 'sum_anyage_WAG<20', 'mean_anyage_WAG<20', 'all_anyage_WAG<25', 'min_anyage_WAG<25', 'max_anyage_WAG<25', 'count_anyage_WAG<25', 'sum_anyage_WAG<25', 'mean_anyage_WAG<25', '%_anyage_WAG<25', 'all_anyage_WAG<30', 'min_anyage_WAG<30', 'max_anyage_WAG<30', 'count_anyage_WAG<30', 'sum_anyage_WAG<30', 'mean_anyage_WAG<30', '%_anyage_WAG<30', 'all_anyage_WAG<35', 'min_anyage_WAG<35', 'max_anyage_WAG<35', 'count_anyage_WAG<35', 'sum_anyage_WAG<35', 'mean_anyage_WAG<35', '%_anyage_WAG<35', 'all_anyage_WAG<40', 'min_anyage_WAG<40', 'max_anyage_WAG<40', 'count_anyage_WAG<40', 'sum_anyage_WAG<40', 'mean_anyage_WAG<40', '%_anyage_WAG<40', 'all_anyage_WAG<45', 'min_anyage_WAG<45', 'max_anyage_WAG<45', 'count_anyage_WAG<45', 'sum_anyage_WAG<45', 'mean_anyage_WAG<45', '%_anyage_WAG<45', 'all_anyage_WAG<50', 'min_anyage_WAG<50', 'max_anyage_WAG<50', 'count_anyage_WAG<50', 'sum_anyage_WAG<50', 'mean_anyage_WAG<50', '%_anyage_WAG<50', 'all_anyage_WAG<60', 'min_anyage_WAG<60', 'max_anyage_WAG<60', 'count_anyage_WAG<60', 'sum_anyage_WAG<60', 'mean_anyage_WAG<60', '%_anyage_WAG<60', 'all_anyage_WAG<70', 'min_anyage_WAG<70', 'max_anyage_WAG<70', 'count_anyage_WAG<70', 'sum_anyage_WAG<70', 'mean_anyage_WAG<70', '%_anyage_WAG<70', 'all_anyage_WAG<80', 'min_anyage_WAG<80', 'max_anyage_WAG<80', 'count_anyage_WAG<80', 'sum_anyage_WAG<80', 'mean_anyage_WAG<80', '%_anyage_WAG<80', 'min_anyage_WAG_any', 'max_anyage_WAG_any', 'count_anyage_WAG_any', 'sum_anyage_WAG_any', 'mean_anyage_WAG_any', 'max_adult_INT1q', 'sum_adult_INT1q', 'mean_adult_INT1q', 'max_adult_INT2q', 'count_adult_INT2q', 'sum_adult_INT2q', 'mean_adult_INT2q', 'min_adult_INT3q', 'max_adult_INT3q', 'count_adult_INT3q', 'sum_adult_INT3q', 'mean_adult_INT3q', 'min_adult_INT4q', 'max_adult_INT4q', 'count_adult_INT4q', 'sum_adult_INT4q', 'mean_adult_INT4q', 'min_adult_INT_any', 'max_adult_INT_any', 'count_adult_INT_any', 'sum_adult_INT_any', 'mean_adult_INT_any', 'all_65+_INT0', 'min_65+_INT0', 'max_65+_INT0', 'sum_65+_INT0', 'mean_65+_INT0', '%_65+_INT0', 'min_65+_INT1q', 'max_65+_INT1q', 'count_65+_INT1q', 'sum_65+_INT1q', 'mean_65+_INT1q', '%_65+_INT1q', 'min_65+_INT2q', 'max_65+_INT2q', 'count_65+_INT2q', 'sum_65+_INT2q', 'mean_65+_INT2q', '%_65+_INT2q', 'min_65+_INT3q', 'max_65+_INT3q', 'count_65+_INT3q', 'sum_65+_INT3q', 'mean_65+_INT3q', '%_65+_INT3q', 'min_65+_INT4q', 'max_65+_INT4q', 'count_65+_INT4q', 'sum_65+_INT4q', 'mean_65+_INT4q', '%_65+_INT4q', 'any_65+_INT_any', 'all_65+_INT_any', 'min_65+_INT_any', 'max_65+_INT_any', 'count_65+_INT_any', 'sum_65+_INT_any', 'mean_65+_INT_any', '%_65+_INT_any', 'mean_18-64_INT0', '%_18-64_INT0', 'min_18-64_INT1q', 'max_18-64_INT1q', 'sum_18-64_INT1q', 'mean_18-64_INT1q', 'min_18-64_INT2q', 'max_18-64_INT2q', 'count_18-64_INT2q', 'sum_18-64_INT2q', 'mean_18-64_INT2q', 'min_18-64_INT3q', 'max_18-64_INT3q', 'count_18-64_INT3q', 'sum_18-64_INT3q', 'mean_18-64_INT3q', 'min_18-64_INT4q', 'max_18-64_INT4q', 'count_18-64_INT4q', 'sum_18-64_INT4q', 'mean_18-64_INT4q', 'any_18-64_INT_any', 'all_18-64_INT_any', 'min_18-64_INT_any', 'max_18-64_INT_any', 'count_18-64_INT_any', 'sum_18-64_INT_any', 'mean_18-64_INT_any', '%_18-64_INT_any', 'any_kid_INT0', 'all_kid_INT0', 'min_kid_INT0', 'max_kid_INT0', 'count_kid_INT0', 'sum_kid_INT0', 'mean_kid_INT0', '%_kid_INT0', 'max_kid_INT1q', 'sum_kid_INT1q', 'mean_kid_INT1q', 'max_kid_INT2q', 'sum_kid_INT2q', 'mean_kid_INT2q', 'max_kid_INT3q', 'sum_kid_INT3q', 'mean_kid_INT3q', 'any_kid_INT_any', 'all_kid_INT_any', 'min_kid_INT_any', 'max_kid_INT_any', 'count_kid_INT_any', 'sum_kid_INT_any', 'mean_kid_INT_any', '%_kid_INT_any', 'all_anyage_INT0', 'max_anyage_INT0', 'count_anyage_INT0', 'sum_anyage_INT0', '%_anyage_INT0', 'any_anyage_INT1q', 'all_anyage_INT1q', 'min_anyage_INT1q', 'max_anyage_INT1q', 'count_anyage_INT1q', 'sum_anyage_INT1q', 'mean_anyage_INT1q', '%_anyage_INT1q', 'any_anyage_INT2q', 'all_anyage_INT2q', 'min_anyage_INT2q', 'max_anyage_INT2q', 'count_anyage_INT2q', 'sum_anyage_INT2q', 'mean_anyage_INT2q', '%_anyage_INT2q', 'any_anyage_INT3q', 'all_anyage_INT3q', 'min_anyage_INT3q', 'max_anyage_INT3q', 'count_anyage_INT3q', 'sum_anyage_INT3q', 'mean_anyage_INT3q', '%_anyage_INT3q', 'any_anyage_INT4q', 'all_anyage_INT4q', 'min_anyage_INT4q', 'max_anyage_INT4q', 'count_anyage_INT4q', 'sum_anyage_INT4q', 'mean_anyage_INT4q', '%_anyage_INT4q', 'min_anyage_INT_any', 'max_anyage_INT_any', 'count_anyage_INT_any', 'sum_anyage_INT_any', 'mean_anyage_INT_any', 'sum_adult_SEMP0', 'max_adult_SEMP1q', 'count_adult_SEMP1q', 'sum_adult_SEMP1q', 'mean_adult_SEMP1q', 'min_adult_SEMP2q', 'max_adult_SEMP2q', 'count_adult_SEMP2q', 'sum_adult_SEMP2q', 'mean_adult_SEMP2q', 'min_adult_SEMP3q', 'max_adult_SEMP3q', 'count_adult_SEMP3q', 'sum_adult_SEMP3q', 'mean_adult_SEMP3q', 'min_adult_SEMP4q', 'max_adult_SEMP4q', 'count_adult_SEMP4q', 'sum_adult_SEMP4q', 'mean_adult_SEMP4q', 'min_adult_SEMP_any', 'max_adult_SEMP_any', 'count_adult_SEMP_any', 'sum_adult_SEMP_any', 'mean_adult_SEMP_any', 'any_65+_SEMP0', 'all_65+_SEMP0', 'min_65+_SEMP0', 'max_65+_SEMP0', 'count_65+_SEMP0', 'sum_65+_SEMP0', 'mean_65+_SEMP0', '%_65+_SEMP0', 'max_65+_SEMP1q', 'sum_65+_SEMP1q', 'mean_65+_SEMP1q', 'max_65+_SEMP2q', 'sum_65+_SEMP2q', 'mean_65+_SEMP2q', 'max_65+_SEMP3q', 'sum_65+_SEMP3q', 'mean_65+_SEMP3q', 'max_65+_SEMP4q', 'sum_65+_SEMP4q', 'mean_65+_SEMP4q', 'any_65+_SEMP_any', 'all_65+_SEMP_any', 'min_65+_SEMP_any', 'max_65+_SEMP_any', 'count_65+_SEMP_any', 'sum_65+_SEMP_any', 'mean_65+_SEMP_any', '%_65+_SEMP_any', 'count_18-64_SEMP0', 'sum_18-64_SEMP0', 'mean_18-64_SEMP0', '%_18-64_SEMP0', 'min_18-64_SEMP1q', 'max_18-64_SEMP1q', 'count_18-64_SEMP1q', 'sum_18-64_SEMP1q', 'mean_18-64_SEMP1q', 'min_18-64_SEMP2q', 'max_18-64_SEMP2q', 'count_18-64_SEMP2q', 'sum_18-64_SEMP2q', 'mean_18-64_SEMP2q', 'any_18-64_SEMP3q', 'min_18-64_SEMP3q', 'max_18-64_SEMP3q', 'count_18-64_SEMP3q', 'sum_18-64_SEMP3q', 'mean_18-64_SEMP3q', 'min_18-64_SEMP4q', 'max_18-64_SEMP4q', 'count_18-64_SEMP4q', 'sum_18-64_SEMP4q', 'mean_18-64_SEMP4q', 'any_18-64_SEMP_any', 'all_18-64_SEMP_any', 'min_18-64_SEMP_any', 'max_18-64_SEMP_any', 'count_18-64_SEMP_any', 'sum_18-64_SEMP_any', 'mean_18-64_SEMP_any', '%_18-64_SEMP_any', 'any_kid_SEMP0', 'all_kid_SEMP0', 'min_kid_SEMP0', 'max_kid_SEMP0', 'count_kid_SEMP0', 'sum_kid_SEMP0', 'mean_kid_SEMP0', '%_kid_SEMP0', 'max_kid_SEMP1q', 'sum_kid_SEMP1q', 'mean_kid_SEMP1q', 'any_kid_SEMP_any', 'all_kid_SEMP_any', 'min_kid_SEMP_any', 'max_kid_SEMP_any', 'count_kid_SEMP_any', 'sum_kid_SEMP_any', 'mean_kid_SEMP_any', '%_kid_SEMP_any', 'all_anyage_SEMP0', 'max_anyage_SEMP0', 'count_anyage_SEMP0', 'sum_anyage_SEMP0', '%_anyage_SEMP0', 'any_anyage_SEMP1q', 'min_anyage_SEMP1q', 'max_anyage_SEMP1q', 'count_anyage_SEMP1q', 'sum_anyage_SEMP1q', 'mean_anyage_SEMP1q', 'any_anyage_SEMP2q', 'min_anyage_SEMP2q', 'max_anyage_SEMP2q', 'count_anyage_SEMP2q', 'sum_anyage_SEMP2q', 'mean_anyage_SEMP2q', '%_anyage_SEMP2q', 'any_anyage_SEMP3q', 'min_anyage_SEMP3q', 'max_anyage_SEMP3q', 'count_anyage_SEMP3q', 'sum_anyage_SEMP3q', 'mean_anyage_SEMP3q', 'any_anyage_SEMP4q', 'min_anyage_SEMP4q', 'max_anyage_SEMP4q', 'count_anyage_SEMP4q', 'sum_anyage_SEMP4q', 'mean_anyage_SEMP4q', '%_anyage_SEMP4q', 'min_anyage_SEMP_any', 'max_anyage_SEMP_any', 'count_anyage_SEMP_any', 'sum_anyage_SEMP_any', 'mean_anyage_SEMP_any', 'mean_adult_SSP0', 'min_adult_SSP1q', 'max_adult_SSP1q', 'count_adult_SSP1q', 'sum_adult_SSP1q', 'mean_adult_SSP1q', 'min_adult_SSP2q', 'max_adult_SSP2q', 'count_adult_SSP2q', 'sum_adult_SSP2q', 'mean_adult_SSP2q', 'min_adult_SSP3q', 'max_adult_SSP3q', 'count_adult_SSP3q', 'sum_adult_SSP3q', 'mean_adult_SSP3q', 'min_adult_SSP4q', 'max_adult_SSP4q', 'count_adult_SSP4q', 'sum_adult_SSP4q', 'mean_adult_SSP4q', 'min_adult_SSP_any', 'max_adult_SSP_any', 'count_adult_SSP_any', 'sum_adult_SSP_any', 'mean_adult_SSP_any', 'min_65+_SSP0', 'max_65+_SSP0', 'count_65+_SSP0', 'sum_65+_SSP0', 'mean_65+_SSP0', '%_65+_SSP0', 'min_65+_SSP1q', 'max_65+_SSP1q', 'count_65+_SSP1q', 'sum_65+_SSP1q', 'mean_65+_SSP1q', '%_65+_SSP1q', 'min_65+_SSP2q', 'max_65+_SSP2q', 'count_65+_SSP2q', 'sum_65+_SSP2q', 'mean_65+_SSP2q', '%_65+_SSP2q', 'any_65+_SSP3q', 'min_65+_SSP3q', 'max_65+_SSP3q', 'count_65+_SSP3q', 'sum_65+_SSP3q', 'mean_65+_SSP3q', '%_65+_SSP3q', 'any_65+_SSP4q', 'min_65+_SSP4q', 'max_65+_SSP4q', 'count_65+_SSP4q', 'sum_65+_SSP4q', 'mean_65+_SSP4q', '%_65+_SSP4q', 'any_65+_SSP_any', 'all_65+_SSP_any', 'min_65+_SSP_any', 'max_65+_SSP_any', 'count_65+_SSP_any', 'sum_65+_SSP_any', 'mean_65+_SSP_any', '%_65+_SSP_any', 'count_18-64_SSP0', 'sum_18-64_SSP0', 'mean_18-64_SSP0', '%_18-64_SSP0', 'min_18-64_SSP1q', 'max_18-64_SSP1q', 'count_18-64_SSP1q', 'sum_18-64_SSP1q', 'mean_18-64_SSP1q', 'min_18-64_SSP2q', 'max_18-64_SSP2q', 'count_18-64_SSP2q', 'sum_18-64_SSP2q', 'mean_18-64_SSP2q', 'min_18-64_SSP3q', 'max_18-64_SSP3q', 'count_18-64_SSP3q', 'sum_18-64_SSP3q', 'mean_18-64_SSP3q', 'min_18-64_SSP4q', 'max_18-64_SSP4q', 'count_18-64_SSP4q', 'sum_18-64_SSP4q', 'mean_18-64_SSP4q', 'any_18-64_SSP_any', 'all_18-64_SSP_any', 'min_18-64_SSP_any', 'max_18-64_SSP_any', 'count_18-64_SSP_any', 'sum_18-64_SSP_any', 'mean_18-64_SSP_any', '%_18-64_SSP_any', 'any_kid_SSP0', 'all_kid_SSP0', 'min_kid_SSP0', 'max_kid_SSP0', 'count_kid_SSP0', 'sum_kid_SSP0', 'mean_kid_SSP0', '%_kid_SSP0', 'max_kid_SSP1q', 'mean_kid_SSP1q', 'max_kid_SSP2q', 'sum_kid_SSP2q', 'mean_kid_SSP2q', 'max_kid_SSP3q', 'sum_kid_SSP3q', 'mean_kid_SSP3q', 'any_kid_SSP_any', 'all_kid_SSP_any', 'min_kid_SSP_any', 'max_kid_SSP_any', 'count_kid_SSP_any', 'sum_kid_SSP_any', 'mean_kid_SSP_any', '%_kid_SSP_any', 'any_anyage_SSP0', 'all_anyage_SSP0', 'max_anyage_SSP0', 'sum_anyage_SSP0', '%_anyage_SSP0', 'any_anyage_SSP1q', 'all_anyage_SSP1q', 'min_anyage_SSP1q', 'max_anyage_SSP1q', 'count_anyage_SSP1q', 'sum_anyage_SSP1q', 'mean_anyage_SSP1q', '%_anyage_SSP1q', 'any_anyage_SSP2q', 'all_anyage_SSP2q', 'min_anyage_SSP2q', 'max_anyage_SSP2q', 'count_anyage_SSP2q', 'sum_anyage_SSP2q', 'mean_anyage_SSP2q', '%_anyage_SSP2q', 'any_anyage_SSP3q', 'all_anyage_SSP3q', 'min_anyage_SSP3q', 'max_anyage_SSP3q', 'count_anyage_SSP3q', 'sum_anyage_SSP3q', 'mean_anyage_SSP3q', '%_anyage_SSP3q', 'any_anyage_SSP4q', 'all_anyage_SSP4q', 'min_anyage_SSP4q', 'max_anyage_SSP4q', 'count_anyage_SSP4q', 'sum_anyage_SSP4q', 'mean_anyage_SSP4q', '%_anyage_SSP4q', 'min_anyage_SSP_any', 'max_anyage_SSP_any', 'count_anyage_SSP_any', 'sum_anyage_SSP_any', 'mean_anyage_SSP_any', 'count_adult_SSIP0', 'min_adult_SSIP1q', 'max_adult_SSIP1q', 'count_adult_SSIP1q', 'sum_adult_SSIP1q', 'mean_adult_SSIP1q', 'max_adult_SSIP2q', 'count_adult_SSIP2q', 'sum_adult_SSIP2q', 'mean_adult_SSIP2q', 'min_adult_SSIP3q', 'max_adult_SSIP3q', 'count_adult_SSIP3q', 'sum_adult_SSIP3q', 'mean_adult_SSIP3q', 'min_adult_SSIP_any', 'max_adult_SSIP_any', 'count_adult_SSIP_any', 'sum_adult_SSIP_any', 'mean_adult_SSIP_any', 'all_65+_SSIP0', 'min_65+_SSIP0', 'max_65+_SSIP0', 'sum_65+_SSIP0', 'mean_65+_SSIP0', '%_65+_SSIP0', 'min_65+_SSIP1q', 'max_65+_SSIP1q', 'count_65+_SSIP1q', 'sum_65+_SSIP1q', 'mean_65+_SSIP1q', 'max_65+_SSIP2q', 'count_65+_SSIP2q', 'sum_65+_SSIP2q', 'mean_65+_SSIP2q', 'min_65+_SSIP3q', 'max_65+_SSIP3q', 'count_65+_SSIP3q', 'sum_65+_SSIP3q', 'mean_65+_SSIP3q', '%_65+_SSIP3q', 'any_65+_SSIP_any', 'all_65+_SSIP_any', 'min_65+_SSIP_any', 'max_65+_SSIP_any', 'count_65+_SSIP_any', 'sum_65+_SSIP_any', 'mean_65+_SSIP_any', '%_65+_SSIP_any', 'count_18-64_SSIP0', 'sum_18-64_SSIP0', 'mean_18-64_SSIP0', '%_18-64_SSIP0', 'max_18-64_SSIP1q', 'sum_18-64_SSIP1q', 'mean_18-64_SSIP1q', 'max_18-64_SSIP2q', 'sum_18-64_SSIP2q', 'mean_18-64_SSIP2q', 'min_18-64_SSIP3q', 'max_18-64_SSIP3q', 'count_18-64_SSIP3q', 'sum_18-64_SSIP3q', 'mean_18-64_SSIP3q', 'any_18-64_SSIP_any', 'all_18-64_SSIP_any', 'min_18-64_SSIP_any', 'max_18-64_SSIP_any', 'count_18-64_SSIP_any', 'sum_18-64_SSIP_any', 'mean_18-64_SSIP_any', '%_18-64_SSIP_any', 'any_kid_SSIP0', 'all_kid_SSIP0', 'min_kid_SSIP0', 'max_kid_SSIP0', 'count_kid_SSIP0', 'sum_kid_SSIP0', 'mean_kid_SSIP0', '%_kid_SSIP0', 'max_kid_SSIP1q', 'sum_kid_SSIP1q', 'mean_kid_SSIP1q', 'max_kid_SSIP2q', 'sum_kid_SSIP2q', 'mean_kid_SSIP2q', 'max_kid_SSIP3q', 'sum_kid_SSIP3q', 'mean_kid_SSIP3q', 'any_kid_SSIP_any', 'all_kid_SSIP_any', 'min_kid_SSIP_any', 'max_kid_SSIP_any', 'count_kid_SSIP_any', 'sum_kid_SSIP_any', 'mean_kid_SSIP_any', '%_kid_SSIP_any', 'any_anyage_SSIP0', 'all_anyage_SSIP0', 'max_anyage_SSIP0', 'count_anyage_SSIP0', 'sum_anyage_SSIP0', '%_anyage_SSIP0', 'any_anyage_SSIP1q', 'min_anyage_SSIP1q', 'max_anyage_SSIP1q', 'count_anyage_SSIP1q', 'sum_anyage_SSIP1q', 'mean_anyage_SSIP1q', 'any_anyage_SSIP2q', 'min_anyage_SSIP2q', 'max_anyage_SSIP2q', 'count_anyage_SSIP2q', 'sum_anyage_SSIP2q', 'mean_anyage_SSIP2q', 'any_anyage_SSIP3q', 'all_anyage_SSIP3q', 'min_anyage_SSIP3q', 'max_anyage_SSIP3q', 'count_anyage_SSIP3q', 'sum_anyage_SSIP3q', 'mean_anyage_SSIP3q', '%_anyage_SSIP3q', 'min_anyage_SSIP_any', 'max_anyage_SSIP_any', 'count_anyage_SSIP_any', 'sum_anyage_SSIP_any', 'mean_anyage_SSIP_any', 'count_adult_PA0', 'sum_adult_PA0', 'max_adult_PA1q', 'sum_adult_PA1q', 'mean_adult_PA1q', 'max_adult_PA2q', 'count_adult_PA2q', 'sum_adult_PA2q', 'mean_adult_PA2q', 'max_adult_PA3q', 'count_adult_PA3q', 'sum_adult_PA3q', 'mean_adult_PA3q', 'min_adult_PA_any', 'max_adult_PA_any', 'count_adult_PA_any', 'sum_adult_PA_any', 'mean_adult_PA_any', 'any_65+_PA0', 'all_65+_PA0', 'min_65+_PA0', 'max_65+_PA0', 'count_65+_PA0', 'sum_65+_PA0', 'mean_65+_PA0', '%_65+_PA0', 'max_65+_PA1q', 'sum_65+_PA1q', 'mean_65+_PA1q', 'max_65+_PA2q', 'sum_65+_PA2q', 'mean_65+_PA2q', 'max_65+_PA3q', 'sum_65+_PA3q', 'mean_65+_PA3q', 'any_65+_PA_any', 'all_65+_PA_any', 'min_65+_PA_any', 'max_65+_PA_any', 'count_65+_PA_any', 'sum_65+_PA_any', 'mean_65+_PA_any', '%_65+_PA_any', 'all_18-64_PA0', 'min_18-64_PA0', 'max_18-64_PA0', 'count_18-64_PA0', 'sum_18-64_PA0', 'mean_18-64_PA0', '%_18-64_PA0', 'max_18-64_PA1q', 'sum_18-64_PA1q', 'mean_18-64_PA1q', 'min_18-64_PA2q', 'max_18-64_PA2q', 'count_18-64_PA2q', 'sum_18-64_PA2q', 'mean_18-64_PA2q', 'min_18-64_PA3q', 'max_18-64_PA3q', 'count_18-64_PA3q', 'sum_18-64_PA3q', 'mean_18-64_PA3q', 'any_18-64_PA_any', 'all_18-64_PA_any', 'min_18-64_PA_any', 'max_18-64_PA_any', 'count_18-64_PA_any', 'sum_18-64_PA_any', 'mean_18-64_PA_any', '%_18-64_PA_any', 'any_kid_PA0', 'all_kid_PA0', 'min_kid_PA0', 'max_kid_PA0', 'count_kid_PA0', 'sum_kid_PA0', 'mean_kid_PA0', '%_kid_PA0', 'max_kid_PA1q', 'mean_kid_PA1q', 'max_kid_PA2q', 'sum_kid_PA2q', 'mean_kid_PA2q', 'max_kid_PA3q', 'sum_kid_PA3q', 'mean_kid_PA3q', 'any_kid_PA_any', 'all_kid_PA_any', 'min_kid_PA_any', 'max_kid_PA_any', 'count_kid_PA_any', 'sum_kid_PA_any', 'mean_kid_PA_any', '%_kid_PA_any', 'all_anyage_PA0', 'min_anyage_PA0', 'max_anyage_PA0', 'count_anyage_PA0', 'sum_anyage_PA0', 'min_anyage_PA1q', 'max_anyage_PA1q', 'count_anyage_PA1q', 'sum_anyage_PA1q', 'mean_anyage_PA1q', 'any_anyage_PA2q', 'min_anyage_PA2q', 'max_anyage_PA2q', 'count_anyage_PA2q', 'sum_anyage_PA2q', 'mean_anyage_PA2q', 'any_anyage_PA3q', 'min_anyage_PA3q', 'max_anyage_PA3q', 'count_anyage_PA3q', 'sum_anyage_PA3q', 'mean_anyage_PA3q', 'min_anyage_PA_any', 'max_anyage_PA_any', 'count_anyage_PA_any', 'sum_anyage_PA_any', 'mean_anyage_PA_any', 'min_adult_RETP1q', 'max_adult_RETP1q', 'count_adult_RETP1q', 'sum_adult_RETP1q', 'mean_adult_RETP1q', 'min_adult_RETP2q', 'max_adult_RETP2q', 'count_adult_RETP2q', 'sum_adult_RETP2q', 'mean_adult_RETP2q', 'min_adult_RETP3q', 'max_adult_RETP3q', 'count_adult_RETP3q', 'sum_adult_RETP3q', 'mean_adult_RETP3q', 'min_adult_RETP_any', 'max_adult_RETP_any', 'count_adult_RETP_any', 'sum_adult_RETP_any', 'mean_adult_RETP_any', '%_65+_RETP0', 'min_65+_RETP1q', 'max_65+_RETP1q', 'count_65+_RETP1q', 'sum_65+_RETP1q', 'mean_65+_RETP1q', '%_65+_RETP1q', 'min_65+_RETP2q', 'max_65+_RETP2q', 'count_65+_RETP2q', 'sum_65+_RETP2q', 'mean_65+_RETP2q', '%_65+_RETP2q', 'min_65+_RETP3q', 'max_65+_RETP3q', 'count_65+_RETP3q', 'sum_65+_RETP3q', 'mean_65+_RETP3q', '%_65+_RETP3q', 'any_65+_RETP_any', 'all_65+_RETP_any', 'min_65+_RETP_any', 'max_65+_RETP_any', 'count_65+_RETP_any', 'sum_65+_RETP_any', 'mean_65+_RETP_any', '%_65+_RETP_any', 'count_18-64_RETP0', '%_18-64_RETP0', 'max_18-64_RETP1q', 'count_18-64_RETP1q', 'sum_18-64_RETP1q', 'mean_18-64_RETP1q', 'max_18-64_RETP2q', 'sum_18-64_RETP2q', 'mean_18-64_RETP2q', 'min_18-64_RETP3q', 'max_18-64_RETP3q', 'count_18-64_RETP3q', 'sum_18-64_RETP3q', 'mean_18-64_RETP3q', 'any_18-64_RETP_any', 'all_18-64_RETP_any', 'min_18-64_RETP_any', 'max_18-64_RETP_any', 'count_18-64_RETP_any', 'sum_18-64_RETP_any', 'mean_18-64_RETP_any', '%_18-64_RETP_any', 'all_kid_RETP0', 'count_kid_RETP0', '%_kid_RETP0', 'max_kid_RETP1q', 'sum_kid_RETP1q', 'mean_kid_RETP1q', 'any_kid_RETP_any', 'all_kid_RETP_any', 'min_kid_RETP_any', 'max_kid_RETP_any', 'count_kid_RETP_any', 'sum_kid_RETP_any', 'mean_kid_RETP_any', '%_kid_RETP_any', 'any_anyage_RETP1q', 'all_anyage_RETP1q', 'min_anyage_RETP1q', 'max_anyage_RETP1q', 'count_anyage_RETP1q', 'sum_anyage_RETP1q', 'mean_anyage_RETP1q', '%_anyage_RETP1q', 'any_anyage_RETP2q', 'all_anyage_RETP2q', 'min_anyage_RETP2q', 'max_anyage_RETP2q', 'count_anyage_RETP2q', 'sum_anyage_RETP2q', 'mean_anyage_RETP2q', '%_anyage_RETP2q', 'any_anyage_RETP3q', 'all_anyage_RETP3q', 'min_anyage_RETP3q', 'max_anyage_RETP3q', 'count_anyage_RETP3q', 'sum_anyage_RETP3q', 'mean_anyage_RETP3q', '%_anyage_RETP3q', 'min_anyage_RETP_any', 'max_anyage_RETP_any', 'count_anyage_RETP_any', 'sum_anyage_RETP_any', 'mean_anyage_RETP_any', 'max_adult_OI1q', 'count_adult_OI1q', 'sum_adult_OI1q', 'mean_adult_OI1q', 'max_adult_OI2q', 'count_adult_OI2q', 'sum_adult_OI2q', 'mean_adult_OI2q', 'max_adult_OI3q', 'count_adult_OI3q', 'sum_adult_OI3q', 'mean_adult_OI3q', 'min_adult_OI_any', 'max_adult_OI_any', 'count_adult_OI_any', 'sum_adult_OI_any', 'mean_adult_OI_any', 'max_65+_OI1q', 'sum_65+_OI1q', 'mean_65+_OI1q', 'max_65+_OI2q', 'sum_65+_OI2q', 'mean_65+_OI2q', 'min_65+_OI3q', 'max_65+_OI3q', 'count_65+_OI3q', 'sum_65+_OI3q', 'mean_65+_OI3q', 'any_65+_OI_any', 'all_65+_OI_any', 'min_65+_OI_any', 'max_65+_OI_any', 'count_65+_OI_any', 'sum_65+_OI_any', 'mean_65+_OI_any', '%_65+_OI_any', 'max_18-64_OI1q', 'sum_18-64_OI1q', 'mean_18-64_OI1q', 'min_18-64_OI2q', 'max_18-64_OI2q', 'count_18-64_OI2q', 'sum_18-64_OI2q', 'mean_18-64_OI2q', 'min_18-64_OI3q', 'max_18-64_OI3q', 'count_18-64_OI3q', 'sum_18-64_OI3q', 'mean_18-64_OI3q', 'any_18-64_OI_any', 'all_18-64_OI_any', 'min_18-64_OI_any', 'max_18-64_OI_any', 'count_18-64_OI_any', 'sum_18-64_OI_any', 'mean_18-64_OI_any', '%_18-64_OI_any', 'max_kid_OI1q', 'sum_kid_OI1q', 'mean_kid_OI1q', 'max_kid_OI2q', 'sum_kid_OI2q', 'mean_kid_OI2q', 'max_kid_OI3q', 'sum_kid_OI3q', 'mean_kid_OI3q', 'any_kid_OI_any', 'all_kid_OI_any', 'min_kid_OI_any', 'max_kid_OI_any', 'count_kid_OI_any', 'sum_kid_OI_any', 'mean_kid_OI_any', '%_kid_OI_any', 'min_anyage_OI1q', 'max_anyage_OI1q', 'count_anyage_OI1q', 'sum_anyage_OI1q', 'mean_anyage_OI1q', 'any_anyage_OI2q', 'min_anyage_OI2q', 'max_anyage_OI2q', 'count_anyage_OI2q', 'sum_anyage_OI2q', 'mean_anyage_OI2q', 'any_anyage_OI3q', 'min_anyage_OI3q', 'max_anyage_OI3q', 'count_anyage_OI3q', 'sum_anyage_OI3q', 'mean_anyage_OI3q', '%_anyage_OI3q', 'min_anyage_OI_any', 'max_anyage_OI_any', 'count_anyage_OI_any', 'sum_anyage_OI_any', 'mean_anyage_OI_any', 'max_adult_White', 'mean_adult_White', '%_adult_White', 'all_adult_Black', 'sum_adult_Black', 'mean_adult_Black', '%_adult_Black', 'sum_adult_Asian', 'mean_adult_Asian', '%_adult_Asian', 'sum_adult_Hisp', 'mean_adult_Hisp', '%_adult_Hisp', 'max_adult_ETH_other', 'sum_adult_ETH_other', 'mean_adult_ETH_other', 'min_adult_ETH_any', 'max_adult_ETH_any', 'count_adult_ETH_any', 'sum_adult_ETH_any', 'mean_adult_ETH_any', 'all_65+_White', 'min_65+_White', 'max_65+_White', 'sum_65+_White', 'mean_65+_White', '%_65+_White', 'all_65+_Black', 'min_65+_Black', 'max_65+_Black', 'sum_65+_Black', 'mean_65+_Black', '%_65+_Black', 'all_65+_Asian', 'min_65+_Asian', 'max_65+_Asian', 'sum_65+_Asian', 'mean_65+_Asian', '%_65+_Asian', 'all_65+_Hisp', 'min_65+_Hisp', 'max_65+_Hisp', 'sum_65+_Hisp', 'mean_65+_Hisp', '%_65+_Hisp', 'max_65+_ETH_other', 'mean_65+_ETH_other', 'any_65+_ETH_any', 'all_65+_ETH_any', 'min_65+_ETH_any', 'max_65+_ETH_any', 'count_65+_ETH_any', 'sum_65+_ETH_any', 'mean_65+_ETH_any', '%_65+_ETH_any', 'max_18-64_White', 'sum_18-64_White', 'mean_18-64_White', '%_18-64_White', 'all_18-64_Black', 'max_18-64_Black', 'sum_18-64_Black', 'mean_18-64_Black', '%_18-64_Black', 'max_18-64_Asian', 'count_18-64_Asian', 'sum_18-64_Asian', 'mean_18-64_Asian', '%_18-64_Asian', 'max_18-64_Hisp', 'count_18-64_Hisp', 'sum_18-64_Hisp', 'mean_18-64_Hisp', '%_18-64_Hisp', 'any_18-64_ETH_other', 'max_18-64_ETH_other', 'count_18-64_ETH_other', 'sum_18-64_ETH_other', 'mean_18-64_ETH_other', '%_18-64_ETH_other', 'any_18-64_ETH_any', 'all_18-64_ETH_any', 'min_18-64_ETH_any', 'max_18-64_ETH_any', 'count_18-64_ETH_any', 'sum_18-64_ETH_any', 'mean_18-64_ETH_any', '%_18-64_ETH_any', 'all_kid_White', 'mean_kid_White', '%_kid_White', 'all_kid_Black', 'mean_kid_Black', '%_kid_Black', 'all_kid_Asian', 'mean_kid_Asian', '%_kid_Asian', 'all_kid_Hisp', 'mean_kid_Hisp', '%_kid_Hisp', 'mean_kid_ETH_other', '%_kid_ETH_other', 'any_kid_ETH_any', 'all_kid_ETH_any', 'min_kid_ETH_any', 'max_kid_ETH_any', 'count_kid_ETH_any', 'sum_kid_ETH_any', 'mean_kid_ETH_any', '%_kid_ETH_any', 'any_anyage_White', 'all_anyage_White', 'min_anyage_White', 'max_anyage_White', 'sum_anyage_White', 'mean_anyage_White', '%_anyage_White', 'any_anyage_Black', 'all_anyage_Black', 'max_anyage_Black', 'sum_anyage_Black', 'mean_anyage_Black', '%_anyage_Black', 'any_anyage_Asian', 'all_anyage_Asian', 'max_anyage_Asian', 'count_anyage_Asian', 'sum_anyage_Asian', 'mean_anyage_Asian', '%_anyage_Asian', 'any_anyage_Hisp', 'all_anyage_Hisp', 'max_anyage_Hisp', 'sum_anyage_Hisp', 'mean_anyage_Hisp', '%_anyage_Hisp', 'all_anyage_ETH_other', 'max_anyage_ETH_other', 'sum_anyage_ETH_other', 'mean_anyage_ETH_other', '%_anyage_ETH_other', 'min_anyage_ETH_any', 'max_anyage_ETH_any', 'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any', 'max_adult_TINP0', 'sum_adult_TINP0', 'mean_adult_TINP0', 'mean_adult_TINP<10', 'mean_adult_TINP<15', 'mean_adult_TINP<20', 'mean_adult_TINP<25', 'count_adult_TINP<30', 'sum_adult_TINP<30', 'mean_adult_TINP<30', 'count_adult_TINP<35', 'sum_adult_TINP<35', 'mean_adult_TINP<35', 'count_adult_TINP<40', 'sum_adult_TINP<40', 'mean_adult_TINP<40', 'max_adult_TINP<45', 'count_adult_TINP<45', 'sum_adult_TINP<45', 'mean_adult_TINP<45', 'min_adult_TINP<50', 'max_adult_TINP<50', 'count_adult_TINP<50', 'sum_adult_TINP<50', 'mean_adult_TINP<50', 'count_adult_TINP<60', 'sum_adult_TINP<60', 'mean_adult_TINP<60', 'count_adult_TINP<70', 'sum_adult_TINP<70', 'mean_adult_TINP<70', 'count_adult_TINP<80', 'sum_adult_TINP<80', 'mean_adult_TINP<80', 'min_adult_TINP_any', 'max_adult_TINP_any', 'count_adult_TINP_any', 'sum_adult_TINP_any', 'mean_adult_TINP_any', 'min_65+_TINP0', 'max_65+_TINP0', 'count_65+_TINP0', 'sum_65+_TINP0', 'mean_65+_TINP0', '%_65+_TINP0', 'min_65+_TINP<10', 'max_65+_TINP<10', 'count_65+_TINP<10', 'sum_65+_TINP<10', 'mean_65+_TINP<10', '%_65+_TINP<10', 'min_65+_TINP<15', 'max_65+_TINP<15', 'sum_65+_TINP<15', 'mean_65+_TINP<15', '%_65+_TINP<15', 'min_65+_TINP<20', 'max_65+_TINP<20', 'sum_65+_TINP<20', 'mean_65+_TINP<20', '%_65+_TINP<20', 'min_65+_TINP<25', 'max_65+_TINP<25', 'sum_65+_TINP<25', 'mean_65+_TINP<25', '%_65+_TINP<25', 'any_65+_TINP<30', 'min_65+_TINP<30', 'max_65+_TINP<30', 'count_65+_TINP<30', 'sum_65+_TINP<30', 'mean_65+_TINP<30', '%_65+_TINP<30', 'any_65+_TINP<35', 'all_65+_TINP<35', 'min_65+_TINP<35', 'max_65+_TINP<35', 'count_65+_TINP<35', 'sum_65+_TINP<35', 'mean_65+_TINP<35', '%_65+_TINP<35', 'any_65+_TINP<40', 'all_65+_TINP<40', 'min_65+_TINP<40', 'max_65+_TINP<40', 'count_65+_TINP<40', 'sum_65+_TINP<40', 'mean_65+_TINP<40', '%_65+_TINP<40', 'any_65+_TINP<45', 'all_65+_TINP<45', 'min_65+_TINP<45', 'max_65+_TINP<45', 'count_65+_TINP<45', 'sum_65+_TINP<45', 'mean_65+_TINP<45', '%_65+_TINP<45', 'any_65+_TINP<50', 'all_65+_TINP<50', 'min_65+_TINP<50', 'max_65+_TINP<50', 'count_65+_TINP<50', 'sum_65+_TINP<50', 'mean_65+_TINP<50', '%_65+_TINP<50', 'any_65+_TINP<60', 'all_65+_TINP<60', 'min_65+_TINP<60', 'max_65+_TINP<60', 'count_65+_TINP<60', 'sum_65+_TINP<60', 'mean_65+_TINP<60', '%_65+_TINP<60', 'any_65+_TINP<70', 'all_65+_TINP<70', 'min_65+_TINP<70', 'max_65+_TINP<70', 'count_65+_TINP<70', 'sum_65+_TINP<70', 'mean_65+_TINP<70', '%_65+_TINP<70', 'any_65+_TINP<80', 'all_65+_TINP<80', 'min_65+_TINP<80', 'max_65+_TINP<80', 'count_65+_TINP<80', 'sum_65+_TINP<80', 'mean_65+_TINP<80', '%_65+_TINP<80', 'any_65+_TINP_any', 'all_65+_TINP_any', 'min_65+_TINP_any', 'max_65+_TINP_any', 'count_65+_TINP_any', 'sum_65+_TINP_any', 'mean_65+_TINP_any', '%_65+_TINP_any', 'max_18-64_TINP0', 'count_18-64_TINP0', 'sum_18-64_TINP0', 'mean_18-64_TINP0', 'max_18-64_TINP<10', 'mean_18-64_TINP<10', 'mean_18-64_TINP<15', 'count_18-64_TINP<20', 'mean_18-64_TINP<20', 'count_18-64_TINP<25', 'mean_18-64_TINP<25', 'count_18-64_TINP<30', 'sum_18-64_TINP<30', 'mean_18-64_TINP<30', 'count_18-64_TINP<35', 'sum_18-64_TINP<35', 'mean_18-64_TINP<35', 'count_18-64_TINP<40', 'sum_18-64_TINP<40', 'mean_18-64_TINP<40', 'any_18-64_TINP<45', 'max_18-64_TINP<45', 'count_18-64_TINP<45', 'sum_18-64_TINP<45', 'mean_18-64_TINP<45', '%_18-64_TINP<45', 'any_18-64_TINP<50', 'min_18-64_TINP<50', 'max_18-64_TINP<50', 'count_18-64_TINP<50', 'sum_18-64_TINP<50', 'mean_18-64_TINP<50', '%_18-64_TINP<50', 'any_18-64_TINP<60', 'all_18-64_TINP<60', 'min_18-64_TINP<60', 'max_18-64_TINP<60', 'count_18-64_TINP<60', 'sum_18-64_TINP<60', 'mean_18-64_TINP<60', '%_18-64_TINP<60', 'any_18-64_TINP<70', 'all_18-64_TINP<70', 'min_18-64_TINP<70', 'max_18-64_TINP<70', 'count_18-64_TINP<70', 'sum_18-64_TINP<70', 'mean_18-64_TINP<70', '%_18-64_TINP<70', 'any_18-64_TINP<80', 'all_18-64_TINP<80', 'min_18-64_TINP<80', 'max_18-64_TINP<80', 'count_18-64_TINP<80', 'sum_18-64_TINP<80', 'mean_18-64_TINP<80', '%_18-64_TINP<80', 'any_18-64_TINP_any', 'all_18-64_TINP_any', 'min_18-64_TINP_any', 'max_18-64_TINP_any', 'count_18-64_TINP_any', 'sum_18-64_TINP_any', 'mean_18-64_TINP_any', '%_18-64_TINP_any', 'any_kid_TINP0', 'all_kid_TINP0', 'min_kid_TINP0', 'max_kid_TINP0', 'count_kid_TINP0', 'sum_kid_TINP0', 'mean_kid_TINP0', '%_kid_TINP0', 'any_kid_TINP<10', 'all_kid_TINP<10', 'min_kid_TINP<10', 'max_kid_TINP<10', 'count_kid_TINP<10', 'sum_kid_TINP<10', 'mean_kid_TINP<10', '%_kid_TINP<10', 'any_kid_TINP<15', 'all_kid_TINP<15', 'min_kid_TINP<15', 'max_kid_TINP<15', 'count_kid_TINP<15', 'sum_kid_TINP<15', 'mean_kid_TINP<15', '%_kid_TINP<15', 'any_kid_TINP<20', 'all_kid_TINP<20', 'min_kid_TINP<20', 'max_kid_TINP<20', 'count_kid_TINP<20', 'sum_kid_TINP<20', 'mean_kid_TINP<20', '%_kid_TINP<20', 'any_kid_TINP<25', 'all_kid_TINP<25', 'min_kid_TINP<25', 'max_kid_TINP<25', 'count_kid_TINP<25', 'sum_kid_TINP<25', 'mean_kid_TINP<25', '%_kid_TINP<25', 'any_kid_TINP<30', 'all_kid_TINP<30', 'min_kid_TINP<30', 'max_kid_TINP<30', 'count_kid_TINP<30', 'sum_kid_TINP<30', 'mean_kid_TINP<30', '%_kid_TINP<30', 'any_kid_TINP<35', 'all_kid_TINP<35', 'min_kid_TINP<35', 'max_kid_TINP<35', 'count_kid_TINP<35', 'sum_kid_TINP<35', 'mean_kid_TINP<35', '%_kid_TINP<35', 'any_kid_TINP<40', 'all_kid_TINP<40', 'min_kid_TINP<40', 'max_kid_TINP<40', 'count_kid_TINP<40', 'sum_kid_TINP<40', 'mean_kid_TINP<40', '%_kid_TINP<40', 'any_kid_TINP<45', 'all_kid_TINP<45', 'min_kid_TINP<45', 'max_kid_TINP<45', 'count_kid_TINP<45', 'sum_kid_TINP<45', 'mean_kid_TINP<45', '%_kid_TINP<45', 'any_kid_TINP<50', 'all_kid_TINP<50', 'min_kid_TINP<50', 'max_kid_TINP<50', 'count_kid_TINP<50', 'sum_kid_TINP<50', 'mean_kid_TINP<50', '%_kid_TINP<50', 'any_kid_TINP<60', 'all_kid_TINP<60', 'min_kid_TINP<60', 'max_kid_TINP<60', 'count_kid_TINP<60', 'sum_kid_TINP<60', 'mean_kid_TINP<60', '%_kid_TINP<60', 'any_kid_TINP<70', 'all_kid_TINP<70', 'min_kid_TINP<70', 'max_kid_TINP<70', 'count_kid_TINP<70', 'sum_kid_TINP<70', 'mean_kid_TINP<70', '%_kid_TINP<70', 'any_kid_TINP<80', 'all_kid_TINP<80', 'min_kid_TINP<80', 'max_kid_TINP<80', 'count_kid_TINP<80', 'sum_kid_TINP<80', 'mean_kid_TINP<80', '%_kid_TINP<80', 'any_kid_TINP_any', 'all_kid_TINP_any', 'min_kid_TINP_any', 'max_kid_TINP_any', 'count_kid_TINP_any', 'sum_kid_TINP_any', 'mean_kid_TINP_any', '%_kid_TINP_any', 'all_anyage_TINP0', 'max_anyage_TINP0', 'mean_anyage_TINP0', 'all_anyage_TINP<10', 'max_anyage_TINP<10', 'sum_anyage_TINP<10', 'mean_anyage_TINP<10', 'all_anyage_TINP<15', 'max_anyage_TINP<15', 'count_anyage_TINP<15', 'sum_anyage_TINP<15', 'mean_anyage_TINP<15', 'all_anyage_TINP<20', 'max_anyage_TINP<20', 'count_anyage_TINP<20', 'sum_anyage_TINP<20', 'mean_anyage_TINP<20', 'all_anyage_TINP<25', 'max_anyage_TINP<25', 'count_anyage_TINP<25', 'sum_anyage_TINP<25', 'mean_anyage_TINP<25', 'all_anyage_TINP<30', 'max_anyage_TINP<30', 'count_anyage_TINP<30', 'sum_anyage_TINP<30', 'mean_anyage_TINP<30', '%_anyage_TINP<30', 'all_anyage_TINP<35', 'max_anyage_TINP<35', 'count_anyage_TINP<35', 'sum_anyage_TINP<35', 'mean_anyage_TINP<35', '%_anyage_TINP<35', 'all_anyage_TINP<40', 'max_anyage_TINP<40', 'count_anyage_TINP<40', 'sum_anyage_TINP<40', 'mean_anyage_TINP<40', '%_anyage_TINP<40', 'all_anyage_TINP<45', 'min_anyage_TINP<45', 'max_anyage_TINP<45', 'count_anyage_TINP<45', 'sum_anyage_TINP<45', 'mean_anyage_TINP<45', '%_anyage_TINP<45', 'all_anyage_TINP<50', 'min_anyage_TINP<50', 'max_anyage_TINP<50', 'count_anyage_TINP<50', 'sum_anyage_TINP<50', 'mean_anyage_TINP<50', '%_anyage_TINP<50', 'all_anyage_TINP<60', 'max_anyage_TINP<60', 'count_anyage_TINP<60', 'sum_anyage_TINP<60', 'mean_anyage_TINP<60', '%_anyage_TINP<60', 'all_anyage_TINP<70', 'max_anyage_TINP<70', 'count_anyage_TINP<70', 'sum_anyage_TINP<70', 'mean_anyage_TINP<70', '%_anyage_TINP<70', 'all_anyage_TINP<80', 'min_anyage_TINP<80', 'max_anyage_TINP<80', 'count_anyage_TINP<80', 'sum_anyage_TINP<80', 'mean_anyage_TINP<80', '%_anyage_TINP<80', 'min_anyage_TINP_any', 'max_anyage_TINP_any', 'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any', 'MSP_2_1.0', 'HousingStatus_7.0', 'HousingStatus_8.0']\n"
     ]
    }
   ],
   "source": [
    "def id_cols_to_drop(df, threshold):\n",
    "    \"\"\"\n",
    "    Identifies columns to drop from a dataframe due to high correlation.\n",
    "    Input: the dataframe of interest and the correlation coefficient threshold.\n",
    "    Output: a list of the columns to drop.  Prints elapsed time to the screen because this takes a long time for a large\n",
    "    dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "        \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    tt = time.time() - time_0\n",
    "    print('Done. Took ' + str(tt) + 'seconds.')\n",
    "\n",
    "    return(to_drop)\n",
    "    \n",
    "#tester_copy = tester.copy()\n",
    "#print(len(tester_copy.columns))\n",
    "# to_drop = id_cols_to_drop(tester_copy, 0.95)\n",
    "to_drop = ['SCHL_19', 'WAGP_adj_15', 'SSP_adj_20', 'SSIP_adj_14', 'SSIP_adj_20', 'PA_adj_14', 'PA_adj_16', 'PA_adj_17', 'PA_adj_18', 'PA_adj_19', 'PA_adj_20', 'TINP_3', 'TINP_10', 'TINP_11', 'TINP_12', 'TINP_13', 'TINP_14', 'TINP_15', 'TINP_16', 'TINP_17', 'TINP_18', 'TINP_19', 'TINP_20', 'all_65+_age', 'min_65+_age', 'max_65+_age', 'sum_65+_age', 'mean_65+_age', '%_65+_age', 'all_18-64_age', 'mean_18-64_age', '%_18-64_age', 'all_kid_age', 'mean_kid_age', '%_kid_age', 'max_anyage_age', 'sum_anyage_age', 'max_adult_non-cit', 'sum_adult_non-cit', 'mean_adult_non-cit', 'any_adult_citizen', 'all_adult_citizen', 'mean_adult_citizen', '%_adult_citizen', 'max_adult_naturalized_cit', 'sum_adult_naturalized_cit', 'mean_adult_naturalized_cit', 'min_adult_any_CIT', 'max_adult_any_CIT', 'count_adult_any_CIT', 'sum_adult_any_CIT', 'mean_adult_any_CIT', 'min_65+_non-cit', 'max_65+_non-cit', 'count_65+_non-cit', 'sum_65+_non-cit', 'mean_65+_non-cit', '%_65+_non-cit', 'all_65+_citizen', 'min_65+_citizen', 'max_65+_citizen', 'sum_65+_citizen', 'mean_65+_citizen', '%_65+_citizen', 'min_65+_naturalized_cit', 'max_65+_naturalized_cit', 'sum_65+_naturalized_cit', 'mean_65+_naturalized_cit', '%_65+_naturalized_cit', 'any_65+_any_CIT', 'all_65+_any_CIT', 'min_65+_any_CIT', 'max_65+_any_CIT', 'count_65+_any_CIT', 'sum_65+_any_CIT', 'mean_65+_any_CIT', '%_65+_any_CIT', 'max_18-64_non-cit', 'count_18-64_non-cit', 'sum_18-64_non-cit', 'mean_18-64_non-cit', 'mean_18-64_citizen', '%_18-64_citizen', 'min_18-64_naturalized_cit', 'max_18-64_naturalized_cit', 'sum_18-64_naturalized_cit', 'mean_18-64_naturalized_cit', 'any_18-64_any_CIT', 'all_18-64_any_CIT', 'min_18-64_any_CIT', 'max_18-64_any_CIT', 'count_18-64_any_CIT', 'sum_18-64_any_CIT', 'mean_18-64_any_CIT', '%_18-64_any_CIT', 'max_kid_non-cit', 'mean_kid_non-cit', 'any_kid_citizen', 'all_kid_citizen', 'min_kid_citizen', 'max_kid_citizen', 'count_kid_citizen', 'sum_kid_citizen', 'mean_kid_citizen', '%_kid_citizen', 'max_kid_naturalized_cit', 'mean_kid_naturalized_cit', 'any_kid_any_CIT', 'all_kid_any_CIT', 'min_kid_any_CIT', 'max_kid_any_CIT', 'count_kid_any_CIT', 'sum_kid_any_CIT', 'mean_kid_any_CIT', '%_kid_any_CIT', 'any_anyage_non-cit', 'min_anyage_non-cit', 'max_anyage_non-cit', 'count_anyage_non-cit', 'sum_anyage_non-cit', 'mean_anyage_non-cit', '%_anyage_non-cit', 'any_anyage_citizen', 'all_anyage_citizen', 'max_anyage_citizen', 'sum_anyage_citizen', 'mean_anyage_citizen', '%_anyage_citizen', 'any_anyage_naturalized_cit', 'min_anyage_naturalized_cit', 'max_anyage_naturalized_cit', 'count_anyage_naturalized_cit', 'sum_anyage_naturalized_cit', 'mean_anyage_naturalized_cit', '%_anyage_naturalized_cit', 'min_anyage_any_CIT', 'max_anyage_any_CIT', 'count_anyage_any_CIT', 'sum_anyage_any_CIT', 'mean_anyage_any_CIT', 'max_adult_college', 'mean_adult_college', 'mean_adult_HS', 'any_adult_no_diploma', 'all_adult_no_diploma', 'max_adult_no_diploma', 'mean_adult_no_diploma', '%_adult_no_diploma', 'max_adult_diploma_no_bachelors', 'mean_adult_diploma_no_bachelors', 'min_adult_any_SCHL', 'max_adult_any_SCHL', 'count_adult_any_SCHL', 'sum_adult_any_SCHL', 'mean_adult_any_SCHL', 'min_65+_college', 'max_65+_college', 'sum_65+_college', 'mean_65+_college', '%_65+_college', 'min_65+_HS', 'max_65+_HS', 'sum_65+_HS', 'mean_65+_HS', '%_65+_HS', 'min_65+_no_diploma', 'max_65+_no_diploma', 'sum_65+_no_diploma', 'mean_65+_no_diploma', '%_65+_no_diploma', 'min_65+_diploma_no_bachelors', 'max_65+_diploma_no_bachelors', 'count_65+_diploma_no_bachelors', 'sum_65+_diploma_no_bachelors', 'mean_65+_diploma_no_bachelors', '%_65+_diploma_no_bachelors', 'any_65+_any_SCHL', 'all_65+_any_SCHL', 'min_65+_any_SCHL', 'max_65+_any_SCHL', 'count_65+_any_SCHL', 'sum_65+_any_SCHL', 'mean_65+_any_SCHL', '%_65+_any_SCHL', 'max_18-64_college', 'mean_18-64_college', 'mean_18-64_HS', 'max_18-64_no_diploma', 'sum_18-64_no_diploma', 'mean_18-64_no_diploma', 'max_18-64_diploma_no_bachelors', 'mean_18-64_diploma_no_bachelors', 'any_18-64_any_SCHL', 'all_18-64_any_SCHL', 'min_18-64_any_SCHL', 'max_18-64_any_SCHL', 'count_18-64_any_SCHL', 'sum_18-64_any_SCHL', 'mean_18-64_any_SCHL', '%_18-64_any_SCHL', 'max_kid_HS', 'sum_kid_HS', 'mean_kid_HS', 'any_kid_no_diploma', 'all_kid_no_diploma', 'min_kid_no_diploma', 'max_kid_no_diploma', 'count_kid_no_diploma', 'sum_kid_no_diploma', 'mean_kid_no_diploma', '%_kid_no_diploma', 'min_kid_diploma_no_bachelors', 'max_kid_diploma_no_bachelors', 'sum_kid_diploma_no_bachelors', 'mean_kid_diploma_no_bachelors', 'any_kid_any_SCHL', 'all_kid_any_SCHL', 'min_kid_any_SCHL', 'max_kid_any_SCHL', 'count_kid_any_SCHL', 'sum_kid_any_SCHL', 'mean_kid_any_SCHL', '%_kid_any_SCHL', 'any_anyage_college', 'min_anyage_college', 'max_anyage_college', 'count_anyage_college', 'sum_anyage_college', 'mean_anyage_college', '%_anyage_college', 'any_anyage_HS', 'min_anyage_HS', 'max_anyage_HS', 'count_anyage_HS', 'sum_anyage_HS', 'mean_anyage_HS', 'any_anyage_no_diploma', 'all_anyage_no_diploma', 'max_anyage_no_diploma', 'sum_anyage_no_diploma', 'mean_anyage_no_diploma', '%_anyage_no_diploma', 'any_anyage_diploma_no_bachelors', 'min_anyage_diploma_no_bachelors', 'max_anyage_diploma_no_bachelors', 'count_anyage_diploma_no_bachelors', 'sum_anyage_diploma_no_bachelors', 'mean_anyage_diploma_no_bachelors', '%_anyage_diploma_no_bachelors', 'min_anyage_any_SCHL', 'max_anyage_any_SCHL', 'count_anyage_any_SCHL', 'sum_anyage_any_SCHL', 'mean_anyage_any_SCHL', 'mean_adult_male', 'any_adult_female', 'all_adult_female', 'mean_adult_female', '%_adult_female', 'min_adult_any_SEX', 'max_adult_any_SEX', 'count_adult_any_SEX', 'sum_adult_any_SEX', 'mean_adult_any_SEX', 'min_65+_male', 'max_65+_male', 'count_65+_male', 'sum_65+_male', 'mean_65+_male', 'min_65+_female', 'max_65+_female', 'count_65+_female', 'sum_65+_female', 'mean_65+_female', '%_65+_female', 'any_65+_any_SEX', 'all_65+_any_SEX', 'min_65+_any_SEX', 'max_65+_any_SEX', 'count_65+_any_SEX', 'sum_65+_any_SEX', 'mean_65+_any_SEX', '%_65+_any_SEX', 'mean_18-64_male', 'mean_18-64_female', 'any_18-64_any_SEX', 'all_18-64_any_SEX', 'min_18-64_any_SEX', 'max_18-64_any_SEX', 'count_18-64_any_SEX', 'sum_18-64_any_SEX', 'mean_18-64_any_SEX', '%_18-64_any_SEX', 'mean_kid_male', 'mean_kid_female', 'any_kid_any_SEX', 'all_kid_any_SEX', 'min_kid_any_SEX', 'max_kid_any_SEX', 'count_kid_any_SEX', 'sum_kid_any_SEX', 'mean_kid_any_SEX', '%_kid_any_SEX', 'all_anyage_male', 'max_anyage_male', 'sum_anyage_male', 'mean_anyage_male', '%_anyage_male', 'any_anyage_female', 'all_anyage_female', 'max_anyage_female', 'sum_anyage_female', 'mean_anyage_female', '%_anyage_female', 'min_anyage_any_SEX', 'max_anyage_any_SEX', 'count_anyage_any_SEX', 'sum_anyage_any_SEX', 'mean_anyage_any_SEX', 'min_adult_ENG_no', 'max_adult_ENG_no', 'sum_adult_ENG_no', 'mean_adult_ENG_no', 'max_adult_ENG_nvw', 'sum_adult_ENG_nvw', 'mean_adult_ENG_nvw', 'max_adult_ENG_well', 'mean_adult_ENG_well', 'max_adult_ENG_vw', 'mean_adult_ENG_vw', 'mean_adult_ENG_only', '%_adult_ENG_only', 'min_adult_ENG_any', 'max_adult_ENG_any', 'count_adult_ENG_any', 'sum_adult_ENG_any', 'mean_adult_ENG_any', 'min_65+_ENG_no', 'max_65+_ENG_no', 'count_65+_ENG_no', 'sum_65+_ENG_no', 'mean_65+_ENG_no', '%_65+_ENG_no', 'min_65+_ENG_nvw', 'max_65+_ENG_nvw', 'count_65+_ENG_nvw', 'sum_65+_ENG_nvw', 'mean_65+_ENG_nvw', '%_65+_ENG_nvw', 'min_65+_ENG_well', 'max_65+_ENG_well', 'count_65+_ENG_well', 'sum_65+_ENG_well', 'mean_65+_ENG_well', '%_65+_ENG_well', 'min_65+_ENG_vw', 'max_65+_ENG_vw', 'sum_65+_ENG_vw', 'mean_65+_ENG_vw', '%_65+_ENG_vw', 'all_65+_ENG_only', 'min_65+_ENG_only', 'max_65+_ENG_only', 'sum_65+_ENG_only', 'mean_65+_ENG_only', '%_65+_ENG_only', 'any_65+_ENG_any', 'all_65+_ENG_any', 'min_65+_ENG_any', 'max_65+_ENG_any', 'count_65+_ENG_any', 'sum_65+_ENG_any', 'mean_65+_ENG_any', '%_65+_ENG_any', 'min_18-64_ENG_no', 'max_18-64_ENG_no', 'sum_18-64_ENG_no', 'mean_18-64_ENG_no', 'min_18-64_ENG_nvw', 'max_18-64_ENG_nvw', 'sum_18-64_ENG_nvw', 'mean_18-64_ENG_nvw', 'min_18-64_ENG_well', 'max_18-64_ENG_well', 'sum_18-64_ENG_well', 'mean_18-64_ENG_well', 'max_18-64_ENG_vw', 'sum_18-64_ENG_vw', 'mean_18-64_ENG_vw', 'sum_18-64_ENG_only', 'mean_18-64_ENG_only', '%_18-64_ENG_only', 'any_18-64_ENG_any', 'all_18-64_ENG_any', 'min_18-64_ENG_any', 'max_18-64_ENG_any', 'count_18-64_ENG_any', 'sum_18-64_ENG_any', 'mean_18-64_ENG_any', '%_18-64_ENG_any', 'max_kid_ENG_no', 'mean_kid_ENG_no', 'max_kid_ENG_nvw', 'mean_kid_ENG_nvw', 'max_kid_ENG_well', 'sum_kid_ENG_well', 'mean_kid_ENG_well', 'max_kid_ENG_vw', 'sum_kid_ENG_vw', 'mean_kid_ENG_vw', '%_kid_ENG_vw', 'max_kid_ENG_only', 'sum_kid_ENG_only', 'mean_kid_ENG_only', '%_kid_ENG_only', 'any_kid_ENG_any', 'all_kid_ENG_any', 'min_kid_ENG_any', 'max_kid_ENG_any', 'count_kid_ENG_any', 'sum_kid_ENG_any', 'mean_kid_ENG_any', '%_kid_ENG_any', 'any_anyage_ENG_no', 'all_anyage_ENG_no', 'min_anyage_ENG_no', 'max_anyage_ENG_no', 'count_anyage_ENG_no', 'sum_anyage_ENG_no', 'mean_anyage_ENG_no', '%_anyage_ENG_no', 'any_anyage_ENG_nvw', 'min_anyage_ENG_nvw', 'max_anyage_ENG_nvw', 'count_anyage_ENG_nvw', 'sum_anyage_ENG_nvw', 'mean_anyage_ENG_nvw', '%_anyage_ENG_nvw', 'any_anyage_ENG_well', 'min_anyage_ENG_well', 'max_anyage_ENG_well', 'sum_anyage_ENG_well', 'mean_anyage_ENG_well', '%_anyage_ENG_well', 'min_anyage_ENG_vw', 'max_anyage_ENG_vw', 'sum_anyage_ENG_vw', 'mean_anyage_ENG_vw', '%_anyage_ENG_vw', 'any_anyage_ENG_only', 'max_anyage_ENG_only', 'sum_anyage_ENG_only', 'mean_anyage_ENG_only', '%_anyage_ENG_only', 'min_anyage_ENG_any', 'max_anyage_ENG_any', 'count_anyage_ENG_any', 'sum_anyage_ENG_any', 'mean_anyage_ENG_any', 'max_adult_married', 'sum_adult_married', 'mean_adult_married', 'min_adult_widowed', 'max_adult_widowed', 'count_adult_widowed', 'sum_adult_widowed', 'mean_adult_widowed', 'min_adult_sep/divorced', 'max_adult_sep/divorced', 'count_adult_sep/divorced', 'sum_adult_sep/divorced', 'mean_adult_sep/divorced', 'max_adult_not_married', 'mean_adult_not_married', 'min_adult_any_MSP', 'max_adult_any_MSP', 'count_adult_any_MSP', 'sum_adult_any_MSP', 'mean_adult_any_MSP', 'all_65+_married', 'min_65+_married', 'max_65+_married', 'count_65+_married', 'sum_65+_married', 'mean_65+_married', '%_65+_married', 'all_65+_widowed', 'min_65+_widowed', 'max_65+_widowed', 'count_65+_widowed', 'sum_65+_widowed', 'mean_65+_widowed', '%_65+_widowed', 'all_65+_sep/divorced', 'min_65+_sep/divorced', 'max_65+_sep/divorced', 'count_65+_sep/divorced', 'sum_65+_sep/divorced', 'mean_65+_sep/divorced', '%_65+_sep/divorced', 'all_65+_not_married', 'min_65+_not_married', 'max_65+_not_married', 'count_65+_not_married', 'sum_65+_not_married', 'mean_65+_not_married', '%_65+_not_married', 'any_65+_any_MSP', 'all_65+_any_MSP', 'min_65+_any_MSP', 'max_65+_any_MSP', 'count_65+_any_MSP', 'sum_65+_any_MSP', 'mean_65+_any_MSP', '%_65+_any_MSP', 'min_18-64_married', 'max_18-64_married', 'sum_18-64_married', 'mean_18-64_married', '%_18-64_married', 'min_18-64_widowed', 'max_18-64_widowed', 'count_18-64_widowed', 'sum_18-64_widowed', 'mean_18-64_widowed', 'min_18-64_sep/divorced', 'max_18-64_sep/divorced', 'count_18-64_sep/divorced', 'sum_18-64_sep/divorced', 'mean_18-64_sep/divorced', 'max_18-64_not_married', 'count_18-64_not_married', 'mean_18-64_not_married', 'any_18-64_any_MSP', 'all_18-64_any_MSP', 'min_18-64_any_MSP', 'max_18-64_any_MSP', 'count_18-64_any_MSP', 'sum_18-64_any_MSP', 'mean_18-64_any_MSP', '%_18-64_any_MSP', 'max_kid_married', 'sum_kid_married', 'mean_kid_married', 'max_kid_sep/divorced', 'sum_kid_sep/divorced', 'mean_kid_sep/divorced', 'min_kid_not_married', 'max_kid_not_married', 'count_kid_not_married', 'sum_kid_not_married', 'mean_kid_not_married', 'any_kid_any_MSP', 'all_kid_any_MSP', 'min_kid_any_MSP', 'max_kid_any_MSP', 'count_kid_any_MSP', 'sum_kid_any_MSP', 'mean_kid_any_MSP', '%_kid_any_MSP', 'any_anyage_married', 'min_anyage_married', 'max_anyage_married', 'count_anyage_married', 'sum_anyage_married', 'mean_anyage_married', 'any_anyage_widowed', 'all_anyage_widowed', 'min_anyage_widowed', 'max_anyage_widowed', 'count_anyage_widowed', 'sum_anyage_widowed', 'mean_anyage_widowed', '%_anyage_widowed', 'any_anyage_sep/divorced', 'min_anyage_sep/divorced', 'max_anyage_sep/divorced', 'count_anyage_sep/divorced', 'sum_anyage_sep/divorced', 'mean_anyage_sep/divorced', '%_anyage_sep/divorced', 'min_anyage_not_married', 'max_anyage_not_married', 'sum_anyage_not_married', 'mean_anyage_not_married', '%_anyage_not_married', 'min_anyage_any_MSP', 'max_anyage_any_MSP', 'count_anyage_any_MSP', 'sum_anyage_any_MSP', 'mean_anyage_any_MSP', 'max_adult_no_work', 'mean_adult_no_work', 'max_adult_<14WKW', 'count_adult_<14WKW', 'sum_adult_<14WKW', 'mean_adult_<14WKW', 'max_adult_14-26WKW', 'count_adult_14-26WKW', 'sum_adult_14-26WKW', 'mean_adult_14-26WKW', 'max_adult_27-39WKW', 'count_adult_27-39WKW', 'sum_adult_27-39WKW', 'mean_adult_27-39WKW', 'max_adult_40-47WKW', 'count_adult_40-47WKW', 'sum_adult_40-47WKW', 'mean_adult_40-47WKW', 'max_adult_48-49WKW', 'count_adult_48-49WKW', 'sum_adult_48-49WKW', 'mean_adult_48-49WKW', 'mean_adult_50-52WKW', 'mean_adult_>40WKW', 'any_adult_nonzero_WKW', 'all_adult_nonzero_WKW', 'mean_adult_nonzero_WKW', '%_adult_nonzero_WKW', 'min_adult_any_WKW', 'max_adult_any_WKW', 'count_adult_any_WKW', 'sum_adult_any_WKW', 'mean_adult_any_WKW', 'min_65+_no_work', 'max_65+_no_work', 'sum_65+_no_work', 'mean_65+_no_work', '%_65+_no_work', 'max_65+_<14WKW', 'sum_65+_<14WKW', 'mean_65+_<14WKW', 'max_65+_14-26WKW', 'sum_65+_14-26WKW', 'mean_65+_14-26WKW', 'max_65+_27-39WKW', 'sum_65+_27-39WKW', 'mean_65+_27-39WKW', 'max_65+_40-47WKW', 'sum_65+_40-47WKW', 'mean_65+_40-47WKW', 'max_65+_48-49WKW', 'sum_65+_48-49WKW', 'mean_65+_48-49WKW', 'min_65+_50-52WKW', 'max_65+_50-52WKW', 'count_65+_50-52WKW', 'sum_65+_50-52WKW', 'mean_65+_50-52WKW', '%_65+_50-52WKW', 'min_65+_>40WKW', 'max_65+_>40WKW', 'count_65+_>40WKW', 'sum_65+_>40WKW', 'mean_65+_>40WKW', '%_65+_>40WKW', 'min_65+_nonzero_WKW', 'max_65+_nonzero_WKW', 'count_65+_nonzero_WKW', 'sum_65+_nonzero_WKW', 'mean_65+_nonzero_WKW', '%_65+_nonzero_WKW', 'any_65+_any_WKW', 'all_65+_any_WKW', 'min_65+_any_WKW', 'max_65+_any_WKW', 'count_65+_any_WKW', 'sum_65+_any_WKW', 'mean_65+_any_WKW', '%_65+_any_WKW', 'max_18-64_no_work', 'mean_18-64_no_work', 'max_18-64_<14WKW', 'count_18-64_<14WKW', 'sum_18-64_<14WKW', 'mean_18-64_<14WKW', 'any_18-64_14-26WKW', 'max_18-64_14-26WKW', 'count_18-64_14-26WKW', 'sum_18-64_14-26WKW', 'mean_18-64_14-26WKW', 'any_18-64_27-39WKW', 'max_18-64_27-39WKW', 'count_18-64_27-39WKW', 'sum_18-64_27-39WKW', 'mean_18-64_27-39WKW', 'any_18-64_40-47WKW', 'max_18-64_40-47WKW', 'count_18-64_40-47WKW', 'sum_18-64_40-47WKW', 'mean_18-64_40-47WKW', 'any_18-64_48-49WKW', 'min_18-64_48-49WKW', 'max_18-64_48-49WKW', 'count_18-64_48-49WKW', 'sum_18-64_48-49WKW', 'mean_18-64_48-49WKW', '%_18-64_48-49WKW', 'count_18-64_50-52WKW', 'mean_18-64_50-52WKW', 'count_18-64_>40WKW', 'mean_18-64_>40WKW', 'count_18-64_nonzero_WKW', 'mean_18-64_nonzero_WKW', 'any_18-64_any_WKW', 'all_18-64_any_WKW', 'min_18-64_any_WKW', 'max_18-64_any_WKW', 'count_18-64_any_WKW', 'sum_18-64_any_WKW', 'mean_18-64_any_WKW', '%_18-64_any_WKW', 'any_kid_no_work', 'all_kid_no_work', 'min_kid_no_work', 'max_kid_no_work', 'count_kid_no_work', 'sum_kid_no_work', 'mean_kid_no_work', '%_kid_no_work', 'max_kid_<14WKW', 'sum_kid_<14WKW', 'mean_kid_<14WKW', 'max_kid_14-26WKW', 'sum_kid_14-26WKW', 'mean_kid_14-26WKW', 'max_kid_27-39WKW', 'sum_kid_27-39WKW', 'mean_kid_27-39WKW', 'max_kid_40-47WKW', 'sum_kid_40-47WKW', 'mean_kid_40-47WKW', 'max_kid_50-52WKW', 'sum_kid_50-52WKW', 'mean_kid_50-52WKW', 'max_kid_>40WKW', 'sum_kid_>40WKW', 'mean_kid_>40WKW', 'max_kid_nonzero_WKW', 'sum_kid_nonzero_WKW', 'mean_kid_nonzero_WKW', 'any_kid_any_WKW', 'all_kid_any_WKW', 'min_kid_any_WKW', 'max_kid_any_WKW', 'count_kid_any_WKW', 'sum_kid_any_WKW', 'mean_kid_any_WKW', '%_kid_any_WKW', 'all_anyage_no_work', 'max_anyage_no_work', 'sum_anyage_no_work', 'mean_anyage_no_work', 'any_anyage_<14WKW', 'min_anyage_<14WKW', 'max_anyage_<14WKW', 'count_anyage_<14WKW', 'sum_anyage_<14WKW', 'mean_anyage_<14WKW', '%_anyage_<14WKW', 'any_anyage_14-26WKW', 'all_anyage_14-26WKW', 'min_anyage_14-26WKW', 'max_anyage_14-26WKW', 'count_anyage_14-26WKW', 'sum_anyage_14-26WKW', 'mean_anyage_14-26WKW', '%_anyage_14-26WKW', 'any_anyage_27-39WKW', 'min_anyage_27-39WKW', 'max_anyage_27-39WKW', 'count_anyage_27-39WKW', 'sum_anyage_27-39WKW', 'mean_anyage_27-39WKW', '%_anyage_27-39WKW', 'any_anyage_40-47WKW', 'min_anyage_40-47WKW', 'max_anyage_40-47WKW', 'count_anyage_40-47WKW', 'sum_anyage_40-47WKW', 'mean_anyage_40-47WKW', '%_anyage_40-47WKW', 'any_anyage_48-49WKW', 'min_anyage_48-49WKW', 'max_anyage_48-49WKW', 'count_anyage_48-49WKW', 'sum_anyage_48-49WKW', 'mean_anyage_48-49WKW', '%_anyage_48-49WKW', 'any_anyage_50-52WKW', 'min_anyage_50-52WKW', 'max_anyage_50-52WKW', 'count_anyage_50-52WKW', 'sum_anyage_50-52WKW', 'mean_anyage_50-52WKW', 'any_anyage_>40WKW', 'min_anyage_>40WKW', 'max_anyage_>40WKW', 'count_anyage_>40WKW', 'sum_anyage_>40WKW', 'mean_anyage_>40WKW', 'any_anyage_nonzero_WKW', 'all_anyage_nonzero_WKW', 'min_anyage_nonzero_WKW', 'max_anyage_nonzero_WKW', 'count_anyage_nonzero_WKW', 'sum_anyage_nonzero_WKW', 'mean_anyage_nonzero_WKW', '%_anyage_nonzero_WKW', 'min_anyage_any_WKW', 'max_anyage_any_WKW', 'count_anyage_any_WKW', 'sum_anyage_any_WKW', 'mean_anyage_any_WKW', 'any_adult_no_work_hrs', 'all_adult_no_work_hrs', 'min_adult_no_work_hrs', 'max_adult_no_work_hrs', 'count_adult_no_work_hrs', 'sum_adult_no_work_hrs', 'mean_adult_no_work_hrs', '%_adult_no_work_hrs', 'any_adult_<10_work_hrs', 'all_adult_<10_work_hrs', 'min_adult_<10_work_hrs', 'max_adult_<10_work_hrs', 'count_adult_<10_work_hrs', 'sum_adult_<10_work_hrs', 'mean_adult_<10_work_hrs', '%_adult_<10_work_hrs', 'any_adult_<15_work_hrs', 'all_adult_<15_work_hrs', 'min_adult_<15_work_hrs', 'max_adult_<15_work_hrs', 'count_adult_<15_work_hrs', 'sum_adult_<15_work_hrs', 'mean_adult_<15_work_hrs', '%_adult_<15_work_hrs', 'any_adult_<20_work_hrs', 'all_adult_<20_work_hrs', 'min_adult_<20_work_hrs', 'max_adult_<20_work_hrs', 'count_adult_<20_work_hrs', 'sum_adult_<20_work_hrs', 'mean_adult_<20_work_hrs', '%_adult_<20_work_hrs', 'sum_adult_<30_work_hrs', 'mean_adult_<30_work_hrs', 'mean_adult_<40_work_hrs', 'any_adult_50_plus_work_hrs', 'all_adult_50_plus_work_hrs', 'max_adult_50_plus_work_hrs', 'sum_adult_50_plus_work_hrs', 'mean_adult_50_plus_work_hrs', '%_adult_50_plus_work_hrs', 'any_adult_40_plus_work_hrs', 'all_adult_40_plus_work_hrs', 'max_adult_40_plus_work_hrs', 'mean_adult_40_plus_work_hrs', '%_adult_40_plus_work_hrs', 'min_adult_any_WKHP', 'max_adult_any_WKHP', 'count_adult_any_WKHP', 'sum_adult_any_WKHP', 'mean_adult_any_WKHP', 'any_65+_no_work_hrs', 'all_65+_no_work_hrs', 'min_65+_no_work_hrs', 'max_65+_no_work_hrs', 'count_65+_no_work_hrs', 'sum_65+_no_work_hrs', 'mean_65+_no_work_hrs', '%_65+_no_work_hrs', 'any_65+_<10_work_hrs', 'all_65+_<10_work_hrs', 'min_65+_<10_work_hrs', 'max_65+_<10_work_hrs', 'count_65+_<10_work_hrs', 'sum_65+_<10_work_hrs', 'mean_65+_<10_work_hrs', '%_65+_<10_work_hrs', 'any_65+_<15_work_hrs', 'all_65+_<15_work_hrs', 'min_65+_<15_work_hrs', 'max_65+_<15_work_hrs', 'count_65+_<15_work_hrs', 'sum_65+_<15_work_hrs', 'mean_65+_<15_work_hrs', '%_65+_<15_work_hrs', 'any_65+_<20_work_hrs', 'all_65+_<20_work_hrs', 'min_65+_<20_work_hrs', 'max_65+_<20_work_hrs', 'count_65+_<20_work_hrs', 'sum_65+_<20_work_hrs', 'mean_65+_<20_work_hrs', '%_65+_<20_work_hrs', 'any_65+_<30_work_hrs', 'all_65+_<30_work_hrs', 'min_65+_<30_work_hrs', 'max_65+_<30_work_hrs', 'count_65+_<30_work_hrs', 'sum_65+_<30_work_hrs', 'mean_65+_<30_work_hrs', '%_65+_<30_work_hrs', 'any_65+_<40_work_hrs', 'all_65+_<40_work_hrs', 'min_65+_<40_work_hrs', 'max_65+_<40_work_hrs', 'count_65+_<40_work_hrs', 'sum_65+_<40_work_hrs', 'mean_65+_<40_work_hrs', '%_65+_<40_work_hrs', 'any_65+_<50_work_hrs', 'all_65+_<50_work_hrs', 'min_65+_<50_work_hrs', 'max_65+_<50_work_hrs', 'count_65+_<50_work_hrs', 'sum_65+_<50_work_hrs', 'mean_65+_<50_work_hrs', '%_65+_<50_work_hrs', 'max_65+_50_plus_work_hrs', 'sum_65+_50_plus_work_hrs', 'mean_65+_50_plus_work_hrs', 'min_65+_40_plus_work_hrs', 'max_65+_40_plus_work_hrs', 'count_65+_40_plus_work_hrs', 'sum_65+_40_plus_work_hrs', 'mean_65+_40_plus_work_hrs', '%_65+_40_plus_work_hrs', 'any_65+_any_WKHP', 'all_65+_any_WKHP', 'min_65+_any_WKHP', 'max_65+_any_WKHP', 'count_65+_any_WKHP', 'sum_65+_any_WKHP', 'mean_65+_any_WKHP', '%_65+_any_WKHP', 'any_18-64_no_work_hrs', 'all_18-64_no_work_hrs', 'min_18-64_no_work_hrs', 'max_18-64_no_work_hrs', 'count_18-64_no_work_hrs', 'sum_18-64_no_work_hrs', 'mean_18-64_no_work_hrs', '%_18-64_no_work_hrs', 'any_18-64_<10_work_hrs', 'all_18-64_<10_work_hrs', 'min_18-64_<10_work_hrs', 'max_18-64_<10_work_hrs', 'count_18-64_<10_work_hrs', 'sum_18-64_<10_work_hrs', 'mean_18-64_<10_work_hrs', '%_18-64_<10_work_hrs', 'any_18-64_<15_work_hrs', 'all_18-64_<15_work_hrs', 'min_18-64_<15_work_hrs', 'max_18-64_<15_work_hrs', 'count_18-64_<15_work_hrs', 'sum_18-64_<15_work_hrs', 'mean_18-64_<15_work_hrs', '%_18-64_<15_work_hrs', 'any_18-64_<20_work_hrs', 'all_18-64_<20_work_hrs', 'min_18-64_<20_work_hrs', 'max_18-64_<20_work_hrs', 'count_18-64_<20_work_hrs', 'sum_18-64_<20_work_hrs', 'mean_18-64_<20_work_hrs', '%_18-64_<20_work_hrs', 'mean_18-64_<30_work_hrs', 'mean_18-64_<40_work_hrs', 'mean_18-64_<50_work_hrs', '%_18-64_<50_work_hrs', 'any_18-64_50_plus_work_hrs', 'all_18-64_50_plus_work_hrs', 'min_18-64_50_plus_work_hrs', 'max_18-64_50_plus_work_hrs', 'count_18-64_50_plus_work_hrs', 'sum_18-64_50_plus_work_hrs', 'mean_18-64_50_plus_work_hrs', '%_18-64_50_plus_work_hrs', 'max_18-64_40_plus_work_hrs', 'count_18-64_40_plus_work_hrs', 'mean_18-64_40_plus_work_hrs', 'any_18-64_any_WKHP', 'all_18-64_any_WKHP', 'min_18-64_any_WKHP', 'max_18-64_any_WKHP', 'count_18-64_any_WKHP', 'sum_18-64_any_WKHP', 'mean_18-64_any_WKHP', '%_18-64_any_WKHP', 'any_kid_no_work_hrs', 'all_kid_no_work_hrs', 'min_kid_no_work_hrs', 'max_kid_no_work_hrs', 'count_kid_no_work_hrs', 'sum_kid_no_work_hrs', 'mean_kid_no_work_hrs', '%_kid_no_work_hrs', 'any_kid_<10_work_hrs', 'all_kid_<10_work_hrs', 'min_kid_<10_work_hrs', 'max_kid_<10_work_hrs', 'count_kid_<10_work_hrs', 'sum_kid_<10_work_hrs', 'mean_kid_<10_work_hrs', '%_kid_<10_work_hrs', 'any_kid_<15_work_hrs', 'all_kid_<15_work_hrs', 'min_kid_<15_work_hrs', 'max_kid_<15_work_hrs', 'count_kid_<15_work_hrs', 'sum_kid_<15_work_hrs', 'mean_kid_<15_work_hrs', '%_kid_<15_work_hrs', 'any_kid_<20_work_hrs', 'all_kid_<20_work_hrs', 'min_kid_<20_work_hrs', 'max_kid_<20_work_hrs', 'count_kid_<20_work_hrs', 'sum_kid_<20_work_hrs', 'mean_kid_<20_work_hrs', '%_kid_<20_work_hrs', 'any_kid_<30_work_hrs', 'all_kid_<30_work_hrs', 'min_kid_<30_work_hrs', 'max_kid_<30_work_hrs', 'count_kid_<30_work_hrs', 'sum_kid_<30_work_hrs', 'mean_kid_<30_work_hrs', '%_kid_<30_work_hrs', 'any_kid_<40_work_hrs', 'all_kid_<40_work_hrs', 'min_kid_<40_work_hrs', 'max_kid_<40_work_hrs', 'count_kid_<40_work_hrs', 'sum_kid_<40_work_hrs', 'mean_kid_<40_work_hrs', '%_kid_<40_work_hrs', 'any_kid_<50_work_hrs', 'all_kid_<50_work_hrs', 'min_kid_<50_work_hrs', 'max_kid_<50_work_hrs', 'count_kid_<50_work_hrs', 'sum_kid_<50_work_hrs', 'mean_kid_<50_work_hrs', '%_kid_<50_work_hrs', 'max_kid_40_plus_work_hrs', 'sum_kid_40_plus_work_hrs', 'mean_kid_40_plus_work_hrs', 'any_kid_any_WKHP', 'all_kid_any_WKHP', 'min_kid_any_WKHP', 'max_kid_any_WKHP', 'count_kid_any_WKHP', 'sum_kid_any_WKHP', 'mean_kid_any_WKHP', '%_kid_any_WKHP', 'any_anyage_no_work_hrs', 'all_anyage_no_work_hrs', 'min_anyage_no_work_hrs', 'max_anyage_no_work_hrs', 'count_anyage_no_work_hrs', 'sum_anyage_no_work_hrs', 'mean_anyage_no_work_hrs', '%_anyage_no_work_hrs', 'any_anyage_<10_work_hrs', 'all_anyage_<10_work_hrs', 'min_anyage_<10_work_hrs', 'max_anyage_<10_work_hrs', 'count_anyage_<10_work_hrs', 'sum_anyage_<10_work_hrs', 'mean_anyage_<10_work_hrs', '%_anyage_<10_work_hrs', 'any_anyage_<15_work_hrs', 'all_anyage_<15_work_hrs', 'min_anyage_<15_work_hrs', 'max_anyage_<15_work_hrs', 'count_anyage_<15_work_hrs', 'sum_anyage_<15_work_hrs', 'mean_anyage_<15_work_hrs', '%_anyage_<15_work_hrs', 'any_anyage_<20_work_hrs', 'all_anyage_<20_work_hrs', 'min_anyage_<20_work_hrs', 'max_anyage_<20_work_hrs', 'count_anyage_<20_work_hrs', 'sum_anyage_<20_work_hrs', 'mean_anyage_<20_work_hrs', '%_anyage_<20_work_hrs', 'all_anyage_<30_work_hrs', 'min_anyage_<30_work_hrs', 'max_anyage_<30_work_hrs', 'count_anyage_<30_work_hrs', 'sum_anyage_<30_work_hrs', 'mean_anyage_<30_work_hrs', 'all_anyage_<40_work_hrs', 'max_anyage_<40_work_hrs', 'sum_anyage_<40_work_hrs', 'mean_anyage_<40_work_hrs', '%_anyage_<40_work_hrs', 'any_anyage_<50_work_hrs', 'all_anyage_<50_work_hrs', 'max_anyage_<50_work_hrs', 'count_anyage_<50_work_hrs', 'sum_anyage_<50_work_hrs', 'mean_anyage_<50_work_hrs', '%_anyage_<50_work_hrs', 'any_anyage_50_plus_work_hrs', 'all_anyage_50_plus_work_hrs', 'min_anyage_50_plus_work_hrs', 'max_anyage_50_plus_work_hrs', 'count_anyage_50_plus_work_hrs', 'sum_anyage_50_plus_work_hrs', 'mean_anyage_50_plus_work_hrs', '%_anyage_50_plus_work_hrs', 'any_anyage_40_plus_work_hrs', 'all_anyage_40_plus_work_hrs', 'min_anyage_40_plus_work_hrs', 'max_anyage_40_plus_work_hrs', 'count_anyage_40_plus_work_hrs', 'sum_anyage_40_plus_work_hrs', 'mean_anyage_40_plus_work_hrs', '%_anyage_40_plus_work_hrs', 'min_anyage_any_WKHP', 'max_anyage_any_WKHP', 'count_anyage_any_WKHP', 'sum_anyage_any_WKHP', 'mean_anyage_any_WKHP', 'max_adult_DIS', 'sum_adult_DIS', 'mean_adult_DIS', 'any_adult_not_DIS', 'all_adult_not_DIS', 'mean_adult_not_DIS', '%_adult_not_DIS', 'min_adult_any_DIS', 'max_adult_any_DIS', 'count_adult_any_DIS', 'sum_adult_any_DIS', 'mean_adult_any_DIS', 'min_65+_DIS', 'max_65+_DIS', 'count_65+_DIS', 'sum_65+_DIS', 'mean_65+_DIS', '%_65+_DIS', 'min_65+_not_DIS', 'max_65+_not_DIS', 'sum_65+_not_DIS', 'mean_65+_not_DIS', '%_65+_not_DIS', 'any_65+_any_DIS', 'all_65+_any_DIS', 'min_65+_any_DIS', 'max_65+_any_DIS', 'count_65+_any_DIS', 'sum_65+_any_DIS', 'mean_65+_any_DIS', '%_65+_any_DIS', 'min_18-64_DIS', 'max_18-64_DIS', 'sum_18-64_DIS', 'mean_18-64_DIS', 'mean_18-64_not_DIS', '%_18-64_not_DIS', 'any_18-64_any_DIS', 'all_18-64_any_DIS', 'min_18-64_any_DIS', 'max_18-64_any_DIS', 'count_18-64_any_DIS', 'sum_18-64_any_DIS', 'mean_18-64_any_DIS', '%_18-64_any_DIS', 'max_kid_DIS', 'mean_kid_DIS', 'any_kid_not_DIS', 'all_kid_not_DIS', 'min_kid_not_DIS', 'max_kid_not_DIS', 'count_kid_not_DIS', 'sum_kid_not_DIS', 'mean_kid_not_DIS', '%_kid_not_DIS', 'any_kid_any_DIS', 'all_kid_any_DIS', 'min_kid_any_DIS', 'max_kid_any_DIS', 'count_kid_any_DIS', 'sum_kid_any_DIS', 'mean_kid_any_DIS', '%_kid_any_DIS', 'any_anyage_DIS', 'all_anyage_DIS', 'min_anyage_DIS', 'max_anyage_DIS', 'count_anyage_DIS', 'sum_anyage_DIS', 'mean_anyage_DIS', '%_anyage_DIS', 'any_anyage_not_DIS', 'all_anyage_not_DIS', 'max_anyage_not_DIS', 'sum_anyage_not_DIS', '%_anyage_not_DIS', 'min_anyage_any_DIS', 'max_anyage_any_DIS', 'count_anyage_any_DIS', 'sum_anyage_any_DIS', 'mean_anyage_any_DIS', 'all_adult_NP1', 'max_adult_NP1', 'count_adult_NP1', 'sum_adult_NP1', 'mean_adult_NP1', '%_adult_NP1', 'all_adult_NP2', 'max_adult_NP2', 'count_adult_NP2', 'sum_adult_NP2', 'mean_adult_NP2', '%_adult_NP2', 'all_adult_NP3', 'count_adult_NP3', 'sum_adult_NP3', 'mean_adult_NP3', '%_adult_NP3', 'all_adult_NP4', 'max_adult_NP4', 'sum_adult_NP4', 'mean_adult_NP4', '%_adult_NP4', 'all_adult_NP5', 'max_adult_NP5', 'sum_adult_NP5', 'mean_adult_NP5', '%_adult_NP5', 'all_adult_NP>5', 'sum_adult_NP>5', 'mean_adult_NP>5', '%_adult_NP>5', 'all_adult_NP>6', 'max_adult_NP>6', 'sum_adult_NP>6', 'mean_adult_NP>6', '%_adult_NP>6', 'all_adult_NP>8', 'max_adult_NP>8', 'sum_adult_NP>8', 'mean_adult_NP>8', '%_adult_NP>8', 'sum_adult_NP>10', 'mean_adult_NP>10', 'sum_adult_NP>12', 'mean_adult_NP>12', 'min_adult_anyNP', 'max_adult_anyNP', 'count_adult_anyNP', 'sum_adult_anyNP', 'mean_adult_anyNP', 'all_65+_NP1', 'min_65+_NP1', 'max_65+_NP1', 'count_65+_NP1', 'sum_65+_NP1', 'mean_65+_NP1', '%_65+_NP1', 'all_65+_NP2', 'min_65+_NP2', 'max_65+_NP2', 'sum_65+_NP2', 'mean_65+_NP2', '%_65+_NP2', 'all_65+_NP3', 'min_65+_NP3', 'max_65+_NP3', 'sum_65+_NP3', 'mean_65+_NP3', '%_65+_NP3', 'all_65+_NP4', 'min_65+_NP4', 'max_65+_NP4', 'sum_65+_NP4', 'mean_65+_NP4', '%_65+_NP4', 'all_65+_NP5', 'min_65+_NP5', 'max_65+_NP5', 'sum_65+_NP5', 'mean_65+_NP5', '%_65+_NP5', 'all_65+_NP>5', 'min_65+_NP>5', 'max_65+_NP>5', 'sum_65+_NP>5', 'mean_65+_NP>5', '%_65+_NP>5', 'max_65+_NP>6', 'sum_65+_NP>6', 'mean_65+_NP>6', 'max_65+_NP>8', 'mean_65+_NP>8', 'max_65+_NP>10', 'mean_65+_NP>10', 'max_65+_NP>12', 'sum_65+_NP>12', 'mean_65+_NP>12', 'any_65+_anyNP', 'all_65+_anyNP', 'min_65+_anyNP', 'max_65+_anyNP', 'count_65+_anyNP', 'sum_65+_anyNP', 'mean_65+_anyNP', '%_65+_anyNP', 'all_18-64_NP1', 'min_18-64_NP1', 'max_18-64_NP1', 'count_18-64_NP1', 'sum_18-64_NP1', 'mean_18-64_NP1', '%_18-64_NP1', 'all_18-64_NP2', 'max_18-64_NP2', 'sum_18-64_NP2', 'mean_18-64_NP2', '%_18-64_NP2', 'any_18-64_NP3', 'all_18-64_NP3', 'min_18-64_NP3', 'max_18-64_NP3', 'sum_18-64_NP3', 'mean_18-64_NP3', '%_18-64_NP3', 'any_18-64_NP4', 'all_18-64_NP4', 'min_18-64_NP4', 'max_18-64_NP4', 'count_18-64_NP4', 'sum_18-64_NP4', 'mean_18-64_NP4', '%_18-64_NP4', 'any_18-64_NP5', 'all_18-64_NP5', 'min_18-64_NP5', 'max_18-64_NP5', 'count_18-64_NP5', 'sum_18-64_NP5', 'mean_18-64_NP5', '%_18-64_NP5', 'any_18-64_NP>5', 'all_18-64_NP>5', 'max_18-64_NP>5', 'count_18-64_NP>5', 'sum_18-64_NP>5', 'mean_18-64_NP>5', '%_18-64_NP>5', 'any_18-64_NP>6', 'all_18-64_NP>6', 'min_18-64_NP>6', 'max_18-64_NP>6', 'count_18-64_NP>6', 'sum_18-64_NP>6', 'mean_18-64_NP>6', '%_18-64_NP>6', 'max_18-64_NP>8', 'count_18-64_NP>8', 'sum_18-64_NP>8', 'mean_18-64_NP>8', 'min_18-64_NP>10', 'max_18-64_NP>10', 'count_18-64_NP>10', 'sum_18-64_NP>10', 'mean_18-64_NP>10', 'min_18-64_NP>12', 'max_18-64_NP>12', 'count_18-64_NP>12', 'sum_18-64_NP>12', 'mean_18-64_NP>12', 'any_18-64_anyNP', 'all_18-64_anyNP', 'min_18-64_anyNP', 'max_18-64_anyNP', 'count_18-64_anyNP', 'sum_18-64_anyNP', 'mean_18-64_anyNP', '%_18-64_anyNP', 'max_kid_NP1', 'sum_kid_NP1', 'mean_kid_NP1', 'all_kid_NP2', 'max_kid_NP2', 'count_kid_NP2', 'sum_kid_NP2', 'mean_kid_NP2', '%_kid_NP2', 'max_kid_NP3', 'count_kid_NP3', 'sum_kid_NP3', 'mean_kid_NP3', '%_kid_NP3', 'all_kid_NP4', 'count_kid_NP4', 'sum_kid_NP4', 'mean_kid_NP4', '%_kid_NP4', 'all_kid_NP5', 'mean_kid_NP5', '%_kid_NP5', 'all_kid_NP>5', 'mean_kid_NP>5', '%_kid_NP>5', 'all_kid_NP>6', 'mean_kid_NP>6', '%_kid_NP>6', 'sum_kid_NP>8', 'mean_kid_NP>8', 'mean_kid_NP>10', 'sum_kid_NP>12', 'mean_kid_NP>12', 'any_kid_anyNP', 'all_kid_anyNP', 'min_kid_anyNP', 'max_kid_anyNP', 'count_kid_anyNP', 'sum_kid_anyNP', 'mean_kid_anyNP', '%_kid_anyNP', 'any_anyage_NP1', 'all_anyage_NP1', 'min_anyage_NP1', 'max_anyage_NP1', 'count_anyage_NP1', 'sum_anyage_NP1', 'mean_anyage_NP1', '%_anyage_NP1', 'any_anyage_NP2', 'all_anyage_NP2', 'min_anyage_NP2', 'max_anyage_NP2', 'count_anyage_NP2', 'sum_anyage_NP2', 'mean_anyage_NP2', '%_anyage_NP2', 'any_anyage_NP3', 'all_anyage_NP3', 'max_anyage_NP3', 'count_anyage_NP3', 'sum_anyage_NP3', 'mean_anyage_NP3', '%_anyage_NP3', 'any_anyage_NP4', 'all_anyage_NP4', 'max_anyage_NP4', 'count_anyage_NP4', 'sum_anyage_NP4', 'mean_anyage_NP4', '%_anyage_NP4', 'any_anyage_NP5', 'all_anyage_NP5', 'max_anyage_NP5', 'sum_anyage_NP5', 'mean_anyage_NP5', '%_anyage_NP5', 'any_anyage_NP>5', 'all_anyage_NP>5', 'max_anyage_NP>5', 'sum_anyage_NP>5', 'mean_anyage_NP>5', '%_anyage_NP>5', 'any_anyage_NP>6', 'all_anyage_NP>6', 'max_anyage_NP>6', 'sum_anyage_NP>6', 'mean_anyage_NP>6', '%_anyage_NP>6', 'any_anyage_NP>8', 'all_anyage_NP>8', 'max_anyage_NP>8', 'sum_anyage_NP>8', 'mean_anyage_NP>8', '%_anyage_NP>8', 'max_anyage_NP>10', 'sum_anyage_NP>10', 'mean_anyage_NP>10', 'min_anyage_NP>12', 'max_anyage_NP>12', 'count_anyage_NP>12', 'sum_anyage_NP>12', 'mean_anyage_NP>12', 'min_anyage_anyNP', 'max_anyage_anyNP', 'count_anyage_anyNP', 'sum_anyage_anyNP', 'mean_anyage_anyNP', 'count_adult_work_trans', 'all_65+_work_trans', 'count_65+_work_trans', 'sum_65+_work_trans', 'mean_65+_work_trans', '%_65+_work_trans', 'all_18-64_work_trans', 'count_18-64_work_trans', 'sum_18-64_work_trans', '%_18-64_work_trans', 'all_kid_work_trans', 'count_kid_work_trans', 'sum_kid_work_trans', '%_kid_work_trans', 'any_anyage_work_trans', 'max_anyage_work_trans', 'count_anyage_work_trans', 'sum_anyage_work_trans', 'mean_anyage_work_trans', 'max_adult_WAG0', 'sum_adult_WAG0', 'mean_adult_WAG0', 'sum_adult_WAG<10', 'mean_adult_WAG<10', 'min_adult_WAG<15', 'max_adult_WAG<15', 'sum_adult_WAG<15', 'mean_adult_WAG<15', 'min_adult_WAG<20', 'max_adult_WAG<20', 'count_adult_WAG<20', 'sum_adult_WAG<20', 'mean_adult_WAG<20', 'min_adult_WAG<25', 'max_adult_WAG<25', 'count_adult_WAG<25', 'sum_adult_WAG<25', 'mean_adult_WAG<25', 'min_adult_WAG<30', 'max_adult_WAG<30', 'count_adult_WAG<30', 'sum_adult_WAG<30', 'mean_adult_WAG<30', 'min_adult_WAG<35', 'max_adult_WAG<35', 'count_adult_WAG<35', 'sum_adult_WAG<35', 'mean_adult_WAG<35', 'min_adult_WAG<40', 'max_adult_WAG<40', 'count_adult_WAG<40', 'sum_adult_WAG<40', 'mean_adult_WAG<40', 'min_adult_WAG<45', 'max_adult_WAG<45', 'count_adult_WAG<45', 'sum_adult_WAG<45', 'mean_adult_WAG<45', 'min_adult_WAG<50', 'max_adult_WAG<50', 'count_adult_WAG<50', 'sum_adult_WAG<50', 'mean_adult_WAG<50', 'max_adult_WAG<60', 'count_adult_WAG<60', 'sum_adult_WAG<60', 'mean_adult_WAG<60', 'max_adult_WAG<70', 'count_adult_WAG<70', 'sum_adult_WAG<70', 'mean_adult_WAG<70', 'min_adult_WAG<80', 'max_adult_WAG<80', 'count_adult_WAG<80', 'sum_adult_WAG<80', 'mean_adult_WAG<80', 'min_adult_WAG_any', 'max_adult_WAG_any', 'count_adult_WAG_any', 'sum_adult_WAG_any', 'mean_adult_WAG_any', 'any_65+_WAG0', 'all_65+_WAG0', 'min_65+_WAG0', 'max_65+_WAG0', 'count_65+_WAG0', 'sum_65+_WAG0', 'mean_65+_WAG0', '%_65+_WAG0', 'any_65+_WAG<10', 'all_65+_WAG<10', 'min_65+_WAG<10', 'max_65+_WAG<10', 'count_65+_WAG<10', 'sum_65+_WAG<10', 'mean_65+_WAG<10', '%_65+_WAG<10', 'any_65+_WAG<15', 'all_65+_WAG<15', 'min_65+_WAG<15', 'max_65+_WAG<15', 'count_65+_WAG<15', 'sum_65+_WAG<15', 'mean_65+_WAG<15', '%_65+_WAG<15', 'any_65+_WAG<20', 'all_65+_WAG<20', 'min_65+_WAG<20', 'max_65+_WAG<20', 'count_65+_WAG<20', 'sum_65+_WAG<20', 'mean_65+_WAG<20', '%_65+_WAG<20', 'any_65+_WAG<25', 'all_65+_WAG<25', 'min_65+_WAG<25', 'max_65+_WAG<25', 'count_65+_WAG<25', 'sum_65+_WAG<25', 'mean_65+_WAG<25', '%_65+_WAG<25', 'any_65+_WAG<30', 'all_65+_WAG<30', 'min_65+_WAG<30', 'max_65+_WAG<30', 'count_65+_WAG<30', 'sum_65+_WAG<30', 'mean_65+_WAG<30', '%_65+_WAG<30', 'any_65+_WAG<35', 'all_65+_WAG<35', 'min_65+_WAG<35', 'max_65+_WAG<35', 'count_65+_WAG<35', 'sum_65+_WAG<35', 'mean_65+_WAG<35', '%_65+_WAG<35', 'any_65+_WAG<40', 'all_65+_WAG<40', 'min_65+_WAG<40', 'max_65+_WAG<40', 'count_65+_WAG<40', 'sum_65+_WAG<40', 'mean_65+_WAG<40', '%_65+_WAG<40', 'any_65+_WAG<45', 'all_65+_WAG<45', 'min_65+_WAG<45', 'max_65+_WAG<45', 'count_65+_WAG<45', 'sum_65+_WAG<45', 'mean_65+_WAG<45', '%_65+_WAG<45', 'any_65+_WAG<50', 'all_65+_WAG<50', 'min_65+_WAG<50', 'max_65+_WAG<50', 'count_65+_WAG<50', 'sum_65+_WAG<50', 'mean_65+_WAG<50', '%_65+_WAG<50', 'any_65+_WAG<60', 'all_65+_WAG<60', 'min_65+_WAG<60', 'max_65+_WAG<60', 'count_65+_WAG<60', 'sum_65+_WAG<60', 'mean_65+_WAG<60', '%_65+_WAG<60', 'any_65+_WAG<70', 'all_65+_WAG<70', 'min_65+_WAG<70', 'max_65+_WAG<70', 'count_65+_WAG<70', 'sum_65+_WAG<70', 'mean_65+_WAG<70', '%_65+_WAG<70', 'any_65+_WAG<80', 'all_65+_WAG<80', 'min_65+_WAG<80', 'max_65+_WAG<80', 'count_65+_WAG<80', 'sum_65+_WAG<80', 'mean_65+_WAG<80', '%_65+_WAG<80', 'any_65+_WAG_any', 'all_65+_WAG_any', 'min_65+_WAG_any', 'max_65+_WAG_any', 'count_65+_WAG_any', 'sum_65+_WAG_any', 'mean_65+_WAG_any', '%_65+_WAG_any', 'max_18-64_WAG0', 'mean_18-64_WAG0', 'mean_18-64_WAG<10', 'mean_18-64_WAG<15', 'count_18-64_WAG<20', 'sum_18-64_WAG<20', 'mean_18-64_WAG<20', 'count_18-64_WAG<25', 'sum_18-64_WAG<25', 'mean_18-64_WAG<25', 'max_18-64_WAG<30', 'count_18-64_WAG<30', 'sum_18-64_WAG<30', 'mean_18-64_WAG<30', 'max_18-64_WAG<35', 'count_18-64_WAG<35', 'sum_18-64_WAG<35', 'mean_18-64_WAG<35', 'max_18-64_WAG<40', 'count_18-64_WAG<40', 'sum_18-64_WAG<40', 'mean_18-64_WAG<40', 'any_18-64_WAG<45', 'max_18-64_WAG<45', 'count_18-64_WAG<45', 'sum_18-64_WAG<45', 'mean_18-64_WAG<45', 'any_18-64_WAG<50', 'min_18-64_WAG<50', 'max_18-64_WAG<50', 'count_18-64_WAG<50', 'sum_18-64_WAG<50', 'mean_18-64_WAG<50', '%_18-64_WAG<50', 'count_18-64_WAG<60', 'sum_18-64_WAG<60', 'mean_18-64_WAG<60', 'count_18-64_WAG<70', 'sum_18-64_WAG<70', 'mean_18-64_WAG<70', 'max_18-64_WAG<80', 'count_18-64_WAG<80', 'sum_18-64_WAG<80', 'mean_18-64_WAG<80', 'any_18-64_WAG_any', 'all_18-64_WAG_any', 'min_18-64_WAG_any', 'max_18-64_WAG_any', 'count_18-64_WAG_any', 'sum_18-64_WAG_any', 'mean_18-64_WAG_any', '%_18-64_WAG_any', 'any_kid_WAG0', 'all_kid_WAG0', 'min_kid_WAG0', 'max_kid_WAG0', 'count_kid_WAG0', 'sum_kid_WAG0', 'mean_kid_WAG0', '%_kid_WAG0', 'any_kid_WAG<10', 'all_kid_WAG<10', 'min_kid_WAG<10', 'max_kid_WAG<10', 'count_kid_WAG<10', 'sum_kid_WAG<10', 'mean_kid_WAG<10', '%_kid_WAG<10', 'any_kid_WAG<15', 'all_kid_WAG<15', 'min_kid_WAG<15', 'max_kid_WAG<15', 'count_kid_WAG<15', 'sum_kid_WAG<15', 'mean_kid_WAG<15', '%_kid_WAG<15', 'any_kid_WAG<20', 'all_kid_WAG<20', 'min_kid_WAG<20', 'max_kid_WAG<20', 'count_kid_WAG<20', 'sum_kid_WAG<20', 'mean_kid_WAG<20', '%_kid_WAG<20', 'any_kid_WAG<25', 'all_kid_WAG<25', 'min_kid_WAG<25', 'max_kid_WAG<25', 'count_kid_WAG<25', 'sum_kid_WAG<25', 'mean_kid_WAG<25', '%_kid_WAG<25', 'any_kid_WAG<30', 'all_kid_WAG<30', 'min_kid_WAG<30', 'max_kid_WAG<30', 'count_kid_WAG<30', 'sum_kid_WAG<30', 'mean_kid_WAG<30', '%_kid_WAG<30', 'any_kid_WAG<35', 'all_kid_WAG<35', 'min_kid_WAG<35', 'max_kid_WAG<35', 'count_kid_WAG<35', 'sum_kid_WAG<35', 'mean_kid_WAG<35', '%_kid_WAG<35', 'any_kid_WAG<40', 'all_kid_WAG<40', 'min_kid_WAG<40', 'max_kid_WAG<40', 'count_kid_WAG<40', 'sum_kid_WAG<40', 'mean_kid_WAG<40', '%_kid_WAG<40', 'any_kid_WAG<45', 'all_kid_WAG<45', 'min_kid_WAG<45', 'max_kid_WAG<45', 'count_kid_WAG<45', 'sum_kid_WAG<45', 'mean_kid_WAG<45', '%_kid_WAG<45', 'any_kid_WAG<50', 'all_kid_WAG<50', 'min_kid_WAG<50', 'max_kid_WAG<50', 'count_kid_WAG<50', 'sum_kid_WAG<50', 'mean_kid_WAG<50', '%_kid_WAG<50', 'any_kid_WAG<60', 'all_kid_WAG<60', 'min_kid_WAG<60', 'max_kid_WAG<60', 'count_kid_WAG<60', 'sum_kid_WAG<60', 'mean_kid_WAG<60', '%_kid_WAG<60', 'any_kid_WAG<70', 'all_kid_WAG<70', 'min_kid_WAG<70', 'max_kid_WAG<70', 'count_kid_WAG<70', 'sum_kid_WAG<70', 'mean_kid_WAG<70', '%_kid_WAG<70', 'any_kid_WAG<80', 'all_kid_WAG<80', 'min_kid_WAG<80', 'max_kid_WAG<80', 'count_kid_WAG<80', 'sum_kid_WAG<80', 'mean_kid_WAG<80', '%_kid_WAG<80', 'any_kid_WAG_any', 'all_kid_WAG_any', 'min_kid_WAG_any', 'max_kid_WAG_any', 'count_kid_WAG_any', 'sum_kid_WAG_any', 'mean_kid_WAG_any', '%_kid_WAG_any', 'all_anyage_WAG0', 'min_anyage_WAG0', 'max_anyage_WAG0', 'count_anyage_WAG0', 'sum_anyage_WAG0', 'mean_anyage_WAG0', 'all_anyage_WAG<10', 'max_anyage_WAG<10', 'count_anyage_WAG<10', 'sum_anyage_WAG<10', 'mean_anyage_WAG<10', 'all_anyage_WAG<15', 'min_anyage_WAG<15', 'max_anyage_WAG<15', 'count_anyage_WAG<15', 'sum_anyage_WAG<15', 'mean_anyage_WAG<15', 'all_anyage_WAG<20', 'min_anyage_WAG<20', 'max_anyage_WAG<20', 'count_anyage_WAG<20', 'sum_anyage_WAG<20', 'mean_anyage_WAG<20', 'all_anyage_WAG<25', 'min_anyage_WAG<25', 'max_anyage_WAG<25', 'count_anyage_WAG<25', 'sum_anyage_WAG<25', 'mean_anyage_WAG<25', '%_anyage_WAG<25', 'all_anyage_WAG<30', 'min_anyage_WAG<30', 'max_anyage_WAG<30', 'count_anyage_WAG<30', 'sum_anyage_WAG<30', 'mean_anyage_WAG<30', '%_anyage_WAG<30', 'all_anyage_WAG<35', 'min_anyage_WAG<35', 'max_anyage_WAG<35', 'count_anyage_WAG<35', 'sum_anyage_WAG<35', 'mean_anyage_WAG<35', '%_anyage_WAG<35', 'all_anyage_WAG<40', 'min_anyage_WAG<40', 'max_anyage_WAG<40', 'count_anyage_WAG<40', 'sum_anyage_WAG<40', 'mean_anyage_WAG<40', '%_anyage_WAG<40', 'all_anyage_WAG<45', 'min_anyage_WAG<45', 'max_anyage_WAG<45', 'count_anyage_WAG<45', 'sum_anyage_WAG<45', 'mean_anyage_WAG<45', '%_anyage_WAG<45', 'all_anyage_WAG<50', 'min_anyage_WAG<50', 'max_anyage_WAG<50', 'count_anyage_WAG<50', 'sum_anyage_WAG<50', 'mean_anyage_WAG<50', '%_anyage_WAG<50', 'all_anyage_WAG<60', 'min_anyage_WAG<60', 'max_anyage_WAG<60', 'count_anyage_WAG<60', 'sum_anyage_WAG<60', 'mean_anyage_WAG<60', '%_anyage_WAG<60', 'all_anyage_WAG<70', 'min_anyage_WAG<70', 'max_anyage_WAG<70', 'count_anyage_WAG<70', 'sum_anyage_WAG<70', 'mean_anyage_WAG<70', '%_anyage_WAG<70', 'all_anyage_WAG<80', 'min_anyage_WAG<80', 'max_anyage_WAG<80', 'count_anyage_WAG<80', 'sum_anyage_WAG<80', 'mean_anyage_WAG<80', '%_anyage_WAG<80', 'min_anyage_WAG_any', 'max_anyage_WAG_any', 'count_anyage_WAG_any', 'sum_anyage_WAG_any', 'mean_anyage_WAG_any', 'max_adult_INT1q', 'sum_adult_INT1q', 'mean_adult_INT1q', 'max_adult_INT2q', 'count_adult_INT2q', 'sum_adult_INT2q', 'mean_adult_INT2q', 'min_adult_INT3q', 'max_adult_INT3q', 'count_adult_INT3q', 'sum_adult_INT3q', 'mean_adult_INT3q', 'min_adult_INT4q', 'max_adult_INT4q', 'count_adult_INT4q', 'sum_adult_INT4q', 'mean_adult_INT4q', 'min_adult_INT_any', 'max_adult_INT_any', 'count_adult_INT_any', 'sum_adult_INT_any', 'mean_adult_INT_any', 'all_65+_INT0', 'min_65+_INT0', 'max_65+_INT0', 'sum_65+_INT0', 'mean_65+_INT0', '%_65+_INT0', 'min_65+_INT1q', 'max_65+_INT1q', 'count_65+_INT1q', 'sum_65+_INT1q', 'mean_65+_INT1q', '%_65+_INT1q', 'min_65+_INT2q', 'max_65+_INT2q', 'count_65+_INT2q', 'sum_65+_INT2q', 'mean_65+_INT2q', '%_65+_INT2q', 'min_65+_INT3q', 'max_65+_INT3q', 'count_65+_INT3q', 'sum_65+_INT3q', 'mean_65+_INT3q', '%_65+_INT3q', 'min_65+_INT4q', 'max_65+_INT4q', 'count_65+_INT4q', 'sum_65+_INT4q', 'mean_65+_INT4q', '%_65+_INT4q', 'any_65+_INT_any', 'all_65+_INT_any', 'min_65+_INT_any', 'max_65+_INT_any', 'count_65+_INT_any', 'sum_65+_INT_any', 'mean_65+_INT_any', '%_65+_INT_any', 'mean_18-64_INT0', '%_18-64_INT0', 'min_18-64_INT1q', 'max_18-64_INT1q', 'sum_18-64_INT1q', 'mean_18-64_INT1q', 'min_18-64_INT2q', 'max_18-64_INT2q', 'count_18-64_INT2q', 'sum_18-64_INT2q', 'mean_18-64_INT2q', 'min_18-64_INT3q', 'max_18-64_INT3q', 'count_18-64_INT3q', 'sum_18-64_INT3q', 'mean_18-64_INT3q', 'min_18-64_INT4q', 'max_18-64_INT4q', 'count_18-64_INT4q', 'sum_18-64_INT4q', 'mean_18-64_INT4q', 'any_18-64_INT_any', 'all_18-64_INT_any', 'min_18-64_INT_any', 'max_18-64_INT_any', 'count_18-64_INT_any', 'sum_18-64_INT_any', 'mean_18-64_INT_any', '%_18-64_INT_any', 'any_kid_INT0', 'all_kid_INT0', 'min_kid_INT0', 'max_kid_INT0', 'count_kid_INT0', 'sum_kid_INT0', 'mean_kid_INT0', '%_kid_INT0', 'max_kid_INT1q', 'sum_kid_INT1q', 'mean_kid_INT1q', 'max_kid_INT2q', 'sum_kid_INT2q', 'mean_kid_INT2q', 'max_kid_INT3q', 'sum_kid_INT3q', 'mean_kid_INT3q', 'any_kid_INT_any', 'all_kid_INT_any', 'min_kid_INT_any', 'max_kid_INT_any', 'count_kid_INT_any', 'sum_kid_INT_any', 'mean_kid_INT_any', '%_kid_INT_any', 'all_anyage_INT0', 'max_anyage_INT0', 'count_anyage_INT0', 'sum_anyage_INT0', '%_anyage_INT0', 'any_anyage_INT1q', 'all_anyage_INT1q', 'min_anyage_INT1q', 'max_anyage_INT1q', 'count_anyage_INT1q', 'sum_anyage_INT1q', 'mean_anyage_INT1q', '%_anyage_INT1q', 'any_anyage_INT2q', 'all_anyage_INT2q', 'min_anyage_INT2q', 'max_anyage_INT2q', 'count_anyage_INT2q', 'sum_anyage_INT2q', 'mean_anyage_INT2q', '%_anyage_INT2q', 'any_anyage_INT3q', 'all_anyage_INT3q', 'min_anyage_INT3q', 'max_anyage_INT3q', 'count_anyage_INT3q', 'sum_anyage_INT3q', 'mean_anyage_INT3q', '%_anyage_INT3q', 'any_anyage_INT4q', 'all_anyage_INT4q', 'min_anyage_INT4q', 'max_anyage_INT4q', 'count_anyage_INT4q', 'sum_anyage_INT4q', 'mean_anyage_INT4q', '%_anyage_INT4q', 'min_anyage_INT_any', 'max_anyage_INT_any', 'count_anyage_INT_any', 'sum_anyage_INT_any', 'mean_anyage_INT_any', 'sum_adult_SEMP0', 'max_adult_SEMP1q', 'count_adult_SEMP1q', 'sum_adult_SEMP1q', 'mean_adult_SEMP1q', 'min_adult_SEMP2q', 'max_adult_SEMP2q', 'count_adult_SEMP2q', 'sum_adult_SEMP2q', 'mean_adult_SEMP2q', 'min_adult_SEMP3q', 'max_adult_SEMP3q', 'count_adult_SEMP3q', 'sum_adult_SEMP3q', 'mean_adult_SEMP3q', 'min_adult_SEMP4q', 'max_adult_SEMP4q', 'count_adult_SEMP4q', 'sum_adult_SEMP4q', 'mean_adult_SEMP4q', 'min_adult_SEMP_any', 'max_adult_SEMP_any', 'count_adult_SEMP_any', 'sum_adult_SEMP_any', 'mean_adult_SEMP_any', 'any_65+_SEMP0', 'all_65+_SEMP0', 'min_65+_SEMP0', 'max_65+_SEMP0', 'count_65+_SEMP0', 'sum_65+_SEMP0', 'mean_65+_SEMP0', '%_65+_SEMP0', 'max_65+_SEMP1q', 'sum_65+_SEMP1q', 'mean_65+_SEMP1q', 'max_65+_SEMP2q', 'sum_65+_SEMP2q', 'mean_65+_SEMP2q', 'max_65+_SEMP3q', 'sum_65+_SEMP3q', 'mean_65+_SEMP3q', 'max_65+_SEMP4q', 'sum_65+_SEMP4q', 'mean_65+_SEMP4q', 'any_65+_SEMP_any', 'all_65+_SEMP_any', 'min_65+_SEMP_any', 'max_65+_SEMP_any', 'count_65+_SEMP_any', 'sum_65+_SEMP_any', 'mean_65+_SEMP_any', '%_65+_SEMP_any', 'count_18-64_SEMP0', 'sum_18-64_SEMP0', 'mean_18-64_SEMP0', '%_18-64_SEMP0', 'min_18-64_SEMP1q', 'max_18-64_SEMP1q', 'count_18-64_SEMP1q', 'sum_18-64_SEMP1q', 'mean_18-64_SEMP1q', 'min_18-64_SEMP2q', 'max_18-64_SEMP2q', 'count_18-64_SEMP2q', 'sum_18-64_SEMP2q', 'mean_18-64_SEMP2q', 'any_18-64_SEMP3q', 'min_18-64_SEMP3q', 'max_18-64_SEMP3q', 'count_18-64_SEMP3q', 'sum_18-64_SEMP3q', 'mean_18-64_SEMP3q', 'min_18-64_SEMP4q', 'max_18-64_SEMP4q', 'count_18-64_SEMP4q', 'sum_18-64_SEMP4q', 'mean_18-64_SEMP4q', 'any_18-64_SEMP_any', 'all_18-64_SEMP_any', 'min_18-64_SEMP_any', 'max_18-64_SEMP_any', 'count_18-64_SEMP_any', 'sum_18-64_SEMP_any', 'mean_18-64_SEMP_any', '%_18-64_SEMP_any', 'any_kid_SEMP0', 'all_kid_SEMP0', 'min_kid_SEMP0', 'max_kid_SEMP0', 'count_kid_SEMP0', 'sum_kid_SEMP0', 'mean_kid_SEMP0', '%_kid_SEMP0', 'max_kid_SEMP1q', 'sum_kid_SEMP1q', 'mean_kid_SEMP1q', 'any_kid_SEMP_any', 'all_kid_SEMP_any', 'min_kid_SEMP_any', 'max_kid_SEMP_any', 'count_kid_SEMP_any', 'sum_kid_SEMP_any', 'mean_kid_SEMP_any', '%_kid_SEMP_any', 'all_anyage_SEMP0', 'max_anyage_SEMP0', 'count_anyage_SEMP0', 'sum_anyage_SEMP0', '%_anyage_SEMP0', 'any_anyage_SEMP1q', 'min_anyage_SEMP1q', 'max_anyage_SEMP1q', 'count_anyage_SEMP1q', 'sum_anyage_SEMP1q', 'mean_anyage_SEMP1q', 'any_anyage_SEMP2q', 'min_anyage_SEMP2q', 'max_anyage_SEMP2q', 'count_anyage_SEMP2q', 'sum_anyage_SEMP2q', 'mean_anyage_SEMP2q', '%_anyage_SEMP2q', 'any_anyage_SEMP3q', 'min_anyage_SEMP3q', 'max_anyage_SEMP3q', 'count_anyage_SEMP3q', 'sum_anyage_SEMP3q', 'mean_anyage_SEMP3q', 'any_anyage_SEMP4q', 'min_anyage_SEMP4q', 'max_anyage_SEMP4q', 'count_anyage_SEMP4q', 'sum_anyage_SEMP4q', 'mean_anyage_SEMP4q', '%_anyage_SEMP4q', 'min_anyage_SEMP_any', 'max_anyage_SEMP_any', 'count_anyage_SEMP_any', 'sum_anyage_SEMP_any', 'mean_anyage_SEMP_any', 'mean_adult_SSP0', 'min_adult_SSP1q', 'max_adult_SSP1q', 'count_adult_SSP1q', 'sum_adult_SSP1q', 'mean_adult_SSP1q', 'min_adult_SSP2q', 'max_adult_SSP2q', 'count_adult_SSP2q', 'sum_adult_SSP2q', 'mean_adult_SSP2q', 'min_adult_SSP3q', 'max_adult_SSP3q', 'count_adult_SSP3q', 'sum_adult_SSP3q', 'mean_adult_SSP3q', 'min_adult_SSP4q', 'max_adult_SSP4q', 'count_adult_SSP4q', 'sum_adult_SSP4q', 'mean_adult_SSP4q', 'min_adult_SSP_any', 'max_adult_SSP_any', 'count_adult_SSP_any', 'sum_adult_SSP_any', 'mean_adult_SSP_any', 'min_65+_SSP0', 'max_65+_SSP0', 'count_65+_SSP0', 'sum_65+_SSP0', 'mean_65+_SSP0', '%_65+_SSP0', 'min_65+_SSP1q', 'max_65+_SSP1q', 'count_65+_SSP1q', 'sum_65+_SSP1q', 'mean_65+_SSP1q', '%_65+_SSP1q', 'min_65+_SSP2q', 'max_65+_SSP2q', 'count_65+_SSP2q', 'sum_65+_SSP2q', 'mean_65+_SSP2q', '%_65+_SSP2q', 'any_65+_SSP3q', 'min_65+_SSP3q', 'max_65+_SSP3q', 'count_65+_SSP3q', 'sum_65+_SSP3q', 'mean_65+_SSP3q', '%_65+_SSP3q', 'any_65+_SSP4q', 'min_65+_SSP4q', 'max_65+_SSP4q', 'count_65+_SSP4q', 'sum_65+_SSP4q', 'mean_65+_SSP4q', '%_65+_SSP4q', 'any_65+_SSP_any', 'all_65+_SSP_any', 'min_65+_SSP_any', 'max_65+_SSP_any', 'count_65+_SSP_any', 'sum_65+_SSP_any', 'mean_65+_SSP_any', '%_65+_SSP_any', 'count_18-64_SSP0', 'sum_18-64_SSP0', 'mean_18-64_SSP0', '%_18-64_SSP0', 'min_18-64_SSP1q', 'max_18-64_SSP1q', 'count_18-64_SSP1q', 'sum_18-64_SSP1q', 'mean_18-64_SSP1q', 'min_18-64_SSP2q', 'max_18-64_SSP2q', 'count_18-64_SSP2q', 'sum_18-64_SSP2q', 'mean_18-64_SSP2q', 'min_18-64_SSP3q', 'max_18-64_SSP3q', 'count_18-64_SSP3q', 'sum_18-64_SSP3q', 'mean_18-64_SSP3q', 'min_18-64_SSP4q', 'max_18-64_SSP4q', 'count_18-64_SSP4q', 'sum_18-64_SSP4q', 'mean_18-64_SSP4q', 'any_18-64_SSP_any', 'all_18-64_SSP_any', 'min_18-64_SSP_any', 'max_18-64_SSP_any', 'count_18-64_SSP_any', 'sum_18-64_SSP_any', 'mean_18-64_SSP_any', '%_18-64_SSP_any', 'any_kid_SSP0', 'all_kid_SSP0', 'min_kid_SSP0', 'max_kid_SSP0', 'count_kid_SSP0', 'sum_kid_SSP0', 'mean_kid_SSP0', '%_kid_SSP0', 'max_kid_SSP1q', 'mean_kid_SSP1q', 'max_kid_SSP2q', 'sum_kid_SSP2q', 'mean_kid_SSP2q', 'max_kid_SSP3q', 'sum_kid_SSP3q', 'mean_kid_SSP3q', 'any_kid_SSP_any', 'all_kid_SSP_any', 'min_kid_SSP_any', 'max_kid_SSP_any', 'count_kid_SSP_any', 'sum_kid_SSP_any', 'mean_kid_SSP_any', '%_kid_SSP_any', 'any_anyage_SSP0', 'all_anyage_SSP0', 'max_anyage_SSP0', 'sum_anyage_SSP0', '%_anyage_SSP0', 'any_anyage_SSP1q', 'all_anyage_SSP1q', 'min_anyage_SSP1q', 'max_anyage_SSP1q', 'count_anyage_SSP1q', 'sum_anyage_SSP1q', 'mean_anyage_SSP1q', '%_anyage_SSP1q', 'any_anyage_SSP2q', 'all_anyage_SSP2q', 'min_anyage_SSP2q', 'max_anyage_SSP2q', 'count_anyage_SSP2q', 'sum_anyage_SSP2q', 'mean_anyage_SSP2q', '%_anyage_SSP2q', 'any_anyage_SSP3q', 'all_anyage_SSP3q', 'min_anyage_SSP3q', 'max_anyage_SSP3q', 'count_anyage_SSP3q', 'sum_anyage_SSP3q', 'mean_anyage_SSP3q', '%_anyage_SSP3q', 'any_anyage_SSP4q', 'all_anyage_SSP4q', 'min_anyage_SSP4q', 'max_anyage_SSP4q', 'count_anyage_SSP4q', 'sum_anyage_SSP4q', 'mean_anyage_SSP4q', '%_anyage_SSP4q', 'min_anyage_SSP_any', 'max_anyage_SSP_any', 'count_anyage_SSP_any', 'sum_anyage_SSP_any', 'mean_anyage_SSP_any', 'count_adult_SSIP0', 'min_adult_SSIP1q', 'max_adult_SSIP1q', 'count_adult_SSIP1q', 'sum_adult_SSIP1q', 'mean_adult_SSIP1q', 'max_adult_SSIP2q', 'count_adult_SSIP2q', 'sum_adult_SSIP2q', 'mean_adult_SSIP2q', 'min_adult_SSIP3q', 'max_adult_SSIP3q', 'count_adult_SSIP3q', 'sum_adult_SSIP3q', 'mean_adult_SSIP3q', 'min_adult_SSIP_any', 'max_adult_SSIP_any', 'count_adult_SSIP_any', 'sum_adult_SSIP_any', 'mean_adult_SSIP_any', 'all_65+_SSIP0', 'min_65+_SSIP0', 'max_65+_SSIP0', 'sum_65+_SSIP0', 'mean_65+_SSIP0', '%_65+_SSIP0', 'min_65+_SSIP1q', 'max_65+_SSIP1q', 'count_65+_SSIP1q', 'sum_65+_SSIP1q', 'mean_65+_SSIP1q', 'max_65+_SSIP2q', 'count_65+_SSIP2q', 'sum_65+_SSIP2q', 'mean_65+_SSIP2q', 'min_65+_SSIP3q', 'max_65+_SSIP3q', 'count_65+_SSIP3q', 'sum_65+_SSIP3q', 'mean_65+_SSIP3q', '%_65+_SSIP3q', 'any_65+_SSIP_any', 'all_65+_SSIP_any', 'min_65+_SSIP_any', 'max_65+_SSIP_any', 'count_65+_SSIP_any', 'sum_65+_SSIP_any', 'mean_65+_SSIP_any', '%_65+_SSIP_any', 'count_18-64_SSIP0', 'sum_18-64_SSIP0', 'mean_18-64_SSIP0', '%_18-64_SSIP0', 'max_18-64_SSIP1q', 'sum_18-64_SSIP1q', 'mean_18-64_SSIP1q', 'max_18-64_SSIP2q', 'sum_18-64_SSIP2q', 'mean_18-64_SSIP2q', 'min_18-64_SSIP3q', 'max_18-64_SSIP3q', 'count_18-64_SSIP3q', 'sum_18-64_SSIP3q', 'mean_18-64_SSIP3q', 'any_18-64_SSIP_any', 'all_18-64_SSIP_any', 'min_18-64_SSIP_any', 'max_18-64_SSIP_any', 'count_18-64_SSIP_any', 'sum_18-64_SSIP_any', 'mean_18-64_SSIP_any', '%_18-64_SSIP_any', 'any_kid_SSIP0', 'all_kid_SSIP0', 'min_kid_SSIP0', 'max_kid_SSIP0', 'count_kid_SSIP0', 'sum_kid_SSIP0', 'mean_kid_SSIP0', '%_kid_SSIP0', 'max_kid_SSIP1q', 'sum_kid_SSIP1q', 'mean_kid_SSIP1q', 'max_kid_SSIP2q', 'sum_kid_SSIP2q', 'mean_kid_SSIP2q', 'max_kid_SSIP3q', 'sum_kid_SSIP3q', 'mean_kid_SSIP3q', 'any_kid_SSIP_any', 'all_kid_SSIP_any', 'min_kid_SSIP_any', 'max_kid_SSIP_any', 'count_kid_SSIP_any', 'sum_kid_SSIP_any', 'mean_kid_SSIP_any', '%_kid_SSIP_any', 'any_anyage_SSIP0', 'all_anyage_SSIP0', 'max_anyage_SSIP0', 'count_anyage_SSIP0', 'sum_anyage_SSIP0', '%_anyage_SSIP0', 'any_anyage_SSIP1q', 'min_anyage_SSIP1q', 'max_anyage_SSIP1q', 'count_anyage_SSIP1q', 'sum_anyage_SSIP1q', 'mean_anyage_SSIP1q', 'any_anyage_SSIP2q', 'min_anyage_SSIP2q', 'max_anyage_SSIP2q', 'count_anyage_SSIP2q', 'sum_anyage_SSIP2q', 'mean_anyage_SSIP2q', 'any_anyage_SSIP3q', 'all_anyage_SSIP3q', 'min_anyage_SSIP3q', 'max_anyage_SSIP3q', 'count_anyage_SSIP3q', 'sum_anyage_SSIP3q', 'mean_anyage_SSIP3q', '%_anyage_SSIP3q', 'min_anyage_SSIP_any', 'max_anyage_SSIP_any', 'count_anyage_SSIP_any', 'sum_anyage_SSIP_any', 'mean_anyage_SSIP_any', 'count_adult_PA0', 'sum_adult_PA0', 'max_adult_PA1q', 'sum_adult_PA1q', 'mean_adult_PA1q', 'max_adult_PA2q', 'count_adult_PA2q', 'sum_adult_PA2q', 'mean_adult_PA2q', 'max_adult_PA3q', 'count_adult_PA3q', 'sum_adult_PA3q', 'mean_adult_PA3q', 'min_adult_PA_any', 'max_adult_PA_any', 'count_adult_PA_any', 'sum_adult_PA_any', 'mean_adult_PA_any', 'any_65+_PA0', 'all_65+_PA0', 'min_65+_PA0', 'max_65+_PA0', 'count_65+_PA0', 'sum_65+_PA0', 'mean_65+_PA0', '%_65+_PA0', 'max_65+_PA1q', 'sum_65+_PA1q', 'mean_65+_PA1q', 'max_65+_PA2q', 'sum_65+_PA2q', 'mean_65+_PA2q', 'max_65+_PA3q', 'sum_65+_PA3q', 'mean_65+_PA3q', 'any_65+_PA_any', 'all_65+_PA_any', 'min_65+_PA_any', 'max_65+_PA_any', 'count_65+_PA_any', 'sum_65+_PA_any', 'mean_65+_PA_any', '%_65+_PA_any', 'all_18-64_PA0', 'min_18-64_PA0', 'max_18-64_PA0', 'count_18-64_PA0', 'sum_18-64_PA0', 'mean_18-64_PA0', '%_18-64_PA0', 'max_18-64_PA1q', 'sum_18-64_PA1q', 'mean_18-64_PA1q', 'min_18-64_PA2q', 'max_18-64_PA2q', 'count_18-64_PA2q', 'sum_18-64_PA2q', 'mean_18-64_PA2q', 'min_18-64_PA3q', 'max_18-64_PA3q', 'count_18-64_PA3q', 'sum_18-64_PA3q', 'mean_18-64_PA3q', 'any_18-64_PA_any', 'all_18-64_PA_any', 'min_18-64_PA_any', 'max_18-64_PA_any', 'count_18-64_PA_any', 'sum_18-64_PA_any', 'mean_18-64_PA_any', '%_18-64_PA_any', 'any_kid_PA0', 'all_kid_PA0', 'min_kid_PA0', 'max_kid_PA0', 'count_kid_PA0', 'sum_kid_PA0', 'mean_kid_PA0', '%_kid_PA0', 'max_kid_PA1q', 'mean_kid_PA1q', 'max_kid_PA2q', 'sum_kid_PA2q', 'mean_kid_PA2q', 'max_kid_PA3q', 'sum_kid_PA3q', 'mean_kid_PA3q', 'any_kid_PA_any', 'all_kid_PA_any', 'min_kid_PA_any', 'max_kid_PA_any', 'count_kid_PA_any', 'sum_kid_PA_any', 'mean_kid_PA_any', '%_kid_PA_any', 'all_anyage_PA0', 'min_anyage_PA0', 'max_anyage_PA0', 'count_anyage_PA0', 'sum_anyage_PA0', 'min_anyage_PA1q', 'max_anyage_PA1q', 'count_anyage_PA1q', 'sum_anyage_PA1q', 'mean_anyage_PA1q', 'any_anyage_PA2q', 'min_anyage_PA2q', 'max_anyage_PA2q', 'count_anyage_PA2q', 'sum_anyage_PA2q', 'mean_anyage_PA2q', 'any_anyage_PA3q', 'min_anyage_PA3q', 'max_anyage_PA3q', 'count_anyage_PA3q', 'sum_anyage_PA3q', 'mean_anyage_PA3q', 'min_anyage_PA_any', 'max_anyage_PA_any', 'count_anyage_PA_any', 'sum_anyage_PA_any', 'mean_anyage_PA_any', 'min_adult_RETP1q', 'max_adult_RETP1q', 'count_adult_RETP1q', 'sum_adult_RETP1q', 'mean_adult_RETP1q', 'min_adult_RETP2q', 'max_adult_RETP2q', 'count_adult_RETP2q', 'sum_adult_RETP2q', 'mean_adult_RETP2q', 'min_adult_RETP3q', 'max_adult_RETP3q', 'count_adult_RETP3q', 'sum_adult_RETP3q', 'mean_adult_RETP3q', 'min_adult_RETP_any', 'max_adult_RETP_any', 'count_adult_RETP_any', 'sum_adult_RETP_any', 'mean_adult_RETP_any', '%_65+_RETP0', 'min_65+_RETP1q', 'max_65+_RETP1q', 'count_65+_RETP1q', 'sum_65+_RETP1q', 'mean_65+_RETP1q', '%_65+_RETP1q', 'min_65+_RETP2q', 'max_65+_RETP2q', 'count_65+_RETP2q', 'sum_65+_RETP2q', 'mean_65+_RETP2q', '%_65+_RETP2q', 'min_65+_RETP3q', 'max_65+_RETP3q', 'count_65+_RETP3q', 'sum_65+_RETP3q', 'mean_65+_RETP3q', '%_65+_RETP3q', 'any_65+_RETP_any', 'all_65+_RETP_any', 'min_65+_RETP_any', 'max_65+_RETP_any', 'count_65+_RETP_any', 'sum_65+_RETP_any', 'mean_65+_RETP_any', '%_65+_RETP_any', 'count_18-64_RETP0', '%_18-64_RETP0', 'max_18-64_RETP1q', 'count_18-64_RETP1q', 'sum_18-64_RETP1q', 'mean_18-64_RETP1q', 'max_18-64_RETP2q', 'sum_18-64_RETP2q', 'mean_18-64_RETP2q', 'min_18-64_RETP3q', 'max_18-64_RETP3q', 'count_18-64_RETP3q', 'sum_18-64_RETP3q', 'mean_18-64_RETP3q', 'any_18-64_RETP_any', 'all_18-64_RETP_any', 'min_18-64_RETP_any', 'max_18-64_RETP_any', 'count_18-64_RETP_any', 'sum_18-64_RETP_any', 'mean_18-64_RETP_any', '%_18-64_RETP_any', 'all_kid_RETP0', 'count_kid_RETP0', '%_kid_RETP0', 'max_kid_RETP1q', 'sum_kid_RETP1q', 'mean_kid_RETP1q', 'any_kid_RETP_any', 'all_kid_RETP_any', 'min_kid_RETP_any', 'max_kid_RETP_any', 'count_kid_RETP_any', 'sum_kid_RETP_any', 'mean_kid_RETP_any', '%_kid_RETP_any', 'any_anyage_RETP1q', 'all_anyage_RETP1q', 'min_anyage_RETP1q', 'max_anyage_RETP1q', 'count_anyage_RETP1q', 'sum_anyage_RETP1q', 'mean_anyage_RETP1q', '%_anyage_RETP1q', 'any_anyage_RETP2q', 'all_anyage_RETP2q', 'min_anyage_RETP2q', 'max_anyage_RETP2q', 'count_anyage_RETP2q', 'sum_anyage_RETP2q', 'mean_anyage_RETP2q', '%_anyage_RETP2q', 'any_anyage_RETP3q', 'all_anyage_RETP3q', 'min_anyage_RETP3q', 'max_anyage_RETP3q', 'count_anyage_RETP3q', 'sum_anyage_RETP3q', 'mean_anyage_RETP3q', '%_anyage_RETP3q', 'min_anyage_RETP_any', 'max_anyage_RETP_any', 'count_anyage_RETP_any', 'sum_anyage_RETP_any', 'mean_anyage_RETP_any', 'max_adult_OI1q', 'count_adult_OI1q', 'sum_adult_OI1q', 'mean_adult_OI1q', 'max_adult_OI2q', 'count_adult_OI2q', 'sum_adult_OI2q', 'mean_adult_OI2q', 'max_adult_OI3q', 'count_adult_OI3q', 'sum_adult_OI3q', 'mean_adult_OI3q', 'min_adult_OI_any', 'max_adult_OI_any', 'count_adult_OI_any', 'sum_adult_OI_any', 'mean_adult_OI_any', 'max_65+_OI1q', 'sum_65+_OI1q', 'mean_65+_OI1q', 'max_65+_OI2q', 'sum_65+_OI2q', 'mean_65+_OI2q', 'min_65+_OI3q', 'max_65+_OI3q', 'count_65+_OI3q', 'sum_65+_OI3q', 'mean_65+_OI3q', 'any_65+_OI_any', 'all_65+_OI_any', 'min_65+_OI_any', 'max_65+_OI_any', 'count_65+_OI_any', 'sum_65+_OI_any', 'mean_65+_OI_any', '%_65+_OI_any', 'max_18-64_OI1q', 'sum_18-64_OI1q', 'mean_18-64_OI1q', 'min_18-64_OI2q', 'max_18-64_OI2q', 'count_18-64_OI2q', 'sum_18-64_OI2q', 'mean_18-64_OI2q', 'min_18-64_OI3q', 'max_18-64_OI3q', 'count_18-64_OI3q', 'sum_18-64_OI3q', 'mean_18-64_OI3q', 'any_18-64_OI_any', 'all_18-64_OI_any', 'min_18-64_OI_any', 'max_18-64_OI_any', 'count_18-64_OI_any', 'sum_18-64_OI_any', 'mean_18-64_OI_any', '%_18-64_OI_any', 'max_kid_OI1q', 'sum_kid_OI1q', 'mean_kid_OI1q', 'max_kid_OI2q', 'sum_kid_OI2q', 'mean_kid_OI2q', 'max_kid_OI3q', 'sum_kid_OI3q', 'mean_kid_OI3q', 'any_kid_OI_any', 'all_kid_OI_any', 'min_kid_OI_any', 'max_kid_OI_any', 'count_kid_OI_any', 'sum_kid_OI_any', 'mean_kid_OI_any', '%_kid_OI_any', 'min_anyage_OI1q', 'max_anyage_OI1q', 'count_anyage_OI1q', 'sum_anyage_OI1q', 'mean_anyage_OI1q', 'any_anyage_OI2q', 'min_anyage_OI2q', 'max_anyage_OI2q', 'count_anyage_OI2q', 'sum_anyage_OI2q', 'mean_anyage_OI2q', 'any_anyage_OI3q', 'min_anyage_OI3q', 'max_anyage_OI3q', 'count_anyage_OI3q', 'sum_anyage_OI3q', 'mean_anyage_OI3q', '%_anyage_OI3q', 'min_anyage_OI_any', 'max_anyage_OI_any', 'count_anyage_OI_any', 'sum_anyage_OI_any', 'mean_anyage_OI_any', 'max_adult_White', 'mean_adult_White', '%_adult_White', 'all_adult_Black', 'sum_adult_Black', 'mean_adult_Black', '%_adult_Black', 'sum_adult_Asian', 'mean_adult_Asian', '%_adult_Asian', 'sum_adult_Hisp', 'mean_adult_Hisp', '%_adult_Hisp', 'max_adult_ETH_other', 'sum_adult_ETH_other', 'mean_adult_ETH_other', 'min_adult_ETH_any', 'max_adult_ETH_any', 'count_adult_ETH_any', 'sum_adult_ETH_any', 'mean_adult_ETH_any', 'all_65+_White', 'min_65+_White', 'max_65+_White', 'sum_65+_White', 'mean_65+_White', '%_65+_White', 'all_65+_Black', 'min_65+_Black', 'max_65+_Black', 'sum_65+_Black', 'mean_65+_Black', '%_65+_Black', 'all_65+_Asian', 'min_65+_Asian', 'max_65+_Asian', 'sum_65+_Asian', 'mean_65+_Asian', '%_65+_Asian', 'all_65+_Hisp', 'min_65+_Hisp', 'max_65+_Hisp', 'sum_65+_Hisp', 'mean_65+_Hisp', '%_65+_Hisp', 'max_65+_ETH_other', 'mean_65+_ETH_other', 'any_65+_ETH_any', 'all_65+_ETH_any', 'min_65+_ETH_any', 'max_65+_ETH_any', 'count_65+_ETH_any', 'sum_65+_ETH_any', 'mean_65+_ETH_any', '%_65+_ETH_any', 'max_18-64_White', 'sum_18-64_White', 'mean_18-64_White', '%_18-64_White', 'all_18-64_Black', 'max_18-64_Black', 'sum_18-64_Black', 'mean_18-64_Black', '%_18-64_Black', 'max_18-64_Asian', 'count_18-64_Asian', 'sum_18-64_Asian', 'mean_18-64_Asian', '%_18-64_Asian', 'max_18-64_Hisp', 'count_18-64_Hisp', 'sum_18-64_Hisp', 'mean_18-64_Hisp', '%_18-64_Hisp', 'any_18-64_ETH_other', 'max_18-64_ETH_other', 'count_18-64_ETH_other', 'sum_18-64_ETH_other', 'mean_18-64_ETH_other', '%_18-64_ETH_other', 'any_18-64_ETH_any', 'all_18-64_ETH_any', 'min_18-64_ETH_any', 'max_18-64_ETH_any', 'count_18-64_ETH_any', 'sum_18-64_ETH_any', 'mean_18-64_ETH_any', '%_18-64_ETH_any', 'all_kid_White', 'mean_kid_White', '%_kid_White', 'all_kid_Black', 'mean_kid_Black', '%_kid_Black', 'all_kid_Asian', 'mean_kid_Asian', '%_kid_Asian', 'all_kid_Hisp', 'mean_kid_Hisp', '%_kid_Hisp', 'mean_kid_ETH_other', '%_kid_ETH_other', 'any_kid_ETH_any', 'all_kid_ETH_any', 'min_kid_ETH_any', 'max_kid_ETH_any', 'count_kid_ETH_any', 'sum_kid_ETH_any', 'mean_kid_ETH_any', '%_kid_ETH_any', 'any_anyage_White', 'all_anyage_White', 'min_anyage_White', 'max_anyage_White', 'sum_anyage_White', 'mean_anyage_White', '%_anyage_White', 'any_anyage_Black', 'all_anyage_Black', 'max_anyage_Black', 'sum_anyage_Black', 'mean_anyage_Black', '%_anyage_Black', 'any_anyage_Asian', 'all_anyage_Asian', 'max_anyage_Asian', 'count_anyage_Asian', 'sum_anyage_Asian', 'mean_anyage_Asian', '%_anyage_Asian', 'any_anyage_Hisp', 'all_anyage_Hisp', 'max_anyage_Hisp', 'sum_anyage_Hisp', 'mean_anyage_Hisp', '%_anyage_Hisp', 'all_anyage_ETH_other', 'max_anyage_ETH_other', 'sum_anyage_ETH_other', 'mean_anyage_ETH_other', '%_anyage_ETH_other', 'min_anyage_ETH_any', 'max_anyage_ETH_any', 'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any', 'max_adult_TINP0', 'sum_adult_TINP0', 'mean_adult_TINP0', 'mean_adult_TINP<10', 'mean_adult_TINP<15', 'mean_adult_TINP<20', 'mean_adult_TINP<25', 'count_adult_TINP<30', 'sum_adult_TINP<30', 'mean_adult_TINP<30', 'count_adult_TINP<35', 'sum_adult_TINP<35', 'mean_adult_TINP<35', 'count_adult_TINP<40', 'sum_adult_TINP<40', 'mean_adult_TINP<40', 'max_adult_TINP<45', 'count_adult_TINP<45', 'sum_adult_TINP<45', 'mean_adult_TINP<45', 'min_adult_TINP<50', 'max_adult_TINP<50', 'count_adult_TINP<50', 'sum_adult_TINP<50', 'mean_adult_TINP<50', 'count_adult_TINP<60', 'sum_adult_TINP<60', 'mean_adult_TINP<60', 'count_adult_TINP<70', 'sum_adult_TINP<70', 'mean_adult_TINP<70', 'count_adult_TINP<80', 'sum_adult_TINP<80', 'mean_adult_TINP<80', 'min_adult_TINP_any', 'max_adult_TINP_any', 'count_adult_TINP_any', 'sum_adult_TINP_any', 'mean_adult_TINP_any', 'min_65+_TINP0', 'max_65+_TINP0', 'count_65+_TINP0', 'sum_65+_TINP0', 'mean_65+_TINP0', '%_65+_TINP0', 'min_65+_TINP<10', 'max_65+_TINP<10', 'count_65+_TINP<10', 'sum_65+_TINP<10', 'mean_65+_TINP<10', '%_65+_TINP<10', 'min_65+_TINP<15', 'max_65+_TINP<15', 'sum_65+_TINP<15', 'mean_65+_TINP<15', '%_65+_TINP<15', 'min_65+_TINP<20', 'max_65+_TINP<20', 'sum_65+_TINP<20', 'mean_65+_TINP<20', '%_65+_TINP<20', 'min_65+_TINP<25', 'max_65+_TINP<25', 'sum_65+_TINP<25', 'mean_65+_TINP<25', '%_65+_TINP<25', 'any_65+_TINP<30', 'min_65+_TINP<30', 'max_65+_TINP<30', 'count_65+_TINP<30', 'sum_65+_TINP<30', 'mean_65+_TINP<30', '%_65+_TINP<30', 'any_65+_TINP<35', 'all_65+_TINP<35', 'min_65+_TINP<35', 'max_65+_TINP<35', 'count_65+_TINP<35', 'sum_65+_TINP<35', 'mean_65+_TINP<35', '%_65+_TINP<35', 'any_65+_TINP<40', 'all_65+_TINP<40', 'min_65+_TINP<40', 'max_65+_TINP<40', 'count_65+_TINP<40', 'sum_65+_TINP<40', 'mean_65+_TINP<40', '%_65+_TINP<40', 'any_65+_TINP<45', 'all_65+_TINP<45', 'min_65+_TINP<45', 'max_65+_TINP<45', 'count_65+_TINP<45', 'sum_65+_TINP<45', 'mean_65+_TINP<45', '%_65+_TINP<45', 'any_65+_TINP<50', 'all_65+_TINP<50', 'min_65+_TINP<50', 'max_65+_TINP<50', 'count_65+_TINP<50', 'sum_65+_TINP<50', 'mean_65+_TINP<50', '%_65+_TINP<50', 'any_65+_TINP<60', 'all_65+_TINP<60', 'min_65+_TINP<60', 'max_65+_TINP<60', 'count_65+_TINP<60', 'sum_65+_TINP<60', 'mean_65+_TINP<60', '%_65+_TINP<60', 'any_65+_TINP<70', 'all_65+_TINP<70', 'min_65+_TINP<70', 'max_65+_TINP<70', 'count_65+_TINP<70', 'sum_65+_TINP<70', 'mean_65+_TINP<70', '%_65+_TINP<70', 'any_65+_TINP<80', 'all_65+_TINP<80', 'min_65+_TINP<80', 'max_65+_TINP<80', 'count_65+_TINP<80', 'sum_65+_TINP<80', 'mean_65+_TINP<80', '%_65+_TINP<80', 'any_65+_TINP_any', 'all_65+_TINP_any', 'min_65+_TINP_any', 'max_65+_TINP_any', 'count_65+_TINP_any', 'sum_65+_TINP_any', 'mean_65+_TINP_any', '%_65+_TINP_any', 'max_18-64_TINP0', 'count_18-64_TINP0', 'sum_18-64_TINP0', 'mean_18-64_TINP0', 'max_18-64_TINP<10', 'mean_18-64_TINP<10', 'mean_18-64_TINP<15', 'count_18-64_TINP<20', 'mean_18-64_TINP<20', 'count_18-64_TINP<25', 'mean_18-64_TINP<25', 'count_18-64_TINP<30', 'sum_18-64_TINP<30', 'mean_18-64_TINP<30', 'count_18-64_TINP<35', 'sum_18-64_TINP<35', 'mean_18-64_TINP<35', 'count_18-64_TINP<40', 'sum_18-64_TINP<40', 'mean_18-64_TINP<40', 'any_18-64_TINP<45', 'max_18-64_TINP<45', 'count_18-64_TINP<45', 'sum_18-64_TINP<45', 'mean_18-64_TINP<45', '%_18-64_TINP<45', 'any_18-64_TINP<50', 'min_18-64_TINP<50', 'max_18-64_TINP<50', 'count_18-64_TINP<50', 'sum_18-64_TINP<50', 'mean_18-64_TINP<50', '%_18-64_TINP<50', 'any_18-64_TINP<60', 'all_18-64_TINP<60', 'min_18-64_TINP<60', 'max_18-64_TINP<60', 'count_18-64_TINP<60', 'sum_18-64_TINP<60', 'mean_18-64_TINP<60', '%_18-64_TINP<60', 'any_18-64_TINP<70', 'all_18-64_TINP<70', 'min_18-64_TINP<70', 'max_18-64_TINP<70', 'count_18-64_TINP<70', 'sum_18-64_TINP<70', 'mean_18-64_TINP<70', '%_18-64_TINP<70', 'any_18-64_TINP<80', 'all_18-64_TINP<80', 'min_18-64_TINP<80', 'max_18-64_TINP<80', 'count_18-64_TINP<80', 'sum_18-64_TINP<80', 'mean_18-64_TINP<80', '%_18-64_TINP<80', 'any_18-64_TINP_any', 'all_18-64_TINP_any', 'min_18-64_TINP_any', 'max_18-64_TINP_any', 'count_18-64_TINP_any', 'sum_18-64_TINP_any', 'mean_18-64_TINP_any', '%_18-64_TINP_any', 'any_kid_TINP0', 'all_kid_TINP0', 'min_kid_TINP0', 'max_kid_TINP0', 'count_kid_TINP0', 'sum_kid_TINP0', 'mean_kid_TINP0', '%_kid_TINP0', 'any_kid_TINP<10', 'all_kid_TINP<10', 'min_kid_TINP<10', 'max_kid_TINP<10', 'count_kid_TINP<10', 'sum_kid_TINP<10', 'mean_kid_TINP<10', '%_kid_TINP<10', 'any_kid_TINP<15', 'all_kid_TINP<15', 'min_kid_TINP<15', 'max_kid_TINP<15', 'count_kid_TINP<15', 'sum_kid_TINP<15', 'mean_kid_TINP<15', '%_kid_TINP<15', 'any_kid_TINP<20', 'all_kid_TINP<20', 'min_kid_TINP<20', 'max_kid_TINP<20', 'count_kid_TINP<20', 'sum_kid_TINP<20', 'mean_kid_TINP<20', '%_kid_TINP<20', 'any_kid_TINP<25', 'all_kid_TINP<25', 'min_kid_TINP<25', 'max_kid_TINP<25', 'count_kid_TINP<25', 'sum_kid_TINP<25', 'mean_kid_TINP<25', '%_kid_TINP<25', 'any_kid_TINP<30', 'all_kid_TINP<30', 'min_kid_TINP<30', 'max_kid_TINP<30', 'count_kid_TINP<30', 'sum_kid_TINP<30', 'mean_kid_TINP<30', '%_kid_TINP<30', 'any_kid_TINP<35', 'all_kid_TINP<35', 'min_kid_TINP<35', 'max_kid_TINP<35', 'count_kid_TINP<35', 'sum_kid_TINP<35', 'mean_kid_TINP<35', '%_kid_TINP<35', 'any_kid_TINP<40', 'all_kid_TINP<40', 'min_kid_TINP<40', 'max_kid_TINP<40', 'count_kid_TINP<40', 'sum_kid_TINP<40', 'mean_kid_TINP<40', '%_kid_TINP<40', 'any_kid_TINP<45', 'all_kid_TINP<45', 'min_kid_TINP<45', 'max_kid_TINP<45', 'count_kid_TINP<45', 'sum_kid_TINP<45', 'mean_kid_TINP<45', '%_kid_TINP<45', 'any_kid_TINP<50', 'all_kid_TINP<50', 'min_kid_TINP<50', 'max_kid_TINP<50', 'count_kid_TINP<50', 'sum_kid_TINP<50', 'mean_kid_TINP<50', '%_kid_TINP<50', 'any_kid_TINP<60', 'all_kid_TINP<60', 'min_kid_TINP<60', 'max_kid_TINP<60', 'count_kid_TINP<60', 'sum_kid_TINP<60', 'mean_kid_TINP<60', '%_kid_TINP<60', 'any_kid_TINP<70', 'all_kid_TINP<70', 'min_kid_TINP<70', 'max_kid_TINP<70', 'count_kid_TINP<70', 'sum_kid_TINP<70', 'mean_kid_TINP<70', '%_kid_TINP<70', 'any_kid_TINP<80', 'all_kid_TINP<80', 'min_kid_TINP<80', 'max_kid_TINP<80', 'count_kid_TINP<80', 'sum_kid_TINP<80', 'mean_kid_TINP<80', '%_kid_TINP<80', 'any_kid_TINP_any', 'all_kid_TINP_any', 'min_kid_TINP_any', 'max_kid_TINP_any', 'count_kid_TINP_any', 'sum_kid_TINP_any', 'mean_kid_TINP_any', '%_kid_TINP_any', 'all_anyage_TINP0', 'max_anyage_TINP0', 'mean_anyage_TINP0', 'all_anyage_TINP<10', 'max_anyage_TINP<10', 'sum_anyage_TINP<10', 'mean_anyage_TINP<10', 'all_anyage_TINP<15', 'max_anyage_TINP<15', 'count_anyage_TINP<15', 'sum_anyage_TINP<15', 'mean_anyage_TINP<15', 'all_anyage_TINP<20', 'max_anyage_TINP<20', 'count_anyage_TINP<20', 'sum_anyage_TINP<20', 'mean_anyage_TINP<20', 'all_anyage_TINP<25', 'max_anyage_TINP<25', 'count_anyage_TINP<25', 'sum_anyage_TINP<25', 'mean_anyage_TINP<25', 'all_anyage_TINP<30', 'max_anyage_TINP<30', 'count_anyage_TINP<30', 'sum_anyage_TINP<30', 'mean_anyage_TINP<30', '%_anyage_TINP<30', 'all_anyage_TINP<35', 'max_anyage_TINP<35', 'count_anyage_TINP<35', 'sum_anyage_TINP<35', 'mean_anyage_TINP<35', '%_anyage_TINP<35', 'all_anyage_TINP<40', 'max_anyage_TINP<40', 'count_anyage_TINP<40', 'sum_anyage_TINP<40', 'mean_anyage_TINP<40', '%_anyage_TINP<40', 'all_anyage_TINP<45', 'min_anyage_TINP<45', 'max_anyage_TINP<45', 'count_anyage_TINP<45', 'sum_anyage_TINP<45', 'mean_anyage_TINP<45', '%_anyage_TINP<45', 'all_anyage_TINP<50', 'min_anyage_TINP<50', 'max_anyage_TINP<50', 'count_anyage_TINP<50', 'sum_anyage_TINP<50', 'mean_anyage_TINP<50', '%_anyage_TINP<50', 'all_anyage_TINP<60', 'max_anyage_TINP<60', 'count_anyage_TINP<60', 'sum_anyage_TINP<60', 'mean_anyage_TINP<60', '%_anyage_TINP<60', 'all_anyage_TINP<70', 'max_anyage_TINP<70', 'count_anyage_TINP<70', 'sum_anyage_TINP<70', 'mean_anyage_TINP<70', '%_anyage_TINP<70', 'all_anyage_TINP<80', 'min_anyage_TINP<80', 'max_anyage_TINP<80', 'count_anyage_TINP<80', 'sum_anyage_TINP<80', 'mean_anyage_TINP<80', '%_anyage_TINP<80', 'min_anyage_TINP_any', 'max_anyage_TINP_any', 'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any', 'MSP_2_1.0', 'HousingStatus_7.0', 'HousingStatus_8.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3406"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing -- at a personal level -- total income versus non-financial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 335.54s to fit \n",
      "\n",
      "Test score: 0.35290137507414676\n",
      "Training score: 0.9194132193643912\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'clf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5f5aa6937271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTest score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OOB score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers_inc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clf'"
     ]
    }
   ],
   "source": [
    "personal = all_2016[all_2016.AGEP >= 18].copy()\n",
    "\n",
    "# Add total personal income ('TINP') and total rent/mortgage ('MRNT')\n",
    "personal['TINP'] = personal.WAGP_adj + personal.INTP_adj + personal.SEMP_adj + personal.SSP_adj + personal.SSIP_adj + \\\n",
    "                    personal.PA_adj + personal.RETP_adj + personal.OI_adj\n",
    "personal['MRNT'] = personal.MRGP_adj + personal.RNTP_adj\n",
    "\n",
    "# Only keep the features that may be useful\n",
    "features_to_keep = ['AGEP', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'LANX', 'ENG', 'MSP', 'MAR', 'WKW', 'WKHP', \n",
    "                    'DIS', 'NP', 'TEN', 'HHT', 'JWTR', 'Povunit_Rel', 'FamType_PU', 'HousingStatus', 'Ethnicity', \n",
    "                    'TotalWorkHrs_PU', 'Boro', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork', 'MRNT', 'TINP']\n",
    "personal = personal[features_to_keep]\n",
    "\n",
    "# Track which columns we'll need to make dummies for\n",
    "dummy_these = ['AGEP', 'CIT', 'SCH', 'SCHG', 'SCHL', 'SEX', 'ESR', 'LANX', 'ENG', 'MSP', 'MAR', 'WKW', 'WKHP', \n",
    "                    'DIS', 'NP', 'TEN', 'HHT', 'JWTR', 'Povunit_Rel', 'FamType_PU', 'HousingStatus', 'Ethnicity', \n",
    "                    'TotalWorkHrs_PU', 'Boro', 'EducAttain', 'CitizenStatus', 'AgeCateg', 'FTPTWork']\n",
    "\n",
    "# Pull off 'TINP' for our target variable\n",
    "y_pers = personal['TINP'].copy()\n",
    "X_pers = personal.copy().drop('TINP', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pers, y_pers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare our steps for the pipeline\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=1000, max_features='auto', oob_score=True, random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pers_inc_pipeline = imbPipeline(steps=[('cat', categorizer), \n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "# Fire away\n",
    "t0 = time.time()\n",
    "pers_inc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "print('\\nTest score: ' + str(pers_inc_pipeline.score(X_test, y_test)))\n",
    "print('Training score: ' + str(pers_inc_pipeline.score(X_train, y_train)))\n",
    "print('OOB score: ' + str(pers_inc_pipeline.named_steps['reg'].oob_score_))\n",
    "print('n_estimators: ' + str(pers_inc_pipeline.named_steps['reg'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_pers = pers_inc_pipeline.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(y_test, predictions_pers)#, marker='.', linestyle='none')\n",
    "lower = 0\n",
    "upper = max(y_test.max(), predictions_pers.max()) + 10000\n",
    "liner = np.arange(lower, upper)\n",
    "ax.plot(liner, liner, color='k')\n",
    "ax.set_xlim(lower, upper)\n",
    "ax.set_ylim(lower, upper)\n",
    "ax.set_title('Total Personal Income vs. Predicted')\n",
    "ax.set_xlabel('Actual Total Personal Income')\n",
    "ax.set_ylabel('Predicted Total Personal Income')\n",
    "plt.rcParams[\"figure.figsize\"] = [4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.015547567291145592, 'AGEP'),\n",
       " (0.006694876419869801, 'FamType_PU'),\n",
       " (0.006608194143419285, 'TotalWorkHrs_PU'),\n",
       " (0.004774831141534058, 'FTPTWork'),\n",
       " (0.00469248382048341, 'EducAttain'),\n",
       " (0.00436351341183179, 'MRNT'),\n",
       " (0.0037353994532746382, 'Boro'),\n",
       " (0.003696698220815743, 'JWTR'),\n",
       " (0.0036964648389549537, 'Ethnicity'),\n",
       " (0.0036936192163132564, 'TEN'),\n",
       " (0.0030972619116118702, 'WKHP'),\n",
       " (0.002844298571018428, 'Povunit_Rel'),\n",
       " (0.0027464484440693875, 'AgeCateg'),\n",
       " (0.002433785650907912, 'NP'),\n",
       " (0.0022940933411346323, 'HousingStatus')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imps_pers = list(zip(pers_inc_pipeline.named_steps['reg'].feature_importances_, \n",
    "                     X_train.columns))\n",
    "sorted(imps_pers, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "#scalers = [StandardScaler(), Normalizer(), PowerTransformer(), QuantileTransformer()]\n",
    "scalers = [Normalizer()]\n",
    "scaler = Normalizer()\n",
    "#classifiers = [LogisticRegression(), SGDClassifier(), AdaBoostClassifier(), BaggingClassifier(), GradientBoostingClassifier(), \n",
    "               #RandomForestClassifier(), BalancedBaggingClassifier(), BalancedRandomForestClassifier(), RUSBoostClassifier()]\n",
    "#classifiers = [BalancedBaggingClassifier(), BaggingClassifier(), RandomForestClassifier(), BalancedRandomForestClassifier(), \n",
    "               #AdaBoostClassifier(), GradientBoostingClassifier()]\n",
    "#classifiers = [RandomForestClassifier(), BalancedRandomForestClassifier()]\n",
    "classifiers = [BalancedRandomForestClassifier()]\n",
    "\n",
    "#sampler = TomekLinks(random_state=42)\n",
    "#scaler = QuantileTransformer()\n",
    "#clf = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = AdaBoostClassifier()\n",
    "#params={0: {'clf__C': [1, 1e-1, 1e-2, 1e-3], 'clf__max_iter': [1e2, 1e3, 1e4], # Logistic Regression\n",
    "                               #'clf__solver': ['lbfgs', 'liblinear', 'sag', 'saga']}, \n",
    "        #1: {'n_estimators': [1e1, 1e2, 1e3], 'max_features': [5, 10, 50, 100], # Random Forest Classifier\n",
    "                         #'criterion': ['gini', 'entropy']}\n",
    "       #}\n",
    "#params = {0: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy']},\n",
    "          #1: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy'], 'clf_sampling_strategy': [0.05, 0.25, 0.5, 0.75, 0.95]}\n",
    "         #}\n",
    "\n",
    "params = {0: {'clf__n_estimators': [1000], 'clf__max_features': [100],\n",
    "              'clf__sampling_strategy': ['not minority', 'not majority', 'all']}}\n",
    "          #1: {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100],\n",
    "              #'clf__criterion': ['gini', 'entropy']},\n",
    "         #}\n",
    "\n",
    "#parameters = {'clf__n_estimators': [10, 100, 1000], 'clf__max_features': [5, 10, 50, 100], 'clf__criterion': ['gini', 'entropy']}\n",
    "parameters = {'clf__n_estimators': [100], 'clf__max_features': ['auto'], 'clf__criterion': ['gini']}\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "#pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              #('dummies', dummy_encoder),\n",
    "                              #('sampler', sampler),\n",
    "                              #('scaler', scaler),\n",
    "                              #('clf', BalancedRandomForestClassifier())], \n",
    "                      #memory=cachedir)\n",
    "                    \n",
    "#grid = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, n_jobs=-1, pre_dispatch=2, verbose=9)#, scoring=balanced_accuracy_score())\n",
    "#grid = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, n_jobs=-1, verbose=9)\n",
    "\n",
    "#t0 = time.time()\n",
    "#grid.fit(X_train, y_train)\n",
    "#time_to_fit = time.time() - t0\n",
    "#print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "#print(grid.cv_results_)\n",
    "\n",
    "#for sampler, i in zip(samplers, range(len(samplers))):\n",
    "for i in range(1):\n",
    "    #for scaler, j in zip(scalers, range(len(scalers))):\n",
    "    for scaler in scalers:\n",
    "        for k in range(len(classifiers)):\n",
    "            #pipeline = Pipeline(steps=[#('cat', categorizer),\n",
    "            pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                                          ('dummies', dummy_encoder),\n",
    "                                          #('sampler', sampler),\n",
    "                                          ('scaler', scaler),\n",
    "                                          ('clf', classifiers[k])],\n",
    "                                  memory=cachedir)\n",
    "\n",
    "            #print(pipeline)\n",
    "            #print(params[i])\n",
    "            #pipeline.get_params().keys()\n",
    "            grid = GridSearchCV(estimator=pipeline, param_grid=params[k], cv=3, n_jobs=-1, verbose=9)#, scoring=balanced_accuracy_score())\n",
    "\n",
    "            t0 = time.time()\n",
    "            #pipeline.fit(X_train, y_train)\n",
    "            grid.fit(X_train, y_train)\n",
    "            time_to_fit = time.time() - t0\n",
    "            print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "            print(grid.cv_results_)\n",
    "            print('best estimator: ' + str(grid.best_estimator_))\n",
    "            print('best params: ' + str(grid.best_params_))\n",
    "            print('best index: ' + str(grid.best_index_))\n",
    "            \n",
    "            #print(str(sampler) + ',' + str(scaler) + ',' + str(classifiers[k]))\n",
    "            #print(str(scaler) + ',' + str(classifiers[k]))\n",
    "                  \n",
    "            #means = grid.cv_results_['mean_test_score']\n",
    "            #stds = grid.cv_results_['std_test_score']\n",
    "            #for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "                #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "            #predictions = pipeline.predict(X_test)\n",
    "\n",
    "#print('Predictions: ' + str(predictions))\n",
    "#print('Actual:\\n' + str(y_small))\n",
    "            #print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "            #print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "            #print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "            #print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975358685378098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_mean_score(grid.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.019535791275811728, 'WKW_2'),\n",
       " (0.020252231346152935, 'INTP_adj_1'),\n",
       " (0.020452137721584687, 'SCHL_2'),\n",
       " (0.020767468686063252, 'RNTP_adj'),\n",
       " (0.02515045254416771, 'WKHP_2'),\n",
       " (0.026205088630138082, 'AGEP_1'),\n",
       " (0.02817688155652038, 'SCHL_1'),\n",
       " (0.03238306328525264, 'WKW_1'),\n",
       " (0.03242418603775719, 'JWTR_1'),\n",
       " (0.03587014309356664, 'RETP_adj_1'),\n",
       " (0.041251391667779504, 'WKHP_1'),\n",
       " (0.05057339662820781, 'SSP_adj_1'),\n",
       " (0.052182437399624144, 'WAGP_adj_2'),\n",
       " (0.07156076688876317, 'TotalWorkHrs_PU'),\n",
       " (0.14873418922209963, 'WAGP_adj_1')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tester = BalancedRandomForestClassifier().fit(X=X_train, y=y_train)\n",
    "#len(tester.feature_importances_)\n",
    "#X_train.columns\n",
    "#geometric_mean_score(tester.predict(X_test), y_test)  #0.775727880752169\n",
    "imps = list(zip(tester.feature_importances_, X_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.356531</td>\n",
       "      <td>0.774929</td>\n",
       "      <td>7.338355</td>\n",
       "      <td>0.130668</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.912454</td>\n",
       "      <td>0.913203</td>\n",
       "      <td>0.911165</td>\n",
       "      <td>0.912274</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>22</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.269967</td>\n",
       "      <td>2.907710</td>\n",
       "      <td>8.925081</td>\n",
       "      <td>2.030989</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.918662</td>\n",
       "      <td>0.920046</td>\n",
       "      <td>0.921176</td>\n",
       "      <td>0.919961</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.631243</td>\n",
       "      <td>11.630676</td>\n",
       "      <td>24.091638</td>\n",
       "      <td>2.337423</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.919422</td>\n",
       "      <td>0.920426</td>\n",
       "      <td>0.919909</td>\n",
       "      <td>0.919919</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.915396</td>\n",
       "      <td>0.285015</td>\n",
       "      <td>8.093561</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.909033</td>\n",
       "      <td>0.911809</td>\n",
       "      <td>0.910404</td>\n",
       "      <td>0.910416</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>24</td>\n",
       "      <td>0.996515</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.996706</td>\n",
       "      <td>0.996621</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.711045</td>\n",
       "      <td>0.981712</td>\n",
       "      <td>7.328075</td>\n",
       "      <td>1.507757</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.920806</td>\n",
       "      <td>0.920289</td>\n",
       "      <td>0.919116</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151.528578</td>\n",
       "      <td>11.447976</td>\n",
       "      <td>19.518697</td>\n",
       "      <td>3.485998</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.919802</td>\n",
       "      <td>0.919792</td>\n",
       "      <td>0.921810</td>\n",
       "      <td>0.920468</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.778635</td>\n",
       "      <td>0.298928</td>\n",
       "      <td>7.595569</td>\n",
       "      <td>0.218479</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.916002</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.918388</td>\n",
       "      <td>0.917300</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>18</td>\n",
       "      <td>0.995248</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996326</td>\n",
       "      <td>0.995734</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.483098</td>\n",
       "      <td>3.360073</td>\n",
       "      <td>6.941224</td>\n",
       "      <td>1.106543</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.922463</td>\n",
       "      <td>0.924354</td>\n",
       "      <td>0.925231</td>\n",
       "      <td>0.924016</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>353.551459</td>\n",
       "      <td>24.645494</td>\n",
       "      <td>14.723334</td>\n",
       "      <td>2.187714</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.922970</td>\n",
       "      <td>0.925494</td>\n",
       "      <td>0.927005</td>\n",
       "      <td>0.925156</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.911089</td>\n",
       "      <td>0.593627</td>\n",
       "      <td>7.788339</td>\n",
       "      <td>0.047878</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.914608</td>\n",
       "      <td>0.914090</td>\n",
       "      <td>0.917754</td>\n",
       "      <td>0.915484</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>19</td>\n",
       "      <td>0.995818</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.996304</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.250116</td>\n",
       "      <td>6.208748</td>\n",
       "      <td>7.382807</td>\n",
       "      <td>1.209777</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.927024</td>\n",
       "      <td>0.929676</td>\n",
       "      <td>0.925992</td>\n",
       "      <td>0.927564</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>604.099197</td>\n",
       "      <td>40.388460</td>\n",
       "      <td>15.118818</td>\n",
       "      <td>2.104008</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_features'...</td>\n",
       "      <td>0.927277</td>\n",
       "      <td>0.927902</td>\n",
       "      <td>0.927893</td>\n",
       "      <td>0.927690</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.635937</td>\n",
       "      <td>0.202809</td>\n",
       "      <td>8.041993</td>\n",
       "      <td>0.094281</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.911187</td>\n",
       "      <td>0.911049</td>\n",
       "      <td>0.910784</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>23</td>\n",
       "      <td>0.995311</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.703423</td>\n",
       "      <td>0.274799</td>\n",
       "      <td>9.826621</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.920182</td>\n",
       "      <td>0.919539</td>\n",
       "      <td>0.921049</td>\n",
       "      <td>0.920257</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>125.815334</td>\n",
       "      <td>10.479840</td>\n",
       "      <td>25.741467</td>\n",
       "      <td>3.183750</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.919676</td>\n",
       "      <td>0.920426</td>\n",
       "      <td>0.920289</td>\n",
       "      <td>0.920130</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.241193</td>\n",
       "      <td>0.842785</td>\n",
       "      <td>6.291520</td>\n",
       "      <td>1.195959</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.913088</td>\n",
       "      <td>0.909275</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>21</td>\n",
       "      <td>0.996452</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.362928</td>\n",
       "      <td>1.091575</td>\n",
       "      <td>8.315560</td>\n",
       "      <td>0.948133</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.920182</td>\n",
       "      <td>0.921946</td>\n",
       "      <td>0.922443</td>\n",
       "      <td>0.921524</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>141.452599</td>\n",
       "      <td>12.096369</td>\n",
       "      <td>18.503021</td>\n",
       "      <td>1.951633</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.921820</td>\n",
       "      <td>0.920542</td>\n",
       "      <td>0.921186</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.892606</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>7.927964</td>\n",
       "      <td>0.195101</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.914354</td>\n",
       "      <td>0.915864</td>\n",
       "      <td>0.914713</td>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996262</td>\n",
       "      <td>0.995819</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.995924</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28.135110</td>\n",
       "      <td>1.850436</td>\n",
       "      <td>7.699444</td>\n",
       "      <td>1.007361</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.925250</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.924978</td>\n",
       "      <td>0.925621</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>273.912406</td>\n",
       "      <td>17.282531</td>\n",
       "      <td>13.551803</td>\n",
       "      <td>1.713333</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.927151</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.927386</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.285676</td>\n",
       "      <td>0.373293</td>\n",
       "      <td>7.967199</td>\n",
       "      <td>0.167094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.916002</td>\n",
       "      <td>0.920172</td>\n",
       "      <td>0.919402</td>\n",
       "      <td>0.918525</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>17</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.996009</td>\n",
       "      <td>0.995755</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44.109372</td>\n",
       "      <td>4.389925</td>\n",
       "      <td>7.425203</td>\n",
       "      <td>1.210115</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.926390</td>\n",
       "      <td>0.929042</td>\n",
       "      <td>0.926879</td>\n",
       "      <td>0.927437</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>356.878639</td>\n",
       "      <td>99.027548</td>\n",
       "      <td>11.762577</td>\n",
       "      <td>2.313773</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_featur...</td>\n",
       "      <td>0.928544</td>\n",
       "      <td>0.931323</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       29.356531      0.774929         7.338355        0.130668   \n",
       "1       21.269967      2.907710         8.925081        2.030989   \n",
       "2      133.631243     11.630676        24.091638        2.337423   \n",
       "3        6.915396      0.285015         8.093561        0.456263   \n",
       "4       17.711045      0.981712         7.328075        1.507757   \n",
       "5      151.528578     11.447976        19.518697        3.485998   \n",
       "6        8.778635      0.298928         7.595569        0.218479   \n",
       "7       36.483098      3.360073         6.941224        1.106543   \n",
       "8      353.551459     24.645494        14.723334        2.187714   \n",
       "9       10.911089      0.593627         7.788339        0.047878   \n",
       "10      62.250116      6.208748         7.382807        1.209777   \n",
       "11     604.099197     40.388460        15.118818        2.104008   \n",
       "12       6.635937      0.202809         8.041993        0.094281   \n",
       "13      18.703423      0.274799         9.826621        0.189647   \n",
       "14     125.815334     10.479840        25.741467        3.183750   \n",
       "15       5.241193      0.842785         6.291520        1.195959   \n",
       "16      16.362928      1.091575         8.315560        0.948133   \n",
       "17     141.452599     12.096369        18.503021        1.951633   \n",
       "18       7.892606      0.185923         7.927964        0.195101   \n",
       "19      28.135110      1.850436         7.699444        1.007361   \n",
       "20     273.912406     17.282531        13.551803        1.713333   \n",
       "21       9.285676      0.373293         7.967199        0.167094   \n",
       "22      44.109372      4.389925         7.425203        1.210115   \n",
       "23     356.878639     99.027548        11.762577        2.313773   \n",
       "\n",
       "   param_clf__criterion param_clf__max_features param_clf__n_estimators  \\\n",
       "0                  gini                       5                      10   \n",
       "1                  gini                       5                     100   \n",
       "2                  gini                       5                    1000   \n",
       "3                  gini                      10                      10   \n",
       "4                  gini                      10                     100   \n",
       "5                  gini                      10                    1000   \n",
       "6                  gini                      50                      10   \n",
       "7                  gini                      50                     100   \n",
       "8                  gini                      50                    1000   \n",
       "9                  gini                     100                      10   \n",
       "10                 gini                     100                     100   \n",
       "11                 gini                     100                    1000   \n",
       "12              entropy                       5                      10   \n",
       "13              entropy                       5                     100   \n",
       "14              entropy                       5                    1000   \n",
       "15              entropy                      10                      10   \n",
       "16              entropy                      10                     100   \n",
       "17              entropy                      10                    1000   \n",
       "18              entropy                      50                      10   \n",
       "19              entropy                      50                     100   \n",
       "20              entropy                      50                    1000   \n",
       "21              entropy                     100                      10   \n",
       "22              entropy                     100                     100   \n",
       "23              entropy                     100                    1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'clf__criterion': 'gini', 'clf__max_features'...           0.912454   \n",
       "1   {'clf__criterion': 'gini', 'clf__max_features'...           0.918662   \n",
       "2   {'clf__criterion': 'gini', 'clf__max_features'...           0.919422   \n",
       "3   {'clf__criterion': 'gini', 'clf__max_features'...           0.909033   \n",
       "4   {'clf__criterion': 'gini', 'clf__max_features'...           0.916255   \n",
       "5   {'clf__criterion': 'gini', 'clf__max_features'...           0.919802   \n",
       "6   {'clf__criterion': 'gini', 'clf__max_features'...           0.916002   \n",
       "7   {'clf__criterion': 'gini', 'clf__max_features'...           0.922463   \n",
       "8   {'clf__criterion': 'gini', 'clf__max_features'...           0.922970   \n",
       "9   {'clf__criterion': 'gini', 'clf__max_features'...           0.914608   \n",
       "10  {'clf__criterion': 'gini', 'clf__max_features'...           0.927024   \n",
       "11  {'clf__criterion': 'gini', 'clf__max_features'...           0.927277   \n",
       "12  {'clf__criterion': 'entropy', 'clf__max_featur...           0.911187   \n",
       "13  {'clf__criterion': 'entropy', 'clf__max_featur...           0.920182   \n",
       "14  {'clf__criterion': 'entropy', 'clf__max_featur...           0.919676   \n",
       "15  {'clf__criterion': 'entropy', 'clf__max_featur...           0.913088   \n",
       "16  {'clf__criterion': 'entropy', 'clf__max_featur...           0.920182   \n",
       "17  {'clf__criterion': 'entropy', 'clf__max_featur...           0.921196   \n",
       "18  {'clf__criterion': 'entropy', 'clf__max_featur...           0.914354   \n",
       "19  {'clf__criterion': 'entropy', 'clf__max_featur...           0.925250   \n",
       "20  {'clf__criterion': 'entropy', 'clf__max_featur...           0.927151   \n",
       "21  {'clf__criterion': 'entropy', 'clf__max_featur...           0.916002   \n",
       "22  {'clf__criterion': 'entropy', 'clf__max_featur...           0.926390   \n",
       "23  {'clf__criterion': 'entropy', 'clf__max_featur...           0.928544   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913203           0.911165         0.912274        0.000842   \n",
       "1            0.920046           0.921176         0.919961        0.001028   \n",
       "2            0.920426           0.919909         0.919919        0.000410   \n",
       "3            0.911809           0.910404         0.910416        0.001133   \n",
       "4            0.920806           0.920289         0.919116        0.002035   \n",
       "5            0.919792           0.921810         0.920468        0.000949   \n",
       "6            0.917511           0.918388         0.917300        0.000986   \n",
       "7            0.924354           0.925231         0.924016        0.001155   \n",
       "8            0.925494           0.927005         0.925156        0.001665   \n",
       "9            0.914090           0.917754         0.915484        0.001619   \n",
       "10           0.929676           0.925992         0.927564        0.001552   \n",
       "11           0.927902           0.927893         0.927690        0.000292   \n",
       "12           0.911049           0.910784         0.911007        0.000167   \n",
       "13           0.919539           0.921049         0.920257        0.000619   \n",
       "14           0.920426           0.920289         0.920130        0.000326   \n",
       "15           0.909275           0.915347         0.912570        0.002505   \n",
       "16           0.921946           0.922443         0.921524        0.000970   \n",
       "17           0.921820           0.920542         0.921186        0.000521   \n",
       "18           0.915864           0.914713         0.914977        0.000644   \n",
       "19           0.926635           0.924978         0.925621        0.000725   \n",
       "20           0.927015           0.927386         0.927184        0.000153   \n",
       "21           0.920172           0.919402         0.918525        0.001812   \n",
       "22           0.929042           0.926879         0.927437        0.001152   \n",
       "23           0.931323           0.927132         0.929000        0.001741   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                22            0.997085            0.995628   \n",
       "1                14            1.000000            1.000000   \n",
       "2                15            1.000000            1.000000   \n",
       "3                24            0.996515            0.996642   \n",
       "4                16            1.000000            1.000000   \n",
       "5                11            1.000000            1.000000   \n",
       "6                18            0.995248            0.995628   \n",
       "7                 8            1.000000            1.000000   \n",
       "8                 7            1.000000            1.000000   \n",
       "9                19            0.995818            0.996199   \n",
       "10                3            1.000000            1.000000   \n",
       "11                2            1.000000            1.000000   \n",
       "12               23            0.995311            0.995882   \n",
       "13               12            1.000000            1.000000   \n",
       "14               13            1.000000            1.000000   \n",
       "15               21            0.996452            0.996642   \n",
       "16                9            1.000000            1.000000   \n",
       "17               10            1.000000            1.000000   \n",
       "18               20            0.996262            0.995819   \n",
       "19                6            1.000000            1.000000   \n",
       "20                5            1.000000            1.000000   \n",
       "21               17            0.997466            0.996009   \n",
       "22                4            1.000000            1.000000   \n",
       "23                1            1.000000            1.000000   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.996769          0.996494         0.000626  \n",
       "1             1.000000          1.000000         0.000000  \n",
       "2             1.000000          1.000000         0.000000  \n",
       "3             0.996706          0.996621         0.000079  \n",
       "4             1.000000          1.000000         0.000000  \n",
       "5             1.000000          1.000000         0.000000  \n",
       "6             0.996326          0.995734         0.000446  \n",
       "7             1.000000          1.000000         0.000000  \n",
       "8             1.000000          1.000000         0.000000  \n",
       "9             0.996896          0.996304         0.000446  \n",
       "10            1.000000          1.000000         0.000000  \n",
       "11            1.000000          1.000000         0.000000  \n",
       "12            0.995882          0.995692         0.000269  \n",
       "13            1.000000          1.000000         0.000000  \n",
       "14            1.000000          1.000000         0.000000  \n",
       "15            0.996072          0.996389         0.000237  \n",
       "16            0.999937          0.999979         0.000030  \n",
       "17            1.000000          1.000000         0.000000  \n",
       "18            0.995692          0.995924         0.000244  \n",
       "19            1.000000          1.000000         0.000000  \n",
       "20            1.000000          1.000000         0.000000  \n",
       "21            0.995755          0.996410         0.000754  \n",
       "22            1.000000          1.000000         0.000000  \n",
       "23            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'mean_fit_time': np.array([ 29.3565313 ,  21.269967  , 133.63124331,   6.9153959 ,\n",
    "        17.71104503, 151.52857844,   8.77863534,  36.48309787,\n",
    "       353.55145939,  10.91108894,  62.25011571, 604.09919691,\n",
    "         6.63593658,  18.70342271, 125.81533424,   5.24119258,\n",
    "        16.36292839, 141.45259889,   7.89260626,  28.13510966,\n",
    "       273.91240621,   9.28567576,  44.10937214, 356.8786389 ]), 'std_fit_time': np.array([ 0.77492853,  2.90770999, 11.63067571,  0.2850153 ,  0.98171153,\n",
    "       11.44797585,  0.29892795,  3.36007335, 24.64549427,  0.59362711,\n",
    "        6.20874779, 40.38846034,  0.20280898,  0.27479866, 10.47984029,\n",
    "        0.84278515,  1.09157463, 12.09636917,  0.18592348,  1.8504363 ,\n",
    "       17.28253135,  0.37329269,  4.38992519, 99.02754836]), 'mean_score_time': np.array([ 7.33835514,  8.92508117, 24.09163777,  8.09356125,  7.32807509,\n",
    "       19.51869694,  7.59556937,  6.94122378, 14.72333399,  7.78833922,\n",
    "        7.38280678, 15.11881781,  8.04199298,  9.8266205 , 25.7414674 ,\n",
    "        6.29152044,  8.31556026, 18.50302108,  7.92796397,  7.69944366,\n",
    "       13.55180319,  7.96719853,  7.42520293, 11.7625773 ]), 'std_score_time': np.array([0.1306685 , 2.03098883, 2.33742256, 0.45626301, 1.50775737,\n",
    "       3.48599838, 0.21847926, 1.10654311, 2.18771397, 0.04787844,\n",
    "       1.2097773 , 2.10400838, 0.09428107, 0.18964651, 3.18375043,\n",
    "       1.19595878, 0.94813268, 1.95163257, 0.19510065, 1.0073612 ,\n",
    "       1.71333338, 0.16709411, 1.21011483, 2.31377346]), 'param_clf__criterion': np.ma.masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
    "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
    "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
    "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
    "                   'entropy'],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'param_clf__max_features': np.ma.masked_array(data=[5, 5, 5, 10, 10, 10, 50, 50, 50, 100, 100, 100, 5, 5,\n",
    "                   5, 10, 10, 10, 50, 50, 50, 100, 100, 100],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'param_clf__n_estimators': np.ma.masked_array(data=[10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
    "                   1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
    "                   100, 1000],\n",
    "             mask=[False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False,\n",
    "                   False, False, False, False, False, False, False, False],\n",
    "       fill_value='?',\n",
    "            dtype=object), 'params': [{'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 5, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 1000}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 10}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 100}, {'clf__criterion': 'gini', 'clf__max_features': 100, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 5, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 1000}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 10}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 100}, {'clf__criterion': 'entropy', 'clf__max_features': 100, 'clf__n_estimators': 1000}], 'split0_test_score': np.array([0.91245407, 0.91866211, 0.91942227, 0.90903332, 0.91625491,\n",
    "       0.91980236, 0.91600152, 0.92246294, 0.92296972, 0.91460788,\n",
    "       0.92702395, 0.92727733, 0.91118713, 0.92018244, 0.91967566,\n",
    "       0.91308755, 0.92018244, 0.921196  , 0.91435449, 0.92525022,\n",
    "       0.92715064, 0.91600152, 0.92639047, 0.92854428]), 'split1_test_score': np.array([0.91320324, 0.92004562, 0.92042575, 0.91180943, 0.92080588,\n",
    "       0.91979219, 0.9175114 , 0.92435378, 0.92549417, 0.91409022,\n",
    "       0.92967562, 0.92790167, 0.91104916, 0.91953877, 0.92042575,\n",
    "       0.90927522, 0.92194627, 0.92181956, 0.91586417, 0.92663457,\n",
    "       0.9270147 , 0.92017233, 0.92904207, 0.93132286]), 'split2_test_score': np.array([0.91116462, 0.92117602, 0.91990876, 0.91040426, 0.92028894,\n",
    "       0.92180966, 0.91838804, 0.92523128, 0.92700545, 0.9177544 ,\n",
    "       0.92599164, 0.92789254, 0.91078444, 0.9210493 , 0.92028894,\n",
    "       0.9153466 , 0.92244329, 0.92054239, 0.91471296, 0.92497782,\n",
    "       0.92738563, 0.91940185, 0.92687872, 0.92713218]), 'mean_test_score': np.array([0.91227403, 0.91996114, 0.91991891, 0.91041561, 0.9191164 ,\n",
    "       0.92046798, 0.91730022, 0.92401588, 0.92515628, 0.91548403,\n",
    "       0.92756378, 0.92769049, 0.91100693, 0.9202568 , 0.92013009,\n",
    "       0.91256969, 0.92152391, 0.92118601, 0.91497719, 0.92562088,\n",
    "       0.92718365, 0.91852509, 0.92743707, 0.92899983]), 'std_test_score': np.array([0.00084192, 0.00102804, 0.00040974, 0.00113341, 0.00203455,\n",
    "       0.00094862, 0.00098567, 0.00115515, 0.00166481, 0.00161909,\n",
    "       0.00155163, 0.0002922 , 0.00016709, 0.00061889, 0.00032618,\n",
    "       0.00250546, 0.00097011, 0.00052144, 0.00064403, 0.00072536,\n",
    "       0.00015322, 0.00181211, 0.00115228, 0.00174085]), 'rank_test_score': np.array([22, 14, 15, 24, 16, 11, 18,  8,  7, 19,  3,  2, 23, 12, 13, 21,  9,\n",
    "       10, 20,  6,  5, 17,  4,  1], dtype=np.int32), 'split0_train_score': np.array([0.99708547, 1.        , 1.        , 0.99651524, 1.        ,\n",
    "       1.        , 0.99524805, 1.        , 1.        , 0.99581829,\n",
    "       1.        , 1.        , 0.99531141, 1.        , 1.        ,\n",
    "       0.99645188, 1.        , 1.        , 0.9962618 , 1.        ,\n",
    "       1.        , 0.99746563, 1.        , 1.        ]), 'split1_train_score': np.array([0.99562848, 1.        , 1.        , 0.99664217, 1.        ,\n",
    "       1.        , 0.99562848, 1.        , 1.        , 0.99619868,\n",
    "       1.        , 1.        , 0.99588191, 1.        , 1.        ,\n",
    "       0.99664217, 1.        , 1.        , 0.99581855, 1.        ,\n",
    "       1.        , 0.99600862, 1.        , 1.        ]), 'split2_train_score': np.array([0.99676908, 1.        , 1.        , 0.99670573, 1.        ,\n",
    "       1.        , 0.99632563, 1.        , 1.        , 0.99689579,\n",
    "       1.        , 1.        , 0.99588217, 1.        , 1.        ,\n",
    "       0.99607222, 0.99993665, 1.        , 0.99569211, 1.        ,\n",
    "       1.        , 0.99575546, 1.        , 1.        ]), 'mean_train_score': np.array([0.99649435, 1.        , 1.        , 0.99662105, 1.        ,\n",
    "       1.        , 0.99573405, 1.        , 1.        , 0.99630425,\n",
    "       1.        , 1.        , 0.99569183, 1.        , 1.        ,\n",
    "       0.99638876, 0.99997888, 1.        , 0.99592415, 1.        ,\n",
    "       1.        , 0.9964099 , 1.        , 1.        ]), 'std_train_score': np.array([6.25733424e-04, 0.00000000e+00, 0.00000000e+00, 7.91906591e-05,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.46206266e-04, 0.00000000e+00,\n",
    "       0.00000000e+00, 4.46177186e-04, 0.00000000e+00, 0.00000000e+00,\n",
    "       2.68995301e-04, 0.00000000e+00, 0.00000000e+00, 2.36922985e-04,\n",
    "       2.98640811e-05, 0.00000000e+00, 2.44267970e-04, 0.00000000e+00,\n",
    "       0.00000000e+00, 7.53630262e-04, 0.00000000e+00, 0.00000000e+00])})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.30s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1928.47s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, max_features=100, sampling_strategy='auto')\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0005020056104968013, 'JWTR_4'),\n",
       " (0.0006180397991121181, 'Boro_10'),\n",
       " (0.0006182323610456678, 'ENG_11'),\n",
       " (0.0006666647803905448, 'CIT_10'),\n",
       " (0.000845561954102215, 'Ethnicity_3'),\n",
       " (0.0010203369930211923, 'JWTR_3'),\n",
       " (0.0016273172555736843, 'INTP_adj_2'),\n",
       " (0.002282882484302701, 'Ethnicity_11'),\n",
       " (0.002428528916065317, 'AGEP_1'),\n",
       " (0.0039253585625141215, 'DIS_10'),\n",
       " (0.005603247830117554, 'JWTR_2'),\n",
       " (0.006984126312808381, 'INTP_adj_1'),\n",
       " (0.011814645668473192, 'Boro_1'),\n",
       " (0.016108428339244498, 'JWTR_1'),\n",
       " (0.05686880032439872, 'ENG_10')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline.named_steps['clf'].feature_importances_\n",
    "imps = list(zip(pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]\n",
    "#geometric_mean_score(y_test, pipeline.predict(X_test)) # 0.901335010891502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.12s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.78s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1172.32s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X = X.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_features=100)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
       " <a list of 15 Text xticklabel objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEtCAYAAADk97CmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJztnXmcXEW1+L9n9sxMlsnMZN9mkrCEHULY0QeCIEtAQSI/FhFFkEUFRHgKKMJ7Aioqi8KTpwgqIItGQXFBHvsSNgEByUYIazayTyYzc35/nOrMTadnptfp6e7z/Xz603epW/fcqrqn6p46VSWqiuM4jlMalOVbAMdxHKf/cKXvOI5TQrjSdxzHKSFc6TuO45QQrvQdx3FKCFf6juM4JYQrfcdxnBLClb7jOE4J4UrfcRynhHCl7ziOU0JU5FuAeJqamnTSpEn5FsNxHKegePbZZ5eqanNf4Qac0p80aRJz5szJtxiO4zgFhYi8mUw4N+84juOUEK70HcdxSghX+o7jOCWEK33HcZwSwpW+4zhOCeFK33Ecp4QoGqX/4bp2/vjPd1iyekO+RXEcxxmwFI3Sf3PZOs769fM8t2hFvkVxHMcZsBSN0m9prgNg/pK1eZbEcRxn4FI0Sn9ITSVN9dXMX7Im36I4juMMWIpG6QO0Ntcxf6m39B3HcXqiqJT+5OY6b+k7juP0QlEp/damelas28iKte35FsVxHGdAUlxKP9aZu9Rb+47jOIkoMqVfD8A89+BxHMdJSFEp/fENg6gsF3fbdBzH6YGiUvoV5WVMGF7rnbmO4zg9UFRKH8zE426bjuM4iSlCpV/Hm8vW0tHZlW9RHMdxBhxFp/QnN9WzsVNZvGJ9vkVxHMcZcBSd0o+5bS5wE4/jOM4WFKHSj7ltemeu4zhOPEWn9IfXVTGsttI7cx3HcRJQdEofoLXJ5+BxHMdJRHEq/eZ6H6DlOI6TgKJU+i1NdXywegOr2zbmWxTHcZwBRVEq/cnuweM4jpOQolT6MQ8eN/E4juNsTlJKX0QOEZHXRWSuiFyY4Hy1iNwRzj8lIpPC8Ukisl5EXgi/n2ZX/MRMbKylTPDOXMdxnDgq+gogIuXA9cBBwGLgGRGZrar/igQ7FVihqlNEZBZwJXBcODdPVXfOsty9Ul1RzriGWua5ecdxHGczkmnpzwDmqup8VW0HbgdmxoWZCdwStu8CDhQRyZ6YqdPaXOfmHcdxnDiSUfpjgbci+4vDsYRhVLUDWAk0hnMtIvK8iPyfiOyXobxJ09pUz4Kla+jq0v66peM4zoAnGaWfqMUer0l7CvMuMEFVdwHOBX4tIkO2uIHIaSIyR0TmLFmyJAmR+qa1uY62jV28u6otK/E5juMUA8ko/cXA+Mj+OOCdnsKISAUwFFiuqhtUdRmAqj4LzAO2ir+Bqt6kqtNVdXpzc3PqT5GATevlemeu4zjOJpJR+s8AU0WkRUSqgFnA7Lgws4GTw/YxwIOqqiLSHDqCEZFWYCowPzui985kd9t0HMfZgj69d1S1Q0TOAh4AyoH/VdVXROQyYI6qzgZuBm4VkbnAcqxiANgfuExEOoBO4HRVXZ6LB4lnxOBq6qrKfYCW4zhOhD6VPoCq3g/cH3fsksh2G3BsguvuBu7OUMa0EBFam+t9imXHcZwIRTkiN4a7bTqO42xOcSv9pnreWbmeto2d+RbFcRxnQFDcSr+5DlWfeM1xHCdG0St9cA8ex3GcGEWt9Fua3FffcRwnSlEr/dqqCkYPrfH1ch3HcQJFrfQh5sHjLX3HcRwoBaXfZOvlqvrEa47jOMWv9JvrWL2hgyVrNuRbFMdxnLxTAkrf5+BxHMeJUfxKv8ndNh3HcWIUvdIfO2wQ1RVl3pnrOI5DCSj9sjKhpanO3TYdx3EoAaUP7rbpOI4TozSUflM9b61YT3tHV75FcRzHySulofSb6+jsUhYtX5dvURzHcfJKiSj9mNumm3gcxyltSkTpB7dN78x1HKfEKQmlP6Smkqb6am/pO45T8pSE0gdfOtFxHAdKSOlPbnZffcdxnJJR+i1NdSxf286H69rzLYrjOE7eKBml39pkHjzz3MTjOE4JUzpKv9mXTnQcxykZpT9+eC0VZeJ2fcdxSpqSUfqV5WVMaKz1lr7jOCVNUkpfRA4RkddFZK6IXJjgfLWI3BHOPyUik+LOTxCRNSJyfnbETo/Y0omO4zilSp9KX0TKgeuBQ4FpwGdEZFpcsFOBFao6BbgGuDLu/DXAnzIXNzMmN9fx5rJ1dHb5ermO45QmybT0ZwBzVXW+qrYDtwMz48LMBG4J23cBB4qIAIjIUcB84JXsiJw+rc11tHd2sXiFT7zmOE5pkozSHwu8FdlfHI4lDKOqHcBKoFFE6oCvA9/OXNTM2TTxmnfmOo5ToiSj9CXBsXj7SE9hvg1co6q99p6KyGkiMkdE5ixZsiQJkdLD18t1HKfUqUgizGJgfGR/HPBOD2EWi0gFMBRYDuwBHCMiVwHDgC4RaVPV66IXq+pNwE0A06dPz5nBfXhdFUMHVboHj+M4JUsySv8ZYKqItABvA7OA4+PCzAZOBp4AjgEeVFUF9osFEJFvAWviFX5/IiI+8ZrjOCVNn+adYKM/C3gAeBW4U1VfEZHLROTIEOxmzIY/FzgX2MKtc6DQ2lTP/KXe0nccpzRJpqWPqt4P3B937JLIdhtwbB9xfCsN+bJOa3Mddz+3mDUbOqivTurxHcdxioaSGZEbY3KYg2eBm3gcxylBSk7pd7ttuonHcZzSo+SU/sTGWkR8imXHcUqTklP61RXljGsY5G6bjuOUJCWn9MEnXnMcp3QpTaXfXMeCpWvp8onXHMcpMUpU6dezfmMn761qy7cojuM4/UpJKv3JPgeP4zglSkkqfXfbdBynVClJpT9ySDV1VeXe0nccp+QoSaUvIrQ01/m8+o7jlBwlqfQh5rbp5h3HcUqL0lX6zXW8/eF62jZ25lsUx3GcfqOElX49qrBwmZt4HMcpHUpX6bvbpuM4JUjpKv3mmNJ3u77jOKVDySr92qoKRg+t8Za+4zglRckqfbDW/jx323Qcp4QobaUf3DZtDXfHcZzip6SVfktTHavbOli6pj3fojiO4/QLJa30vTPXcZxSo6SV/uRNE6+5Xd9xnNKgpJX+mGGDqKoo85a+4zglQ0kr/fIyoaWxzt02HccpGUpa6YPZ9d284zhOqeBKv7mORcvXsbGzK9+iOI7j5JyklL6IHCIir4vIXBG5MMH5ahG5I5x/SkQmheMzROSF8HtRRI7OrviZ09pUT2eXsmj5unyL4jiOk3P6VPoiUg5cDxwKTAM+IyLT4oKdCqxQ1SnANcCV4fjLwHRV3Rk4BLhRRCqyJXw26HbbdBOP4zjFTzIt/RnAXFWdr6rtwO3AzLgwM4FbwvZdwIEiIqq6TlU7wvEaYMANfd20Xq578DiOUwIko/THAm9F9heHYwnDBCW/EmgEEJE9ROQV4CXg9EglMCAYOqiSpvoqb+k7jlMSJKP0JcGx+BZ7j2FU9SlV3Q7YHbhIRGq2uIHIaSIyR0TmLFmyJAmRsktrUz3zl3pL33Gc4icZpb8YGB/ZHwe801OYYLMfCiyPBlDVV4G1wPbxN1DVm1R1uqpOb25uTl76LNHa7L76juOUBsko/WeAqSLSIiJVwCxgdlyY2cDJYfsY4EFV1XBNBYCITAS2BhZmRfIs0tpcx7K17axctzHfojiO4+SUPpV+sMGfBTwAvArcqaqviMhlInJkCHYz0Cgic4FzgZhb577AiyLyAnAv8CVVXZrth8iU1ibrzJ3nJh7HcYqcpNwnVfV+4P64Y5dEttuAYxNcdytwa4Yy5pyo2+auExryLI3jOE7uKPkRuQDjh9dSUSbutuk4TtHjSh+oLC9jwvBa78x1HKfocaUfsInXvKXvOE5x40o/0Npcz8Jl6+jsGnCDhh3HcbKGK/1Aa1Md7R1dvL1ifb5FcRzHyRmu9AOb5uBxE4/jOEWMK/2Az7bpOE4p4Eo/0FhXxZCaCm/pO45T1LjSD4gIrc313tJ3HKeocaUfwSdecxyn2HGlH2Fycz3vrWpj7YYBNeW/4zhO1nClH6G1yTpzFyz11r7jOMWJK/0IMbfNeT4Hj+M4RYor/QgTG2sRcbdNx3GKF1f6EWoqyxnXMIj5bt5xHKdIcaUfR2tTvU+x7DhO0eJKP47W5joWLF2Lqk+85jhO8eFKP47W5nrWtXfy3qq2fIviOI6TdVzpxxFz2/TOXMdxihFX+nF0T7zmdn3HcYoPV/pxjBpSQ21VOfO8pe84ThHiSj8OEaGlqc5H5TqOU5S40k9Aa3O9T7HsOE5R4ko/Aa1NdSxesZ62jZ35FsVxHCeruNJPQGtzHarw5rJ1+RbFcRwnq7jST8Dk2Hq57sHjOE6RkZTSF5FDROR1EZkrIhcmOF8tIneE80+JyKRw/CAReVZEXgr/B2RX/NzQEvPV985cx3GKjD6VvoiUA9cDhwLTgM+IyLS4YKcCK1R1CnANcGU4vhQ4QlV3AE4Gbs2W4LmkrrqCUUNqfIplx3GKjmRa+jOAuao6X1XbgduBmXFhZgK3hO27gANFRFT1eVV9Jxx/BagRkepsCJ5rfOlEx3GKkWSU/ljgrcj+4nAsYRhV7QBWAo1xYT4FPK+qG9ITtX8xpb/GJ15zHKeoSEbpS4Jj8Zqw1zAish1m8vliwhuInCYic0RkzpIlS5IQKfe0NtWzqq2DZWvb8y2K4zhO1khG6S8Gxkf2xwHv9BRGRCqAocDysD8OuBc4SVXnJbqBqt6kqtNVdXpzc3NqT5AjuufgcROP4zjFQzJK/xlgqoi0iEgVMAuYHRdmNtZRC3AM8KCqqogMA+4DLlLVx7IldH/gbpuO4xQjfSr9YKM/C3gAeBW4U1VfEZHLROTIEOxmoFFE5gLnAjG3zrOAKcDFIvJC+I3I+lPkgDHDBlFVUeZum47jFBUVyQRS1fuB++OOXRLZbgOOTXDd5cDlGcqYF8rLhEmNtd7SdxynqPARub1g6+V6S99xnOLBlX4vtDbXsWj5OjZ2duVbFMdxnKzgSr8XWpvr6ehS3lruE685jlMcuNLvBXfbdByn2HCl3wuTm4Lbpi+o4jhOkeBKvxeG1lbSWFflLX3HcYoGV/p94BOvOY5TTLjS74PWpnrm+cRrjuMUCa70+2CXCcNYtradU2+Zwwer2/ItjuM4Tka40u+DT08fz7eOmMZjc5fy8Wse5s8vv5tvkRzHcdLGlX4flJUJn92nhfvO2ZdxDbWcfttznHvnC6xq25hv0RzHcVLGlX6STBkxmHu+tDfnHDiV37/wDof+8BGemLcs32I5juOkhCv9FKgsL+Pcg7birtP3oqqijON/9iSX//FftG3szLdojuM4SeFKPw12mdDAfefsywl7TORnjy7gyOse5eW3V+ZbLMdxnD5xpZ8mtVUVfOeo7fnFKbvz4bqNHH3DY1z/j7l0drlrp+M4AxdX+hny0a1H8MBX9ufgaaO4+oHX+fSNT/DmMh/M5TjOwMSVfhZoqKviuuN34YfH7cy/31/NoT96hN88vcgHdDmOM+BwpZ8lRISjdhnLA1/Zn53HD+Oie17i8z6gy3GcAYYr/SwzZtggbjt1Dy45fBqP+oAux3EGGK70c0BZmfC5fW1A19iGQZx+23Ocd+eLPqDLcZy840o/h0wZMZh7ztiHsw+Ywr3PL/YBXY7j5B1X+jmmqqKM8w7emrvO2JvKcvEBXY7j5BVX+v3ErhMauP/L+3H8jAmbBnS98o4P6HIcp39xpd+P1FZVcMXRO/DzU3ZnxbqNHH3D49w55618i+U4TgnhSj8P/MfWI/jzl/dj+sQGLrjrn1x0zz/d3OM4Tr/gSj9PNNZX88vPzeCMj07mN0+/xbE/fYLFK9blWyzHcYqcpJS+iBwiIq+LyFwRuTDB+WoRuSOcf0pEJoXjjSLyDxFZIyLXZVf0wqeivIyvH7INN524GwuXruXwax/l4X8vybdYjuMUMX0qfREpB64HDgWmAZ8RkWlxwU4FVqjqFOAa4MpwvA24GDg/axIXIQdvN4rZZ+/LyME1nPzzp7n272/Q5RO3OY6TA5Jp6c8A5qrqfFVtB24HZsaFmQncErbvAg4UEVHVtar6KKb8nV5oaarj3jP3ZuZOY/j+X//NF345h5XrfDCX4zjZJRmlPxaIupgsDscShlHVDmAl0JgNAUuJ2qoKrjluZy6buR3/9+8lHHHdo/zrnVX5FstxnCIiGaUvCY7F2x6SCdPzDUROE5E5IjJnyZLStmmLCCftNYk7vrgXGzo6OfqGx7j72cX5FstxnCIhGaW/GBgf2R8HvNNTGBGpAIYCy5MVQlVvUtXpqjq9ubk52cuKmt0mNvDHs/djlwnDOO+3L/LN373Ehg5363QcJzOSUfrPAFNFpEVEqoBZwOy4MLOBk8P2McCD6pPJZ0zz4GpuO3UPvrh/K7c9uYhP3/gk73y4Pt9iOY5TwPSp9ION/izgAeBV4E5VfUVELhORI0Owm4FGEZkLnAtscusUkYXAD4DPisjiBJ4/Ti9UlJdx0Se25acn7Mq8D9Zw+LWP8tjcpfkWy3GcAkUGWoN8+vTpOmfOnHyLMSCZt2QNp9/6LPOWrOH8j2/NGR+ZjEii7hTHcUoNEXlWVaf3Fc5H5BYQk5vr+d2Z+3DYjmO46s+vc9qtz/oc/Y7jpIQr/QKjrrqCH8/amUuPmMY/XvuAI699lNfec7dOx3GSw5V+ASIinLJPC785bU/WtXdy9PWP87vn3863WI7jFACu9AuY3ScN54/n7MsO44bylTte4NLfv0x7R1e+xXIcZwDjSr/AGTG4hl99fg++sF8LtzzxJrNueoIn5y9jfbv79DuOsyUV+RbAyZzK8jK+cdg0dh7fwAV3vcism56kokzYdvQQdp0wjF0nNrDrhAbGNQxybx/HKXHcZbPIWLluI88uWs5zb37Ic4tW8OJbH7I2tPqb6qs3qwR2HDeUmsryPEvsOE42SNZl01v6RcbQ2koO2GYkB2wzEoDOLuX191bz3KIVPPfmCp5btIK//Ot9ACrKhGljhrDrhAZ2mTDMvwYcpwTwln4JsmzNBp5fZF8C9jWwkvVhucbmweFrYEIDu05sYIex/jXgOIWAt/SdHmmsr+Zj00bysWn2NdDR2cVr763m+UUreC5UBg+80v01sN2YIewyoYF9pjSxZ+twBtdU5lN8x3EywFv6TkKWRr8G3lzBi4s/pG1jF+Vlwi7jh7Hf1Gb2ndrETuOGUlHuTmCOk2+Sbem70neSYkNHJ8++uYJH31jKo3OX8tLbK1GFwTUV7D25kX2nNrPflCYmNtZ6n4Dj5AFX+k5OWbG2ncfmLeXRN5byyBtLeTtM+Tx++CD2ndLMflOb2HtyI8Nqq/IsqeOUBq70nX5DVVm4bB2PvLGER95YypPzlrF6QwdlAjuMG8Z+U5rYd2oTu05ooKrCTUGOkwtc6Tt5Y2NnFy++9SGPBFPQC299SGeXUltVzp6tjew7pYn9t2picnO9m4IcJ0u40ncGDKvaNvLEvGWb+gMWLF0LwKghNewzpYk9WoczY9Jw7w9wnAxwpe8MWN5avo5H51p/wOPzlrJina0JMGJwNTNahrNHy3BmtDQydUQ9ZWVeCThOMrjSdwqCri5l3pI1PLVgOc8sXM5T85fz3qo2AIbVVjJ9YqwSGM52Y4a4e6jj9IAPznIKgrIyYerIwUwdOZgT9pyIqrJ4xXqeWrCcpxcs45mFK/jbqzZQrLaqnN0mNjBjklUCO40f5qOFHSdFvKXvDHg+WNXG0wuX8/QC+7323moAqsrL2Hn8MHZvaWBGSyO7TWygvtrbMU5p4uYdp2j5cF07cxau4OmFy3lqwXJefnslnV1KmcD2Y4ey+6ThtDbXUVleRlV5GZXlZVSWC5UVcfvlZVRVdO9XbXbejnnHslMouHnHKVqG1VZtNnfQ2g0dPL/oQ55esIynFizn1iffzNoKYrHKIfZrrKti5NAaRg2pZtSQmrBdw8ghNYwaWsPw2irvfHYGNK70nYKnrrqCfafaADCwKSM+XLeR9o4uNnZ2sbFT2djZRXtnFxs74vZjvw7dfD+EiW23d3SxoaOLZWs28P6qNl5/bxVLVm+gK+5DubJcGDHYKoDuyqCaUUMHMWqIHRsxpNr7Ipy84UrfKTqqK8oZOST3SrWjs4slazbw3so23l/Vxnsr23hv1YZN26++u4p/vP4B6xIsXdlQW7np62DUkBpGDK6mOfyPGFzNiCE1NNdX+whmJ+u40necNKkoL2P00EGMHjqoxzCqyuoNHby/so33VrXx7sq2Tdvvr7L/l99exbK1G0jUvdZQW8mIwfZ10P2/5fagKv9ycJLDlb7j5BARYUhNJUNqKpk6cnCP4To6u1i2tp0PVm3gg9VtfLB6w+bbqzcw94OlLFm9gY54mxIwuLqC5miFMLiahroqqivKwq/cOqpDZ3V1pf3Hjm0Wprz7mI+LKD6SUvoicgjwI6Ac+JmqfjfufDXwS2A3YBlwnKouDOcuAk4FOoFzVPWBrEnvOEVCRXkZI0MfAAztMVxXl7JiXfumiuCDVVYpLFkdKohVG3jhrQ/5YHUbbRsz78wuEyIVQfmmSqRqs//yhJVJtKKpjvyqotdFKp6KMvOWKhMoE6FMBIltl8WOEcJ0h4uFKS+LhI+FRSAH/eoitsBQRVnheXn1qfRFpBy4HjgIWAw8IyKzVfVfkWCnAitUdYqIzAKuBI4TkWnALGA7YAzwNxHZSlW3NHI6jtMnZWVCY301jfXVbDu653CqStvGLuuA7uykvcO22zu72LDR/mPHNnR0saGjc9P52LHoNe0hTPR4bHv9xk4+XN++xXUbItcXO+VlEioBoSK4+1aUlVFR3n2sosw8wTYdC+crw7mKcmH6xOF8bt+WnMqaTEt/BjBXVecDiMjtwEwgqvRnAt8K23cB14lVfTOB21V1A7BAROaG+J7IjviO4yRCRBhUVR5s/fld3rKryzyjElUoscpmQ0cXXap0KXSpoqp0dbHpmEbO2fnuc11duuW1kfO5QFXp6FI6gndXR1cXHZ2RY+F/07GuEK6zK4SxY+s3bn7tqCE99w9li2SU/ljgrcj+YmCPnsKoaoeIrAQaw/En464dm7a0juMUHGVlQk1ZubupDhCS6aVJZKyKrz97CpPMtYjIaSIyR0TmLFmyJAmRHMdxnHRIRukvBsZH9scB7/QURkQqsJ6o5Ulei6repKrTVXV6c3Nz8tI7juM4KZGM0n8GmCoiLSJShXXMzo4LMxs4OWwfAzyoNqnPbGCWiFSLSAswFXg6O6I7juM4qdKnTT/Y6M8CHsBcNv9XVV8RkcuAOao6G7gZuDV01C7HKgZCuDuxTt8O4Ez33HEcx8kfPsum4zhOEZDsLJs+3M5xHKeEcKXvOI5TQrjSdxzHKSEGnE1fRJYAb2YQRROwNEvi5DJOjzd3cRZavIUka6HFW0iyZhrvRFXt0+d9wCn9TBGROcl0ZuQ7To83d3EWWryFJGuhxVtIsuYy3ihu3nEcxykhXOk7juOUEMWo9G8qkDg93tzFWWjxFpKshRZvIcmay3g3UXQ2fcdxHKdnirGl7ziO4/SAK33HcZwSwpW+kzYi4uWnn8k0zQshzyRuwdn4fSczBnwByAQxBoftqmzHnc34Qpzl/VnAM7mXiNSqalem8cTFWRnyrDEb8cXFXRSKI5M0F5HBsetzTVhXIy1UVUWkQkTqRaQ6TNNecHmYhQp6eFijPKsUdUeuiFwI7I1Vbn8HXgUeVtV1acY3Chihqv+MHBPNQiKKSL2qrgnb5bmaglpEhgHjVPXlyLGkn0FEdgI+A+wHPKaqF2RJLgFuA9YBtcD7wOWqujwb8Yd7lPWX0ssmIjIB+CxwFHCLqv4oxet3w9a7OACYrar/GTmXlfIbd7/PAh8FqoGvqOr7KV7/JeDjWBkQ4CFV/VWWZSzD6pesPXvIp0HAaFV9KBwTwo1SjGsv4IfAVcBzqrogW3IWbUtfRPYEzsJell8B9cDBwOdEpCHNaO8Cvi4ip4rIZOjOzExqdRH5LvCaiHw5xNkZjudiUdGbgatF5HwRmRjupynIfyWwAjgH2FpEzoyezKA19l2gE7gBK+yDgH+IyBfTjC8mz1Yi8hnYrJWc03IvIheLyP6R/UxbqD/A3tX/BE4SkStSvP5ybE2LWcA4EdlRRI6E1JVRX4jIFODrwLXYeh0nicj0sAhTn19wQXFeDFwC/Bb4G3CYiNwsItOyIN+BItKkql0plvu+4h2BLRr1VeAbIvKCiBykgTTKwHpgDHAgcLKI7CMi40Rk34yF1bB6fLH9gMOBGyP7g4FPYn6w56UR3wHAXOB07CX8L2yVsNHh/NA05RwJvIFVTvcCjwCHRc5XA01ZSpM9sOUqjw/y34i1AIeF83VAZS/XH4W1umL7+wd5m2JpnKZcZcD1wDFhvzz8fwT4NXB4Bs/8JPAUVvF/LHJcclTu9gO6gHnAz4CxGcb3UeDZyP4U4H5geNgf1Mf1R8fl2Wrge8DDwD+BqVl+/t8BF4btw7DK5n7gl8BZSZbRX0T2a4CtgK8BF2co2z7AB8AfgM/HncuoPITye1Vk/3PYcrF3xPIqhbgEqzD/B7gIqwRvBF4Absg4j7KZ4QPpB4zFlnr8JjAmcnx74FFg2xTjGw1MD9s7AucDP8ZaX/sA84Hd05BzNHBGULjVmPJ/EvuqGBYy/NgspUkD8B/hXtsAp2Atsh8CewVFsF8v1x8MfCru2K9iaQk8DmyfpmyHAw8CO0SOVQMnhsJfk+qLCewJPA/sHNL43vC824fz44HJWS53n8da1NVB7rmhjFSH818nhYoAq0Rmhe3K8H9npCz+Hti1l+v3jzzvUdjKd7FzVwFfzOKzVwInRPbvAU4N2weG93GbPuIYFsrRtUBN5PjWWKv/YxnIdwemnA/ETIm/AQ6KnN+OXho9fcR9NvCfYTtmNo81ZlJuZIbrdwW+G7a/gK1KeHN4b+vTTodsZfhA/AE7YeaIbwFHAHXh+IvAHmnEVx3ZLgtK8KvAs8CfM5RVItujgQvR7zdrAAAav0lEQVSwlsJKoDaLaVIW2a7BKqzPYhXN80lcPzoqb0jbL2NfDL/N5NnDMy8ArokoyR1D+qb7Mm6NmYpqwkv0bayldx6mkD+S5TI3FGiN7O8SlNVjmOnq6RTjq8D6YKLHvhGe45PYetRJ5TlWydVFjl8A/DSbzx933zFx+3+hl0ZFJNxI4H8xc8nxcdd/MgN5pgLbYpXTFOBLWKV5BXAucF8Gce8Y5DstwT3vi703KcYp2FfZ9JAWXwl5fn5G+ZKrDM/Xj8jnbki0fYALgyJ5Fmsl/THDe0QV9CRs/d+tw355unElOPc88KWwXZHDNGvCKpe9U71XeHkWYF86U8OxsgxkmQzcArwH/AirjM5JNW17SldgBLADZtr4U47LYnlk+xjM7HNQOuUkQX49CfwbmJFmuavDGj+xcpt2niV5vxOBv/QmT9x+I/bFdH+Q8wZsTe5sylQflPU3Q958Mp20oLtS3Qd4Kby3+4dnODYTuTFz1zzghcixikzyLGeZnI8fMC4oio8SsaNh9vytsM/8jxJsz5m8eOF6AXYDvp2N+OLi3gG4O3qvHKbbroTP/nTuE17My8J20gUR8wL6BQnMYsA04FPAdjl43gbMM2SbbOUbcWatiCKIvaDHYJ4zmd4nFu9s4H/SyTPsa+QbwBWp5lmaMo8JZWS/ROmNmcJuwVrejZHjsb6dQ7DWblOi65O4/6C4fYnbv5w0v9RJYGbBTD3PAj8HHgAOzaScBZ21Y9hO64s3+isql00RmY0psHuxVtBjwGuapotmvgl+1atFpEJVOzKIJ2lXxeAx1KVJFIyYu19wL5ujqhuTdQEUkRpgIZZXIzF32utV9Z34+JORO1mCt8YE7EX8STbcOEVkK+zT/mngZlV9IBzf5K4nIjOAeaq6LBmX3L7kCt5p/1LVVankWeT6rYG5fcmRDYKb8ChVfS3sb/b8InI91ml/DzAc69v5Xab5EuIeh3UC3wu8qKorIufKVbVTRC4HblXV11Nxlw5edycAV2ucG20YpzAKeF9VN2b6HNmkaJS+2CCsM4G7gRasZdUBPIHZ1CZhn9ZXZvm+sYIzXAe4T3lPcYpIZVDYtZlUkMEVLqlVf0RkZ8yl9jJMCR+FdS7/WVWvE5GjgfdU9Yk05IhVRlmvNHq4322Y7f13wHHA21gF9mo4PyZamaUYd1/Kf9P4jjTjb1TVZelen8J9EuZFUI7nAy8DizCzyHbAGqz1/xZwKvCjdCqoBA3BR4FXVbUtWRl7iHdkiOsKYCZmcvuuqt4Xzpdj1oYlWRzLU6aqXRnrmkw/FQbSD7PX1oTtGqyw/BK4FHOL/FoKccU+y3tzYYza9n9Fmi6LPcQd+4y/gkjHYIpxfAw4N+5Yj5+YmHtkU2Q/mTSIdgynlAbReLHW/tHATzFTQDu2/Fs6z93rJzDdXjAZuVNG4tsfs73WYh23l4ZnOAs4FOtHSsoEk0yexZW7dPIsa+WW7objDlgrvSz+Wek20+wBXJcojojcQzEPs29grtFvkaabImbWvRDrTD0Yc9e+AetfaMAqgwvTjLsvr7tLSNLrLpk8iwufWZ5lo9APtF9coS4LL2DSnSkhE6/DvDy+DDRH46VbIccK89nAN5KMO3ZNI9ayHReLPypz+N8OM1GlZc8PBXs0Ziu9js2VbHnc/3HAj/sjDeLzKHKsClOcL9Ftb06l8/aw8GJfFV7sXr2eMLtrSj7UScoxHBvXcTXWQRjrjO/Tdj6Q86wXmSvCsx7SR7jfA1ulEOe3sMZaTO50+puy1hDsqxyThtddPvIsq4V9IP3iMuP/gE9EE6+Pa3+AtTi/ANxOZNBFfPxYa+JJoCpZmTAXwnswG/BtoXDvEM3ksH03KY4niFy7e2R7BtYCeQY4OXI86l3yGJHWQ67SIAm5t8NcKVN60cML/WJ4KS4J6XtAgnCxl+dM4KIcl8GvAU8We56F+E4EXie4WCZQVp8mUkElGedjwJnxz52mfBk1BHuLL8G5pL3u8pFnOSvwA+WH+eROjez32trC/Lrfj+xXYS2UG7BW5F2Yko4V5muBo1OU6WrgmrC9P+Y9cDObt+pmATel+cwVoeC9CfxH5PinsArwAYJ7Zjh+BXB6f6ZBD3LHCndssFfSngrAT4BrI/tfwwbPVUWOxRRRVhVeHzLtH7Z7VVqFlmeRvKqIHDsI66MZkiD8y6RokmBzs1U2PKzSbgimcI+kve7y9Z4V7dw7MVR1o6q+Ednvq3N0DPCmiFwdPBzKsBF8/8b8Ze8B3lHrvB2CvaS/S1EsAV4L8jwMfAezac+IhNkFs0emjKp2qOou2NDt+0XkbhGZoKp3YzbjvwPXici5wYtmNTZ6NEbO0qC3OUg0lGwNHaCapNeD2Ayqo4GPisjx4XA79sK1R+KP5f13MY+LdnKIqp4R8jeZsAM2z3qQV8Pm0SJyg4h8AnOcOAD4eZhDB9jUaX+pqq4O+zUiMra3+EOn5SanAM2Cl1FMZhGpxKZhuD92KtO4I/d4CbPvE7zueou7X/MsRkF774hILVYLru4lTMy7ZhKwi6re20vY/bHa92lsBO90zO5+p6pe0sM1lckqpxB+DDYy8r+wz7pHVPU9EXkF+IxGZvBMh6ingIj8F6b8dsE6x25U1a+Fc1thYxr+H7A69gy5SoOgqEaq6pt9hIvl17HYaNM+PUtCOWgL8n4VazWPByapqopIVUzBB6+Kj0de+JyQjutr2B4weZaE3PthrpbLsQ7rx4PM47DO1+viny/sXwMs1F5mC416qmCt25szkbW/SNbrLl95BhSueQcrbFdhrn7x3g1bmHBIohMJ++T7SNhuxAZF/DJce1IGssbMCocQ7IjY/BlXYROWzcZc/CBLg7CwIdt/jOxvg42abccGqk2N3bOf0uCG8OvxEz+STs3Yl1CfI4OxF+YHkf1abIqFNzAz2rh0Ze7lnhl7rBRCnvUgYyPBxIDNgrlr5NzQ8H841hcxM8H1O2Ed6FW9lfdIGv8UODAF+Wp7K2NxeTOJLJhLeijDvXrd9WeebXHvXEaeU8HhH1jnUaygTSEyeVJc5h4F/KyP+M4hblg+ZoYZhdlVf08YdZqBzDfGXgSs137HoDh2pXuumayMjsRc1H4Yd+xEwujhsF8Zdz4naYCNhH6WzafI+Bg26nZk5D7RF32LTtge4v4/umfnnEG3O+YkrFX8LrkZ1ZsLj5UBk2e9yFgX8qeLSEcoW1Z6lwA/SXD9XzETRRU99KlE3tvdSWE+HHLQEEwgU8Zed/2dZ1vcP1cR5/KHDea4J+7YfaEw3RSfkdjUug29xDc0KIdHsYEWo6MZFgro1tgCKlsU8CRlnhoKwlwiHXU5SJuY4hyDfW7fg5k6xmJfFbsneoZcpgE2xXBsBsLtsD6MZcCf4ws3NjPmH5KM9zxsJGVMGS0iztuJNGf9TPL+WfFYGYh51oOc0YnkYoOdXoiVZ2ym1q9iXz7HEaYOiFzzaeA5bGzB3di8NL29lw+QwhgVstwQTJA/GXvd9XeeJZQhVy9Ern6hQP2CyGx9wJEhEbcKGfH/IudmEfFy6CHOn2FeBweGgvYLzDaZ9vSlPcg9EZta9x6sRdKSxfhjhXkI5p0yEijHWqOvhWfq0RsoF2kQeVlOwlp+U7EZJ2/AzB6tmFKbEbnmFyQxxzvdLpoxL6jL2Hw+cwl5n/FcJQmeJyseKwMxz/p4/h9jrdEWYEI4dg5m078H84jawqQTuf4fdE8QdwrW6r8Jm6gsfn6cfYHvpSBbVhuCPdwjY6+7/s6zhDL0142yXPiuwCYzitausUUlrgYuiRzfml5MJphN9mq6zQI12ACLh4D/xkwwabn2RZTEttgcHbtiHXR7YR4kj5H9+dxvDy/nvdg87k10Tym92eCefkqDqqAo7guK4a9s7or3KN0TcZWR5BS02AyJx2NfDb/BFscYFTl/JZG547OcxsdiFdcnwgv7KNa6mxAJszNxaw8USp71Vp5Dus/B1mDYLpLH5xOZBjnBtQcQN+8/9nV2CdYQ+H5c+o0m+RGqWW8I9nCf7xFZfwAz0f4R2Ceu3CUc8JePPEsoR65vkBOh7bP3VuzzaETk+ATs8zE2G1+fn0bhJdtiVF6I64fY5+v0NGSMfervjnVq/RbrsL0Ua/EOAvbMUnrEKpdTggLZDpvu+PuhUF6EDQ1PWPnlMA0Ow1p3+4T9aiKjFAnzmacRbzXdSnEa3QNbrsBajTEzSewTOWuzSGKLmnwzyP6HkLZ/wVaIOisSrteyN1DzLAl5KzB79g+widHOpwfbdmS/AqvwHyKiICPnt8Y6MSdlIF/WGoI9xD8G+zr9O1bpjwrHXyHOjNVLHP2aZz3KkesbZFVYa9XFpik9Obwc38aWJjsjFKxLEhW8XuI8IGTcbBJ4ehAxPaQp861023wnYvP6P0UW5+mJ3Os67NP721iLY1gopDfQ+1wsOUkDrDP1i9gn9k/Y3NPj49iXzk5hP5XpFr6PtZB2CfuVWCvpgpAGi4FvplIO+rhfRh4rhZRnPdwr9rXxSSJLFmIV7K+xCra31buOpnvcybNYq3x8D2HTnXIkaw3ByLVZ9brrzzzrVY7+uEmWCt6g8FL/Jbz0w4NSib0sdwFHpFJ4IplajinjHxH5ZM20MAaZfxhkjHqu3N7bS5Jm+gjmVVCLeQnFFjS5le6OtkQeDDlNg3DdFGwCrT9idtDGkDYzUo0X8274a4gjJvsRdHsBHQR8J1OZ4+6ZkcdKIeZZonti019voZgwU0pPnjh7Y30vscp9NGYmeQn7YsqoUiYHDcEE98jY6y4fedajLLmMPOvCmu1w21BoHsLmT9mihZhMomH24KsJFQX2eX11UE5pd/5hrc5RdH8O7461bI4KL8D22DzyW3T8ZTGdvoHZuH9EZMWdfkyDRswl89tYp1VjKOz7YJXgX+nF/ttH3P8kYhbDBgW9jrlunheOZc39lQw9Vgolz5KQ7xDg3rhj5dgU5j363GN29WMSHN8N+wJcSB/r5vYiU9YbggnukbHXXb7yrEd5+vuGaSZaSyhgY8N+c1CmN4YX8agU4yvHWtsfYB4Wt2DuZJdhpoF/EFmgO8W4b8Xsk08TbIeYbfsnoZD/ATgxJkcO0+w44DRCRzFxA51ynAb3YJ2rVwF/At4BLgjnarEVsw5OI97phHV46W45/TYonqn0YjbIIB0z8lgplDzrQZ6x0e1Qdg+guyPyCHrpk8FaxH+N5Reb29trMMW/V4YyZq0h2EP8GXnd9XeeJfMb8NMwiEgTllhvY3NPNGE2uh2xz8bTgPVYCyulhSpE5BisAlmDzb+hmP0xtvjwD1KM7wRs6tZZmO1vCfY5+xDm8VCJFfyVqcTbxz3jVyFKafGVHKTBSVildlDk2H6Yq9rjWH5tNidOCnHXYy/J11T1oXBsnKouDnOT3A+coKoLU427l3sKZt55CGu1/o+qvhLm+zkHmxvl1ynGOaDyrCcZscbLGdiX0xIRORv7snkIew9nYjb+vyR6BrFVyu7BzG3PhmOxBXuGhnOnqurCVBcaEZEWbFzGKFV9W0SasVb+57HplG9R1bTmqYkswrMtVjH9C0vjmvDM+2GjZuelEGfO8yxp+rOGSbOmHYeNUPsnNvDiKKzFd0TYPxmbPAmSm698CObxIZhXwXnY53l0NsZPE2zwJD+1bwVWCY0O+zdjrf2LsYUgbieL7lhEFpJOJCObj3Ddi829ZvorDero7gQci5lg0lq4hO6W/bmY3/WBRExkWAvse6nIm8Q90/ZYKZQ860Peeky5v01YbATrM7kilOtPJ5F238EG4cUPkjqT8NWWhlxNwHtYp/A9wMOY2fBBzF6+FlgKjMmgnGXsdZePPEvmN6Bb+qE271LVN0Xkc5iv+9OYbfGpBOH7bDGJyHfC5mjMFngf9mm4DbY4weORsKksnzYZ+yK5FPuEuwvzDV4UWjx3YysiLUgmvj7udTnmlbAz8FVV/XuCMLEJq3bEOrKOiZzLdRpcoaqXR47Xquo6EfkV8HNV/VuKz7tpoqmQlpdhra7YF9MKbJWqPVR1ZTaWp4tM/PZJrMPtO+H4PpjCmoS5aD6XZHwDMs+SlH0vTGGNxUZQ/ynufI/3E5Fq7ItoIvZF/hxm8rgI+KTaurSpfumMA67HTG5XYzOOLsbSZhhmkqlU1Z+lGnfkHrdiUyX8WkQmYvMi7Q18THuZ4DEujrzlWa/0R82S7g+zIUY7YoZigxgewjpBtiU1V79DMA+M72F29scxc8HnsNr87wQvgzTlrcSUfheRuTWw1ZDmkubyf3H3+ARmR94GK4jzgN16CX8Xkbln+ikNLsGGmp8clwavkcYoZMys8iusn+Bz2ORU12D++beF/+1D2GzOjZ6Wx0qh5VmC+8e+zgYRvKLC/nHY19ozmBJP1i26CvtC+M9w/cV0z2Wfqr98S+w9Cs//IDbQcY+e8jCN58/Y666/8yyl58vHTZNMtBOAv0T2v073WpI7YeuOJjV3Rly8n8daBb/FOhV3xFoxPw6Z9NEsyN6AuY7NwaYauITgRphOIYyL+0nMbh3bvww4JS5M1K/6f/KUBo0hDZ6j26Piv1NNg/AC3oKZCA4IMn8T86D5K6ZEz8hRGUzLY6VQ8yz6PCHd7wqy/4ngV465LJ6dzHOncr8Uwme1IRiJJ+ted/2VZyk/az5umkRiVWA2/FhBuwK4LUG4hvCfjD01frm0G4FVRNabJMvzX2CV0zvYZ23SSqKX+KZjQ9YvCgqwPOzH/JTjR0L+jcj8IoWaBuGFe4HuivNwrAU+C7ORbpNp2kbulZHHSqHnWUTpfSfcaxA2gGwV8P24sOn6vafrSZOThmC4Pmted/l4z1J61nzduI9EmxyUxPnYJFSPEBnBhnmAnJlm3NE1RqdgLYS3iZgisvwsQvfnaJ/zw/cSTz1mxtg1vJD/i5k8HukhfAORuUgKPQ2wzrsbMV//v5DkGqSplo2QpkPoXqD6bGzU6WmYeeIpgrtpX0qv0PKMboXfHJTdAZFzLdiX6/25KCNJyJb1hmDkmhMw08tIbNTwqdjX5L5Y39FgwsjrVMtTrvMsrbTM5837SLCe7OON2Gi+KRnGH/UZPizE+c18P3cv8t4EXBnZPwAbyHMr5vq1A6m3oAsiDej2qDgRW1RkYQ7vlbbHSrHkGeYR93iooHZncy+p2LQTORtj0oNMOWkI0g9edwPtPcvLTVNMsHj7+KXA5fGJmWbcElEoY7EOlpyNlM1Azh2BxVG5w395UIS/JjJ7XzGmQUTeQzEX3r3JYis/wX32wmzaTxBMMfHpVkx5Fv88mEntWmwd3hMx88lmA6zykPdZbwhGKpMLIpVJbBBeGTb4M+Mp0AfSezbgF0ZX1RWqejj2yfUo9vl1Wex0hnGrdrtzTQTeVtVVmcSZI64AOkXkzyJyuIaSo6qdqnor1vq5W23QS48LjyeigNIAADV3wYexTrKMF8uOEQYjISKDRGSkqj6h5jL5Q+BCEXlGRCYGl1FiedALBZNncWv0HisinwZqVPVszJ79Caz1X6FpuD9mC1XdqKrfxpR8p4jMEZFWzF3396o6N5Y/KcQ5DzPnDcI8ztao6qJweij2NZbxMw+k92xA++nHE16OCWp++xWq2pHluKtUdUO24swGInI05g9+oIicgo2QnI/5cf87y/cakGmQiMhI3LT8sOPiio3AHISZXsZhvv9fCPeoxswH1yWh7As2z0TkAky5/xmbx+ZdrB9lKbC1qj7Xr/7kfSAiO2GeRQ2Y2ak9E/lEpAHL/1HYoKkTsC+xi7NRziL3yet7VlBKvxQRke8Cv1HVF8P+SKxz8UhssMdlqro+jyIWPBGl/x1sCP9XMNPLSZj75HmRsMkMACyYPBORQ7GRxrHR7j/B5hXaHVsdajrmtnpL3oTshVw0BLNdmQw0XOkPYMLoz2nYp+sHcee2x6Ypfl9Vv5gP+YqBiMJvxsyGv1XVB8O5FszH+gNV/USS8RVcnonI1ZjSb8NmP308HJ+AKf9/q+pLeRSx38mlVSHfuNIfoIRCdx6mQBZiroJzVHVZXJg6VV2Tzc/PUkRETsYWfFmA2fFfj9lcRWSo2vQOm02UliCOgsqz6POITSD3C8yr6FuqemU47uWqyHClP8ARkV0ws8B4zE/5OeCZQrC7D3TiP9lDS/yLmG/2w1h6vwSQiuIrhDwLSn6q2oyh9wPfVdWHRWQGtmpXIzb74915FdTJOq70ByChQ2kiNuq0XlWXicjh2CLc67ApZf+kqovzKGZBE++xgrnUzVfVOSJyGNaJ9y7mq9/nNNCFlmciMgwbM7AH8KGq7hl3/kRspPM38iGfkztc6Q9AROQZbB7vh7DpBw7G/IU/iQ0eGo+t2fr7fMlYLGTLY6WQ8iz0VYiqzheRv2PTDtwBXBO8laZg9uxY34abeIoIV/oDiEin4qnYpF4t2LS0L2OeBMMwd8L1qjo7f5IWNtn0WCnEPBORP2Bz1Pw+mLTewAZh7YkNyJoJ/F1V/zuPYjo5wpX+ACIMLBmhqu+JSC3m3/1ZbK6ZKxN4gxSNG1l/ky2PlULLM7HV3U5S1YPD/gWqelXY3hdbz3WBql49EOR1so8r/QGE2PJszwHXquoF4VgrNgp5OnCfql6cRxELnmx7rBRSnolIBSbrJ4IZ578wM84JkTDRvg436xQhA34ahlJCVV/FhoSvEZF3ReSzqjpfVU/DXAFniMjY/EpZuAQlv03Yvh9b9u544CPAsSKyQEQ+lYqiK7A8m4gt+TcrDBjbD6ucABCRLwBfiu27wi9OvKU/QBGRRmx+71HA6ar6TOSct8DSINceK4WQZyJSiU0RfSnwgKoeGo43Yp3QR6vNYeNmnSLFlf4AJzIk/AFVPSXf8hQq/emxUgh5JlvOM3MiNs/MNwdKBeXkBlf6BUAYxdmqqvO8BZYe/e2xUih5JkU+z4yzJa70naLHPVZ6J1RQRTnPjLMlrvSdosY9Vhxnc9x7xyl23GPFcSK40neKGu1eGamO7pWRFsMmj5VzgAfCfkorWDlOIeLmHadkcI8Vx3Gl75Qg7rHilDKu9J2SxD1WnFLFlb7jOE4J4R25juM4JYQrfcdxnBLClb7jOE4J4UrfcRynhHCl7ziOU0K40nccxykh/j/oxMy8KXICbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imps = list(zip(X_train.columns, pipeline.named_steps['clf'].feature_importances_))\n",
    "imps=(sorted(imps, key=lambda tup: tup[1]))\n",
    "imps.reverse()\n",
    "#geometric_mean_score(y_test, pipeline.predict(X_test)) # 0.8741667300789631\n",
    "labels_i = [x[0] for x in imps][:15]\n",
    "ys_i = [x[1] for x in imps][:15]\n",
    "plt.plot(labels_i, ys_i)\n",
    "plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - No Financials\n",
    "This will be as above, but pulling out the financial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>AGEP_11</th>\n",
       "      <th>AGEP_12</th>\n",
       "      <th>AGEP_13</th>\n",
       "      <th>AGEP_14</th>\n",
       "      <th>AGEP_15</th>\n",
       "      <th>AGEP_16</th>\n",
       "      <th>AGEP_17</th>\n",
       "      <th>AGEP_18</th>\n",
       "      <th>...</th>\n",
       "      <th>WKW_19</th>\n",
       "      <th>WKW_2</th>\n",
       "      <th>WKW_20</th>\n",
       "      <th>WKW_3</th>\n",
       "      <th>WKW_4</th>\n",
       "      <th>WKW_5</th>\n",
       "      <th>WKW_6</th>\n",
       "      <th>WKW_7</th>\n",
       "      <th>WKW_8</th>\n",
       "      <th>WKW_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1521345</th>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521371</th>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521389</th>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521399</th>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521415</th>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_10  AGEP_11  AGEP_12  AGEP_13  AGEP_14  \\\n",
       "SERIALNO Povunit_ID                                                        \n",
       "1521345  1             32.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521371  1             32.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521389  1             57.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521399  1             39.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1521415  1             36.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "                     AGEP_15  AGEP_16  AGEP_17  AGEP_18  ...    WKW_19  WKW_2  \\\n",
       "SERIALNO Povunit_ID                                      ...                    \n",
       "1521345  1               0.0      0.0      0.0      0.0  ...       0.0    0.0   \n",
       "1521371  1               0.0      0.0      0.0      0.0  ...       0.0    0.0   \n",
       "1521389  1               0.0      0.0      0.0      0.0  ...       0.0    1.0   \n",
       "1521399  1               0.0      0.0      0.0      0.0  ...       0.0    1.0   \n",
       "1521415  1               0.0      0.0      0.0      0.0  ...       0.0    3.0   \n",
       "\n",
       "                     WKW_20  WKW_3  WKW_4  WKW_5  WKW_6  WKW_7  WKW_8  WKW_9  \n",
       "SERIALNO Povunit_ID                                                           \n",
       "1521345  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521371  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521389  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521399  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1521415  1              0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = all_2016.copy()\n",
    "\n",
    "categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "# We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "pu_columns = ['NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU', 'NYCgov_Pov_Stat']\n",
    "\n",
    "# Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "X2_pers = X2.copy()\n",
    "X2_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "X2_pers = X2_pers[X2_pers_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X2_pers = X2_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "X2_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in X2_pers.columns)]))\n",
    "\n",
    "# Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "X2_pu = X2.copy()\n",
    "X2_pu_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + pu_columns\n",
    "X2_pu = X2_pu[X2_pu_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X2_pu = X2_pu.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "X2_pu = X2_pu.stack().groupby(['SERIALNO', 'Povunit_ID']).max()\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "X2 = X2_pers.add(X2_pu, fill_value=0)\n",
    "X2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.03s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 977.44s to fit \n"
     ]
    }
   ],
   "source": [
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y2 = X2['NYCgov_Pov_Stat'].replace({'NYCgov_Pov_Stat': {1: 'Pov', 2:'Not Pov'}})\n",
    "X2 = X2.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2)\n",
    "\n",
    "# Transforms for pipeline: \n",
    "# 1) categorize to prep for one-hot encoding\n",
    "# 2) one-hot encode, dropping one to avoid colinearity\n",
    "# 3) deal with imbalanced data with sampling strategies (poverty is ~20% of total)\n",
    "# 4) scale data\n",
    "# 5) classifiers\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_features=100)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "pipeline = imbPipeline(steps=[('cat', categorizer),\n",
    "                              ('dummies', dummy_encoder),\n",
    "                              ('scaler', scaler),\n",
    "                              ('clf', classifier)], \n",
    "                      memory=cachedir)\n",
    "                    \n",
    "t0 = time.time()\n",
    "pipeline.fit(X2_train, y2_train)\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0019536750561223435, 'CIT_16'),\n",
       " (0.0019766238091623893, 'CIT_8'),\n",
       " (0.002074372847437007, 'CIT_19'),\n",
       " (0.002103638190090756, 'CIT_7'),\n",
       " (0.0021084495403344244, 'CIT_12'),\n",
       " (0.002192773240239379, 'CIT_20'),\n",
       " (0.0022114526799705417, 'CIT_5'),\n",
       " (0.0022167018769647475, 'CIT_15'),\n",
       " (0.0023101070754851017, 'CIT_18'),\n",
       " (0.0023378895980513356, 'DIS_7'),\n",
       " (0.0023659286886432707, 'CIT_6'),\n",
       " (0.0024051439784516827, 'CIT_3'),\n",
       " (0.0024677871327048293, 'CIT_17'),\n",
       " (0.002469216276971846, 'CIT_14'),\n",
       " (0.002591447212012863, 'CIT_4')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline.named_steps['clf'].feature_importances_\n",
    "imps = list(zip(pipeline.named_steps['clf'].feature_importances_, X2_train.columns))\n",
    "sorted(imps, key=lambda tup: tup[0])[-15:]\n",
    "#geometric_mean_score(y2_test, pipeline.predict(X2_test)) # 0.5891144868773415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'INTP_adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-1fcd7c603bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_2016\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTP_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#len(all_2016[all_2016.INTP_adj > 0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTP_adj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INTP_adj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'INTP_adj'"
     ]
    }
   ],
   "source": [
    "all_2016.INTP_adj.describe()\n",
    "#len(all_2016[all_2016.INTP_adj > 0])\n",
    "X.loc[X.INTP_adj > 0, 'INTP_adj'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chachi/miniconda3/envs/pandas-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    24259.000000\n",
       "mean      1623.764093\n",
       "std        994.621840\n",
       "min          4.030352\n",
       "25%        967.284480\n",
       "50%       1410.623200\n",
       "75%       2115.934800\n",
       "max       6448.563200\n",
       "Name: RNTP+MRGP, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = all_2016.copy()\n",
    "\n",
    "categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "# We'll create separate dataframes for personal and poverty-unit variables, then join them together\n",
    "#personal_columns = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj', 'Ethnicity', 'Boro']\n",
    "personal_nums = ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj'] \n",
    "#pu_columns = ['NP', 'TEN', 'HHT', 'MRGP_adj', 'RNTP_adj', 'HousingStatus', 'TotalWorkHrs_PU', 'NYCgov_Pov_Stat']\n",
    "\n",
    "# Create a dataframe for the personal columns, including our 3 indicator variables\n",
    "#X_pers = X.copy()\n",
    "#X_pers_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_columns\n",
    "#X_pers = X_pers[X_pers_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "#X_pers = X_pers.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Turn the multi-index columns into a single indexed column: 'AGEP_1', 'AGEP_2', 'AGEP_3', etc.\n",
    "#X_pers.columns = list(map('_'.join, [(y, str(z)) for y, z in (x for x in X_pers.columns)]))\n",
    "\n",
    "# Create a dataframe for the poverty-unit columns, including our 3 indicator variables\n",
    "X_trials = trials.copy()\n",
    "X_trials_columns = ['SERIALNO', 'Povunit_ID', 'SPORDER'] + personal_nums\n",
    "X_trials = X_trials[X_trials_columns]\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "X_trials = X_trials.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Groupby and take the max of SPORDER (these are poverty-unit variables; if there is a nonzero value, it's unique)\n",
    "X_trials = X_trials.stack().groupby(['SERIALNO', 'Povunit_ID']).sum()\n",
    "\n",
    "# Add the personal and poverty-unit dataframes\n",
    "#X = X_pers.add(X_pu, fill_value=0)\n",
    "#X.tail()\n",
    "#X_trials[X_trials.OI_adj > 0].OI_adj.describe()\n",
    "#X_trials.MRGP_adj.describe()\n",
    "#all_2016[all_2016.Povunit_Rel == 1].RNTP_adj.describe()\n",
    "#all_2016.loc[(all_2016.Povunit_Rel == 1) & (all_2016.RNTP_adj > 0)].RNTP_adj.describe()\n",
    "all_2016['RNTP+MRGP'] = all_2016.RNTP_adj + all_2016.MRGP_adj\n",
    "all_2016.loc[(all_2016.Povunit_Rel == 1) & (all_2016['RNTP+MRGP'] > 0)]['RNTP+MRGP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SERIALNO  SPORDER  Povunit_ID  ENG  WKW  TotalWorkHrs_PU\n",
      "710612        39        1           1  1.0  0.0                5\n",
      "710613        55        1           1  5.0  1.0                1\n",
      "710614        55        2           1  5.0  1.0                1\n",
      "710615        55        3           1  5.0  2.0                1\n",
      "710616        55        4           1  5.0  5.0                1\n",
      "710617        55        5           1  5.0  4.0                1\n",
      "710618        69        1           1  5.0  1.0                3\n",
      "710619       210        1           1  5.0  1.0                2\n",
      "710620       261        1           1  5.0  1.0                2\n",
      "710621       261        2           1  5.0  0.0                2\n",
      "        SERIALNO  SPORDER  Povunit_ID  ENG  WKW  TotalWorkHrs_PU\n",
      "710612        39        1           1    4    0                0\n",
      "710613        55        1           1    5    6                4\n",
      "710614        55        2           1    5    6                4\n",
      "710615        55        3           1    5    5                4\n",
      "710616        55        4           1    5    2                4\n",
      "710617        55        5           1    5    3                4\n",
      "710618        69        1           1    5    6                2\n",
      "710619       210        1           1    5    6                3\n",
      "710620       261        1           1    5    6                3\n",
      "710621       261        2           1    5    0                3\n"
     ]
    }
   ],
   "source": [
    "fX = all_2016.copy()\n",
    "print(fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].head(10))\n",
    "fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "              'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "#fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].map(fix_orders).head(10)\n",
    "fX['ENG'] = fX['ENG'].map(fix_orders['ENG'])\n",
    "fX['WKW'] = fX['WKW'].map(fix_orders['WKW'])\n",
    "fX['TotalWorkHrs_PU'] = fX['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "print(fX[['SERIALNO', 'SPORDER', 'Povunit_ID', 'ENG', 'WKW', 'TotalWorkHrs_PU']].head(10))\n",
    "\n",
    "#Number of adults, number of kids, number of retirement-age adults, number of working-age adults, any kids, \n",
    "#any retirement-age adults\n",
    "fX['n_adults'] = fX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SERIALNO  Povunit_ID  SPORDER  CIT  SCHL  SEX\n",
      "710612        39           1        1    1  18.0    1\n",
      "710613        55           1        1    1  20.0    1\n",
      "710614        55           1        2    1  16.0    2\n",
      "710615        55           1        3    1  21.0    1\n",
      "710616        55           1        4    1  16.0    1\n",
      "        SERIALNO  Povunit_ID  SPORDER  ENG  MSP  WKW\n",
      "710612        39           1        1  1.0  6.0  0.0\n",
      "710613        55           1        1  5.0  1.0  1.0\n",
      "710614        55           1        2  5.0  1.0  1.0\n",
      "710615        55           1        3  5.0  6.0  2.0\n",
      "710616        55           1        4  5.0  6.0  5.0\n",
      "        SERIALNO  Povunit_ID  SPORDER  WKHP  DIS  NP\n",
      "710612        39           1        1     0  1.0   1\n",
      "710613        55           1        1    32  2.0   5\n",
      "710614        55           1        2    40  2.0   5\n",
      "710615        55           1        3    10  2.0   5\n",
      "710616        55           1        4    40  2.0   5\n",
      "        SERIALNO  Povunit_ID  SPORDER  JWTR  Ethnicity\n",
      "710612        39           1        1   0.0          4\n",
      "710613        55           1        1   1.0          1\n",
      "710614        55           1        2   1.0          1\n",
      "710615        55           1        3   1.0          1\n",
      "710616        55           1        4   1.0          1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SERIALNO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 3078, in get_loc\n    return self._engine.get_loc(key)\n  File \"pandas/_libs/index.pyx\", line 140, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'SERIALNO'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-15-db1489088e2f>\", line 21, in add_columns_by_group\n    add_pu_columns(df1, groups, group_names, categories[column], category_names[column], column)\n  File \"<ipython-input-15-db1489088e2f>\", line 38, in add_pu_columns\n    df = df.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 3909, in set_index\n    level = frame[col]._values\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 2686, in __getitem__\n    return self._getitem_multilevel(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/frame.py\", line 2730, in _getitem_multilevel\n    loc = self.columns.get_loc(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/multi.py\", line 2237, in get_loc\n    loc = self._get_level_indexer(key, level=0)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/multi.py\", line 2496, in _get_level_indexer\n    loc = level_index.get_loc(key)\n  File \"/home/ubuntu/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n    return self._engine.get_loc(self._maybe_cast_indexer(key))\n  File \"pandas/_libs/index.pyx\", line 140, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'SERIALNO'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-db1489088e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;31m#def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m \u001b[0mtest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengineer_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_fin_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAGEP_yes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0mtest_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/testnewfunctions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-db1489088e2f>\u001b[0m in \u001b[0;36mengineer_features\u001b[0;34m(df, columns_to_use, categories, category_names, num_processors, AGEP_yes)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# FIX THIS -- FOLLOW THE EXAMPLE BELOW TO SPLIT DFC INTO CHUNKS AND THEN MAP OVER THEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_columns_by_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Close the pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SERIALNO'"
     ]
    }
   ],
   "source": [
    "# DON'T USE THIS ONE FOR NOW - USE THE OTHER ONE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_columns_by_group(df):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Helper function \n",
    "    \"\"\"\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    #print('df1 columns: ' + str(df1.columns))\n",
    "    #columns = df1.columns[0]\n",
    "    columns = df1.columns\n",
    "    #print('columns: ' + str(columns))\n",
    "    for column in columns:\n",
    "        if not column in ['SERIALNO', 'Povunit_ID', 'SPORDER']:\n",
    "            #print('df1:' + str(df1.head()))\n",
    "            #print('groups:' + str(groups))\n",
    "            #print('group names:' + str(group_names))\n",
    "            #print('categories:' + str(categories[column]))\n",
    "            #print('category names:' + str(category_names[column]))\n",
    "            #print('column:' + str(column))\n",
    "            #print(columns)\n",
    "            print(df1.head())\n",
    "            add_pu_columns(df1, groups, group_names, categories[column], category_names[column], column)\n",
    "            add_pu_columns(df1, groups, group_names, categories[column], category_names[column], 'AGEP')\n",
    "            df1.drop(column, axis='columns')\n",
    "    return df1\n",
    "\n",
    "def add_pu_columns(df, groups, group_names, categories, category_names, column):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Adds columns to dataframe 'df' containing calculations by poverty-unit, restricted by categories, considering groups.\n",
    "    Calculations include any(), all(), min(), max(), count(), sum(), mean(), and % in given category.\n",
    "    Input: a dataframe with multi-index consisting of 'SERIALNO', 'Povunit_ID', and 'SPORDER'; a set of masks and list of\n",
    "    names for the groups; a set of masks and a list of names for the categories; and the column of interest.\n",
    "    Output: no return value.  Inserts a series of columns into the dataframe including min, max, count, sum, any, all,\n",
    "    % of total, and mean - within households, focusing on the groups and categories of interest. \n",
    "    \"\"\"\n",
    "    for group, group_name in zip(groups, group_names):\n",
    "        for category, category_name in zip(categories, category_names):\n",
    "            # Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "            df = df.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "            stacked = df[group & category].stack().groupby(['SERIALNO', 'Povunit_ID'])[column]\n",
    "            #print('columns to be stacked ' + str(df[group & category].columns))\n",
    "            #print('length to be stacked ' + str(len(df[group & category])))\n",
    "            #print('cat:' + str(category_name) + ', group:' + str(group_name))\n",
    "            #print(df.loc[group & category].head())\n",
    "            anys = stacked.any()\n",
    "            # would love to use .all() here, but it would always be True because we filtered out everyone else\n",
    "            mins = stacked.min()\n",
    "            maxes = stacked.max()\n",
    "            counts = stacked.count()\n",
    "            sums = stacked.sum()\n",
    "            means = sums/counts\n",
    "            # The divisor below only restricts by 'groups' - so the final calculation is within a household, within\n",
    "            # the group of interest (e.g. adults), what % is in the category of interest (e.g. works 40 hrs/week)\n",
    "            divisor_for_percents = df[column][group].stack().groupby(['SERIALNO', 'Povunit_ID']).count()\n",
    "            try:\n",
    "                percents = counts.div(divisor_for_percents, axis=0)\n",
    "                alls = percents == 1\n",
    "            except: # if the calculation failed, leave percents and alls as a column of zeros\n",
    "                df_len = len(df.groupby(['SERIALNO', 'Povunit_ID']).sum())\n",
    "                percents = np.zeros(df_len)\n",
    "\n",
    "                alls = np.zeros(df_len)\n",
    "            \n",
    "            # loop through, put in the dataframe, and fill in NAs of appropriate type\n",
    "            series_and_names = zip([anys, alls, mins, maxes, counts, sums, means, percents], \n",
    "                                  ['any', 'all', 'min', 'max', 'count', 'sum', 'mean', '%'])\n",
    "            for series, series_name in series_and_names:\n",
    "                column_title = series_name + '_' + group_name + '_' + category_name\n",
    "                df[column_title] = series\n",
    "                if series_name in ['any', 'all']:\n",
    "                    df[column_title] = df[column_title].fillna(False)\n",
    "                else:\n",
    "                    df[column_title] = df[column_title].fillna(0)\n",
    "                    \n",
    "def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\n",
    "    \"\"\"EDIT THIS DOCSTRING!!!!!!!!!\n",
    "    Create features for the dataframe. This function is heavily custom and was solely created for DRY-ness.\n",
    "    Input: a poverty dataframe and whether or not to include financial features.\n",
    "    Output: returns a copy of the dataframe summarized by poverty-unit, with *only* the new features included. \n",
    "    Prints progess updates to the screen as it goes.\n",
    "    \"\"\"\n",
    "\n",
    "    time_0 = time.time()\n",
    "\n",
    "    # Create dataframe to house new features \n",
    "    dfc = df.copy() \n",
    "    dfc = dfc[['SERIALNO', 'Povunit_ID', 'SPORDER'] + columns_to_use]\n",
    "\n",
    "    # Split columns_to_use into num_processors groups for use in parallel processing\n",
    "    n = len(columns_to_use)\n",
    "    s = num_processors\n",
    "    labels = [columns_to_use[i * (n//s + 1) : (i+1) * (n//s + 1)] for i in range(s)]\n",
    "    chunks = []\n",
    "    for i in range(s):\n",
    "        chunks.append(dfc[['SERIALNO', 'Povunit_ID', 'SPORDER'] + labels[i]])\n",
    "        #print(labels[i])\n",
    "\n",
    "    # engineer features in parallel\n",
    "    pool = Pool(num_processors)\n",
    "    \n",
    "    #curried = lambda x: partial(add_columns_by_group, dfc, groups, group_names, categories, category_names, x)\n",
    "    #def add_columns_by_group(df, groups, group_names, categories, category_names, columns):\n",
    "    #curried = partial(add_columns_by_group, dfc, groups, group_names, categories, category_names, chunks)\n",
    "    \n",
    "    \n",
    "    # FIX THIS -- FOLLOW THE EXAMPLE BELOW TO SPLIT DFC INTO CHUNKS AND THEN MAP OVER THEM\n",
    "    new_df = pd.concat(pool.map(add_columns_by_group, chunks))\n",
    "    \n",
    "    # Close the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "#def parallel_feature_calculation(df, partitions=10, processes=4):\n",
    "    # calculate features in parallel by splitting the dataframe into partitions and using parallel processes\n",
    "    #pool = Pool(processes)\n",
    "    #df_split = np.array_split(df, partitions, axis=1)  # split dataframe into partitions column wise\n",
    "    #df = pd.concat(pool.map(feature_calculation, df_split))\n",
    "    #pool.close()\n",
    "    #pool.join()\n",
    "    #return df\n",
    "\n",
    "    # add columns with age only, no categories\n",
    "    add_pu_columns(new_df, groups, group_names, [mask_any_age], ['age'], 'AGEP')\n",
    "\n",
    "    # We added a column 'TINP' - drop it if we're not doing financials\n",
    "    if not 'WAGP_adj' in columns_to_use:\n",
    "        new_df.drop('TINP', axis='columns')\n",
    "\n",
    "    # Only return the new features that we engineered\n",
    "    # The variables features_to_mask and max_ppl were created at the beginning of this function\n",
    "    #columns_to_mask = features_to_mask * max_ppl\n",
    "    #dfc = dfc.iloc[:, columns_to_mask:].copy()\n",
    "\n",
    "    # We ended up with multi-level column headers - just keep the top level\n",
    "    new_df.columns = new_df.columns.get_level_values(0)\n",
    "    \n",
    "    time_took = time.time() - time_0\n",
    "    print('Complete. Took ' + str(time_took) + 's')\n",
    "    return(new_df)\n",
    "\n",
    "dfa = all_2016.copy()\n",
    "\n",
    "# First, some categoricals have odd ordering; remap them\n",
    "fix_orders = {'ENG': {0:0, 4:1, 3:2, 2:3, 1:4, 5:5}, 'WKW': {0:0, 6:1, 5:2, 4:3, 3:4, 2:5, 1:6}, \n",
    "              'TotalWorkHrs_PU': {5:0, 4:1, 3:2, 2:3, 1:4}}\n",
    "dfa['ENG'] = dfa['ENG'].map(fix_orders['ENG'])\n",
    "dfa['WKW'] = dfa['WKW'].map(fix_orders['WKW'])\n",
    "dfa['TotalWorkHrs_PU'] = dfa['TotalWorkHrs_PU'].map(fix_orders['TotalWorkHrs_PU'])\n",
    "\n",
    "# Add a column for total personal income - will be ignored if we don't need it\n",
    "dfa['TINP'] = dfa.WAGP_adj + dfa.INTP_adj + dfa.SEMP_adj + dfa.SSP_adj + dfa.SSIP_adj + \\\n",
    "                dfa.PA_adj + dfa.RETP_adj + dfa.OI_adj\n",
    "\n",
    "# Grouping by SERIALNO and Povunit_ID, put SPORDER (person # in household) at the top as multi-index columns\n",
    "dfa = dfa.set_index(['SERIALNO', 'Povunit_ID', 'SPORDER']).unstack('SPORDER').fillna(0)\n",
    "\n",
    "# Create empty dicts for use in adding new columns\n",
    "categories = {}\n",
    "category_names = {}\n",
    "\n",
    "# Create masks for age groups to use in creating new features\n",
    "mask_adult = (dfa.AgeCateg == 2) | (dfa.AgeCateg == 3)\n",
    "mask_65_plus = dfa.AgeCateg == 3\n",
    "mask_18_64 = dfa.AgeCateg == 2\n",
    "mask_kid = dfa.AgeCateg == 1\n",
    "mask_any_age = dfa.AgeCateg != 0\n",
    "mask_any = mask_any_age\n",
    "\n",
    "groups = [mask_adult, mask_65_plus, mask_18_64, mask_kid, mask_any_age]\n",
    "group_names = ['adult', '65+', '18-64', 'kid', 'anyage']\n",
    "\n",
    "# add masks for CIT\n",
    "mask_non_cit = dfa.CIT == 5\n",
    "mask_cit = (dfa.CIT != 5) & (dfa.CIT != 0)\n",
    "mask_naturalized = dfa.CIT == 4\n",
    "\n",
    "categories['CIT'] = [mask_non_cit, mask_cit, mask_naturalized, mask_any]\n",
    "category_names['CIT'] = ['non-cit', 'citizen', 'naturalized_cit', 'any_CIT']\n",
    "\n",
    "# add masks for SCHL\n",
    "mask_college_degree = (dfa.SCHL >= 21)\n",
    "mask_HS_diploma = (dfa.SCHL >= 17)\n",
    "mask_no_diploma = (dfa.SCHL <= 16)\n",
    "\n",
    "categories['SCHL'] = [mask_college_degree, mask_HS_diploma, mask_no_diploma, mask_HS_diploma & ~mask_college_degree, mask_any]\n",
    "category_names['SCHL'] = ['college', 'HS', 'no_diploma', 'diploma_no_bachelors', 'any_SCHL']\n",
    "\n",
    "# add masks for SEX\n",
    "mask_male = dfa.SEX == 1\n",
    "mask_female = dfa.SEX == 2\n",
    "\n",
    "categories['SEX'] = [mask_male, mask_female, mask_any]\n",
    "category_names['SEX'] = ['male', 'female', 'any_SEX']\n",
    "\n",
    "# add masks for English ability (ENG)\n",
    "# Keep in mind we switched ENG above so that 0 is NA, 1 is not at all, 2 is not very well, ..., 5 is only English\n",
    "mask_no_english = dfa.ENG == 1\n",
    "mask_eng_nvw = dfa.ENG == 2\n",
    "mask_sep_well = dfa.ENG == 3\n",
    "mask_eng_vw = dfa.ENG == 4\n",
    "mask_only_eng = dfa.ENG == 5\n",
    "\n",
    "categories['ENG'] = [mask_no_english, mask_eng_nvw, mask_sep_well, mask_eng_vw, mask_only_eng, mask_any]\n",
    "category_names['ENG'] = ['ENG_no', 'ENG_nvw', 'ENG_well', 'ENG_vw', 'ENG_only', 'ENG_any']\n",
    "\n",
    "# add masks for marital status (MSP)\n",
    "mask_married = (dfa.MSP == 1) | (dfa.MSP == 2)\n",
    "mask_widowed = dfa.MSP == 3\n",
    "mask_sep_div = (dfa.MSP == 4) | (dfa.MSP == 5)\n",
    "mask_not_married = dfa.MSP == 6\n",
    "\n",
    "categories['MSP'] = [mask_married, mask_widowed, mask_sep_div, mask_not_married, mask_any]\n",
    "category_names['MSP'] = ['married', 'widowed', 'sep/divorced', 'not_married', 'any_MSP']\n",
    "\n",
    "# add masks for weeks worked (WKW) -- this is *weeks* worked last year, not *hours per week* (that's WKHP)\n",
    "# Keep in mind we switched WKW above so that 0 is none, 1 is <14 weeks, 2 is 14-26 weeks, etc.\n",
    "mask_0_WKW = dfa.WKW == 0\n",
    "mask_u14_WKW = dfa.WKW == 1\n",
    "mask_14_26_WKW = dfa.WKW == 2\n",
    "mask_27_39_WKW = dfa.WKW == 3\n",
    "mask_40_47_WKW = dfa.WKW == 4\n",
    "mask_48_49_WKW = dfa.WKW == 5\n",
    "mask_50_52_WKW = dfa.WKW == 6\n",
    "\n",
    "categories['WKW'] = [mask_0_WKW, mask_u14_WKW, mask_14_26_WKW, mask_27_39_WKW, mask_40_47_WKW, mask_48_49_WKW, mask_50_52_WKW, \n",
    "             (mask_40_47_WKW | mask_48_49_WKW | mask_50_52_WKW), ~mask_0_WKW, mask_any]\n",
    "category_names['WKW'] = ['no_work', '<14WKW', '14-26WKW', '27-39WKW', '40-47WKW', '48-49WKW', '50-52WKW', '>40WKW', 'nonzero_WKW',\n",
    "                 'any_WKW']\n",
    "\n",
    "# add masks for usual hours worked per week last 12 months (WKHP)\n",
    "mask_0_WKHP = dfa.WKHP == 0\n",
    "mask_u10_WKHP = dfa.WKHP < 10\n",
    "mask_u15_WKHP = dfa.WKHP < 15\n",
    "mask_u20_WKHP = dfa.WKHP < 20\n",
    "mask_u30_WKHP = dfa.WKHP < 30\n",
    "mask_u40_WKHP = dfa.WKHP < 40\n",
    "mask_u50_WKHP = dfa.WKHP < 50\n",
    "mask_50_plus_WKHP = dfa.WKHP >= 50\n",
    "mask_40_plus_WKHP = dfa.WKHP >= 40\n",
    "\n",
    "categories['WKHP'] = [mask_0_WKHP, mask_u10_WKHP, mask_u15_WKHP, mask_u20_WKHP, mask_u30_WKHP, mask_u40_WKHP, \n",
    "              mask_u50_WKHP, mask_50_plus_WKHP, mask_40_plus_WKHP, mask_any]\n",
    "category_names['WKHP'] = ['no_work_hrs', '<10_work_hrs', '<15_work_hrs', '<20_work_hrs', '<30_work_hrs', '<40_work_hrs', \n",
    "                  '<50_work_hrs', '50_plus_work_hrs', '40_plus_work_hrs', 'any_WKHP']\n",
    "\n",
    "# add masks for disability status (DIS)\n",
    "mask_DIS = dfa.DIS == 1\n",
    "mask_not_DIS = dfa.DIS == 2\n",
    "\n",
    "categories['DIS'] = [mask_DIS, mask_not_DIS, mask_any]\n",
    "category_names['DIS'] = ['DIS', 'not_DIS', 'any_DIS']\n",
    "\n",
    "# add masks for number of people (NP)\n",
    "mask_1_NP = dfa.NP == 1\n",
    "mask_2_NP = dfa.NP == 2\n",
    "mask_3_NP = dfa.NP == 3\n",
    "mask_4_NP = dfa.NP == 4\n",
    "mask_5_NP = dfa.NP == 5\n",
    "mask_p5_NP = dfa.NP > 5\n",
    "mask_p6_NP = dfa.NP > 6\n",
    "mask_p8_NP = dfa.NP > 8\n",
    "mask_p10_NP = dfa.NP > 10\n",
    "mask_p12_NP = dfa.NP > 12\n",
    "\n",
    "categories['NP'] = [mask_1_NP, mask_2_NP, mask_3_NP, mask_4_NP, mask_5_NP, mask_p5_NP, mask_p6_NP, mask_p8_NP, mask_p10_NP, \n",
    "              mask_p12_NP, mask_any]\n",
    "category_names['NP'] = ['NP1', 'NP2', 'NP3', 'NP4', 'NP5', 'NP>5', 'NP>6', 'NP>8', 'NP>10', 'NP>12', 'anyNP']\n",
    "\n",
    "# add masks for means of transportation to work (JWTR)\n",
    "categories['JWTR'] = [mask_any]\n",
    "category_names['JWTR'] = ['work_trans']\n",
    "\n",
    "# add masks for wages (WAGP_adj)\n",
    "mask_0_WAG = dfa.WAGP_adj == 0\n",
    "mask_u10_WAG = dfa.WAGP_adj < 10000\n",
    "mask_u15_WAG = dfa.WAGP_adj < 15000\n",
    "mask_u20_WAG = dfa.WAGP_adj < 20000\n",
    "mask_u25_WAG = dfa.WAGP_adj < 25000\n",
    "mask_u30_WAG = dfa.WAGP_adj < 30000\n",
    "mask_u35_WAG = dfa.WAGP_adj < 35000\n",
    "mask_u40_WAG = dfa.WAGP_adj < 40000\n",
    "mask_u45_WAG = dfa.WAGP_adj < 45000\n",
    "mask_u50_WAG = dfa.WAGP_adj < 50000\n",
    "mask_u60_WAG = dfa.WAGP_adj < 60000\n",
    "mask_u70_WAG = dfa.WAGP_adj < 70000\n",
    "mask_u80_WAG = dfa.WAGP_adj < 80000\n",
    "\n",
    "categories['WAGP_adj'] = [mask_0_WAG, mask_u10_WAG, mask_u15_WAG, mask_u20_WAG, mask_u25_WAG, mask_u30_WAG,  mask_u35_WAG, \n",
    "              mask_u40_WAG, mask_u45_WAG, mask_u50_WAG, mask_u60_WAG, mask_u70_WAG, mask_u80_WAG, mask_any]\n",
    "category_names['WAGP_adj'] = ['WAG0', 'WAG<10', 'WAG<15', 'WAG<20', 'WAG<25', 'WAG<30', 'WAG<35', \n",
    "                  'WAG<40', 'WAG<45', 'WAG<50', 'WAG<60', 'WAG<70', 'WAG<80', 'WAG_any']\n",
    "\n",
    "# add masks for interest income (INTP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_INT = dfa.INTP_adj <= 0\n",
    "mask_INT_1q = (dfa.INTP_adj > 0) & (dfa.INTP_adj <= 400)\n",
    "mask_INT_2q = (dfa.INTP_adj > 400) & (dfa.INTP_adj <= 4000)\n",
    "mask_INT_3q = (dfa.INTP_adj > 4000) & (dfa.INTP_adj <= 15000)\n",
    "mask_INT_4q = dfa.INTP_adj > 15000\n",
    "\n",
    "categories['INTP_adj'] = [mask_0_INT, mask_INT_1q, mask_INT_2q, mask_INT_3q, mask_INT_4q, mask_any]\n",
    "category_names['INTP_adj'] = ['INT0', 'INT1q', 'INT2q', 'INT3q', 'INT4q', 'INT_any']\n",
    "\n",
    "# add masks for self-employment income (SEMP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_SEMP = dfa.SEMP_adj <= 0\n",
    "mask_SEMP_1q = (dfa.SEMP_adj > 0) & (dfa.SEMP_adj <= 5000)\n",
    "mask_SEMP_2q = (dfa.SEMP_adj > 5000) & (dfa.SEMP_adj <= 15000)\n",
    "mask_SEMP_3q = (dfa.SEMP_adj > 15000) & (dfa.SEMP_adj <= 35000)\n",
    "mask_SEMP_4q = dfa.SEMP_adj > 35000\n",
    "\n",
    "categories['SEMP_adj'] = [mask_0_SEMP, mask_SEMP_1q, mask_SEMP_2q, mask_SEMP_3q, mask_SEMP_4q, mask_any]\n",
    "category_names['SEMP_adj'] = ['SEMP0', 'SEMP1q', 'SEMP2q', 'SEMP3q', 'SEMP4q', 'SEMP_any']\n",
    "\n",
    "# add masks for social security income (SSP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "# min 10, 25% 8000, 50% 12,000, 75% 18,000, max 50,000\n",
    "mask_0_SSP = dfa.SSP_adj <= 0\n",
    "mask_SSP_1q = (dfa.SSP_adj > 0) & (dfa.SSP_adj <= 8000)\n",
    "mask_SSP_2q = (dfa.SSP_adj > 8000) & (dfa.SSP_adj <= 12000)\n",
    "mask_SSP_3q = (dfa.SSP_adj > 12000) & (dfa.SSP_adj <= 18000)\n",
    "mask_SSP_4q = dfa.SSP_adj > 18000\n",
    "\n",
    "categories['SSP_adj'] = [mask_0_SSP, mask_SSP_1q, mask_SSP_2q, mask_SSP_3q, mask_SSP_4q, mask_any]\n",
    "category_names['SSP_adj'] = ['SSP0', 'SSP1q', 'SSP2q', 'SSP3q', 'SSP4q', 'SSP_any']\n",
    "\n",
    "# add masks for supplemental security income (SSIP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_SSIP = dfa.SSIP_adj <= 0 \n",
    "mask_SSIP_1q = (dfa.SSIP_adj > 0) & (dfa.SSIP_adj <= 5500) \n",
    "mask_SSIP_2q = (dfa.SSIP_adj > 5500) & (dfa.SSIP_adj <= 8000) \n",
    "mask_SSIP_3q = (dfa.SSIP_adj > 8000)\n",
    "\n",
    "categories['SSIP_adj'] = [mask_0_SSIP, mask_SSIP_1q, mask_SSIP_2q, mask_SSIP_3q, mask_any]\n",
    "category_names['SSIP_adj'] = ['SSIP0', 'SSIP1q', 'SSIP2q', 'SSIP3q', 'SSIP_any']\n",
    "\n",
    "# add masks for public assistance income (PA_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_0_PA = dfa.PA_adj <= 0 \n",
    "mask_PA_1q = (dfa.PA_adj > 0) & (dfa.PA_adj <= 900) \n",
    "mask_PA_2q = (dfa.PA_adj > 900)\n",
    "\n",
    "categories['PA_adj'] = [mask_0_PA, mask_PA_1q, mask_PA_2q, mask_any]\n",
    "category_names['PA_adj'] = ['PA0', 'PA1q', 'PA2q', 'PA_any']\n",
    "\n",
    "# add masks for retirement income (RETP_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_RETP_1q = (dfa.RETP_adj > 0) & (dfa.RETP_adj <= 6000) \n",
    "mask_RETP_2q = (dfa.RETP_adj > 6000) & (dfa.RETP_adj <= 13400) \n",
    "mask_RETP_3q = (dfa.RETP_adj > 13400)\n",
    "\n",
    "categories['RETP_adj'] = [mask_RETP_1q, mask_RETP_2q, mask_RETP_3q, mask_any]\n",
    "category_names['RETP_adj'] = ['RETP1q', 'RETP2q', 'RETP3q', 'RETP_any']\n",
    "\n",
    "# add masks for other income (OI_adj)\n",
    "# cutoffs taken from quartiles of nonzero values\n",
    "mask_OI_1q = (dfa.OI_adj > 0) & (dfa.OI_adj <= 2000) \n",
    "mask_OI_2q = (dfa.OI_adj > 2000) & (dfa.OI_adj <= 6000) \n",
    "mask_OI_3q = (dfa.OI_adj > 6000)\n",
    "\n",
    "categories['OI_adj'] = [mask_OI_1q, mask_OI_2q, mask_OI_3q, mask_any]\n",
    "category_names['OI_adj'] = ['OI1q', 'OI2q', 'OI3q', 'OI_any']\n",
    "\n",
    "# add masks for ethnicity\n",
    "mask_white = dfa.Ethnicity == 1\n",
    "mask_black = dfa.Ethnicity == 2\n",
    "mask_asian = dfa.Ethnicity == 3\n",
    "mask_hisp = dfa.Ethnicity == 4\n",
    "mask_other = dfa.Ethnicity == 5\n",
    "\n",
    "categories['Ethnicity'] = [mask_white, mask_black, mask_asian, mask_hisp, mask_other, mask_any]\n",
    "category_names['Ethnicity'] = ['White', 'Black', 'Asian', 'Hisp', 'ETH_other', 'ETH_any']\n",
    "\n",
    "# add masks for our constructed column 'TINP'\n",
    "mask_0_TINP = dfa.TINP == 0\n",
    "mask_u10_TINP = dfa.TINP < 10000\n",
    "mask_u15_TINP = dfa.TINP < 15000\n",
    "mask_u20_TINP = dfa.TINP < 20000\n",
    "mask_u25_TINP = dfa.TINP < 25000\n",
    "mask_u30_TINP = dfa.TINP < 30000\n",
    "mask_u35_TINP = dfa.TINP < 35000\n",
    "mask_u40_TINP = dfa.TINP < 40000\n",
    "mask_u45_TINP = dfa.TINP < 45000\n",
    "mask_u50_TINP = dfa.TINP < 50000\n",
    "mask_u60_TINP = dfa.TINP < 60000\n",
    "mask_u70_TINP = dfa.TINP < 70000\n",
    "mask_u80_TINP = dfa.TINP < 80000\n",
    "\n",
    "categories['TINP'] = [mask_0_TINP, mask_u10_TINP, mask_u15_TINP, mask_u20_TINP, mask_u25_TINP, mask_u30_TINP, \n",
    "                      mask_u35_TINP, mask_u40_TINP, mask_u45_TINP, mask_u50_TINP, mask_u60_TINP, mask_u70_TINP, \n",
    "                      mask_u80_TINP, mask_any]\n",
    "category_names['TINP'] = ['TINP0', 'TINP<10', 'TINP<15', 'TINP<20', 'TINP<25', 'TINP<30', 'TINP<35', \n",
    "              'TINP<40', 'TINP<45', 'TINP<50', 'TINP<60', 'TINP<70', 'TINP<80', 'TINP_any']\n",
    "\n",
    "financial_columns = ['WAGP_adj', 'INTP_adj', 'SEMP_adj', 'SSP_adj', 'SSIP_adj', 'PA_adj', 'RETP_adj', 'OI_adj']\n",
    "non_fin_columns = ['CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'NP', 'JWTR', 'Ethnicity']\n",
    "\n",
    "#new_features = engineer_features(all_2016, include_financials=True)\n",
    "\n",
    "#new_features.to_csv('data/EngineeredFeatures.csv')\n",
    "\n",
    "#def engineer_features(df, columns_to_use, categories, category_names, num_processors, AGEP_yes=True):\n",
    "\n",
    "test_new = engineer_features(all_2016, non_fin_columns, categories, category_names, num_processors=4, AGEP_yes=True)\n",
    "\n",
    "test_new.to_csv('data/testnewfunctions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Coding Categorical Variables for One-Hot Encoding\n",
    "We need to do a little cleanup on the data before one-hot encoding. Some of our columns are categorical, and we need\n",
    "them to have type Categorical before one-hot encoding.  \n",
    "\n",
    "Normally we could just pass this to a pre-processor like \n",
    "dask-ml's 'Categorizer'; but remember that we split up each column like 'SCHL' into 20 columns 'SCHL_1', 'SCHL_2', etc. \n",
    "Moreover, some of these columns, like 'SCHL_20', will be pretty sparse since there are very few households with 20\n",
    "people. So we want to be sure that when we code each 'SCHL_n' column, we have ALL of the possible SCHL values encoded in\n",
    "the Categorical so that we don't get an error when we try to generalize to unseen data.\n",
    "\n",
    "Some categories are unordered (e.g. disability\n",
    "status), and we have to be aware of personal categories vs poverty-unit categories; the poverty-unit categories only show\n",
    "up in one column each, while the personal categories show up in many columns each (suffixed with '\\_1', '\\_2', etc.).\n",
    "\n",
    "Again this is one-off code poorly disguised as a function, solely for DRY purposes. 'Tighter' code would be to pull out\n",
    "the hard-coded lists and turn the loops into helper functions - falling back on YAGNI and 3-strikes rule for now (we're\n",
    "at 2 strikes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_categoricals(df, old_df):\n",
    "    \"\"\"Turn the categorical columns of df into true Categorical types in preparation for one-hot encoding, and return a \n",
    "    dictionary of columns to pass to the one-hot encoder.\n",
    "    Input: the dataframe of interest, and the 'old' dataframe with the original categories. (The dataframe at this\n",
    "    point will include columns like 'AGEP_1', 'AGEP_2', etc. which may not have all of the values, so we refer to old_df.)\n",
    "    Output: returns a 2-tuple of the dataframe with columns transformed, and a dictionary to pass to the one-hot encoder.)\n",
    "    \"\"\"\n",
    "    \n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # Number of enumerated columns for each feature ('AGEP_1', 'AGEP_2', etc.)\n",
    "    # This is equal to the maximum number of people in any household, which is the max of SPORDER\n",
    "    n = old_df.SPORDER.max()\n",
    "\n",
    "    # All the categoricals that we'll have to set up\n",
    "    categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro', 'NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "    personal_categoricals = ['AGEP', 'CIT', 'SCHL', 'SEX', 'ENG', 'MSP', 'WKW', 'WKHP', 'DIS', 'JWTR', 'Ethnicity', 'Boro']\n",
    "    pu_categoricals = ['NP', 'TEN', 'HHT', 'HousingStatus', 'TotalWorkHrs_PU']\n",
    "\n",
    "    categories = {} # Dict for each initial categorical\n",
    "\n",
    "    # Some categoricals have no ordering\n",
    "    unordered = ['DIS', 'SEX', 'MSP', 'JWTR', 'Ethnicity', 'Boro', 'TEN', 'HHT', 'HousingStatus']\n",
    "\n",
    "    # Loop through and assign appropriate category structure for personal categoricals\n",
    "    for feature in personal_categoricals:\n",
    "        cats = old_df[feature].unique() # Get all of the category values, to use in assigning the type of Categorical\n",
    "        if not 0 in cats:\n",
    "            # Even if 0 was not in the original categorization - here it means 'no person', so we need it\n",
    "            cats = np.append(cats, 0)\n",
    "        cats.sort()\n",
    "        # Loop through and assign for each suffixed column '_1', '_2', etc.\n",
    "        for i in range(1,n+1):\n",
    "            suffixed_name = feature + '_' + str(i)\n",
    "            # Assign Categorical type to columns\n",
    "            if feature in unordered:\n",
    "                categories[suffixed_name] = pd.Categorical(cats, ordered=False)\n",
    "                dfc[suffixed_name] = pd.Categorical(dfc[suffixed_name], ordered=False, categories=cats)\n",
    "            else: # Category is ordered\n",
    "                categories[suffixed_name] = pd.Categorical(cats, ordered=True, categories=cats)\n",
    "                dfc[suffixed_name] = pd.Categorical(dfc[suffixed_name], ordered=True, categories=cats)\n",
    "\n",
    "    # Loop through and assign appropriate category structure for poverty-unit categoricals\n",
    "    for feature in pu_categoricals:\n",
    "        cats = old_df[feature].unique() # Get all of the category values, to use in assigning the type of Categorical\n",
    "        if not 0 in cats:\n",
    "            # Even if 0 was not in the original categorization - here it means 'no person', so we need it\n",
    "            cats = np.append(cats, 0)\n",
    "        cats.sort()\n",
    "        # Assign Categorical type to columns\n",
    "        if feature in unordered:\n",
    "            categories[feature] = pd.Categorical(cats, ordered=False)\n",
    "            dfc[feature] = pd.Categorical(dfc[feature], ordered=False, categories=cats)\n",
    "        else: # Category is ordered\n",
    "            categories[feature] = pd.Categorical(cats, ordered=True, categories=cats)\n",
    "            dfc[feature] = pd.Categorical(dfc[feature], ordered=True, categories=cats)\n",
    "\n",
    "    # Create a dictionary 'dummy_these' that we'll pass to our dummy-maker later\n",
    "    # The poverty-unit categoricals can be passed as-is. For the personal categoricals, we'll have features \n",
    "    # like 'AGEP_1', 'AGEP_2', ..., 'AGEP_20' - so we have to loop through and assign categories.\n",
    "    dummy_these = {}\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        for feature in personal_categoricals:\n",
    "            name = feature + '_' + str(i)\n",
    "            dummy_these[name] = categories[name]\n",
    "\n",
    "    for feature in pu_categoricals:\n",
    "        dummy_these[feature] = categories[name]\n",
    "    \n",
    "    return(dfc, dummy_these)\n",
    "\n",
    "#X_and_y, dummy_these = code_categoricals(X_and_y, all_2016)\n",
    "#X_and_y.to_csv('data/FeaturesCoded.csv')\n",
    "\n",
    "\n",
    "    \n",
    "#for col in cols:\n",
    "#    if rama[col].dtype == 'bool':\n",
    "#        cats = rama[col].unique()\n",
    "#        cats.sort()\n",
    "#        rama[col] = pd.Categorical(rama[col], ordered=True, categories=cats)\n",
    "#    if rama[col].dtype == 'int64':\n",
    "#        cats = rama[col].unique()\n",
    "#        cats.sort()\n",
    "#        rama[col] = pd.Categorical(rama[col], ordered=True, categories=cats)\n",
    "\n",
    "#rama.info()\n",
    "\n",
    "#for col in cols:\n",
    "    #if rama[col].dtype == 'category':\n",
    "        # ind = cols.get_loc(col)\n",
    "        # categorical_features += ind\n",
    "        # categorical_names[ind] = cats # (cats from above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with grid search and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  3.6min remaining:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  5.3min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 11.8min finished\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.34s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1020.30s to fit \n",
      "Pipeline(memory='/mnt/ssd/tmp/tmp5ozdrgyr',\n",
      "     steps=[('dummies', DummyEncoder(columns=None, drop_first=True)), ('scaler', Normalizer(copy=True, norm='l2')), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0...mators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "0.9234668018246326\n",
      "{'clf__n_estimators': 1000}\n",
      "{'std_score_time': array([ 1.16240683,  3.84877212, 10.16093959]), 'mean_test_score': array([0.91518838, 0.92253759, 0.9234668 ]), 'split2_test_score': array([0.91572678, 0.91990876, 0.92206311]), 'std_train_score': array([7.87808717e-05, 0.00000000e+00, 0.00000000e+00]), 'params': [{'clf__n_estimators': 10}, {'clf__n_estimators': 100}, {'clf__n_estimators': 1000}], 'split0_train_score': array([0.99543813, 1.        , 1.        ]), 'std_test_score': array([0.00040945, 0.00190335, 0.0014685 ]), 'mean_fit_time': array([ 97.98711038,  94.02541296, 446.90180969]), 'mean_score_time': array([15.49286358, 16.71451068, 24.16282201]), 'split1_test_score': array([0.9151039 , 0.92435378, 0.92549417]), 'split0_test_score': array([0.91473457, 0.9233498 , 0.92284303]), 'mean_train_score': array([0.99535395, 1.        , 1.        ]), 'split2_train_score': array([0.99524865, 1.        , 1.        ]), 'split1_train_score': array([0.99537506, 1.        , 1.        ]), 'std_fit_time': array([ 8.68384898, 55.33325929,  9.10461366]), 'rank_test_score': array([3, 2, 1], dtype=int32), 'param_clf__n_estimators': masked_array(data=[10, 100, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  2.3min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  3.1min remaining:  1.5min\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1207838ff1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtime_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mretrieval_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain = {}\n",
    "results_balanced = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain, results_balanced]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "    \n",
    "    params = {'clf__n_estimators': [10, 100, 1000]}\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=9)\n",
    "\n",
    "    t0 = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    print(grid.best_estimator_)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.94s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.15s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 477.30s to fit \n",
      "\n",
      "Balanced accuracy: 0.8802950749897955\n",
      "Geometric mean: 0.8772013286319785\n",
      "Confusion matrix:\n",
      "[[4483  216]\n",
      " [ 236  984]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.95      0.95      0.81      0.95      0.88      0.78      4699\n",
      "        Pov       0.82      0.81      0.95      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.84      0.92      0.88      0.78      5919\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'named_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-af3514c8bac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix:\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nClassification report:\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nOOB score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nn_estimators: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'named_features'"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOB score: 0.9254096975840513\n",
      "\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.00670862784332334, 'any_adult_TINP<20'),\n",
       " (0.0066194372159959405, '%_adult_TINP<20'),\n",
       " (0.006479640639032289, '%_anyage_WAG<45'),\n",
       " (0.006334087270109876, '%_anyage_any_WKHP'),\n",
       " (0.0062931342915874214, '%_anyage_TINP<15'),\n",
       " (0.005944444651839958, 'all_anyage_WAG_any'),\n",
       " (0.005501383040418589, 'all_anyage_WAG<60'),\n",
       " (0.005464648575639451, '%_anyage_WAG<20'),\n",
       " (0.005377005353263044, 'any_anyage_WAG<50'),\n",
       " (0.005214485567674988, 'any_anyage_any_WKHP'),\n",
       " (0.0051429150100985345, 'all_anyage_TINP<20'),\n",
       " (0.00510779175422798, '%_anyage_WAG<70'),\n",
       " (0.005029627256854295, 'any_anyage_TINP<25'),\n",
       " (0.005021266220117347, 'all_anyage_age'),\n",
       " (0.004970895146790292, 'any_anyage_SSP_any')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(pipeline.named_steps['clf'].feature_importances_, pipeline.named_steps['dummies'].transformed_columns_))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini data set with n_estimators = 10 and RandomForestClassifier - prep for LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5618\n",
      "Took: 7.72s to fit \n",
      "\n",
      "Balanced accuracy: 1.0\n",
      "Geometric mean: 1.0\n",
      "Confusion matrix:\n",
      "[[7 0]\n",
      " [0 3]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00         7\n",
      "          1       1.00      1.00      1.00      1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00        10\n",
      "\n",
      "\n",
      "OOB score: 0.8\n",
      "n_estimators: 10\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y_small = X_and_y.iloc[:50,:].copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y_small['NYCgov_Pov_Stat']\n",
    "y.replace({'Not Pov': 0, 'Pov': 1}, inplace=True)\n",
    "X = X_and_y_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=10, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3eefa342b2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtime_took\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    272\u001b[0m         ).ravel()\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0myss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# for classification, the model needs to provide a list of tuples - classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-3eefa342b2db>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtime_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Specify the prediction function for use with LIME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/dask_ml/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mSame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \"\"\"\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             raise ValueError(\n\u001b[1;32m    623\u001b[0m                 \u001b[0;34m\"Columns of 'X' do not match the training \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "# Specify the prediction function for use with LIME\n",
    "predict_fn = lambda x: pipeline.named_steps['clf'].predict_proba(pipeline.predict(x))\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = X_train.columns)#,\n",
    "                                                   #class_names=['Pov', 'Not Pov']),\n",
    "                                                   #categorical_features=categorical_features, \n",
    "                                                   #categorical_names=categorical_names)\n",
    "\n",
    "np.random.seed(42)\n",
    "i = 7\n",
    "exp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "time_took = time.time() - time_0\n",
    "print('Took ' + str(time_took) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 5000 and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1370.52s to fit \n",
      "\n",
      "Balanced accuracy: 0.8801138365679478\n",
      "Geometric mean: 0.8768956359864453\n",
      "Confusion matrix:\n",
      "[[4489  210]\n",
      " [ 238  982]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        Pov       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.84      0.92      0.88      0.78      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9264656191924312\n",
      "n_estimators: 5000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=5000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and RandomForestClassifier using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 242.49s to fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced accuracy: 0.8617460464207591\n",
      "Geometric mean: 0.8568130733410114\n",
      "Confusion matrix:\n",
      "[[4482  217]\n",
      " [ 281  939]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.94      0.95      0.77      0.95      0.86      0.75      4699\n",
      "        Pov       0.81      0.77      0.95      0.79      0.86      0.72      1220\n",
      "\n",
      "avg / total       0.91      0.92      0.81      0.92      0.86      0.74      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9227487751309342\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "X_and_y = pd.read_csv('data/FeaturesCoded.csv', index_col=[0,1], header=0)\n",
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with grid search and BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   9 | elapsed:  5.0min remaining:  2.5min\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed: 26.9min finished\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.35s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 2310.83s to fit \n",
      "Pipeline(memory='/mnt/ssd/tmp/tmpogjb52hr',\n",
      "     steps=[('dummies', DummyEncoder(columns=None, drop_first=True)), ('scaler', Normalizer(copy=True, norm='l2')), ('clf', BalancedRandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                criterion='gini', max_depth=None, max_features='auto',\n",
      "                max_leaf_nodes=None, min_imp...tate=42, replacement=False,\n",
      "                sampling_strategy='auto', verbose=0, warm_start=False))])\n",
      "0.8971109984794728\n",
      "{'clf__n_estimators': 1000}\n",
      "{'std_score_time': array([ 0.43724339,  6.47117318, 10.0884839 ]), 'mean_test_score': array([0.89453455, 0.89706876, 0.897111  ]), 'split2_test_score': array([0.89798505, 0.89925231, 0.89887213]), 'std_train_score': array([0.00174429, 0.00211428, 0.00166577]), 'params': [{'clf__n_estimators': 10}, {'clf__n_estimators': 100}, {'clf__n_estimators': 1000}], 'split0_train_score': array([0.92023063, 0.92130774, 0.92225813]), 'std_test_score': array([0.00300425, 0.00211323, 0.00223569]), 'mean_fit_time': array([  79.07977804,  111.69476787, 1272.5219895 ]), 'mean_score_time': array([15.21685592, 21.84757996, 24.02181101]), 'split1_test_score': array([0.89495692, 0.89774455, 0.89850482]), 'split0_test_score': array([0.89066261, 0.89421006, 0.89395667]), 'mean_train_score': array([0.9226431 , 0.92405801, 0.92382573]), 'split2_train_score': array([0.92429522, 0.92644916, 0.9261324 ]), 'split1_train_score': array([0.92340345, 0.92441713, 0.92308667]), 'std_fit_time': array([ 9.8503707 ,  5.03462801, 16.42877733]), 'rank_test_score': array([3, 2, 1], dtype=int32), 'param_clf__n_estimators': masked_array(data=[10, 100, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              #('sampler', sampler), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', balanced_clf)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "params = {'clf__n_estimators': [10, 100, 1000]}\n",
    "\n",
    "#grid = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=9)\n",
    "grid = GridSearchCV(pipeline, params, n_jobs=3, cv=3, verbose=9)\n",
    "\n",
    "t0 = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and BalancedRandomForestClassifier using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.13s to fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced accuracy: 0.9080515910256455\n",
      "Geometric mean: 0.9076684804536956\n",
      "Confusion matrix:\n",
      "[[4143  556]\n",
      " [  80 1140]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.98      0.88      0.93      0.93      0.91      0.82      4699\n",
      "        Pov       0.67      0.93      0.88      0.78      0.91      0.83      1220\n",
      "\n",
      "avg / total       0.92      0.89      0.92      0.90      0.91      0.82      5919\n",
      "\n",
      "\n",
      "OOB score: 0.9238046967393141\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', oob_score=True,\n",
    "                                            random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set with n_estimators = 1000 and BalancedRandomForestClassifier with sampling_strategy changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.90s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.12s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.53s to fit \n",
      "\n",
      "Balanced accuracy: 0.9113460659575284\n",
      "Geometric mean: 0.9108903240199582\n",
      "Confusion matrix:\n",
      "[[4147  552]\n",
      " [  73 1147]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Not Pov       0.98      0.88      0.94      0.93      0.91      0.82      4699\n",
      "        Pov       0.68      0.94      0.88      0.79      0.91      0.83      1220\n",
      "\n",
      "avg / total       0.92      0.89      0.93      0.90      0.91      0.83      5919\n",
      "\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, sampling_strategy=1.0, replacement=True, n_jobs=-1, \n",
    "                                            max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "#print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n",
      "SERIALNO  Povunit_ID\n",
      "1521345   1             2\n",
      "1521371   1             1\n",
      "1521389   1             2\n",
      "1521399   1             1\n",
      "1521415   1             2\n",
      "Name: NYCgov_Pov_Stat, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.84s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.08s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The {2} target class is/are not present in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ce3f4b637a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtime_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m                         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                         verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 437\u001b[0;31m                     for i, (s, t) in enumerate(zip(samplers, trees)))\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0msamplers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamplers_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_local_parallel_build_trees\u001b[0;34m(sampler, tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m     37\u001b[0m                                 class_weight=None):\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# resample before to fit the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_indices_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0;32m---> 83\u001b[0;31m             self.sampling_strategy, y, self._sampling_type)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         return OrderedDict(sorted(\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0m_sampling_strategy_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             .items()))\n\u001b[1;32m    447\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36m_sampling_strategy_dict\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_diff_sampling_strategy_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError(\"The {} target class is/are not present in the\"\n\u001b[0;32m--> 233\u001b[0;31m                          \" data.\".format(set_diff_sampling_strategy_target))\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;31m# check that there is no negative number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The {2} target class is/are not present in the data."
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "X_and_y = X_and_y.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "#X_and_y['NYCgov_Pov_Stat'] = X_and_y['NYCgov_Pov_Stat'].replace({'Pov': 1, 'Not Pov': 2})\n",
    "#X_and_y['NYCgov_Pov_Stat'] = X_and_y['NYCgov_Pov_Stat'].replace({1: 'Pov', 2:'Not Pov'})\n",
    "#X_and_y['NYCgov_Pov_Stat'] = pd.Categorical(X_and_y['NYCgov_Pov_Stat'], ordered=False, categories=['Pov', 'Not Pov'])\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "print(y.tail())\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "\n",
    "sampling_strat = {2: 5919, 1: 17757}\n",
    "\n",
    "classifier = BalancedRandomForestClassifier(n_estimators=1000, sampling_strategy=sampling_strat, replacement=True, \n",
    "                                            n_jobs=-1, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "pipeline = imbPipeline(steps=[('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print('\\nBalanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "#print('\\nOOB score: ' + str(pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = list(zip(pipeline.named_steps['clf'].feature_importances_, pipeline.named_steps['dummies'].transformed_columns_))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set but no grid search, only 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.33s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 70.75s to fit \n",
      "{'confusion_matrix': array([[4503,  196],\n",
      "       [ 295,  925]]), 'geometric_mean_score': 0.8523916799769762, 'balanced_accuracy_score': 0.8582428594852759, 'feature_importances_': array([1.08379062e-04, 2.28520176e-04, 6.73097969e-05, ...,\n",
      "       0.00000000e+00, 1.17332300e-04, 0.00000000e+00]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.94      0.96      0.76      0.95      0.85      0.74      4699\\n        Pov       0.83      0.76      0.96      0.79      0.85      0.71      1220\\n\\navg / total       0.92      0.92      0.80      0.92      0.85      0.74      5919\\n', 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10477)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.33s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 54.02s to fit \n",
      "{'confusion_matrix': array([[4175,  524],\n",
      "       [  93, 1127]]), 'geometric_mean_score': 0.905956948071855, 'balanced_accuracy_score': 0.906128701956119, 'feature_importances_': array([0.00021626, 0.00045376, 0.        , ..., 0.        , 0.        ,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.98      0.89      0.92      0.93      0.91      0.82      4699\\n        Pov       0.68      0.92      0.89      0.79      0.91      0.82      1220\\n\\navg / total       0.92      0.90      0.92      0.90      0.91      0.82      5919\\n', 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10477)}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X.iloc[:50, :].copy()\n",
    "X_small = X.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain = {}\n",
    "results_balanced = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain, results_balanced]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "    results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "    results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "    results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "    results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "    results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "    print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.053261627357831756, 'all_adult_any_WKHP'),\n",
       " (0.053249850993936886, 'any_anyage_TINP_any'),\n",
       " (0.052582859245591876, 'all_anyage_ETH_any'),\n",
       " (0.052276741730780694, 'all_anyage_SSP_any'),\n",
       " (0.05225465701237826, 'any_adult_WAG<50'),\n",
       " (0.05157735756906421, '%_anyage_TINP<25'),\n",
       " (0.05144051199957207, 'any_anyage_TINP<70'),\n",
       " (0.051439137088152176, 'all_anyage_any_WKW'),\n",
       " (0.05046858251637465, 'all_adult_TINP<80'),\n",
       " (0.03912715924380138, 'count_anyage_WAG<10'),\n",
       " (0.011321463620562803, 'all_adult_TINP<25'),\n",
       " (0.007184924649845273, 'MRNT'),\n",
       " (0.006452386132367269, '%_anyage_ETH_any'),\n",
       " (0.0050534530833320915, '%_anyage_ENG_any'),\n",
       " (0.004529686603494478, 'any_anyage_PA0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_plain['feature_importances_'], results_plain['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.06510250878867069, 'any_adult_TINP<20'),\n",
       " (0.06396830168664602, 'all_adult_SSIP_any'),\n",
       " (0.063710355411885, 'all_anyage_WAG<35'),\n",
       " (0.06274658841068068, 'all_anyage_WAG<60'),\n",
       " (0.06236858347937092, 'all_anyage_TINP_any'),\n",
       " (0.062242303320543556, 'any_adult_any_SEX'),\n",
       " (0.062148568051467415, 'all_anyage_WAG<30'),\n",
       " (0.06142120639451819, '%_anyage_ENG_any'),\n",
       " (0.06139662533699729, 'all_adult_TINP<80'),\n",
       " (0.060671661137871404, 'all_anyage_WAG<45'),\n",
       " (0.00716956500302484, 'any_anyage_TINP<15'),\n",
       " (0.006895951467055411, 'count_18-64_WAG<30'),\n",
       " (0.006417046063640315, '%_anyage_TINP<25'),\n",
       " (0.005957844465198908, 'count_anyage_WAG<60'),\n",
       " (0.0058310843547457, 'all_kid_TINP<40')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_balanced['feature_importances_'], results_balanced['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Pov_Gap instead of NYCGov_Pov_Stat\n",
    "We've been looking at poverty status as a classification problem (yes or no), but we can also view it as a regression \n",
    "problem.  Poverty status is essentially whether (Total Poverty-Unit Income) is less than (Poverty-Unit Threshold); but\n",
    "rather than viewing that as a yes-no, the data set has a feature 'NYCgov_Pov_Gap' which is, for households in poverty, \n",
    "the difference between the two.\n",
    "\n",
    "So, let's run the models against 'NYCgov_Pov_Gap' to see where that gets us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "X_pg_ef = pd.read_csv('data/EngineeredFeatures.csv', index_col=[0,1], header=0) # Reuse existing; no change here\n",
    "X_pg = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_PovGap')\n",
    "\n",
    "X_pg = X_pg.join(X_pg_ef)\n",
    "\n",
    "X_pg.to_csv('data/PGFeatures.csv')\n",
    "\n",
    "X_pg, dummy_these = code_categoricals(X_pg, all_2016)\n",
    "X_pg.to_csv('data/PGFeaturesCoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_2</th>\n",
       "      <th>AGEP_3</th>\n",
       "      <th>AGEP_4</th>\n",
       "      <th>AGEP_5</th>\n",
       "      <th>AGEP_6</th>\n",
       "      <th>AGEP_7</th>\n",
       "      <th>AGEP_8</th>\n",
       "      <th>AGEP_9</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_anyage_TINP&lt;80</th>\n",
       "      <th>%_anyage_TINP&lt;80</th>\n",
       "      <th>any_anyage_TINP_any</th>\n",
       "      <th>all_anyage_TINP_any</th>\n",
       "      <th>min_anyage_TINP_any</th>\n",
       "      <th>max_anyage_TINP_any</th>\n",
       "      <th>count_anyage_TINP_any</th>\n",
       "      <th>sum_anyage_TINP_any</th>\n",
       "      <th>mean_anyage_TINP_any</th>\n",
       "      <th>%_anyage_TINP_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  5549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_2  AGEP_3  AGEP_4  AGEP_5  AGEP_6  AGEP_7  \\\n",
       "SERIALNO Povunit_ID                                                           \n",
       "39       1               51       0       0       0       0       0       0   \n",
       "55       1               60      52      26      20      20       0       0   \n",
       "69       1               39       0       0       0       0       0       0   \n",
       "210      1               26       0       0       0       0       0       0   \n",
       "261      1               36      36       6       5       1       0       0   \n",
       "\n",
       "                     AGEP_8  AGEP_9  AGEP_10        ...          \\\n",
       "SERIALNO Povunit_ID                                 ...           \n",
       "39       1                0       0        0        ...           \n",
       "55       1                0       0        0        ...           \n",
       "69       1                0       0        0        ...           \n",
       "210      1                0       0        0        ...           \n",
       "261      1                0       0        0        ...           \n",
       "\n",
       "                     mean_anyage_TINP<80  %_anyage_TINP<80  \\\n",
       "SERIALNO Povunit_ID                                          \n",
       "39       1                          51.0               1.0   \n",
       "55       1                          29.5               0.8   \n",
       "69       1                           0.0               0.0   \n",
       "210      1                           0.0               0.0   \n",
       "261      1                          12.0               0.8   \n",
       "\n",
       "                     any_anyage_TINP_any  all_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          True                 True   \n",
       "55       1                          True                 True   \n",
       "69       1                          True                 True   \n",
       "210      1                          True                 True   \n",
       "261      1                          True                 True   \n",
       "\n",
       "                     min_anyage_TINP_any  max_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          51.0                 51.0   \n",
       "55       1                          20.0                 60.0   \n",
       "69       1                          39.0                 39.0   \n",
       "210      1                          26.0                 26.0   \n",
       "261      1                           1.0                 36.0   \n",
       "\n",
       "                     count_anyage_TINP_any  sum_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                               \n",
       "39       1                               1                 51.0   \n",
       "55       1                               5                178.0   \n",
       "69       1                               1                 39.0   \n",
       "210      1                               1                 26.0   \n",
       "261      1                               5                 84.0   \n",
       "\n",
       "                     mean_anyage_TINP_any  %_anyage_TINP_any  \n",
       "SERIALNO Povunit_ID                                           \n",
       "39       1                           51.0                1.0  \n",
       "55       1                           35.6                1.0  \n",
       "69       1                           39.0                1.0  \n",
       "210      1                           26.0                1.0  \n",
       "261      1                           16.8                1.0  \n",
       "\n",
       "[5 rows x 5549 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pg = pd.read_csv('data/PGFeaturesCoded.csv', index_col=[0,1], header=0) # Reuse existing; no change here\n",
    "X_pg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.04s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 435.60s to fit \n",
      "{'test score': 0.7637718358117817, 'feature_importances_': array([2.65924486e-04, 3.53370510e-04, 2.74746009e-04, ...,\n",
      "       3.13643695e-05, 2.95436761e-06, 1.88089018e-05]), 'transformed_columns_': Index(['AGEP_1', 'AGEP_2', 'AGEP_3', 'AGEP_4', 'AGEP_5', 'AGEP_6', 'AGEP_7',\n",
      "       'AGEP_8', 'AGEP_9', 'AGEP_10',\n",
      "       ...\n",
      "       'mean_anyage_TINP<80', '%_anyage_TINP<80', 'any_anyage_TINP_any',\n",
      "       'all_anyage_TINP_any', 'min_anyage_TINP_any', 'max_anyage_TINP_any',\n",
      "       'count_anyage_TINP_any', 'sum_anyage_TINP_any', 'mean_anyage_TINP_any',\n",
      "       '%_anyage_TINP_any'],\n",
      "      dtype='object', length=5548), 'training score': 0.9532494932642507}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg.iloc[:50, :].copy()\n",
    "X_small = X_pg.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_PovGap']\n",
    "X = X_small.drop('NYCgov_PovGap', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5412542900219832, 'count_adult_SSIP0'),\n",
       " (0.044764803688412166, 'MRNT'),\n",
       " (0.03575995019220828, '%_anyage_TINP<15'),\n",
       " (0.026273516905920235, 'count_adult_PA0'),\n",
       " (0.024040902798597847, 'HousingStatus'),\n",
       " (0.022162946243779853, 'count_adult_TINP<15'),\n",
       " (0.011547900963612707, 'sum_anyage_TINP0'),\n",
       " (0.011313230636374887, 'any_anyage_TINP<15'),\n",
       " (0.004726736757495178, 'count_adult_TINP0'),\n",
       " (0.004470881799395084, 'count_anyage_SSIP0'),\n",
       " (0.003804604176778878, 'TEN'),\n",
       " (0.0036939593046493293, 'count_kid_not_DIS'),\n",
       " (0.003354132355255112, 'Boro_2'),\n",
       " (0.0029390726833299747, 'max_anyage_TINP0'),\n",
       " (0.002557372194562785, 'RNTP_adj')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGEP_1</th>\n",
       "      <th>AGEP_2</th>\n",
       "      <th>AGEP_3</th>\n",
       "      <th>AGEP_4</th>\n",
       "      <th>AGEP_5</th>\n",
       "      <th>AGEP_6</th>\n",
       "      <th>AGEP_7</th>\n",
       "      <th>AGEP_8</th>\n",
       "      <th>AGEP_9</th>\n",
       "      <th>AGEP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_anyage_TINP&lt;80</th>\n",
       "      <th>%_anyage_TINP&lt;80</th>\n",
       "      <th>any_anyage_TINP_any</th>\n",
       "      <th>all_anyage_TINP_any</th>\n",
       "      <th>min_anyage_TINP_any</th>\n",
       "      <th>max_anyage_TINP_any</th>\n",
       "      <th>count_anyage_TINP_any</th>\n",
       "      <th>sum_anyage_TINP_any</th>\n",
       "      <th>mean_anyage_TINP_any</th>\n",
       "      <th>%_anyage_TINP_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>Povunit_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  5549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGEP_1  AGEP_2  AGEP_3  AGEP_4  AGEP_5  AGEP_6  AGEP_7  \\\n",
       "SERIALNO Povunit_ID                                                           \n",
       "39       1               51       0       0       0       0       0       0   \n",
       "55       1               60      52      26      20      20       0       0   \n",
       "69       1               39       0       0       0       0       0       0   \n",
       "210      1               26       0       0       0       0       0       0   \n",
       "261      1               36      36       6       5       1       0       0   \n",
       "\n",
       "                     AGEP_8  AGEP_9  AGEP_10        ...          \\\n",
       "SERIALNO Povunit_ID                                 ...           \n",
       "39       1                0       0        0        ...           \n",
       "55       1                0       0        0        ...           \n",
       "69       1                0       0        0        ...           \n",
       "210      1                0       0        0        ...           \n",
       "261      1                0       0        0        ...           \n",
       "\n",
       "                     mean_anyage_TINP<80  %_anyage_TINP<80  \\\n",
       "SERIALNO Povunit_ID                                          \n",
       "39       1                          51.0               1.0   \n",
       "55       1                          29.5               0.8   \n",
       "69       1                           0.0               0.0   \n",
       "210      1                           0.0               0.0   \n",
       "261      1                          12.0               0.8   \n",
       "\n",
       "                     any_anyage_TINP_any  all_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          True                 True   \n",
       "55       1                          True                 True   \n",
       "69       1                          True                 True   \n",
       "210      1                          True                 True   \n",
       "261      1                          True                 True   \n",
       "\n",
       "                     min_anyage_TINP_any  max_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                             \n",
       "39       1                          51.0                 51.0   \n",
       "55       1                          20.0                 60.0   \n",
       "69       1                          39.0                 39.0   \n",
       "210      1                          26.0                 26.0   \n",
       "261      1                           1.0                 36.0   \n",
       "\n",
       "                     count_anyage_TINP_any  sum_anyage_TINP_any  \\\n",
       "SERIALNO Povunit_ID                                               \n",
       "39       1                               1                 51.0   \n",
       "55       1                               5                178.0   \n",
       "69       1                               1                 39.0   \n",
       "210      1                               1                 26.0   \n",
       "261      1                               5                 84.0   \n",
       "\n",
       "                     mean_anyage_TINP_any  %_anyage_TINP_any  \n",
       "SERIALNO Povunit_ID                                           \n",
       "39       1                           51.0                1.0  \n",
       "55       1                           35.6                1.0  \n",
       "69       1                           39.0                1.0  \n",
       "210      1                           26.0                1.0  \n",
       "261      1                           16.8                1.0  \n",
       "\n",
       "[5 rows x 5549 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Pov_Gap instead of NYCGov_Pov_Stat, with no Financials\n",
    "This is running the models against 'NYCgov_Pov_Gap', without financials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv with no financials\n",
    "X_pg_eng_no_fin = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_pg_no_fin = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_PovGap')\n",
    "\n",
    "X_pg_no_fin.join(X_pg_eng_no_fin)\n",
    "\n",
    "X_pg_no_fin.to_csv('data/PGFeaturesNoFin.csv')\n",
    "\n",
    "X_pg_no_fin, dummy_these = code_categoricals(X_pg_no_fin, all_2016)\n",
    "X_pg_no_fin.to_csv('data/PGFeaturesCodedNoFin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 2.55s to fit \n",
      "{'training score': 0.8864178444566567, 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5285), 'feature_importances_': array([0., 0., 0., ..., 0., 0., 0.]), 'test score': 0.20693738704979336}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "X_small = X_pg_no_fin.iloc[:50, :].copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_PovGap']\n",
    "X = X_small.drop('NYCgov_PovGap', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Income instead of NYCGov_Pov_Stat or NYCgov_Pov_Gap\n",
    "This is running the models against 'NYCgov_Income' - since the poverty calculation comes down to income vs threshold,\n",
    "and the initial poverty classifier shows the feature importance is primarily income-related, let's see what we can do to\n",
    "predict household income and find the relative importance of variables there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv \n",
    "X_pg_eng = pd.read_csv('data/EngineeredFeatures.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_pg_inc = pers_and_pu_features(all_2016, include_financials=True, target_column='NYCgov_Income')\n",
    "\n",
    "X_pg_inc = X_pg_inc.join(X_pg_eng)\n",
    "\n",
    "X_pg_inc.to_csv('data/PGFeaturesInc.csv')\n",
    "\n",
    "X_pg_inc, dummy_these = code_categoricals(X_pg_inc, all_2016)\n",
    "X_pg_inc.to_csv('data/PGFeaturesCodedInc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.18s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 3.35s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 296.30s to fit \n",
      "{'test score': 0.9729990614809677, 'feature_importances_': array([1.76265322e-02, 1.33508395e-03, 1.86835875e-04, ...,\n",
      "       7.67294103e-05, 9.75315989e-03, 0.00000000e+00]), 'transformed_columns_': Index(['WAGP_adj_1', 'WAGP_adj_2', 'WAGP_adj_3', 'WAGP_adj_4', 'WAGP_adj_5',\n",
      "       'WAGP_adj_6', 'WAGP_adj_7', 'WAGP_adj_8', 'WAGP_adj_9', 'WAGP_adj_10',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=10405), 'training score': 0.9904116648702307}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg_inc.iloc[:50, :].copy()\n",
    "X_small = X_pg_inc.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Income']\n",
    "X = X_small.drop('NYCgov_Income', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10587798972092581, 'any_anyage_SSP0'),\n",
       " (0.09244462976532644, 'min_adult_ETH_any'),\n",
       " (0.06807623458215825, 'all_adult_TINP<60'),\n",
       " (0.046101140457224174, 'mean_adult_SSIP_any'),\n",
       " (0.0459944407453176, 'min_adult_any_SEX'),\n",
       " (0.04577931790616139, 'min_adult_any_MSP'),\n",
       " (0.045658913558330134, 'mean_adult_INT_any'),\n",
       " (0.0455650902679534, 'mean_adult_any_MSP'),\n",
       " (0.04538766138869088, 'min_adult_SSP_any'),\n",
       " (0.04423539636490374, 'min_adult_PA_any'),\n",
       " (0.044052367770687724, 'min_adult_TINP_any'),\n",
       " (0.040786907341829416, 'all_anyage_TINP<50'),\n",
       " (0.029136605204614197, '%_adult_TINP<50'),\n",
       " (0.01762653216880664, 'WAGP_adj_1'),\n",
       " (0.016079479946236118, 'all_anyage_TINP<60')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NYCgov_Income instead of NYCGov_Pov_Stat or NYCgov_Pov_Gap - No Financials\n",
    "With the financials, we had everything we needed to actually calculate the NYCgov_Income.  So let's see how predictive\n",
    "we can get without the financials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "# Reuse existing csv \n",
    "X_eng_inc_no_fin = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "X_inc_no_fin = pers_and_pu_features(all_2016, include_financials=False, target_column='NYCgov_Income')\n",
    "\n",
    "X_inc_no_fin = X_inc_no_fin.join(X_eng_inc_no_fin)\n",
    "\n",
    "#X_pg_inc.to_csv('data/PGFeaturesInc.csv')\n",
    "\n",
    "X_inc_no_fin, dummy_these = code_categoricals(X_inc_no_fin, all_2016)\n",
    "#X_pg_inc.to_csv('data/PGFeaturesCodedInc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 624.82s to fit \n",
      "{'training score': 0.9266131362072498, 'feature_importances_': array([0.00450581, 0.00378747, 0.00159843, ..., 0.00644462, 0.17289086,\n",
      "       0.        ]), 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'count_18-64_age', 'sum_18-64_age',\n",
      "       'mean_18-64_age', '%_18-64_age', 'any_kid_age', 'all_kid_age',\n",
      "       'min_kid_age',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=7685), 'test score': 0.5113921081129593}\n"
     ]
    }
   ],
   "source": [
    "print(len(X_inc_no_fin.columns))\n",
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_pg_inc.iloc[:50, :].copy()\n",
    "X_small = X_inc_no_fin.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Income']\n",
    "X = X_small.drop('NYCgov_Income', axis='columns')\n",
    "\n",
    "# Get train and test - no stratifying here since we're doing regression, not classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "scaler = Normalizer()\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=100, max_features='auto', oob_score=True, random_state=42)\n",
    "#balanced_clf = BalancedRandomForestRegressor(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "#results_balanced_no_fin = {}\n",
    "\n",
    "#for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('scaler', scaler), \n",
    "                              ('reg', regressor)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "#results['training score'] = pipeline.named_steps['reg'].score(X_train, y_train)\n",
    "results['training score'] = pipeline.score(X_train, y_train)\n",
    "results['test score'] = pipeline.score(X_test, y_test)\n",
    "results['feature_importances_'] = pipeline.named_steps['reg'].feature_importances_\n",
    "results['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.17647828610194521, 'TotalWorkHrs_PU_4'),\n",
       " (0.05120298914905345, 'TEN_3'),\n",
       " (0.03737420027016401, 'all_adult_college'),\n",
       " (0.02621767443123551, 'sum_adult_college'),\n",
       " (0.023151071578155193, 'MSP_2_1.0'),\n",
       " (0.018641885619837577, 'sum_anyage_college'),\n",
       " (0.018538562622136528, 'Boro_2_3'),\n",
       " (0.012198687139389928, 'Boro_1_3'),\n",
       " (0.010936901048609376, 'any_18-64_>40WKW'),\n",
       " (0.008332179551431998, 'sum_anyage_sep/divorced'),\n",
       " (0.007195776195791315, 'Boro_3_3'),\n",
       " (0.005849933739184079, 'JWTR_1_7.0'),\n",
       " (0.005405100453006394, 'SCHL_1_23.0'),\n",
       " (0.0053595862132493005, 'AGEP_11_6'),\n",
       " (0.0049020987620536785, 'any_adult_>40WKW')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results['feature_importances_'], results['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - No Financials\n",
    "This will be as above, but pulling out the financial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pers complete\n",
      "df_pu complete\n"
     ]
    }
   ],
   "source": [
    "#X_no_fin_new_features = engineer_features(all_2016, include_financials=False)\n",
    "#X_no_fin_new_features.to_csv('data/EngineeredFeaturesNoFin.csv')\n",
    "#X_no_fin_new_features = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "#X_no_fin = pers_and_pu_features(all_2016, include_financials=False, target_column='NYCgov_Pov_Stat')\n",
    "\n",
    "#X_no_fin = X_no_fin.join(X_no_fin_new_features)\n",
    "\n",
    "#X_no_fin.to_csv('data/FeaturesNoFin.csv')\n",
    "#X_no_fin = pd.read_csv('data/FeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "\n",
    "#X_no_fin, dummy_these = code_categoricals(X_no_fin, all_2016)\n",
    "#X_no_fin.to_csv('data/FeaturesNoFinCoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_fin = pd.read_csv('data/FeaturesNoFinCoded.csv', index_col=[0,1], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 16.60s to fit \n",
      "{'balanced_accuracy_score': 0.6087474139946064, 'confusion_matrix': array([[4527,  172],\n",
      "       [ 910,  310]]), 'geometric_mean_score': 0.49477011127488796, 'feature_importances_': array([0.00374215, 0.01136674, 0.01506289, ..., 0.00948223, 0.00527128,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.83      0.96      0.25      0.89      0.49      0.26      4699\\n        Pov       0.64      0.25      0.96      0.36      0.49      0.23      1220\\n\\navg / total       0.79      0.82      0.40      0.78      0.49      0.26      5919\\n', 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'AGEP_1_1', 'AGEP_1_2', 'AGEP_1_3',\n",
      "       'AGEP_1_4', 'AGEP_1_5', 'AGEP_1_6', 'AGEP_1_7',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5105)}\n",
      "Took: 5.65s to fit \n",
      "{'balanced_accuracy_score': 0.7340716022592878, 'confusion_matrix': array([[3363, 1336],\n",
      "       [ 302,  918]]), 'geometric_mean_score': 0.7338412772834307, 'feature_importances_': array([0.00771805, 0.01047624, 0.0078005 , ..., 0.01705998, 0.03820723,\n",
      "       0.        ]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.92      0.72      0.75      0.80      0.73      0.54      4699\\n        Pov       0.41      0.75      0.72      0.53      0.73      0.54      1220\\n\\navg / total       0.81      0.72      0.74      0.75      0.73      0.54      5919\\n', 'transformed_columns_': Index(['MRGP_adj', 'RNTP_adj', 'MRNT', 'AGEP_1_1', 'AGEP_1_2', 'AGEP_1_3',\n",
      "       'AGEP_1_4', 'AGEP_1_5', 'AGEP_1_6', 'AGEP_1_7',\n",
      "       ...\n",
      "       'HousingStatus_5', 'HousingStatus_6', 'HousingStatus_7',\n",
      "       'HousingStatus_8', 'HousingStatus_9', 'TotalWorkHrs_PU_1',\n",
      "       'TotalWorkHrs_PU_2', 'TotalWorkHrs_PU_3', 'TotalWorkHrs_PU_4',\n",
      "       'TotalWorkHrs_PU_5'],\n",
      "      dtype='object', length=5105)}\n"
     ]
    }
   ],
   "source": [
    "# Take a small subset of the data to run POC\n",
    "#X_small = X_no_fin.iloc[:50, :].copy()\n",
    "X_small = X_no_fin.copy()\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_small['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_small.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "#samplers = [SMOTE(random_state=42), SMOTETomek(random_state=42), TomekLinks(random_state=42)]\n",
    "scaler = Normalizer()\n",
    "clf =                  RandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "balanced_clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=10, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp()\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results_plain_no_fin = {}\n",
    "results_balanced_no_fin = {}\n",
    "\n",
    "for classifier, results_dict in zip([clf, balanced_clf], [results_plain_no_fin, results_balanced_no_fin]):\n",
    "\n",
    "    pipeline = imbPipeline(steps=[('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                                  ('dummies', dummy_encoder), \n",
    "                                  #('sampler', sampler), \n",
    "                                  ('scaler', scaler), \n",
    "                                  ('clf', classifier)], \n",
    "                           memory=cachedir)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    time_to_fit = time.time() - t0\n",
    "    print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "    results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "    results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "    results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "    results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "    results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "    print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0333263835863417, 'WKW_1_6.0'),\n",
       " (0.019089687064374118, 'TEN_3'),\n",
       " (0.018658342125886018, 'TotalWorkHrs_PU_1'),\n",
       " (0.015062894956498082, 'MRNT'),\n",
       " (0.014952220424570705, 'TotalWorkHrs_PU_2'),\n",
       " (0.014058264808781803, 'DIS_1_2.0'),\n",
       " (0.011368339383472542, 'WKW_2_6.0'),\n",
       " (0.01136674338124465, 'RNTP_adj'),\n",
       " (0.01131130342588219, 'ENG_1_5.0'),\n",
       " (0.010803276411116742, 'CIT_1_1'),\n",
       " (0.01055147678313992, 'HousingStatus_6'),\n",
       " (0.010142020554241103, 'Ethnicity_1_1'),\n",
       " (0.009638502918302148, 'SEX_1_2'),\n",
       " (0.009620946071791698, 'JWTR_1_4.0'),\n",
       " (0.009482233140690393, 'TotalWorkHrs_PU_3')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_plain_no_fin['feature_importances_'], results_plain_no_fin['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03820723190748078, 'TotalWorkHrs_PU_4'),\n",
       " (0.030424103555162847, 'WKW_2_6.0'),\n",
       " (0.028615346415553754, 'WKHP_1_40'),\n",
       " (0.027021511173145822, 'WKW_1_6.0'),\n",
       " (0.022908203636657767, 'TotalWorkHrs_PU_2'),\n",
       " (0.021245426174740102, 'JWTR_1_4.0'),\n",
       " (0.018196157138579097, 'Ethnicity_2_1'),\n",
       " (0.017950247133279758, 'Ethnicity_1_1'),\n",
       " (0.01705998306092355, 'TotalWorkHrs_PU_3'),\n",
       " (0.016393462842024538, 'SCHL_1_22.0'),\n",
       " (0.015787585540996484, 'WKHP_2_40'),\n",
       " (0.014786053558510643, 'TEN_3'),\n",
       " (0.014167886506504471, 'SCHL_1_21.0'),\n",
       " (0.013906358546812292, 'ENG_1_5.0'),\n",
       " (0.01309187152147428, 'JWTR_2_4.0')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_balanced_no_fin['feature_importances_'], results_balanced_no_fin['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Financials, with SMOTEENN sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved it\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 29595 entries, (39, 1) to (1521415, 1)\n",
      "Columns: 5621 entries, AGEP_1 to %_anyage_TINP_any\n",
      "dtypes: bool(1297), float64(4178), int64(146)\n",
      "memory usage: 1013.2 MB\n"
     ]
    }
   ],
   "source": [
    "#tester_ef = pd.read_csv('data/EngineeredFeaturesNoFin.csv', index_col=[0,1], header=0)\n",
    "#tester_ef.head()\n",
    "#len(tester.columns) #249\n",
    "#len(tester_ef.columns) #2580\n",
    "#tester_joined = tester.join(tester_ef)\n",
    "#tester_joined.head() #2829 columns\n",
    "tester = pd.read_csv('data/Features.csv', index_col=[0,1], header=0)\n",
    "tester, dummies = code_categoricals(tester, all_2016)\n",
    "tester.to_csv('data/TestingCoding.csv')\n",
    "print('saved it')\n",
    "tester = pd.read_csv('data/TestingCoding.csv', index_col=[0,1], header=0)\n",
    "tester.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:200: UserWarning: Persisting input arguments took 4.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  cloned_transformer, Xt, yt, **fit_params_steps[name])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 903.82s to fit \n",
      "{'balanced_accuracy_score': 0.7483153897411029, 'confusion_matrix': array([[3701,  998],\n",
      "       [ 355,  865]]), 'geometric_mean_score': 0.7472827519843549, 'feature_importances_': array([0.00101219, 0.001638  , 0.00023066, ..., 0.00143429, 0.00032838,\n",
      "       0.00031573]), 'classification_report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n    Not Pov       0.91      0.79      0.71      0.85      0.75      0.56      4699\\n        Pov       0.46      0.71      0.79      0.56      0.75      0.55      1220\\n\\navg / total       0.82      0.77      0.73      0.79      0.75      0.56      5919\\n', 'transformed_columns_': Index(['AGEP_1', 'AGEP_2', 'AGEP_3', 'AGEP_4', 'AGEP_5', 'AGEP_6', 'AGEP_7',\n",
      "       'AGEP_8', 'AGEP_9', 'AGEP_10',\n",
      "       ...\n",
      "       'mean_anyage_ETH_other', '%_anyage_ETH_other', 'any_anyage_ETH_any',\n",
      "       'all_anyage_ETH_any', 'min_anyage_ETH_any', 'max_anyage_ETH_any',\n",
      "       'count_anyage_ETH_any', 'sum_anyage_ETH_any', 'mean_anyage_ETH_any',\n",
      "       '%_anyage_ETH_any'],\n",
      "      dtype='object', length=2828)}\n"
     ]
    }
   ],
   "source": [
    "X_and_y = pd.read_csv('data/FeaturesNoFinCoded.csv', index_col=[0,1], header=0)\n",
    "print(len(X_and_y.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({1: 'Pov', 2:'Not Pov'}, inplace=True)\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "categorizer = Categorizer(columns=dummy_these)\n",
    "dummy_encoder = DummyEncoder(drop_first=True)\n",
    "sampler = SMOTEENN(random_state=42)\n",
    "scaler = Normalizer()\n",
    "clf = BalancedRandomForestClassifier(n_jobs=-1, n_estimators=1000, max_features='auto', random_state=42)\n",
    "\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "# Create empty dictionaries to hold results\n",
    "results = {}\n",
    "\n",
    "pipeline = imbPipeline(steps=[#('cat', categorizer), # No need for Categorizer since we already did it\n",
    "                              ('dummies', dummy_encoder), \n",
    "                              ('sampler', sampler), \n",
    "                              ('scaler', scaler), \n",
    "                              ('clf', classifier)], \n",
    "                       memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "results_dict['balanced_accuracy_score'] = balanced_accuracy_score(y_test, predictions)\n",
    "results_dict['geometric_mean_score'] = geometric_mean_score(y_test, predictions)\n",
    "results_dict['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "results_dict['classification_report'] = classification_report_imbalanced(y_test, predictions)\n",
    "results_dict['feature_importances_'] = pipeline.named_steps['clf'].feature_importances_\n",
    "results_dict['transformed_columns_'] = pipeline.named_steps['dummies'].transformed_columns_\n",
    "print(str(results_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05414204498575277, 'max_adult_40_plus_work_hrs'),\n",
       " (0.0299772802107448, '%_18-64_<30_work_hrs'),\n",
       " (0.029120004226272207, '%_anyage_40_plus_work_hrs'),\n",
       " (0.02813508930255575, 'max_anyage_40_plus_work_hrs'),\n",
       " (0.02807103273303036, 'any_anyage_>40WKW'),\n",
       " (0.027730196434804382, 'min_anyage_40_plus_work_hrs'),\n",
       " (0.026378429827302253, 'min_adult_>40WKW'),\n",
       " (0.022687981522365352, 'mean_18-64_50-52WKW'),\n",
       " (0.022232016123656696, 'all_18-64_<15_work_hrs'),\n",
       " (0.014389072985389828, 'any_adult_>40WKW'),\n",
       " (0.01381564852426873, 'count_adult_50-52WKW'),\n",
       " (0.01178808204087493, 'all_anyage_<40_work_hrs'),\n",
       " (0.011526602791514214, 'max_18-64_no_diploma'),\n",
       " (0.008817078681850138, 'sum_anyage_>40WKW'),\n",
       " (0.008134514402889726, 'sum_anyage_no_diploma')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = list(zip(results_dict['feature_importances_'], results_dict['transformed_columns_']))\n",
    "sorted(tester, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 225.46s to fit \n",
      "\n",
      "Accuracy: 0.9241425916539956\n",
      "Balanced accuracy: 0.8790971396076599\n",
      "Geometric mean: 0.875750180666023\n",
      "Confusion matrix:\n",
      "[[4491  208]\n",
      " [ 241  979]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        1.0       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.83      0.92      0.88      0.77      5919\n",
      "\n",
      "OOB score: 0.9260010136847441\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "tester = X_and_y.copy()\n",
    "tester = tester.loc[:, tester.astype('float64').std() > .3] #4203 columns\n",
    "\n",
    "print(len(tester.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = tester['NYCgov_Pov_Stat']\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = tester.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "rf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)], memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(rf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('OOB score: ' + str(rf_pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(rf_pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/imblearn/pipeline.py:197: UserWarning: Persisting input arguments took 2.67s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 312.12s to fit \n",
      "\n",
      "Accuracy: 0.9241425916539956\n",
      "Balanced accuracy: 0.8794005700550169\n",
      "Geometric mean: 0.8760997784301491\n",
      "Confusion matrix:\n",
      "[[4490  209]\n",
      " [ 240  980]]\n",
      "\n",
      "Classification report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.95      0.96      0.80      0.95      0.88      0.78      4699\n",
      "        1.0       0.82      0.80      0.96      0.81      0.88      0.76      1220\n",
      "\n",
      "avg / total       0.92      0.92      0.83      0.92      0.88      0.77      5919\n",
      "\n",
      "OOB score: 0.9281128569015036\n",
      "n_estimators: 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_and_y.columns))\n",
    "\n",
    "# Pull off 'NYCgov_Pov_Stat' for our target variable\n",
    "y = X_and_y['NYCgov_Pov_Stat']\n",
    "y.replace({2:0}, inplace=True) # Original coding is 1 in pov, 2 not in pov\n",
    "X = X_and_y.drop('NYCgov_Pov_Stat', axis='columns')\n",
    "\n",
    "# Get train and test - be sure to stratify since this is imbalanced data (poverty ~20% of the set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = Normalizer()\n",
    "classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_features='auto', random_state=42, oob_score=True)\n",
    "cachedir = tempfile.mkdtemp(dir='/mnt/ssd/tmp')\n",
    "\n",
    "rf_pipeline = imbPipeline(steps=[('scaler', scaler), ('clf', classifier)], memory=cachedir)\n",
    "\n",
    "t0 = time.time()\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "time_to_fit = time.time() - t0\n",
    "print('Took: ' + '{:4.2f}'.format(time_to_fit) + 's to fit ')\n",
    "\n",
    "predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy: ' + str(rf_pipeline.score(X_test, y_test)))\n",
    "print('Balanced accuracy: ' + str(balanced_accuracy_score(y_test, predictions)))\n",
    "print('Geometric mean: ' + str(geometric_mean_score(y_test, predictions)))\n",
    "print('Confusion matrix:\\n' + str(confusion_matrix(y_test, predictions)))\n",
    "print('\\nClassification report:\\n' + str(classification_report_imbalanced(y_test, predictions)))\n",
    "print('OOB score: ' + str(rf_pipeline.named_steps['clf'].oob_score_))\n",
    "print('n_estimators: ' + str(rf_pipeline.named_steps['clf'].n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.008738746575772808, 'any_anyage_any_SEX'),\n",
       " (0.007793420790104585, 'all_anyage_TINP<20'),\n",
       " (0.007184138721496747, 'any_adult_TINP<20'),\n",
       " (0.006653662791125626, 'all_anyage_WAG<60'),\n",
       " (0.006535150897617367, 'any_anyage_ETH_any'),\n",
       " (0.006433470037326151, 'all_anyage_work_trans'),\n",
       " (0.006420108118935234, 'all_adult_TINP<20'),\n",
       " (0.00603712066356437, '%_anyage_SEMP_any'),\n",
       " (0.005989984744940004, 'any_anyage_TINP<70'),\n",
       " (0.0056792764598369684, '%_anyage_TINP<25'),\n",
       " (0.0054738810580131836, 'all_anyage_TINP<35'),\n",
       " (0.005471542245196101, '%_anyage_TINP<45'),\n",
       " (0.005455904001405748, 'any_anyage_TINP<40'),\n",
       " (0.0053834925472248125, '%_anyage_RETP_any'),\n",
       " (0.005367176152264387, 'any_anyage_any_DIS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_imps = list(zip(rf_pipeline.named_steps['clf'].feature_importances_, X_train.columns))\n",
    "sorted(rf_imps, key=lambda tup: tup[0], reverse=True)[:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
